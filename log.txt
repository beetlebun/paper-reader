{
    "name": "3-D Reconstruction in Canonical Co-Ordinate Space From Arbitrarily Oriented 2-D Images",
    "paragraphs": [
        "ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 1737 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images benjamin hou , bishesh khanal , amir alansary , steven mcdonagh , alice davidson , mary rutherford , jo v. hajnal , daniel rueckert , ben glocker , and bernhard kainz abstract —limited capture range , and the requirement to provide high quality initialization for optimization-based2-d/3-d image registration method , can signiﬁcantlydegrade the performance of 3-d image reconstruction andmotion compensation pipeline .",
        "challenging clinical imag-ing scenario , which contain signiﬁcant subject motion , such as fetal in-utero imaging , complicate the 3-d image andvolume reconstruction process .",
        "in this paper , we presenta learning-based image registration method capable ofpredicting 3-d rigid transformation of arbitrarily oriented2-d image slice , with respect to a learned canonical atlasco-ordinate system .",
        "only image slice intensity informa-tion be use to perform registration and canonical align-ment , no spatial transform initialization be require .",
        "to ﬁndimage transformation , we utilize a convolutional neuralnetwork architecture to learn the regression function capa-ble of map 2-d image slice to a 3-d canonical atlasspace .",
        "we extensively evaluate the effectiveness of ourapproach quantitatively on simulate magnetic resonanceimaging ( mri ) , fetal brain imagery with synthetic motionand far demonstrate qualitative result on real fetal mri data where our method be integrate into a full recon- struction and motion compensation pipeline .",
        "our learningbased registration achieve an average spatial predictionerror of 7 mm on simulate data and produce qualitativelyimproved reconstruction for heavily move fetus withgestational age of approximately 20 week .",
        "our modelprovides a general and computationally efﬁcient solution tothe 2-d/3-d registration initialization problem and be suitablefor real-time scenario .",
        "index terms —biomedical imaging , magnetic resonance imaging , machine learning , motion compensation , imagereconstruction , image registration .",
        "manuscript receive december 7 , 2017 ; revise january 19 , 2018 ; accept january 23 , 2018 .",
        "date of publication february 19 , 2018 ; dateof current version july 31 , 2018 .",
        "this work be support in part by the wellcome trust ieh award under grant 102431 , ifind , in part by erc under grant 319456 , in part by nvidia ( gpu donations ) , andin part by epsrc under grant ep/n024494/1 .",
        "( corresponding author : benjamin hou . )",
        "b. hou , a. alansary , s. mcdonagh , d. rueckert , b. glocker , and b. kainz be with the biomedical image analysis group , department ofcomputing , imperial college london , london sw7 2az , u.k. ( e-mail : bh1511 @ imperial.ac.uk ) .",
        "b. khanal be with the biomedical image analysis group , department of computing , imperial college london , london sw7 2az , u.k. , and alsowith the department of biomedical engineering , king ’ s college london , london wc2r 2ls , u.k. a. davidson , m. rutherford , and j. v. hajnal be with the department of biomedical engineering , king ’ s college london , london wc2r 2ls , u.k. color version of one or more of the ﬁgures in this paper be available online at http : //ieeexplore.ieee.org .",
        "digital object identiﬁer 10.1109/tmi.2018.2798801i .",
        "introduction reconstructing a 3d volume from misalign and motion corrupt 2d image be a challenging task .",
        "the process involve labor intensive pre-processing step , such as manual landmark matching , exhibit both inter and intra-observer variance .",
        "pre- processing be a necessary step to achieve acceptable input for intens ity-based pose optimization for a volume reconstruction process .",
        "optimization facilitatesalignment and combination of intensity data from multiple image source into a common co-ordinate system .",
        "image registration be also require for application such as atlas-based segmentation [ 1 ] , track [ 2 ] , image fusion from multiple modality [ 3 ] and clinical analysis of image visualize in an anatomical sta ndard co-ordinate system [ 4 ] .",
        "all of these application suffer from poor initialization of automatic registration method , which must be alleviate bymanual pre-processing .",
        "for the 2d/3d case , two distinct registration strategy can be categorize as volume-to- slice and slice-to-volume technique .",
        "the former be concern with align a volume to a give image , e.g.",
        ", align an intra-operative c-arm x-ray image to a pre-operative volumetric scan .",
        "in contrast , the latter be concern with align multiple misalign 2d slice into a unique co-ordinate system of a reference volume.a recent review of slice-to-volume registration technique be give in [ 5 ] .",
        "arbitrary subject motion can invalidate slice alignment assumption that be base on the scanner co-ordinate system , and manual intervention may be necessary .",
        "manual correction of slice-to-volume registration often become unfeasible in practice due to the magnitude of image data involve .",
        "manual volume-to-slice registration be often easy to achieve , sincemanual alignment of one or a few 3d volume to a single 2d slice or projection be less time consume than manual alignment of hundred of individual slice into a commonco-ordinate system .",
        "landmark-based technique can help to automate this process , but this approach be heavily depen- dent on detection accuracy and robustness of the calculated homography between location and the descriptive power of the use landmark encode .",
        "2d slice also do not provide therequired 3d information to establish robust landmark match- ing , therefore this technique can not be use on application such as motion compensation in f etal imaging .",
        "for slice-to- volume registration , method such as [ 6 ] – [ 12 ] be effective in this work be license under a creative commons attrib ution 3.0 license .",
        "for more information , see h ttp : //creativecommons.o rg/licenses/by/3.0/1738 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 case where a coarsely aligned initialization of the 3d volume be provide to initialize the reconstruction process .",
        "this initial 3d reference volume be use as a 2d/3d registration target to seed the iterative estimation of the slice orientation andintensity data combination .",
        "reasonably good initial coarse alignment of 2d image slice be critical to form the seed reference volume .",
        "traditional intensity-based slice-to-volume reconstruction method [ 8 ] , [ 10 ] involve solve the inverse problem of super- resolution from slice acquisition [ 13 ] , show in eq .",
        "1 : y i=dibisimix+ni ; i=1,2 , ... , n ( 1 ) yidenotes the ith low resolution image obtain during scan time , diis the down-sampling matrix , biis the blurring matrix , siis the slice selection matrix , miis a matrix of motion parameter , and xis the high resolution 3d volume with nias a noise vector .",
        "more commonly , di , biandsiare group together in a single matrix wi .",
        "obtaining the true high-resolution volume xi ill-posed , as it require inversion of the large , ill-deﬁned matrix wi .",
        "alternatively , various optimization method [ 8 ] , [ 10 ] , [ 11 ] have be apply to obtain a good approximation of the true volume x .",
        "these be typically two step iterative method , consist of slice-to-v olume registration ( svr ) and super resolution ( sr ) .",
        "in each iteration , each slice be register to a target volume , follow by super resolution reconstruction .",
        "the output volume be therefore use as a registration target for the next iteration .",
        "hence , a good initial alignment be crucial.if any slice can not be register , it be discard and not further utilize for reconstruction .",
        "the optimization method employ in this domain typi- cally do not guarantee a globally optimal registration solution from arbitrarily seed slice alignment .",
        "the function that map each 2d slice to its correct anatomical position in 3d space may be subject to local minimum and the requirement for small initial misalignment typically improve result quality .",
        "previouswork have attempt to make this optimization robust by intro- ducing appropriate objective function and outlier rejection strategy base on robust statistic [ 8 ] , [ 10 ] .",
        "despite theseefforts , good reconstruction quality still depend on have good initial alignment of adjacent and intersecting slice .",
        "the robustness of ( semi- ) automatic 2d/3d registration method be characterize by their capture range , which be the maximum transformation misalignment from which a methodcan recover good spatial alignment .",
        "when the data available be limited , as common for the 2d/3d case , this task become very challenging .",
        "we provide a solution for the 2d/3d capture range problem , which be applicable to many medical image scenario and can be use with any registration method .",
        "we demonstrate thecapabilities of the method in the current work use in-utero fetal mri data as a working example .",
        "during gestation , high- quality and high-resolution stack of slice can be acquire through fast scan technique such as single shot fast spin echo ( ssfse ) [ 7 ] .",
        "slices can be obtain in a fractionof a second , thus freeze in-plane motion .",
        "random motion ( e.g.",
        ", a fetus that be awake and active during a scan ) or oscil- latory motion ( e.g.",
        ", maternal b reathing ) , be likely to causeadjacent slice to become incoherent and corrupt a 3d scan volume .",
        "state-of-the-art slice-to-volume registration method [ 10 ] – [ 12 ] be able to compensate for this motion and to reconstruct a consistent volume from overlap motion-corrupted orthogonal stack of 2d slice .",
        "these method tend to fail for volume with large initial misalignment between the 2d input slice .",
        "thus , svr work best for neonate andolder fetus who have less space to move .",
        "however , for early diagnostics , detailed anatomical reconstruction be require from an early age ( young than 25 week ) .",
        "a .",
        "related work 1 ) 2d/3d registration : image registration method that can compensate for large initial alignment offset usually requirerobust automatic or manual anatomical landmark detec- tion [ 14 ] – [ 16 ] with subsequent 3d location matching .",
        "this often rely on the use of ﬁducial marker [ 16 ] – [ 19 ] involve special equipment and/or invasive procedure .",
        "manual anno- tation of landmark by a domain expert be the current clinicalpractice to initialize automatic image registration [ 16 ] .",
        "fully automatic method be difﬁcult to integrate into the clinical workﬂow because of their limited reliability , complex nature , long computation time , susceptibility to error and lack of generalization .",
        "miao et al .",
        "[ 2 ] use convolutional neural networks ( cnns ) to automatically estimate the spatial arrangement of land- mark in projection image .",
        "their method utilize a cnnto regress transformation residual , δt , which reﬁnes the required transformation to register a source volume to a target x-ray image from an initially assume position t n=tini .",
        "registration be then perform iteratively use synthetic dig- itally reconstructed radiography ( drr ) image generate from the source volume use tn+1=tn+δt .",
        "to address inaccurate transformation ma ppings cause by direct regres- sion of transformation parameter , miao et al .",
        "train their cnn use pose-index feature ( landmark ) extract from source and target image pair and learn their δt .",
        "pose-index feature be insensitive to transform parameter tyet sensitive to change in δt .",
        "this insensitivity to tcan be express as x ( t1 , it1+δt ) ≈x ( t2 , it2+δt ) ∀ ( t1 , t2 ) .",
        "the method require a robust landmark detection algorithm , which be domain and scanner speciﬁc and the detection quality degrades for motion- corrupt data .",
        "similarly , simonovsky et al .",
        "[ 20 ] use cnns to perform 2d to 3d registration between a target 2d slice and a source 3d reference volume .",
        "instead of regress on transformationresiduals , the author regress to a scalar that estimate the dissimilarity between two image patch , and leverage the error from back-propagation to update the transformation para-meters .",
        "to this end , all operation can be efﬁciently compute on a gpu for high throughput .",
        "peiet al .",
        "[ 21 ] train cnns to regress the transformation parameter for 2d to 3d registration .",
        "their regression be perform directly on image slice without feature extrac-tion .",
        "the input to the network be pair of target 2d x-ray image with synthetic drr sour ce image that be generate from a cone-beam computed tomography ( cbct ) volume.hou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1739 each image pair be augmente d with vary level of anisotropic diffusion .",
        "iterative update of the cnn yield new transformation parameter to g enerate new drr image until similarly to the target x-ray converges .",
        "2 ) motion compensation : fetal brain mri be a ﬁeld requir- ing motion compensation to gain diagnostically useful 3d volume .",
        "most algorithms use general 2d to 3d registrationmethods via gradient descent optimization over an intensity base cost function , in conjunction with a super resolution step to recreate the output volume .",
        "the early framework for fetal mri reconstruction be develop by rousseau et al .",
        "[ 6 ] .",
        "it introduce step for motion correction and 3d volume reconstruction via scattered data interpolation ( sdi ) .",
        "for slice registration , rousseau use a gradient ascent method to maximize the normalized mutualinformation ( nmi ) .",
        "this be improve by jiang et al .",
        "[ 7 ] who propose to use cross correlation ( cc ) as the cost function to optimize .",
        "jiang also propose to over-sample the region of interest ( roi ) with thin slice to ensure sufﬁcient sampling .",
        "gholipour et al .",
        "[ 8 ] integrate the mathematical model of super resolution in eq .",
        "1 into the slice-to-volume reconstruction pipeline and introduce outlier rejection .",
        "this be far improve by kuklisova-murgasova et al .",
        "[ 10 ] add intensity matching and bias correction , as well as an em-based model for outlier detection .",
        "the 2d/3d registration method , by [ 2 ] , [ 20 ] , and [ 21 ] , use cnns to compute the unknown transformation of a give 2d slice with respect to a reference 3d volume while [ 6 ] – [ 8 ] , [ 10 ] , [ 11 ] , [ 22 ] , [ 23 ] use general registration algorithm to register slice to an initial 3d target .",
        "in both case , a motion free reference/initial volume be require for successful 2d/3dregistration , which be not guarantee to be obtainable from a clinical scan due to unpredictable subject motion .",
        "kim et al .",
        "[ 9 ] propose to perform slice-to-volume regis- tration by minimize the energy of weighted mean square difference ( wmsd ) of all slice intersection intensity proﬁles.this method do not require an initial target registration volume nor intermediate 3d reconstruction .",
        "the author be able to “ recover motion up to 15 mm of translation and 30 ◦ of rotation for individual slice ” .",
        "our method also estimate slice motion without the need for volume reconstruction .",
        "however , we focus on tackle the problem of a reasonable initial slice alignment in 3d canonical space , which be not guarantee in real scan scenarios.this goal be relate to the natural image processing work of kendall et al .",
        "[ 24 ] who propose posenet , which regress 6-dof camera pose from single rgb image .",
        "posenet istrained from rgb image take n from a particular scene , e.g.",
        ", on an outdoor street or in a corridor .",
        "the cnn be then use to infer localiza tion within the learned 3d space .",
        "expanding on this idea , for a give 2d image slice , we would like to infer pose , relative to a 3d atlas space , without know any initial information besides the image intensity .",
        "hou et al .",
        "[ 25 ] demonstrate the potential of cnns for tackle the volume initialization problem for slice-to-volume3d image reconstruction .",
        "the network architecture in [ 25 ] show promising result , initialize scan slice for fetal brain in-utero volume reconstruction and for pose estimationof drr scan image .",
        "however , it do not provide mean for estimate incorrect prediction and outlier rejection .",
        "failing to account for grossly misalign slice , that constitute outlying sample , hinders reconstruction performance and may resultin volume reconstruction failure .",
        "we extend [ 25 ] by rigor- ous evaluation of several network architecture and introduce monte carlo dropout [ 26 ] for the purpose of establish aprediction conﬁdence metric .",
        "b .",
        "contributions in this paper , we introduce a learning base approach that automatically learn the slice transform model of arbitrarilysampled slice relative to a canonical co-ordinate system ( i.e.",
        ", our approach learn the mapping function that map each slice to a volumetric atlas ) .",
        "this be achieve use onlythe intensity information encode in the slice without rely on image transformation in scanner co-ordinate .",
        "our cnn predict 3d rigid transformation , which be element of a special euclidean group se ( 3 ) .",
        "predicting canonical orienta- tions for each slice in a collection of 3d stack cover a roiprovides an accurate initialization for subsequent automatic 3d reconstruction and registration reﬁnement use intensity- base optimization method .",
        "r ecent statistical analysis and metric [ 27 ] , speciﬁc to lie group , be incorporate to give a more accurate measure of the misalignment between a predicted slice and the corresponding ground truth .",
        "this be combine with traditional image similarity metric such as cross correlation and structural similarity .",
        "we report quantitative comparison , evaluate the predic- tive performance of several cnn architecture with real and synthetic 2d slice that be corrupt with extreme motion.synthetic slice , with know ground truth location , be extract from 3d mri fetal brain volume of approximately 20 week gestational age ( ga ) .",
        "we additionally evaluate the approach qualitatively on heavily motion corrupt fetal mri where ground truth slice transformation and/or 3d volumesare not available .",
        "by provide 2d slice that be canonically align to initialize a subsequent reconstruction step , we can qualitatively assess the improvement our method provide forthe volume reconstruction task .",
        "we implement monte carlo dropout sample during infer- ence to consider the model ’ s epistemic uncertainty , and pro- vide a prediction conﬁdence for each slice .",
        "this be use as a metric for outlier rejection ( i.e.",
        ", if the model be not conﬁdentabout a prediction , then it can be discard before subsequent use during 3d reconstruction ) .",
        "our approach can also be generalize to 3d-3d volumetric registration by predict the transformation parameter of a few select slice to be use as landmark marker .",
        "this be demonstrate in [ 25 ] by predict thorax phantom slice where no organ speciﬁc segmenta tion be perform .",
        "it be also applicable to projective 2d image , which be highly valuablefor x-ray/ct registration .",
        "ii .",
        "m ethod to fully evaluate and assess the performance of 2d/3d registration via a learning base approach , we incorporate it1740 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 fig .",
        "1 .",
        "pipeline to reconstruct volume from stack of heavily motion corrupt scan .",
        "n.b .",
        "this be only use for test case .",
        "( i ) n4 bias correction be perform directly on the raw scan volume ( ii ) [ 28 ] , [ 29 ] be use for approximate organ localiz ation to create segmentation mask for desired roi .",
        "( iii ) the bias correct volume be mask .",
        "( iv ) the volume be intensity rescale to 0 255 to match svrnet train parameter .",
        "( v ) each slice within the volume be crop and center position on a slice for svrnet inference .",
        "( vi ) each slice be infer through svrnet to obtain prediction of atlas space location .",
        "( vii ) optional : use predict transformation , with original or in ference slice , to initialize traditional svr algorithm ( s ) for further registration reﬁnement .",
        "into a full 3d reconstruction pipeline as show in fig .",
        "1 .t h i s feature three modular component : ( 1 ) approximate organ localization , ( 2 ) canonical slice orientation estimation , and ( 3 ) intensity-based 3d volume reconstruction .",
        "organ localiza- tion ( 1 ) be concern with localization of a learned roi .",
        "this can be achieve through rough manual segmentation , organ focus scan sequence or automatic method [ 30 ] – [ 32 ] .",
        "for 3d volume reconstruction ( 3 ) w eu s eam o d i ﬁ e d iterative svr method [ 11 ] , incorporate super-resolution image reconstruction technique [ 11 ] – [ 13 ] .",
        "this additionally allow for compensation of any remain small misalign- ments between single slice , cause d by prediction inaccuracy .",
        "to provide a sufﬁciently high number of sample for svr , multiple stack of 2d-slices be acquire , ideally in orthogonal orientation [ 33 ] .",
        "we modiﬁed [ 11 ] ; such that instead ofgenerating an initial reference volume from all slice orient in scanner co-ordinate , the acquire slice orientation be replace with predicted canonical atlas co-ordinate and the iterative intensity-based reconstruction process continue from that point .",
        "since ( 1 ) a n d ( 3 ) can be achieve use state-of- the-art technique , we focus in the remainder of this section on the canonical slice orientation estimation ( 2 ) , speciﬁcally the learning and prediction of 3d rigid transformation usinga variety of network architecture .",
        "at its core , our method use a cnn , call svrnet , to regress transformation parameter ˆt i , such that ˆti= ψ ( ω i , /theta1 ) ./theta1are the learned network parameter and ωiis a 2d image slice of size l×l , extract from a series of slice acquire from a 3d volume /omega1 .",
        "each /omega1encloses a desired roi , organ or particular use case scenario , such that ωi∈/omega1 .",
        "to train svrnet , slice of vary orientation and their cor- responding ground truth location be obtain from exist organ atlas or from collection of motion-free 3d volume , e.g.",
        ", pre-interventional scan or successfully ( partially manu- ally ) motion compensate subject .",
        "a .",
        "rigid body transformation parameterization the motion of a rigid body in 3d have six degrees of freedom ( 6 dof ) .",
        "one common p arameterization for this motion deﬁnes three parameter for translation ( tx , ty , tz ) and three for rotation ( rx , ry , rz ) .",
        "to model the movement of each slice in 3d space , we divide the parameter into two category ; in-plane transformation tx , tyandrzand out-of- plane transformation tz , rxand ry ( see fig .",
        "2 ( d-j ) ) .",
        "if each dof be allow ten interval delineation , this would result in10 6slices per organ volume .",
        "automatic segmentation method , such as [ 28 ] , [ 29 ] , and [ 34 ] , deﬁne the roi on a slice by slice basis throughout the3d volume .",
        "the desired roi ( e.g.",
        ", segment brain ) be mask and center align within ωi , which vastly decrease the valid range for in-plane motion parameter txandty .",
        "similar to [ 2 ] , we additionally reduce the number of slice require to createtraining and validation data set by simplify the sample space such that it be constrain by the parameter : t z , rx , ryand rz .",
        "we can far discount a portion of slice that yield little or no content at the extremity of the tzrange , in the consider volume .",
        "b .",
        "data pre-processing during scan-time , image int ensity range be inﬂuenced by roi structure and/or set by the radiologist base on visualappeal for diagnostic purpose .",
        "this cause each scanned volume to be bias differently with an intensity range that vary from scan to scan .",
        "pre-processing image intensity , via min-max normaliza- tion or z-score normalization , be typically a necessary stepwhen train cnns .",
        "the process help to keep image feature on a common scale and keep similar feature across different image consistent .",
        "z-score normalization scale all volume tozero mean with a standard deviation of one , and be a common pre-processing step for k-nearest neighbor base technique and cluster algorithm .",
        "alte rnatively , a quicker approxi- mation can be make by perform min-max normalization .",
        "intensity normalization of the pixel , as show in fig .",
        "1 , be perform after the roi be mask .",
        "for training and validation data set , we extract ω ifrom 3d motion correct and segment fetal brain volume that areregistered to a canonical atlas space .",
        "fig .",
        "2a and2bshows an example of slice , ω i , be extract from a brain volume /omega1 .",
        "svr [ 11 ] be perform on raw scan volume with a mask apply on fetal brain as the desired roi .",
        "these volume feature little fetal and maternal motion , and hence , recon-struction be successful .",
        "3d reconstruction be intensity rescale to 0-255 with an isotropic spacing of 0.75 ×0.75 ×0.75 mm , and far manually align to canonical atlas co-ordinate [ 4 ] .",
        "the resulting volume of size l×l×l enclose a brain atlas that be center-aligned .",
        "for inference on raw scan data , raw volume be n4 bias correct ﬁrst ( fig .",
        "1 ( i ) ) .",
        "this ensure that intensity in region affect by small magnetic ﬁeld inhomogeneity be correct .",
        "after roi localization ( fig .",
        "1 ( ii ) ) t h ev o l u m e be mask ( fig .",
        "1 ( iii ) ) and intensity normalize to 0-255 ( fig .",
        "1 ( iv ) ) .",
        "to predict the transformation parameter with svrnet , each slice in the 3d volume be individually scale back to isotropic space with the masked roi centerd within ω i ( fig .",
        "1 ( v ) ) .hou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1741 fig .",
        "2 .",
        "( a-b ) visualization of extract ωifromω .",
        "the identity plane lie ﬂat on the x-yaxis , which be then rotate through an euler angle iterator or a fibonacci point iterator and then shift up and down the normal tz ( represent by red arrow ) to account for out- of-plane transformation .",
        "orange curve arrows represent rotation rx , ryandrz .",
        "( c ) anchor point slice parameterization in 3d space .",
        "( d-j ) transformations in 6 dof .",
        "fig .",
        "3 .",
        "slice plane normal w.r.t the origin via different generation method .",
        "the vector from the origin to each point cross through each slice origin .",
        "note that it be not possible to visualize in plane rotation in thisvisualization c. generating training and validation data to create a comprehensive training and validation set , ωi must cover a large number of transformation permutation in/omega1 .",
        "we parameterize ωiand/omega1with the length l , s u c h that the dimension of a slice ωimatches the dimension of a face of the cubic volume /omega1.e v e r y /omega1encloses a brain atlas that be center-aligned ( i.e.",
        ", the origin be at the center of thebrain ) and which be isotropic and intensity normalize between 0 - 255 .",
        "this be show in fig .",
        "2a and2b .",
        "since the transformation parameter be constrain to vary only r x , ry , rzandtz , we rotate the sampling plane through each axis with multiple offset s , account for vary tz .",
        "the identity plane , which lie ﬂat on the x-yaxis , be initially rotate and then shift up and down along the normal in the new orientation tz ( represent by the red central axis infig .",
        "2 ( a-b ) ) .",
        "the ground truth transformation deﬁnes the transformation of the identity plane to its new and ﬁnal location in 3d space .",
        "a straightforward method be to iterate the rotation through euler angle , where r ( x , y , z ) and [ x , y , z ] ∈u ( −π/2 , π/2 ) .",
        "however , this do not give a balanced training slice dis-tribution as show in fig .",
        "3a .",
        "in this ﬁgure , each point represent the normal vector of the sample plane from the origin ( red arrow in fig .",
        "2a and 2b ) .",
        "another sample approach use polar co-ordinate , p ( φ , θ ) .",
        "uniform sampling of polar co-ordinate cause an i mbalance of sample , with a high density of sample near the pole ( fig .",
        "3b ) .",
        "a good compromise be to use fibonacci sphere sampling [ 35 ] , where each normal have roughly the same degree of separation as itsneighbors ( fig .",
        "3c ) .",
        "the sampling normal be calculate use p ( φ i , cos−1 ( zi ) ) , w h e r e φi=2πi//phi1andzi=1− ( 2i+1 ) /n , i∈0,1,2 , ... , n−1./phi1= ( √ 5+1 ) /2 be the golden ratio and as such /phi1−1=/phi1−1 .",
        "we evaluate the impact of these training data sample scheme in sect .",
        "iv .",
        "the rotation here be deﬁned by the rotation require to transform a 3d vector aonto a 3d vector b.w h e r e a be the start normal , a unit vector in z ( i.e.",
        ", ( 0,0,1 ) ) , and bis the target sample normal .",
        "however , this do not account for any in-plane rotation , rz .",
        "the transformed sampling plane be far rotate around the z-axis through a uniform distribution of angle , such that rz∈u ( 0 , π ) .",
        "for the validation set , slice ar e generate with the polar co- ordinate method use random normal and random in-plane rotation angle that be within the bound of the training set.this be to simulate continuous motion , as test slice will not lie on a discrete training sample interval , as show in fig .",
        "3d .",
        "we constrain the shift along the normal , t z , such that it enclose approximately the central 70 % of the volume and the range of tzis−0.35l≤tz≤0.35l .",
        "edge case be not beneﬁcial to the training set , they contain little or no content .",
        "an edge slice can be ambiguous , its precise location can not be determine without extra information even for atrained medical expert .",
        "ambiguous sample of this nature can introduce adverse effect when train a cnn .",
        "missing information from edge case slice can be recover with intersect orthogonal slice for eventual 3d reconstruction .",
        "d. loss functions and ground truth labels the most commonly used loss function for regression problem be euclidean norm [ 36 ] , [ 37 ] : /vextenddouble/vextenddoubleˆx−x/vextenddouble/vextenddouble n.h o w e v e r , they may not be suitable when the regression target variable lie on a manifold that be non-euclidean .",
        "for our propose method , the slice be be transform rigidly in 3d space , parameterization of each slic e therefore lie within the bound of the se ( 3 ) lie group .",
        "this include both ; a rotation as well as a translation component .",
        "there be numerous waysof represent this transformation , such as for rotation ; euler angle , quaternion , rotation matrix , etc .",
        "to address the aforementioned challenge , kendall et al .",
        "[ 24 ] propose the posenet loss as loss=/vextenddouble/vextenddoubleˆx−x/vextenddouble/vextenddouble 2+β/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆq−q /bardblq/bardbl/vextenddouble/vextenddouble/vextenddouble/vextenddouble 2 ( 2 ) which be use to regress the pose of a camera in 6 dof .",
        "xandqare the predicted cartesian translation and quaternion rotation parameter , whilst ˆxandˆqare the respective ground truth value .",
        "this loss function combine the euclidean dis- tance of translational loss with a weighted euclidean distance of the rotation loss .",
        "βis a tuning parameter that be use to determine the contribution between the loss , by normalize number with different scale .",
        "quaternions can represent a rotation by use four number between +1a n d −1 , however cartesian 3 dof co-ordinate span from −∞ and+∞.t h i s cause an imbalance for combined optimization and requiresmanual correction through β. xuet al .",
        "[ 38 ] have propose a framework base on sep- arating loss function that have an advantage of alleviating1742 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 over-ﬁtting .",
        "the fully connect layer of the network be split into several branch , wh ere each branch be terminate with a separate loss function .",
        "instead of manually tune the contribution of discrete component in a combined lossfunction , the network incorporate the tuning parameter within the connection weight .",
        "as a result , the network be able to learn from multiple representa tions of the ground truth label , for instance , euler-cartesia n parameter ( 3 for rotation and 3 for translation ) and quaterni on-cartesian parameter ( 4 for rotation and 3 for translation ) .",
        "we introduce a novel labelling system where the rota- tion and translation component of the label be combinedtogether .",
        "any three non co-linear point in a 3d euclidean space form a plane , while their order deﬁnes the orientation .",
        "we therefore call them anchor points ( see fig .",
        "2 ( a-c ) ) .",
        "three anchor points can be deﬁned anywhere on an l×l 2d slice ω i , as long as they be not identical or co-linear and the relative in-pane location be consistent throughout all slice in the data set .",
        "for simplicity , we deﬁned p1to be the bottom-left corner ( −l , −l,0 ) , p2to be the origin ( 0,0,0 ) and p3the bottom right corner ( l , −l,0 ) on the identity plane .",
        "fig .",
        "2 show anchor points be mark on multiple slice , and fig .",
        "2c show the anchor point on one particular slice .",
        "anchor points and the identity sample plane be both transform to their destine location use the same transform parameter set .",
        "consequently , anchor point label consist of 9 parameter : ( p1 ( x , y , z ) , p2 ( x , y , z ) and p3 ( x , y , z ) ) .",
        "as each point be cartesian , the optimization be balance and it can be calculate with the standard l2-norm loss function .",
        "incorporating the multi-loss framework [ 38 ] , the loss for p1 , p2and p3are calculate independently .",
        "the combined loss for svrnet can therefore be write as : loss=α/vextenddouble/vextenddouble/vextenddoubleˆp 1−p1/vextenddouble/vextenddouble/vextenddouble 2+β/vextenddouble/vextenddouble/vextenddoubleˆp 2−p2/vextenddouble/vextenddouble/vextenddouble 2+γ/vextenddouble/vextenddouble/vextenddoubleˆp 3−p3/vextenddouble/vextenddouble/vextenddouble 2 ( 3 ) e. network architecture and uncertainties towards make appropriate network architecture choice for svrnet , we explore several state-of-the-art network : caffenet [ 39 ] , googlenet [ 40 ] , inception [ 41 ] , nin [ 42 ] , resnet [ 43 ] and vggnet [ 44 ] .",
        "svrnet take ω ia input whilst compute the loss in eq .",
        "3 of various label meth- od .",
        "in sect .",
        "iv we evaluate each architecture on the regression performance of the previously propose anchor point label .",
        "a common strategy during the training of such large , state- of-the-art network involve the use of dropout [ 45 ] .",
        "this entail mute component of the true signal , provide to individual neuron .",
        "the technique essentially provide a formof model average .",
        "dropout c onstitutes a well-understood regularization technique to reduce over-ﬁtting .",
        "as a result of dropout , neuron have the ability to produce different output upon successive activation .",
        "during inference , dropout be usu- ally disable such that network consistency be not undermine .",
        "regression network be therefore commonly deterministic model at inference time and do not allow for the modelling of uncertainty .",
        "implementing fully probabilistic model thataccount for uncertainty in both ( 1 ) the data and ( 2 ) the model parameter ( aleatoric , e pistemic uncertainty respec- tively [ 46 ] ) may introduce high computational cost [ 47 ] .gal and ghahramani [ 26 ] recently show that dropout layer in neural networks can be interpret as a bayesian approximation to probabilistic model , and can be implement by apply a dropout before every weightlayer .",
        "this be show to be mathematically equivalent , as it approximately integrate over the model weight .",
        "gal and ghahramani [ 48 ] far show that , for the same input , perform multiple prediction during test time with dropout and take a mean of the prediction improve result for cnn base network .",
        "this process of perform multiple prediction from the same input by use dropout layer be call monte carlo dropout sampling , which also providesmodel uncertainty for the give input data .",
        "using this technique , our experimental work in section iv-e focus on take epistemic uncertainty into consideration inorder to gauge alignment prediction conﬁdence in real-world test case .",
        "slice alignment require high precision , and we investigate the idea that a measure of prediction conﬁdence be important to aid reconstruction quality .",
        "network prediction conﬁdence be also use as a metric to screen out corrupted slice , i.e.",
        ", region of the image with signal dropout or intensity bleeding from amniotic ﬂuid .",
        "our data predominately show ’ s signal dropout artefacts butnetwork prediction conﬁdence can be use to reject any kind of image corruption .",
        "an obscured image slice would result in a prediction with low conﬁdence .",
        "slices with low conﬁdence can be discard and not far use for subsequent 3d reconstruction .",
        "f. metrics on non-euclidean manifolds computing the mean prediction of the monte carlo dropout sample require an accurate method of average the network output , which , in our case , be a rigid transformation .",
        "rigidtransformations do not lie on the euclidean manifold , but constitutes of a smooth manifold where an intrinsic mean and correspond variance can be compute [ 49 ] .",
        "this be morecommonly regard as the special euclidean group se ( 3 ) .",
        "considering nrigid transformation predict by the net- work : { x i } ; i=1 , ... , n , we compute a riemannian center of mass that minimize geodesic distance between all point : m=argmin y∈me/bracketleftbig dist ( x , y ) 2/bracketrightbig ( 4 ) wheremis a riemannian manifold and dist ( x , y ) deﬁnes a geodesic distance between two point xand yon this manifold .",
        "a gauss-newton iterative algorithm on rigid trans-formations be use to compute such a mean , m , from the available data point x iby use a left-invariant metric [ 50 ] mt+1=mt◦expid/parenleftbigg1 n/sigma1logid/parenleftbig m−1 t◦xi/parenrightbig/parenrightbigg ( 5 ) where expidand logidare the exponential and logarith- mic mapping from identity as deﬁned by the left-invariant riemannian metric , and ◦is the group composition operator .",
        "once the mean be compute , the corresponding variance isstraightforward to compute as σ=e [ ( x−m ) 2 ] , w h e r et h e logarithmic operator deﬁnes x−mas logm ( x ) .",
        "[ 50 ] provide a detailed overview for these notion and algorithms.hou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1743 g. transformation recovery we transform the predicted anchor point position , euler- cartesian and quaternion-cart esian parameter to a rotation matrix and cartesian offset .",
        "we then transform the corre- sponding slice to its inferred location in 3d space .",
        "however , the network may introduce a prediction error , which will likely cause the anchor points to deviate from a perfect isoscelestriangle formation .",
        "to overcome this problem , we assume : •p2deﬁnes the cartesian offset of the slice , i.e.",
        ", the center point of the slice in world space .",
        "•the vector join point p1andp3aligns with the bot- tom edge of the slice ( this deﬁnes the in-plane rotation ) .",
        "•the anchor points together deﬁne the plane , which contain the slice .",
        "it be use to calculate the rotation matrix to reorient the slice ( see fig .",
        "2c ) .",
        "the cartesian offset , tequals p2 .",
        "for the orientation .",
        "we calculate three orthogonal vector that deﬁnes the new co-ordinate system .",
        "concaten ating these vector give the rotation matrix , which transform an identity plane to thenewly predict orientation .",
        "/vectorv 1=p3−p1and/vectorv2=p2−p1 ( represent by blue arrow in fig .",
        "2c ) ./vectorv1×/vectorv2gives the normal of the plane /vectorn1 , this deﬁnes the new z-axis .",
        "/vectorn1×/vectorv1 give the new y-axis /vectorn2 , a n d /vectorv1itself deﬁnes the new x-axis .",
        "finally , /vectorv2 , /vectorn2and/vectorn1are concatenate together to get the rotation matrix r. it be important to note that anchor points be unable to coincide with one another , by deﬁnition .",
        "each anchor point isregressed use an independent fully connect network layer and , as such , two ( or more ) anchor points may only coincide if their fully connect layer wei ghts would be identical .",
        "layer weight be randomly initialise and will deviate from each other during train due to the pre-deﬁned , non-identical , train sample target location .",
        "it be possible that two anchor points be predict in close proximity in rare error case .",
        "cases of this type be identiﬁed by check the constraintthat anchor points must adhere to a minimum distance from one another .",
        "h. slice to volume reconstruction we use a modiﬁed version of [ 11 ] to perform slice to v olume reconstruction on the individual ωi .",
        "instead of use a pre-existing volume as the initial registration target we create an initial registration target volume from all ωiand their corresponding predict ˆti .",
        "for validation case , ωithat be utilized for inference be also use for reconstruction .",
        "this allow us to verifywhether or not the original volume /omega1can be recover from ω iandˆti , s i n c e ωiwere extract from /omega1for the training and validation data set .",
        "in sect .",
        "iv we employ image qualitymetrics to assess the prediction performance by examine the original and reconstructed volume .",
        "for test case , intensity rescale ω ior original ωiare use for slice-to-volume reconstruction .",
        "the intensity rescale image be only require for svrnet prediction , during which , the top 1 % and bottom 1 % of the intensity distribution be also prune to ensure the distribution be not skew by outlier .",
        "quantizing from 16bit to 8bit reduces the signal to noisepower ratio ( snr ) from 96db to 48db .",
        "48db snr ( calculate by snr =20 log 10 ( 2 ( 16−8 ) ) =48.2db ) be still sufﬁcient for accurate identiﬁcation of impor tant image feature through svrnet .",
        "iii .",
        "i mplementation all network architecture be implement use the caffe [ 39 ] library on an intel i7 6700k cpu with nvidia titan x pascal gpu .",
        "all fetal subject data be provide by the ifind project [ 51 ] .",
        "scans be perform on a philipsachieva 1.5t at st thomas hospital , london , with the mother lie 20 ◦tilt on the left side to avoid pressure on the inferior vena cava or on her back depend on her comfort .",
        "for eachsubject , multiple single shot fast spin echo ( ssfse ) image be acquire with in-plane resolution of 1.25 ×1.25 mm and slice thickness of 2.50 mm .",
        "the gestational age of the fetus at the time of scan be between 21 to 27 week ( mean =24 , stdev =1 ) .",
        "all slice be of size 120 ×120 ( i.e.",
        ", l=120 ) .",
        "six separate data set be generate to cover combination of slice generation and label representation .",
        "three data set be generate via the euler angle iteration , with the remain three gener ated use the fibonacci sphere sampling method .",
        "of each slice generation method , there be a data set for euler-cartesian label s , quaternion-cartesian label and anchor point label .",
        "for the euler generation method , angle be iterate through 18 ◦intervals from −90◦to+90◦ , which give 10 sampling interval for each axis .",
        "40 slice be take in the tzaxis , such that −40≤tz≤+ 40 in 2 mm interval .",
        "this sample approximately the middle 66 % of the volume .",
        "in total , the euler iteration method generate 2.24m image for this training set .",
        "for the fibonacci sphere sampling method , 300 sampling normal be choose .",
        "this give approximately 8◦separation between every normal .",
        "an additional 10 image , between 0◦ and 180◦with 18◦interval , be generate at each normal to account for in-plane rotation .",
        "slices be also take between−40 and +40 in t zwith 4 mm interval .",
        "this generate in total 3.36m image for this training set .",
        "the validation slice be gener ated in similar fashion , except that they be sample at random interval within the bound of the training set to model random subject motion .",
        "we implement [ 27 ] in python for mean , variance and geodesic distance computation on se ( 3 ) group of rigid transformation .",
        "iv .",
        "e xperimentation and evaluation a .",
        "evaluation metrics a naïve progress check involve monitor training and validation loss to ensure that the network be generalize .",
        "to examine a slice in detail , we present the network with a 2d image slice ωi , as extract from /omega1 .",
        "using the parameter obtain from the network during inference , we extract a newslice from the same /omega1and compare it to slice ω i .",
        "comparison be perform via several standard image similarity metric , outline in this section.1744 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 we utilize standard image processing metric ; cross cor- relation ( cc ) , peak signal-to-noise ratio ( psnr ) , mean squared error ( mse ) and structural similarity ( ssim ) .",
        "as these metric do not deﬁnitively assess slice location in 3dspace , we include euclidean distan ce error ( average distance between the predicted and ground truth anchor points ) as well as geodesic distance error ( a unitless metric between twose ( 3 ) pose ) .",
        "cc measure the similarity between two series ( or image ) as a function of the displacement of one relative to the other .",
        "this search for feature that be similar in both image by examine the pixel intensity cc ( ˆf , ˆg ) = m−1/summationdisplay in−1/summationdisplay jˆf ( i , j ) ˆg ( i , j ) ( 6 ) where nis the number of pixel in the image , ˆf=f−¯f /radicalbig /summationtext ( f−¯f ) 2andˆg=g−¯g /radicalbig /summationtext ( g−¯g ) 2 ( 7 ) psnr ( base on the mse metric ) be a ratio between the maximum possible power of a signal and the power of corrupt noise that affect the ﬁdelity of its representation .",
        "this be the delta-error that be estimate by the network during regression and deﬁned as psnr =10·log10 ( max2 i mse ) ( 8 ) where max iis the maximum possible intensity ( pixel value ) of the image and mse ( f , g ) =1 mnm−1/summationdisplay in−1/summationdisplay j ( f ( i , j ) −g ( i , j ) ) 2 ( 9 ) ssim attempt to improve upon psnr and mse , and use a combination luminance , contrast and structure to assess the image quality .",
        "metrics such as mse can give a wide variety ofdegraded quality image with drastically different perceptual quality , which be an undesirable trait .",
        "it be deﬁned as ssim ( f , g ) = ( 2μ fμg+c1 ) ( 2σfg+c2 ) ( μ2 f+μ2g+c1 ) ( σ2 f+σ2g+c2 ) ( 10 ) where μfandμgare the average pixel intensity of image fand grespectively ; σ2 fandσ2 gare the variance of fand grespectively ; σfgis the co-variance of fand g ; c1= ( k1l ) 2and c2= ( k2l ) 2are two variable that stabi- lizes the division with weak de nominator ( i.e.",
        ", case where μ2 f+μ2 g→0o rσ2 f+σ2 g→0 ) ; lis the maximum possible intensity of the image ; with k1=0.01 and k2=0.03 be default constant .",
        "the average euclidean distance error , which be deﬁned as e.d.=1 3 ( /vextenddouble/vextenddouble/vextenddoubleˆp 1−p1/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoubleˆp 2−p2/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoubleˆp 3−p3/vextenddouble/vextenddouble/vextenddouble 2 ) ( 11 ) be the average euclidean distan ce of all three anchor points , and provide an error estimation in mm .",
        "the geodesic distance on the prediction manifold provide an intrinsic distance measure of how far the predicted rigidtransformation be from the ground truth transformation .",
        "if xis a ground truth rigid transformation and yis a predicted rigid transformation , a left-invariant geodesic distance with a metric at the tangent space of xcan be compute as [ 50 ] : g.d.=dist ( x , y ) =/vextenddouble/vextenddoublelogx ( y ) /vextenddouble/vextenddouble x ( 12 ) where log use the same notion as describe in sect .",
        "ii-e. b .",
        "network architecture performance the six network-bases , describe in sect .",
        "ii-e , be explore to examine if their arch itectures affect the regression accuracy for this task , and if so , which architecture givesthe best performance-to-training-time ratio .",
        "all network be train use caffe with the adam optimizer , max iteration of 200000 , batch size of 64 , learn rate of 0 .0001 , momentum of 0.9 , and a learning rate decay of 10 % every 20000 itera- tions .",
        "the exception be the resnet architecture that utilizeda low batch size of 32 , due to available gpu memory .",
        "each network be train with the data set generate by the euler angle iteration method with anchor point label .",
        "fig .",
        "4 show the training and testing loss during the training process , where each curve represent t he loss of each anchor point .",
        "table ii show the number of parameter within each network and the training time for 200000 iteration .",
        "we analyze the performance of each network use prede- ﬁned image similarity metric , as well as geodesic and euclid- ean distance between the predicted and ground truth location .",
        "by comparison to the ground truth , obvious incorrect slicepredictions be ﬁrst discard ( e.g.",
        ", a slice that be predict outside the volume ) .",
        "incorrect slice prediction be deﬁned as possess a geodesic distance that be more than threescaled median absolute deviations ( mad ) from the median .",
        "mad =k·median ( |x i−median ( x ) | ) ; i=1 , ... , n. table i show the average error of 1000 random validation slice that be select from each of the ﬁve test subject .",
        "it can be see that vggnet attain the small geodesicdistance error , as well as best correlation and mse .",
        "this be closely follow by googlenet , which manage to attain the small psnr , ssim and averag e euclidean distance error ( show the average prediction error of a single anchor point to the corresponding ground truth location ) .",
        "nin be the bad performing network with much great error .",
        "for efﬁciency , googlenet be the ideal choice , as it can attain almost just as good performance as vggnet in half the training time.if accuracy be of low importance , caffenet may also be use .",
        "resnet , inception and nin however take much long to train and perform bad compare to vggnet .",
        "fig .",
        "5 show some example of prediction make by the network .",
        "c. image normalization the image analysis literature have emphasize the impor- tance of intensity normalization in many domain and it be widely accept that appropriate normalization be often critical when employ learn base approach .",
        "in thissection we report on empirical exploration of the various alternative image normalization strategy consider .",
        "our ﬁrst experiment involve test the performance and the effect ofhou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1745 fig .",
        "4 .",
        "loss graph of training ( row 1 , 3 ) and validation ( row 2 , 4 ) of the six network architecture use for anchor point prediction .",
        "table i table showing the meanerror and standard deviation of eachevaluation metric table ii parameter count and training duration for different network architectures z-score normalization .",
        "slices ωiin this data set be generate via the euler iterator with anchor point label .",
        "before slice extraction from /omega1 , each brain volume be z-score normalize with a mask ( i.e.",
        ", background pixel be not include ) .",
        "thenetwork be train with the same parameter as deﬁned in sect .",
        "iii , run for a maximum of 280k iteration .",
        "fig .",
        "6a show the validation loss during training .",
        "the peri- odicity of the graph indicate over-ﬁtting as it cycle through each subject in the validation dat abase during training .",
        "the loss be also slightly high compare to googlenet train on the intensity rescale database as see in fig .",
        "4 .",
        "a second normalization experiment alternatively involved take each /omega1 ( use for ω igeneration ) match the intensity proﬁle to a fetal atlas [ 4 ] .",
        "the same procedure be also apply to validation volume .",
        "slices ωiin this data set be also fig .",
        "5 .",
        "top : validation slice that be present to the network .",
        "bottom : slices extract from the respective fetal volume use para- meter predict by the network .",
        "( a ) to ( f ) compare the ground truth slice with predicted slice in order of increase geodesic distance error .",
        "generate via the euler iterator with anchor point label .",
        "the network be train for 200k iteration and all other parameter be keep consistent with the previous experimental setup as deﬁned in sect .",
        "iii .",
        "fig .",
        "6b show the validation loss for this experiment .",
        "it can be see that the validation loss be low than that of the z-score normalization strategy , but high than that of intensity rescaling .",
        "a periodic nature can still be identiﬁed , suggest slight over-ﬁtting .",
        "a ﬁnal experiment explore how many different /omega1are need during training for good generalization .",
        "seven net- work be train with a batch size of 64 and increasing1746 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 fig .",
        "6 .",
        "validation loss on a network trained via euler angle seed and anchor point loss on ( a ) z-score normalize data and ( b ) histogram match data .",
        "fig .",
        "7 .",
        "validation loss on seven network train with vary data set size .",
        "left : avg .",
        "euclidean distance error , right : avg .",
        "geodesic distanceerror .",
        "table iii a verage errors for different fetal datasets iteration of 40k , 80k , 120k , 160k , 200k , 240k and 280k .",
        "this ensure that every network be train with 16 epoch , where epoch =iterations ×batch size / data set size .",
        "slices be generate from 4 , 8 , 12 , 16 , 20 , 24 and 28 fetal volume , where each volume yield 40k s lices via euler iterator .",
        "fig .",
        "7 show box plot of validation score of each trained network .",
        "the left chart show average euclidean distance error of each anchor point , where the right chart show geo- desic distance error ( see sect .",
        "ii-f ) .",
        "with 16 to 20 volume , the average euclidean distan ce error of each anchor point ( include the quartile ) be al ready under 10mm .",
        "this be within the capture range of recent robust svr algorithm discuss in sect .",
        "i-a .",
        "d. regression labels we additionally look to gain an understanding of how our data set affect performance accuracy as their construction differs , in particular , the different type of label parameter- ization .",
        "here we make use of the googlenet architecture due to the note favorable accuracy-speed trade-off that the network posse .",
        "all six data set adopt the multi-loss framework [ 38 ] , and use the same evaluation methodology asbefore .",
        "5k slice from the validation set ( 1k per fetal subject ) have be randomly select and pass through the network .",
        "table iii show the average error , for each data set.table iv t-testscores comparing euler -cartesian and quaternion -cartesian labels to anchor point labels table v psnr ofvolumes reconstructed from synthetic slices compared to ground truth validation volumes fig .",
        "8 .",
        "sequential scan slice from a sagittal image stack of a fetus with extreme motion , it can be observe that the fetus have rotate its head90◦ , cause slice # 14 to be a coronal view .",
        "( a ) # 12 .",
        "( b ) # 13 .",
        "( c ) # 14 .",
        "( d ) # 15 .",
        "( e ) # 16 .",
        "here in every metric , anchor point label be able to yield a great accuracy compare to euler-cartesian and quaternion-cartesian label in all test case .",
        "a two-tails independent t-test be conduct to examine the statisticalsigniﬁcance as show in tab .",
        "iv .",
        "as there be 5000 sample in each data set , the dof be rega rded as inﬁnity .",
        "the p-values for all test be therefore inﬁnitesimally small .",
        "e. 3d reconstruction we evaluate the propose pipeline for reconstruction of a 3d mri fetal brain in order to assess our ability to aid common downstream task , that consider accurate input dataalignment as a hard prerequisite .",
        "200 synthetically motion corrupt slice be extract from the validation set in order to initialize svr [ 11 ] .",
        "for all ﬁve fetal subject , we calculatethe psnr between the original and reconstruct 3d volume use ; gaussian average and svr reﬁnement , see table v .",
        "we further test svrnet on a case , which our clinical part- ners dismiss as impossible to reconstruct .",
        "both , extensive manual and automatic reconstruction attempt have fail for this case .",
        "with no ground truth to compare to , reconstruction quality can only be validate qualitatively .",
        "fig .",
        "10a , bandc show the raw scan stack , and the degree of motion corruption .",
        "in a case like this , excessive motion can cause ambiguity .",
        "fig .",
        "8 show a sequential sagittal stack of slice where the fetus have turn its head almost 90 ◦ , cause a coronal slice to behou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1747 fig .",
        "9 .",
        "slice prediction conﬁdence of four heavily motion corrupt orthogonally scanned stack of slice .",
        "in a scan stack that be assume sagittal .",
        "this unexpected slice do not ﬁt in the stack , and be normally reject by robust statistic implement in svr algorithm .",
        "rejecting too many slice will cause a lack of scan data , while accept too manyslices will cause a corrupt reconstruction volume as see in fig .",
        "10d .fig .",
        "10d show a svr-based reconstruction attempt , use [ 11 ] , without svrnet initialization .",
        "monte carlo dropout sampling be use for early outlier rejection .",
        "each slice be feed through the network 100 times.the ﬁnal prediction be obtain by compute the riemannian center of mass of all predicted transformation .",
        "as we have generate slice to train svrnet from the central portion ofthe fetal volume , network conﬁdence be low for boundary slice as show in fig .",
        "9 .fig .",
        "11 show example of “ good ” and “ bad ” slice with their corresponding prediction variance .",
        "the decision of whether or not to include a slice in sub- sequent reconstruction depend on the prediction conﬁdence and the robustness of the chosen reconstruction algorithm for ( 3 ) .",
        "prediction conﬁdence can be thresholded and if the reconstruction algorithm be very robust , like [ 11 ] , we canmake multiple prediction per slice and let the reconstruction algorithm handle far outlier rejection , which allow for a great margin of error ( see fig .",
        "10 ) .",
        "experimentally we ﬁnd , for the data set utilized in this study , a geodesic variance of approx .",
        "10 allows for the reli-able distinction between slice useful for subsequent volume reconstruction task ( conﬁdent ne twork prediction ) and those which may be discard ( less conﬁdent prediction ) .",
        "fig .",
        "11 ( e ) and ( f ) be slice that suffer from signal loss .",
        "fig .",
        "11 ( g ) and ( h ) be edge case slice where the image plane have only minimal intersectio n with the brain surface .",
        "such instance make for a high degree of ambiguity in true image plane location .",
        "such case also prove highly challenge forexperienced practitioner wit hout additional information .",
        "v. d iscussion in this paper , we show that a learning base approach ( svrnet ) be able to greatly increase the capture range for 2d/3d image registration , and can provide a robust initial-ization for scan with extreme inter-slice motion corruption .",
        "the accuracy of the network pr edictions be inﬂuenced by efﬁ- cient and novel parameterizatio n of label and loss function .",
        "in particular we explore the effect of utilize parameteri- zations that do not lie on a euclidean manifold .",
        "notably , euler- and quaternion-cartesian label attain similar level of performance yet , with a unique parameterization combine with the introduction of anchor points , we can further increasethe attainable accuracy .",
        "we evaluate six different architecture with ﬁxed hyper- parameter conﬁgurations , achieve satisfactory registrationaccuracy .",
        "we provide additional evidence towards typical cost- beneﬁt trade offs of hyperparameter tuning .",
        "for the regression of transformation parameter hyperparameter optimization can be extremely time consuming and computationally expensive , whilst provide little improvement in prediction accuracy .",
        "generating synthetic slice for training be very challenging due to the extensive search through a very large space ofparameters ( 6dof ) .",
        "we constrain the parameter space by leverage the effect of the in-plane transformation , base on the center-aligned content as a result of organ localization .",
        "svrnet need to be retrain for different organ , use case scenario or modality ( e.g.",
        ", mri ﬁeld strength , t1 , t2 , x-ray exposure , etc. )",
        ".",
        "this can be particularly problematic without organ atlas , or exist 3d reference volume .",
        "we have be able to obtain one addition raw 3t scan , and have find that our model , which be train on 1.5t image , be also able to successf ully predict transformation parameter for 3t image .",
        "however , further experimentation be necessary to validate the intra-modality robustness of svrnet .",
        "re-training/transfer learn for each new modality be advisedto achieve a maximum of prediction accuracy .",
        "svrnet require test image to be format in the same way as training , this include identical intensity range , spac-ing and translation offset removal when pre-processing 3d volume .",
        "our method be not restrict with respect to the use imaging modality and scenario , as see in [ 25 ] where the network be train on drr image as well as whole thorax phantom .",
        "this be valuable for 3d to 2d alignment as thewhole volume can be align to individual 2d slice .",
        "for the current implementation , svrnet focus on rigid transformation .",
        "for case where non-rigid deformation oforgans between slice be expect , patch to v olume ( pvr ) reconstruction [ 12 ] can be use as ﬁnal volume reconstruction step .",
        "for such case svrnet will still be able to predict the approximate location of individual 2d slice in canonical 3d space while pvr will handle non-rigid deformation .",
        "svrnet use euclidean distance as the primary loss func- tion to regress on anchor point label .",
        "it be also possible to use image metric , such as one shortlist in section iv-a , as a distance metric if the chosen metric be differentiable .",
        "however , metric like [ 52 ] be intend to be use primarily on natural and not medical image , which mean that use such approach could yield little performance gain .",
        "through experimentation , we ﬁnd that choice relate to slice generation method do not greatly affect prediction per- formance .",
        "in opposition to this , the p arameterization strategy represent regression ground truth label hold signiﬁcantinﬂuence over result quality , as show in table iii .w ee v e n - tually select the euler angle parameterization due to ease of use and the requirement of few training sample relative tothe consider alternative .",
        "for case with little motion , svrnet may be less effective due to the training data sample interval .",
        "for example , we iterate slice rotation in 18 ◦steps for the euler iterator seed , and 2mm step in tz .",
        "this step size can be intuitively interpret as the resolution of the network .",
        "if the motion corruption that be present be small than this interval then the prediction error may introduce a high slice offset than1748 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "8 , august 2018 fig .",
        "10 .",
        "reconstruction attempt of a fetal brain at approx .",
        "20 week ga , from heavily motion-corrupted stack of t2-weighted ssfse scan .",
        "it be not possible to reconstruct this scan with a signiﬁcant amount of manual ef fort by two of the most experienced data scientist in the ﬁeld use state-of-the-art method .",
        "( a ) , ( b ) and ( c ) be 3 example orthogonal input stack , with scan plane di rection in coronal , axial and sagittal respectively .",
        "the view direction be initialize to stack0 as show in ( a ) .s t a c k s ( b ) and ( c ) be not perfectly orthogonal , as they be take at different time point and the fetus have move .",
        "( d ) patch to volume registration ( pvr ) [ 12 ] with large patch , i.e.",
        ", improve svr , use the input stack directly .",
        "( e ) gaussian average of all slice that be predict and realign to atlas space by svrnet .",
        "( f ) reconstructed volume after 4 iteration of slice to volume registration ( svr ) , initialize with slice predict by svrnet .",
        "the arrow point to an area where insufﬁcient data have be acquire .",
        "the fetus move in scan direction , thus slice be miss in this area necessary for an accurate reconstruction .",
        "( g ) training atlas representation of the slice in ( e ) - ( f ) .",
        "note that ( d ) be reconstruct in patient space whereas ( e ) and ( f ) be reconstruct in atlas space .",
        "fig .",
        "11 .",
        "monte carlo prediction of a unitless geodesic distance variance metric for each slice .",
        "a h igher number represent great variance ( i.e.",
        ", the network be less conﬁdent ) .",
        "( a ) - ( d ) represent conﬁdent prediction .",
        "( e ) - ( h ) represent less conﬁdent prediction which be dis- card for subsequent volume reconstruction .",
        "originally present in the scan .",
        "the purpose of svrnet be not to compete against traditional svr method .",
        "it be use for the many case where raw scan volume be corrupt with motion offset that be large than those correctable with traditional svr method , where a signiﬁcant amount of manual intervention would be require .",
        "as a desirable side-effect , svrnet predict slice orientation in canonical atlas co-ordinate , which be not the case for svr method .",
        "another issue , difﬁcult even for human expert , be determin- ing left-right asymmetry of a give slice without additional information .",
        "to tackle this issue , oversampling and capture lot of slice during scan time can allow a great margin formis-predicted slice .",
        "robust statistics [ 11 ] be able to reject slice predict in the wrong hemisphere .",
        "the propose method can also be formulate as a classi- ﬁcation task , where each rigid transformation can be quan- tized as a class .",
        "quantizing the permutation use in ourexperiments would result in 40 kto 50 kclasses .",
        "with only 28 fetal example per class , this will lead to a high class- imbalance introduce new difﬁ culties in training .",
        "reducingthe number of class , however , will decrease the prediction resolution .",
        "vi .",
        "c onclusion svrnet be able to predict slice transformation relative to a canonical atlas co-ordinate system , use only the intensity information in the image .",
        "this allow motion compensation for highly motion corrupt scan , e.g.",
        ", mri scan of veryyoung fetus .",
        "it allow the incorporation of any image that have be acquire during examination , thus relax the requirement for temporal scan-plane proximity .",
        "we have evaluate a wide range of state-of-the-art and popular network architecture to examine their performance on prediction accuracy .",
        "we find that vggnet , in our experiment , attain the small regression error .",
        "however , googlenet be more efﬁcient to train for repeat experiments.it can achieve similar result to vggnet with half the training time , whilst occupy 85 % less memory space .",
        "our work leverage the computational framework to do statistic on se ( 3 ) lie group , perform bayesian inference and monte carlo dropout sample on the rigid transforma- tion prediction of the network .",
        "this approach can also bebeneﬁcial in other application such as [ 24 ] , where cnns be train to produce output transformation that be not in euclidean space .",
        "we have show that by calculate geodesic distance of rigid 3d transformation on a non-euclidean man- ifold provide mean to assess the predicted transformationparameters more accurately .",
        "this pave the way to propagate uncertainty downstream in a pipeline that use the network output to perform other tasks.hou et al .",
        ": 3-d reconstruction in canonical co-ordinate space from arbitrarily oriented 2-d images 1749 acknowledgements the author would like to thank the volunteer , the radiog- raphers j. allsop and m. fox , mitk [ 53 ] , irtk ( cc publiclicense from ixico ltd. ) , the nihr biomedical research center at gstt .",
        "they would also like to thank nina miolane for fruitful discussion .",
        "data access only in line with the informed consent of the participant , subject to approval by the project ethic board and under a formal data sharingagreement ."
    ],
    "processed_text": "ieee transactions medical imaging vol 37 8 august 2018 1737 3d reconstruction canonical coordinate space arbitrarily oriented 2d images benjamin hou bishesh khanal amir alansary steven mcdonagh alice davidson mary rutherford jo v hajnal daniel rueckert ben glocker bernhard kainz abstract limited capture range requirement provide high quality initialization optimizationbased2d/3d image registration method significantlydegrade performance 3d image reconstruction andmotion compensation pipeline challenging clinical imaging scenario contain significant subject motion fetal inutero imaging complicate 3d image andvolume reconstruction process paper presenta learningbased image registration method capable ofpredicting 3d rigid transformation arbitrarily oriented2d image slice respect learned canonical atlascoordinate system image slice intensity information use perform registration canonical alignment spatial transform initialization require findimage transformation utilize convolutional neuralnetwork architecture learn regression function capable map 2d image slice 3d canonical atlasspace extensively evaluate effectiveness ourapproach quantitatively simulate magnetic resonanceimaging mri fetal brain imagery synthetic motionand far demonstrate qualitative result real fetal mri data method integrate full recon struction motion compensation pipeline learningbased registration achieve average spatial predictionerror 7 mm simulate data produce qualitativelyimproved reconstruction heavily move fetus withgestational age approximately 20 week modelprovides general computationally efficient solution tothe 2d/3d registration initialization problem suitablefor realtime scenario index terms biomedical imaging magnetic resonance imaging machine learning motion compensation imagereconstruction image registration manuscript receive december 7 2017 revise january 19 2018 accept january 23 2018 date publication february 19 2018 dateof current version july 31 2018 work support part wellcome trust ieh award grant 102431 ifind part erc grant 319456 part nvidia gpu donations andin part epsrc grant ep/n024494/1 corresponding author benjamin hou b hou alansary mcdonagh rueckert b glocker b kainz biomedical image analysis group department ofcomputing imperial college london london sw7 2az uk email bh1511 @ imperialacuk b khanal biomedical image analysis group department computing imperial college london london sw7 2az uk alsowith department biomedical engineering king college london london wc2r 2ls uk davidson rutherford j v hajnal department biomedical engineering king college london london wc2r 2ls uk color version one figures paper available online http //ieeexploreieeeorg digital object identifier 101109/tmi20182798801i introduction reconstructing 3d volume misalign motion corrupt 2d image challenging task process involve labor intensive preprocessing step manual landmark matching exhibit inter intraobserver variance pre processing necessary step achieve acceptable input intens itybased pose optimization volume reconstruction process optimization facilitatesalignment combination intensity data multiple image source common coordinate system image registration also require application atlasbased segmentation 1 track 2 image fusion multiple modality 3 clinical analysis image visualize anatomical sta ndard coordinate system 4 application suffer poor initialization automatic registration method must alleviate bymanual preprocessing 2d/3d case two distinct registration strategy categorize volumeto slice slicetovolume technique former concern align volume give image eg align intraoperative carm xray image preoperative volumetric scan contrast latter concern align multiple misalign 2d slice unique coordinate system reference volumea recent review slicetovolume registration technique give 5 arbitrary subject motion invalidate slice alignment assumption base scanner coordinate system manual intervention may necessary manual correction slicetovolume registration often become unfeasible practice due magnitude image data involve manual volumetoslice registration often easy achieve sincemanual alignment one 3d volume single 2d slice projection less time consume manual alignment hundred individual slice commoncoordinate system landmarkbased technique help automate process approach heavily depen dent detection accuracy robustness calculated homography location descriptive power use landmark encode 2d slice also provide therequired 3d information establish robust landmark match ing therefore technique use application motion compensation f etal imaging sliceto volume registration method 6 12 effective work license creative commons attrib ution 30 license information see h ttp //creativecommonso rg/licenses/by/30/1738 ieee transactions medical imaging vol 37 8 august 2018 case coarsely aligned initialization 3d volume provide initialize reconstruction process initial 3d reference volume use 2d/3d registration target seed iterative estimation slice orientation andintensity data combination reasonably good initial coarse alignment 2d image slice critical form seed reference volume traditional intensitybased slicetovolume reconstruction method 8 10 involve solve inverse problem super resolution slice acquisition 13 show eq 1 i=dibisimix+ni i=12 n 1 yidenotes ith low resolution image obtain scan time diis downsampling matrix biis blurring matrix siis slice selection matrix miis matrix motion parameter xis high resolution 3d volume nias noise vector commonly di biandsiare group together single matrix wi obtaining true highresolution volume xi illposed require inversion large illdefined matrix wi alternatively various optimization method 8 10 11 apply obtain good approximation true volume x typically two step iterative method consist slicetov olume registration svr super resolution sr iteration slice register target volume follow super resolution reconstruction output volume therefore use registration target next iteration hence good initial alignment crucialif slice register discard utilize reconstruction optimization method employ domain typi cally guarantee globally optimal registration solution arbitrarily seed slice alignment function map 2d slice correct anatomical position 3d space may subject local minimum requirement small initial misalignment typically improve result quality previouswork attempt make optimization robust intro ducing appropriate objective function outlier rejection strategy base robust statistic 8 10 despite theseefforts good reconstruction quality still depend good initial alignment adjacent intersecting slice robustness semi automatic 2d/3d registration method characterize capture range maximum transformation misalignment methodcan recover good spatial alignment data available limited common 2d/3d case task become challenging provide solution 2d/3d capture range problem applicable many medical image scenario use registration method demonstrate thecapabilities method current work use inutero fetal mri data working example gestation high quality highresolution stack slice acquire fast scan technique single shot fast spin echo ssfse 7 slices obtain fractionof second thus freeze inplane motion random motion eg fetus awake active scan oscil latory motion eg maternal b reathing likely causeadjacent slice become incoherent corrupt 3d scan volume stateoftheart slicetovolume registration method 10 12 able compensate motion reconstruct consistent volume overlap motioncorrupted orthogonal stack 2d slice method tend fail volume large initial misalignment 2d input slice thus svr work best neonate andolder fetus less space move however early diagnostics detailed anatomical reconstruction require early age young 25 week related work 1 2d/3d registration image registration method compensate large initial alignment offset usually requirerobust automatic manual anatomical landmark detec tion 14 16 subsequent 3d location matching often rely use fiducial marker 16 19 involve special equipment and/or invasive procedure manual anno tation landmark domain expert current clinicalpractice initialize automatic image registration 16 fully automatic method difficult integrate clinical workflow limited reliability complex nature long computation time susceptibility error lack generalization miao et al 2 use convolutional neural networks cnns automatically estimate spatial arrangement land mark projection image method utilize cnnto regress transformation residual refines required transformation register source volume target xray image initially assume position n=tini registration perform iteratively use synthetic dig itally reconstructed radiography drr image generate source volume use tn+1=tn+t address inaccurate transformation ppings cause direct regres sion transformation parameter miao et al train cnn use poseindex feature landmark extract source target image pair learn poseindex feature insensitive transform parameter tyet sensitive change insensitivity tcan express x t1 it1+t x t2 it2+t t1 t2 method require robust landmark detection algorithm domain scanner specific detection quality degrades motion corrupt data similarly simonovsky et al 20 use cnns perform 2d 3d registration target 2d slice source 3d reference volume instead regress transformationresiduals author regress scalar estimate dissimilarity two image patch leverage error backpropagation update transformation parameters end operation efficiently compute gpu high throughput peiet al 21 train cnns regress transformation parameter 2d 3d registration regression perform directly image slice without feature extraction input network pair target 2d xray image synthetic drr sour ce image generate conebeam computed tomography cbct volumehou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1739 image pair augmente vary level anisotropic diffusion iterative update cnn yield new transformation parameter g enerate new drr image similarly target xray converges 2 motion compensation fetal brain mri field requir ing motion compensation gain diagnostically useful 3d volume algorithms use general 2d 3d registrationmethods via gradient descent optimization intensity base cost function conjunction super resolution step recreate output volume early framework fetal mri reconstruction develop rousseau et al 6 introduce step motion correction 3d volume reconstruction via scattered data interpolation sdi slice registration rousseau use gradient ascent method maximize normalized mutualinformation nmi improve jiang et al 7 propose use cross correlation cc cost function optimize jiang also propose oversample region interest roi thin slice ensure sufficient sampling gholipour et al 8 integrate mathematical model super resolution eq 1 slicetovolume reconstruction pipeline introduce outlier rejection far improve kuklisovamurgasova et al 10 add intensity matching bias correction well embased model outlier detection 2d/3d registration method 2 20 21 use cnns compute unknown transformation give 2d slice respect reference 3d volume 6 8 10 11 22 23 use general registration algorithm register slice initial 3d target case motion free reference/initial volume require successful 2d/3dregistration guarantee obtainable clinical scan due unpredictable subject motion kim et al 9 propose perform slicetovolume regis tration minimize energy weighted mean square difference wmsd slice intersection intensity profilesthis method require initial target registration volume intermediate 3d reconstruction author able recover motion 15 mm translation 30 rotation individual slice method also estimate slice motion without need volume reconstruction however focus tackle problem reasonable initial slice alignment 3d canonical space guarantee real scan scenariosthis goal relate natural image processing work kendall et al 24 propose posenet regress 6dof camera pose single rgb image posenet istrained rgb image take n particular scene eg outdoor street corridor cnn use infer localiza tion within learned 3d space expanding idea give 2d image slice would like infer pose relative 3d atlas space without know initial information besides image intensity hou et al 25 demonstrate potential cnns tackle volume initialization problem slicetovolume3d image reconstruction network architecture 25 show promising result initialize scan slice fetal brain inutero volume reconstruction pose estimationof drr scan image however provide mean estimate incorrect prediction outlier rejection failing account grossly misalign slice constitute outlying sample hinders reconstruction performance may resultin volume reconstruction failure extend 25 rigor ous evaluation several network architecture introduce monte carlo dropout 26 purpose establish aprediction confidence metric b contributions paper introduce learning base approach automatically learn slice transform model arbitrarilysampled slice relative canonical coordinate system ie approach learn mapping function map slice volumetric atlas achieve use onlythe intensity information encode slice without rely image transformation scanner coordinate cnn predict 3d rigid transformation element special euclidean group se 3 predicting canonical orienta tions slice collection 3d stack cover roiprovides accurate initialization subsequent automatic 3d reconstruction registration refinement use intensity base optimization method r ecent statistical analysis metric 27 specific lie group incorporate give accurate measure misalignment predicted slice corresponding ground truth combine traditional image similarity metric cross correlation structural similarity report quantitative comparison evaluate predic tive performance several cnn architecture real synthetic 2d slice corrupt extreme motionsynthetic slice know ground truth location extract 3d mri fetal brain volume approximately 20 week gestational age ga additionally evaluate approach qualitatively heavily motion corrupt fetal mri ground truth slice transformation and/or 3d volumesare available provide 2d slice canonically align initialize subsequent reconstruction step qualitatively assess improvement method provide forthe volume reconstruction task implement monte carlo dropout sample infer ence consider model epistemic uncertainty pro vide prediction confidence slice use metric outlier rejection ie model confidentabout prediction discard subsequent use 3d reconstruction approach also generalize 3d3d volumetric registration predict transformation parameter select slice use landmark marker demonstrate 25 predict thorax phantom slice organ specific segmenta tion perform also applicable projective 2d image highly valuablefor xray/ct registration ii ethod fully evaluate assess performance 2d/3d registration via learning base approach incorporate it1740 ieee transactions medical imaging vol 37 8 august 2018 fig 1 pipeline reconstruct volume stack heavily motion corrupt scan nb use test case n4 bias correction perform directly raw scan volume ii 28 29 use approximate organ localiz ation create segmentation mask desired roi iii bias correct volume mask iv volume intensity rescale 0 255 match svrnet train parameter v slice within volume crop center position slice svrnet inference vi slice infer svrnet obtain prediction atlas space location vii optional use predict transformation original ference slice initialize traditional svr algorithm registration refinement full 3d reconstruction pipeline show fig 1 h feature three modular component 1 approximate organ localization 2 canonical slice orientation estimation 3 intensitybased 3d volume reconstruction organ localiza tion 1 concern localization learned roi achieve rough manual segmentation organ focus scan sequence automatic method 30 32 3d volume reconstruction 3 w eu eam fi e iterative svr method 11 incorporate superresolution image reconstruction technique 11 13 additionally allow compensation remain small misalign ments single slice cause prediction inaccuracy provide sufficiently high number sample svr multiple stack 2dslices acquire ideally orthogonal orientation 33 modified 11 instead ofgenerating initial reference volume slice orient scanner coordinate acquire slice orientation replace predicted canonical atlas coordinate iterative intensitybased reconstruction process continue point since 1 n 3 achieve use stateof theart technique focus remainder section canonical slice orientation estimation 2 specifically learning prediction 3d rigid transformation usinga variety network architecture core method use cnn call svrnet regress transformation parameter ti= /theta1 /theta1are learned network parameter iis 2d image slice size extract series slice acquire 3d volume /omega1 /omega1encloses desired roi organ particular use case scenario i/omega1 train svrnet slice vary orientation cor responding ground truth location obtain exist organ atlas collection motionfree 3d volume eg preinterventional scan successfully partially manu ally motion compensate subject rigid body transformation parameterization motion rigid body 3d six degrees freedom 6 dof one common p arameterization motion defines three parameter translation tx ty tz three rotation rx ry rz model movement slice 3d space divide parameter two category inplane transformation tx tyandrzand outof plane transformation tz rxand ry see fig 2 dj dof allow ten interval delineation would result in10 6slices per organ volume automatic segmentation method 28 29 34 define roi slice slice basis throughout the3d volume desired roi eg segment brain mask center align within vastly decrease valid range inplane motion parameter txandty similar 2 additionally reduce number slice require createtraining validation data set simplify sample space constrain parameter z rx ryand rz far discount portion slice yield little content extremity tzrange consider volume b data preprocessing scantime image int ensity range influenced roi structure and/or set radiologist base visualappeal diagnostic purpose cause scanned volume bias differently intensity range vary scan scan preprocessing image intensity via minmax normaliza tion zscore normalization typically necessary stepwhen train cnns process help keep image feature common scale keep similar feature across different image consistent zscore normalization scale volume tozero mean standard deviation one common preprocessing step knearest neighbor base technique cluster algorithm alte rnatively quicker approxi mation make perform minmax normalization intensity normalization pixel show fig 1 perform roi mask training validation data set extract ifrom 3d motion correct segment fetal brain volume areregistered canonical atlas space fig 2a and2bshows example slice extract brain volume /omega1 svr 11 perform raw scan volume mask apply fetal brain desired roi volume feature little fetal maternal motion hence reconstruction successful 3d reconstruction intensity rescale 0255 isotropic spacing 075 075 075 mm far manually align canonical atlas coordinate 4 resulting volume size lll enclose brain atlas centeraligned inference raw scan data raw volume n4 bias correct first fig 1 ensure intensity region affect small magnetic field inhomogeneity correct roi localization fig 1 ii h ev l u e mask fig 1 iii intensity normalize 0255 fig 1 iv predict transformation parameter svrnet slice 3d volume individually scale back isotropic space masked roi centerd within fig 1 v hou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1741 fig 2 ab visualization extract ifrom identity plane lie flat xyaxis rotate euler angle iterator fibonacci point iterator shift normal tz represent red arrow account ofplane transformation orange curve arrows represent rotation rx ryandrz c anchor point slice parameterization 3d space dj transformations 6 dof fig 3 slice plane normal wrt origin via different generation method vector origin point cross slice origin note possible visualize plane rotation thisvisualization c generating training validation data create comprehensive training validation set must cover large number transformation permutation in/omega1 parameterize iand/omega1with length l u c h dimension slice imatches dimension face cubic volume /omega1e v e r /omega1encloses brain atlas centeraligned ie origin center thebrain isotropic intensity normalize 0 255 show fig 2a and2b since transformation parameter constrain vary r x ry rzandtz rotate sampling plane axis multiple offset account vary tz identity plane lie flat xyaxis initially rotate shift along normal new orientation tz represent red central axis infig 2 ab ground truth transformation defines transformation identity plane new final location 3d space straightforward method iterate rotation euler angle r x z x z u /2 /2 however give balanced training slice distribution show fig 3a figure point represent normal vector sample plane origin red arrow fig 2a 2b another sample approach use polar coordinate p uniform sampling polar coordinate cause mbalance sample high density sample near pole fig 3b good compromise use fibonacci sphere sampling 35 normal roughly degree separation itsneighbors fig 3c sampling normal calculate use p cos1 zi w h e r e i=2i//phi1andzi=1 2i+1 /n i012 n1/phi1= 5+1 /2 golden ratio /phi11=/phi11 evaluate impact training data sample scheme sect iv rotation defined rotation require transform 3d vector aonto 3d vector bw h e r e start normal unit vector z ie 001 bis target sample normal however account inplane rotation rz transformed sampling plane far rotate around zaxis uniform distribution angle rzu 0 validation set slice ar e generate polar co ordinate method use random normal random inplane rotation angle within bound training setthis simulate continuous motion test slice lie discrete training sample interval show fig 3d constrain shift along normal z enclose approximately central 70 volume range tzis035ltz035l edge case beneficial training set contain little content edge slice ambiguous precise location determine without extra information even atrained medical expert ambiguous sample nature introduce adverse effect train cnn missing information edge case slice recover intersect orthogonal slice eventual 3d reconstruction loss functions ground truth labels commonly used loss function regression problem euclidean norm 36 37 /vextenddouble/vextenddoublexx/vextenddouble/vextenddouble nh w e v e r may suitable regression target variable lie manifold noneuclidean propose method slice transform rigidly 3d space parameterization slic e therefore lie within bound se 3 lie group include rotation well translation component numerous waysof represent transformation rotation euler angle quaternion rotation matrix etc address aforementioned challenge kendall et al 24 propose posenet loss loss=/vextenddouble/vextenddoublexx/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddouble/vextenddoubleqq /bardblq/bardbl/vextenddouble/vextenddouble/vextenddouble/vextenddouble 2 2 use regress pose camera 6 dof xandqare predicted cartesian translation quaternion rotation parameter whilst xandqare respective ground truth value loss function combine euclidean dis tance translational loss weighted euclidean distance rotation loss tuning parameter use determine contribution loss normalize number different scale quaternions represent rotation use four number +1a n 1 however cartesian 3 dof coordinate span and+t h cause imbalance combined optimization requiresmanual correction xuet al 38 propose framework base sep arating loss function advantage alleviating1742 ieee transactions medical imaging vol 37 8 august 2018 overfitting fully connect layer network split several branch wh ere branch terminate separate loss function instead manually tune contribution discrete component combined lossfunction network incorporate tuning parameter within connection weight result network able learn multiple representa tions ground truth label instance eulercartesia n parameter 3 rotation 3 translation quaterni oncartesian parameter 4 rotation 3 translation introduce novel labelling system rota tion translation component label combinedtogether three non colinear point 3d euclidean space form plane order defines orientation therefore call anchor points see fig 2 ac three anchor points defined anywhere 2d slice long identical colinear relative inpane location consistent throughout slice data set simplicity defined p1to bottomleft corner l l0 p2to origin 000 p3the bottom right corner l l0 identity plane fig 2 show anchor points mark multiple slice fig 2c show anchor point one particular slice anchor points identity sample plane transform destine location use transform parameter set consequently anchor point label consist 9 parameter p1 x z p2 x z p3 x z point cartesian optimization balance calculate standard l2norm loss function incorporating multiloss framework 38 loss p1 p2and p3are calculate independently combined loss svrnet therefore write loss=/vextenddouble/vextenddouble/vextenddoublep 1p1/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoublep 2p2/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoublep 3p3/vextenddouble/vextenddouble/vextenddouble 2 3 e network architecture uncertainties towards make appropriate network architecture choice svrnet explore several stateoftheart network caffenet 39 googlenet 40 inception 41 nin 42 resnet 43 vggnet 44 svrnet take ia input whilst compute loss eq 3 various label meth od sect iv evaluate architecture regression performance previously propose anchor point label common strategy training large state oftheart network involve use dropout 45 entail mute component true signal provide individual neuron technique essentially provide formof model average dropout c onstitutes wellunderstood regularization technique reduce overfitting result dropout neuron ability produce different output upon successive activation inference dropout usu ally disable network consistency undermine regression network therefore commonly deterministic model inference time allow modelling uncertainty implementing fully probabilistic model thataccount uncertainty 1 data 2 model parameter aleatoric e pistemic uncertainty respec tively 46 may introduce high computational cost 47 gal ghahramani 26 recently show dropout layer neural networks interpret bayesian approximation probabilistic model implement apply dropout every weightlayer show mathematically equivalent approximately integrate model weight gal ghahramani 48 far show input perform multiple prediction test time dropout take mean prediction improve result cnn base network process perform multiple prediction input use dropout layer call monte carlo dropout sampling also providesmodel uncertainty give input data using technique experimental work section ive focus take epistemic uncertainty consideration inorder gauge alignment prediction confidence realworld test case slice alignment require high precision investigate idea measure prediction confidence important aid reconstruction quality network prediction confidence also use metric screen corrupted slice ie region image signal dropout intensity bleeding amniotic fluid data predominately show signal dropout artefacts butnetwork prediction confidence use reject kind image corruption obscured image slice would result prediction low confidence slices low confidence discard far use subsequent 3d reconstruction f metrics noneuclidean manifolds computing mean prediction monte carlo dropout sample require accurate method average network output case rigid transformation rigidtransformations lie euclidean manifold constitutes smooth manifold intrinsic mean correspond variance compute 49 morecommonly regard special euclidean group se 3 considering nrigid transformation predict net work { x } i=1 n compute riemannian center mass minimize geodesic distance point m=argmin yme/bracketleftbig dist x 2/bracketrightbig 4 wheremis riemannian manifold dist x defines geodesic distance two point xand yon manifold gaussnewton iterative algorithm rigid transformations use compute mean available data point x iby use leftinvariant metric 50 mt+1=mtexpid/parenleftbigg1 n/sigma1logid/parenleftbig m1 txi/parenrightbig/parenrightbigg 5 expidand logidare exponential logarith mic mapping identity defined leftinvariant riemannian metric group composition operator mean compute corresponding variance isstraightforward compute =e xm 2 w h e r et h e logarithmic operator defines xmas logm x 50 provide detailed overview notion algorithmshou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1743 g transformation recovery transform predicted anchor point position euler cartesian quaternioncart esian parameter rotation matrix cartesian offset transform corre sponding slice inferred location 3d space however network may introduce prediction error likely cause anchor points deviate perfect isoscelestriangle formation overcome problem assume p2defines cartesian offset slice ie center point slice world space vector join point p1andp3aligns bot tom edge slice defines inplane rotation anchor points together define plane contain slice use calculate rotation matrix reorient slice see fig 2c cartesian offset tequals p2 orientation calculate three orthogonal vector defines new coordinate system concaten ating vector give rotation matrix transform identity plane thenewly predict orientation /vectorv 1=p3p1and/vectorv2=p2p1 represent blue arrow fig 2c /vectorv1/vectorv2gives normal plane /vectorn1 defines new zaxis /vectorn1/vectorv1 give new yaxis /vectorn2 n /vectorv1itself defines new xaxis finally /vectorv2 /vectorn2and/vectorn1are concatenate together get rotation matrix r important note anchor points unable coincide one another definition anchor point isregressed use independent fully connect network layer two anchor points may coincide fully connect layer wei ghts would identical layer weight randomly initialise deviate train due predefined nonidentical train sample target location possible two anchor points predict close proximity rare error case cases type identified check constraintthat anchor points must adhere minimum distance one another h slice volume reconstruction use modified version 11 perform slice v olume reconstruction individual instead use preexisting volume initial registration target create initial registration target volume iand corresponding predict ti validation case ithat utilized inference also use reconstruction allow us verifywhether original volume /omega1can recover iandti n c e iwere extract /omega1for training validation data set sect iv employ image qualitymetrics assess prediction performance examine original reconstructed volume test case intensity rescale ior original iare use slicetovolume reconstruction intensity rescale image require svrnet prediction top 1 bottom 1 intensity distribution also prune ensure distribution skew outlier quantizing 16bit 8bit reduces signal noisepower ratio snr 96db 48db 48db snr calculate snr =20 log 10 2 168 =482db still sufficient accurate identification impor tant image feature svrnet iii mplementation network architecture implement use caffe 39 library intel i7 6700k cpu nvidia titan x pascal gpu fetal subject data provide ifind project 51 scans perform philipsachieva 15t st thomas hospital london mother lie 20 tilt left side avoid pressure inferior vena cava back depend comfort eachsubject multiple single shot fast spin echo ssfse image acquire inplane resolution 125 125 mm slice thickness 250 mm gestational age fetus time scan 21 27 week mean =24 stdev =1 slice size 120 120 ie l=120 six separate data set generate cover combination slice generation label representation three data set generate via euler angle iteration remain three gener ated use fibonacci sphere sampling method slice generation method data set eulercartesian label quaternioncartesian label anchor point label euler generation method angle iterate 18 intervals 90to+90 give 10 sampling interval axis 40 slice take tzaxis 40tz+ 40 2 mm interval sample approximately middle 66 volume total euler iteration method generate 224m image training set fibonacci sphere sampling method 300 sampling normal choose give approximately 8separation every normal additional 10 image 0 180with 18interval generate normal account inplane rotation slices also take between40 +40 zwith 4 mm interval generate total 336m image training set validation slice gener ated similar fashion except sample random interval within bound training set model random subject motion implement 27 python mean variance geodesic distance computation se 3 group rigid transformation iv e xperimentation evaluation evaluation metrics naive progress check involve monitor training validation loss ensure network generalize examine slice detail present network 2d image slice extract /omega1 using parameter obtain network inference extract newslice /omega1and compare slice comparison perform via several standard image similarity metric outline section1744 ieee transactions medical imaging vol 37 8 august 2018 utilize standard image processing metric cross cor relation cc peak signaltonoise ratio psnr mean squared error mse structural similarity ssim metric definitively assess slice location 3dspace include euclidean distan ce error average distance predicted ground truth anchor points well geodesic distance error unitless metric twose 3 pose cc measure similarity two series image function displacement one relative search feature similar image examine pixel intensity cc f g = m1/summationdisplay in1/summationdisplay jf j g j 6 nis number pixel image f=f f /radicalbig /summationtext f f 2andg=g g /radicalbig /summationtext g g 2 7 psnr base mse metric ratio maximum possible power signal power corrupt noise affect fidelity representation deltaerror estimate network regression defined psnr =10log10 max2 mse 8 max iis maximum possible intensity pixel value image mse f g =1 mnm1/summationdisplay in1/summationdisplay j f j g j 2 9 ssim attempt improve upon psnr mse use combination luminance contrast structure assess image quality metrics mse give wide variety ofdegraded quality image drastically different perceptual quality undesirable trait defined ssim f g = 2 fg+c1 2fg+c2 2 f+2g+c1 2 f+2g+c2 10 fandgare average pixel intensity image fand grespectively 2 fand2 gare variance fand grespectively fgis covariance fand g c1= k1l 2and c2= k2l 2are two variable stabi lizes division weak de nominator ie case 2 f+2 g0o r2 f+2 g0 lis maximum possible intensity image k1=001 k2=003 default constant average euclidean distance error defined ed=1 3 /vextenddouble/vextenddouble/vextenddoublep 1p1/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoublep 2p2/vextenddouble/vextenddouble/vextenddouble 2+/vextenddouble/vextenddouble/vextenddoublep 3p3/vextenddouble/vextenddouble/vextenddouble 2 11 average euclidean distan ce three anchor points provide error estimation mm geodesic distance prediction manifold provide intrinsic distance measure far predicted rigidtransformation ground truth transformation xis ground truth rigid transformation yis predicted rigid transformation leftinvariant geodesic distance metric tangent space xcan compute 50 gd=dist x =/vextenddouble/vextenddoublelogx /vextenddouble/vextenddouble x 12 log use notion describe sect iie b network architecture performance six networkbases describe sect iie explore examine arch itectures affect regression accuracy task architecture givesthe best performancetotrainingtime ratio network train use caffe adam optimizer max iteration 200000 batch size 64 learn rate 0 0001 momentum 09 learning rate decay 10 every 20000 itera tions exception resnet architecture utilizeda low batch size 32 due available gpu memory network train data set generate euler angle iteration method anchor point label fig 4 show training testing loss training process curve represent loss anchor point table ii show number parameter within network training time 200000 iteration analyze performance network use prede fined image similarity metric well geodesic euclid ean distance predicted ground truth location comparison ground truth obvious incorrect slicepredictions first discard eg slice predict outside volume incorrect slice prediction defined possess geodesic distance threescaled median absolute deviations mad median mad =kmedian x imedian x i=1 n table show average error 1000 random validation slice select five test subject see vggnet attain small geodesicdistance error well best correlation mse closely follow googlenet manage attain small psnr ssim averag e euclidean distance error show average prediction error single anchor point corresponding ground truth location nin bad performing network much great error efficiency googlenet ideal choice attain almost good performance vggnet half training timeif accuracy low importance caffenet may also use resnet inception nin however take much long train perform bad compare vggnet fig 5 show example prediction make network c image normalization image analysis literature emphasize impor tance intensity normalization many domain widely accept appropriate normalization often critical employ learn base approach thissection report empirical exploration various alternative image normalization strategy consider first experiment involve test performance effect ofhou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1745 fig 4 loss graph training row 1 3 validation row 2 4 six network architecture use anchor point prediction table table showing meanerror standard deviation eachevaluation metric table ii parameter count training duration different network architectures zscore normalization slices iin data set generate via euler iterator anchor point label slice extraction /omega1 brain volume zscore normalize mask ie background pixel include thenetwork train parameter defined sect iii run maximum 280k iteration fig 6a show validation loss training peri odicity graph indicate overfitting cycle subject validation dat abase training loss also slightly high compare googlenet train intensity rescale database see fig 4 second normalization experiment alternatively involved take /omega1 use igeneration match intensity profile fetal atlas 4 procedure also apply validation volume slices iin data set also fig 5 top validation slice present network bottom slices extract respective fetal volume use para meter predict network f compare ground truth slice predicted slice order increase geodesic distance error generate via euler iterator anchor point label network train 200k iteration parameter keep consistent previous experimental setup defined sect iii fig 6b show validation loss experiment see validation loss low zscore normalization strategy high intensity rescaling periodic nature still identified suggest slight overfitting final experiment explore many different /omega1are need training good generalization seven net work train batch size 64 increasing1746 ieee transactions medical imaging vol 37 8 august 2018 fig 6 validation loss network trained via euler angle seed anchor point loss zscore normalize data b histogram match data fig 7 validation loss seven network train vary data set size left avg euclidean distance error right avg geodesic distanceerror table iii verage errors different fetal datasets iteration 40k 80k 120k 160k 200k 240k 280k ensure every network train 16 epoch epoch =iterations batch size / data set size slices generate 4 8 12 16 20 24 28 fetal volume volume yield 40k lices via euler iterator fig 7 show box plot validation score trained network left chart show average euclidean distance error anchor point right chart show geo desic distance error see sect iif 16 20 volume average euclidean distan ce error anchor point include quartile al ready 10mm within capture range recent robust svr algorithm discuss sect ia regression labels additionally look gain understanding data set affect performance accuracy construction differs particular different type label parameter ization make use googlenet architecture due note favorable accuracyspeed tradeoff network posse six data set adopt multiloss framework 38 use evaluation methodology asbefore 5k slice validation set 1k per fetal subject randomly select pass network table iii show average error data settable iv ttestscores comparing euler cartesian quaternion cartesian labels anchor point labels table v psnr ofvolumes reconstructed synthetic slices compared ground truth validation volumes fig 8 sequential scan slice sagittal image stack fetus extreme motion observe fetus rotate head90 cause slice # 14 coronal view # 12 b # 13 c # 14 # 15 e # 16 every metric anchor point label able yield great accuracy compare eulercartesian quaternioncartesian label test case twotails independent ttest conduct examine statisticalsignificance show tab iv 5000 sample data set dof rega rded infinity pvalues test therefore infinitesimally small e 3d reconstruction evaluate propose pipeline reconstruction 3d mri fetal brain order assess ability aid common downstream task consider accurate input dataalignment hard prerequisite 200 synthetically motion corrupt slice extract validation set order initialize svr 11 five fetal subject calculatethe psnr original reconstruct 3d volume use gaussian average svr refinement see table v test svrnet case clinical part ners dismiss impossible reconstruct extensive manual automatic reconstruction attempt fail case ground truth compare reconstruction quality validate qualitatively fig 10a bandc show raw scan stack degree motion corruption case like excessive motion cause ambiguity fig 8 show sequential sagittal stack slice fetus turn head almost 90 cause coronal slice behou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1747 fig 9 slice prediction confidence four heavily motion corrupt orthogonally scanned stack slice scan stack assume sagittal unexpected slice fit stack normally reject robust statistic implement svr algorithm rejecting many slice cause lack scan data accept manyslices cause corrupt reconstruction volume see fig 10d fig 10d show svrbased reconstruction attempt use 11 without svrnet initialization monte carlo dropout sampling use early outlier rejection slice feed network 100 timesthe final prediction obtain compute riemannian center mass predicted transformation generate slice train svrnet central portion ofthe fetal volume network confidence low boundary slice show fig 9 fig 11 show example good bad slice corresponding prediction variance decision whether include slice sub sequent reconstruction depend prediction confidence robustness chosen reconstruction algorithm 3 prediction confidence thresholded reconstruction algorithm robust like 11 canmake multiple prediction per slice let reconstruction algorithm handle far outlier rejection allow great margin error see fig 10 experimentally find data set utilized study geodesic variance approx 10 allows reliable distinction slice useful subsequent volume reconstruction task confident ne twork prediction may discard less confident prediction fig 11 e f slice suffer signal loss fig 11 g h edge case slice image plane minimal intersectio n brain surface instance make high degree ambiguity true image plane location case also prove highly challenge forexperienced practitioner wit hout additional information v iscussion paper show learning base approach svrnet able greatly increase capture range 2d/3d image registration provide robust initialization scan extreme interslice motion corruption accuracy network pr edictions influenced effi cient novel parameterizatio n label loss function particular explore effect utilize parameteri zations lie euclidean manifold notably euler quaternioncartesian label attain similar level performance yet unique parameterization combine introduction anchor points increasethe attainable accuracy evaluate six different architecture fixed hyper parameter configurations achieve satisfactory registrationaccuracy provide additional evidence towards typical cost benefit trade offs hyperparameter tuning regression transformation parameter hyperparameter optimization extremely time consuming computationally expensive whilst provide little improvement prediction accuracy generating synthetic slice training challenging due extensive search large space ofparameters 6dof constrain parameter space leverage effect inplane transformation base centeraligned content result organ localization svrnet need retrain different organ use case scenario modality eg mri field strength t1 t2 xray exposure etc particularly problematic without organ atlas exist 3d reference volume able obtain one addition raw 3t scan find model train 15t image also able successf ully predict transformation parameter 3t image however experimentation necessary validate intramodality robustness svrnet retraining/transfer learn new modality advisedto achieve maximum prediction accuracy svrnet require test image format way training include identical intensity range spacing translation offset removal preprocessing 3d volume method restrict respect use imaging modality scenario see 25 network train drr image well whole thorax phantom valuable 3d 2d alignment thewhole volume align individual 2d slice current implementation svrnet focus rigid transformation case nonrigid deformation oforgans slice expect patch v olume pvr reconstruction 12 use final volume reconstruction step case svrnet still able predict approximate location individual 2d slice canonical 3d space pvr handle nonrigid deformation svrnet use euclidean distance primary loss func tion regress anchor point label also possible use image metric one shortlist section iva distance metric chosen metric differentiable however metric like 52 intend use primarily natural medical image mean use approach could yield little performance gain experimentation find choice relate slice generation method greatly affect prediction per formance opposition p arameterization strategy represent regression ground truth label hold significantinfluence result quality show table iii w ee v e n tually select euler angle parameterization due ease use requirement training sample relative tothe consider alternative case little motion svrnet may less effective due training data sample interval example iterate slice rotation 18 steps euler iterator seed 2mm step tz step size intuitively interpret resolution network motion corruption present small interval prediction error may introduce high slice offset than1748 ieee transactions medical imaging vol 37 8 august 2018 fig 10 reconstruction attempt fetal brain approx 20 week ga heavily motioncorrupted stack t2weighted ssfse scan possible reconstruct scan significant amount manual ef fort two experienced data scientist field use stateoftheart method b c 3 example orthogonal input stack scan plane di rection coronal axial sagittal respectively view direction initialize stack0 show c k b c perfectly orthogonal take different time point fetus move patch volume registration pvr 12 large patch ie improve svr use input stack directly e gaussian average slice predict realign atlas space svrnet f reconstructed volume 4 iteration slice volume registration svr initialize slice predict svrnet arrow point area insufficient data acquire fetus move scan direction thus slice miss area necessary accurate reconstruction g training atlas representation slice e f note reconstruct patient space whereas e f reconstruct atlas space fig 11 monte carlo prediction unitless geodesic distance variance metric slice h igher number represent great variance ie network less confident represent confident prediction e h represent less confident prediction dis card subsequent volume reconstruction originally present scan purpose svrnet compete traditional svr method use many case raw scan volume corrupt motion offset large correctable traditional svr method significant amount manual intervention would require desirable sideeffect svrnet predict slice orientation canonical atlas coordinate case svr method another issue difficult even human expert determin ing leftright asymmetry give slice without additional information tackle issue oversampling capture lot slice scan time allow great margin formispredicted slice robust statistics 11 able reject slice predict wrong hemisphere propose method also formulate classi fication task rigid transformation quan tized class quantizing permutation use ourexperiments would result 40 kto 50 kclasses 28 fetal example per class lead high class imbalance introduce new diffi culties training reducingthe number class however decrease prediction resolution vi c onclusion svrnet able predict slice transformation relative canonical atlas coordinate system use intensity information image allow motion compensation highly motion corrupt scan eg mri scan veryyoung fetus allow incorporation image acquire examination thus relax requirement temporal scanplane proximity evaluate wide range stateoftheart popular network architecture examine performance prediction accuracy find vggnet experiment attain small regression error however googlenet efficient train repeat experimentsit achieve similar result vggnet half training time whilst occupy 85 less memory space work leverage computational framework statistic se 3 lie group perform bayesian inference monte carlo dropout sample rigid transforma tion prediction network approach also bebeneficial application 24 cnns train produce output transformation euclidean space show calculate geodesic distance rigid 3d transformation noneuclidean man ifold provide mean assess predicted transformationparameters accurately pave way propagate uncertainty downstream pipeline use network output perform taskshou et al 3d reconstruction canonical coordinate space arbitrarily oriented 2d images 1749 acknowledgements author would like thank volunteer radiog raphers j allsop fox mitk 53 irtk cc publiclicense ixico ltd nihr biomedical research center gstt would also like thank nina miolane fruitful discussion data access line informed consent participant subject approval project ethic board formal data sharingagreement",
    "bag_of_words": {
        "ieee": 7,
        "transactions": 7,
        "medical": 10,
        "imaging": 13,
        "vol": 7,
        "august": 7,
        "3d": 67,
        "reconstruction": 60,
        "canonical": 21,
        "coordinate": 22,
        "space": 32,
        "arbitrarily": 9,
        "oriented": 7,
        "2d": 32,
        "images": 7,
        "benjamin": 2,
        "hou": 5,
        "bishesh": 1,
        "khanal": 2,
        "amir": 1,
        "alansary": 2,
        "steven": 1,
        "mcdonagh": 2,
        "alice": 1,
        "davidson": 2,
        "mary": 1,
        "rutherford": 2,
        "jo": 1,
        "hajnal": 2,
        "daniel": 1,
        "rueckert": 2,
        "ben": 1,
        "glocker": 2,
        "bernhard": 1,
        "kainz": 2,
        "abstract": 1,
        "limited": 3,
        "capture": 6,
        "range": 11,
        "requirement": 4,
        "provide": 18,
        "high": 13,
        "quality": 11,
        "initialization": 9,
        "optimizationbased2d/3d": 1,
        "image": 86,
        "registration": 40,
        "method": 46,
        "significantlydegrade": 1,
        "performance": 14,
        "andmotion": 1,
        "compensation": 8,
        "pipeline": 7,
        "challenging": 4,
        "clinical": 5,
        "scenario": 6,
        "contain": 3,
        "significant": 3,
        "subject": 12,
        "motion": 40,
        "fetal": 23,
        "inutero": 3,
        "complicate": 1,
        "andvolume": 1,
        "process": 9,
        "paper": 4,
        "presenta": 1,
        "learningbased": 2,
        "capable": 2,
        "ofpredicting": 1,
        "rigid": 14,
        "transformation": 44,
        "oriented2d": 1,
        "slice": 148,
        "respect": 3,
        "learned": 4,
        "atlascoordinate": 1,
        "system": 10,
        "intensity": 30,
        "information": 10,
        "use": 80,
        "perform": 18,
        "alignment": 14,
        "spatial": 4,
        "transform": 10,
        "require": 14,
        "findimage": 1,
        "utilize": 5,
        "convolutional": 2,
        "neuralnetwork": 1,
        "architecture": 16,
        "learn": 8,
        "regression": 12,
        "function": 13,
        "map": 3,
        "atlasspace": 1,
        "extensively": 1,
        "evaluate": 9,
        "effectiveness": 1,
        "ourapproach": 1,
        "quantitatively": 1,
        "simulate": 3,
        "magnetic": 3,
        "resonanceimaging": 1,
        "mri": 10,
        "brain": 14,
        "imagery": 1,
        "synthetic": 6,
        "motionand": 1,
        "far": 9,
        "demonstrate": 4,
        "qualitative": 1,
        "result": 12,
        "real": 3,
        "data": 43,
        "integrate": 4,
        "full": 2,
        "recon": 1,
        "struction": 1,
        "achieve": 9,
        "average": 14,
        "predictionerror": 1,
        "mm": 8,
        "produce": 3,
        "qualitativelyimproved": 1,
        "heavily": 6,
        "move": 4,
        "fetus": 10,
        "withgestational": 1,
        "age": 4,
        "approximately": 6,
        "week": 5,
        "modelprovides": 1,
        "general": 3,
        "computationally": 2,
        "efficient": 2,
        "solution": 3,
        "tothe": 2,
        "2d/3d": 10,
        "problem": 7,
        "suitablefor": 1,
        "realtime": 1,
        "index": 1,
        "terms": 1,
        "biomedical": 6,
        "resonance": 1,
        "machine": 1,
        "learning": 6,
        "imagereconstruction": 1,
        "manuscript": 1,
        "receive": 1,
        "december": 1,
        "revise": 1,
        "january": 2,
        "accept": 3,
        "date": 1,
        "publication": 1,
        "february": 1,
        "dateof": 1,
        "current": 4,
        "version": 3,
        "july": 1,
        "work": 10,
        "support": 1,
        "part": 5,
        "wellcome": 1,
        "trust": 1,
        "ieh": 1,
        "award": 1,
        "grant": 3,
        "ifind": 2,
        "erc": 1,
        "nvidia": 2,
        "gpu": 4,
        "donations": 1,
        "andin": 1,
        "epsrc": 1,
        "ep/n024494/1": 1,
        "corresponding": 6,
        "author": 4,
        "analysis": 5,
        "group": 10,
        "department": 4,
        "ofcomputing": 1,
        "imperial": 2,
        "college": 4,
        "london": 9,
        "sw7": 2,
        "2az": 2,
        "uk": 4,
        "email": 1,
        "bh1511": 1,
        "imperialacuk": 1,
        "computing": 2,
        "alsowith": 1,
        "engineering": 2,
        "king": 2,
        "wc2r": 2,
        "2ls": 2,
        "color": 1,
        "one": 10,
        "figures": 1,
        "available": 5,
        "online": 1,
        "http": 1,
        "//ieeexploreieeeorg": 1,
        "digital": 1,
        "object": 1,
        "identifier": 1,
        "101109/tmi20182798801i": 1,
        "introduction": 2,
        "reconstructing": 1,
        "volume": 81,
        "misalign": 4,
        "corrupt": 12,
        "task": 7,
        "involve": 7,
        "labor": 1,
        "intensive": 1,
        "preprocessing": 6,
        "step": 10,
        "manual": 11,
        "landmark": 8,
        "matching": 3,
        "exhibit": 1,
        "inter": 1,
        "intraobserver": 1,
        "variance": 9,
        "pre": 1,
        "processing": 3,
        "necessary": 5,
        "acceptable": 1,
        "input": 10,
        "intens": 1,
        "itybased": 1,
        "pose": 6,
        "optimization": 10,
        "facilitatesalignment": 1,
        "combination": 4,
        "multiple": 11,
        "source": 5,
        "common": 7,
        "also": 21,
        "application": 4,
        "atlasbased": 1,
        "segmentation": 4,
        "track": 1,
        "fusion": 1,
        "modality": 4,
        "visualize": 2,
        "anatomical": 4,
        "sta": 1,
        "ndard": 1,
        "suffer": 2,
        "poor": 1,
        "automatic": 9,
        "must": 3,
        "alleviate": 1,
        "bymanual": 1,
        "case": 26,
        "two": 10,
        "distinct": 1,
        "strategy": 6,
        "categorize": 1,
        "volumeto": 1,
        "slicetovolume": 8,
        "technique": 11,
        "former": 1,
        "concern": 3,
        "align": 7,
        "give": 13,
        "eg": 9,
        "intraoperative": 1,
        "carm": 1,
        "xray": 5,
        "preoperative": 1,
        "volumetric": 3,
        "scan": 33,
        "contrast": 2,
        "latter": 1,
        "unique": 2,
        "reference": 7,
        "volumea": 1,
        "recent": 2,
        "review": 1,
        "arbitrary": 1,
        "invalidate": 1,
        "assumption": 1,
        "base": 14,
        "scanner": 4,
        "intervention": 2,
        "may": 11,
        "correction": 5,
        "often": 4,
        "become": 3,
        "unfeasible": 1,
        "practice": 1,
        "due": 8,
        "magnitude": 1,
        "volumetoslice": 1,
        "easy": 1,
        "sincemanual": 1,
        "single": 7,
        "projection": 2,
        "less": 7,
        "time": 11,
        "consume": 1,
        "hundred": 1,
        "individual": 6,
        "commoncoordinate": 1,
        "landmarkbased": 1,
        "help": 2,
        "automate": 1,
        "approach": 11,
        "depen": 1,
        "dent": 1,
        "detection": 4,
        "accuracy": 10,
        "robustness": 4,
        "calculated": 1,
        "homography": 1,
        "location": 16,
        "descriptive": 1,
        "power": 3,
        "encode": 2,
        "therequired": 1,
        "establish": 2,
        "robust": 9,
        "match": 4,
        "ing": 3,
        "therefore": 7,
        "etal": 1,
        "sliceto": 1,
        "effective": 2,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attrib": 1,
        "ution": 1,
        "see": 12,
        "ttp": 1,
        "//creativecommonso": 1,
        "rg/licenses/by/30/1738": 1,
        "coarsely": 1,
        "aligned": 1,
        "initialize": 8,
        "initial": 14,
        "target": 15,
        "seed": 5,
        "iterative": 6,
        "estimation": 4,
        "orientation": 11,
        "andintensity": 1,
        "reasonably": 1,
        "good": 10,
        "coarse": 1,
        "critical": 2,
        "form": 2,
        "traditional": 5,
        "intensitybased": 3,
        "solve": 1,
        "inverse": 1,
        "super": 5,
        "resolution": 10,
        "acquisition": 1,
        "show": 34,
        "eq": 3,
        "i=dibisimix+ni": 1,
        "i=12": 1,
        "yidenotes": 1,
        "ith": 1,
        "low": 7,
        "obtain": 8,
        "diis": 1,
        "downsampling": 1,
        "matrix": 11,
        "biis": 1,
        "blurring": 1,
        "siis": 1,
        "selection": 1,
        "miis": 1,
        "parameter": 34,
        "xis": 2,
        "nias": 1,
        "noise": 2,
        "vector": 9,
        "commonly": 3,
        "di": 2,
        "biandsiare": 1,
        "together": 3,
        "wi": 2,
        "obtaining": 1,
        "true": 4,
        "highresolution": 2,
        "xi": 1,
        "illposed": 1,
        "inversion": 1,
        "large": 8,
        "illdefined": 1,
        "alternatively": 2,
        "various": 3,
        "apply": 4,
        "approximation": 2,
        "typically": 3,
        "consist": 2,
        "slicetov": 1,
        "olume": 3,
        "svr": 15,
        "sr": 1,
        "iteration": 11,
        "register": 4,
        "follow": 2,
        "output": 6,
        "next": 1,
        "hence": 2,
        "crucialif": 1,
        "discard": 5,
        "employ": 3,
        "domain": 4,
        "typi": 1,
        "cally": 1,
        "guarantee": 3,
        "globally": 1,
        "optimal": 1,
        "correct": 5,
        "position": 4,
        "local": 1,
        "minimum": 2,
        "small": 8,
        "misalignment": 4,
        "improve": 6,
        "previouswork": 1,
        "attempt": 5,
        "make": 6,
        "intro": 1,
        "ducing": 1,
        "appropriate": 3,
        "objective": 1,
        "outlier": 8,
        "rejection": 6,
        "statistic": 3,
        "despite": 1,
        "theseefforts": 1,
        "still": 4,
        "depend": 3,
        "adjacent": 1,
        "intersecting": 1,
        "semi": 1,
        "characterize": 1,
        "maximum": 6,
        "methodcan": 1,
        "recover": 4,
        "applicable": 2,
        "many": 5,
        "thecapabilities": 1,
        "working": 1,
        "example": 7,
        "gestation": 1,
        "stack": 14,
        "acquire": 7,
        "fast": 3,
        "shot": 2,
        "spin": 2,
        "echo": 2,
        "ssfse": 3,
        "slices": 8,
        "fractionof": 1,
        "second": 2,
        "thus": 4,
        "freeze": 1,
        "inplane": 9,
        "random": 6,
        "awake": 1,
        "active": 1,
        "oscil": 1,
        "latory": 1,
        "maternal": 2,
        "reathing": 1,
        "likely": 2,
        "causeadjacent": 1,
        "incoherent": 1,
        "stateoftheart": 4,
        "able": 10,
        "compensate": 3,
        "reconstruct": 7,
        "consistent": 4,
        "overlap": 1,
        "motioncorrupted": 2,
        "orthogonal": 6,
        "tend": 1,
        "fail": 2,
        "best": 3,
        "neonate": 1,
        "andolder": 1,
        "however": 12,
        "early": 4,
        "diagnostics": 1,
        "detailed": 2,
        "young": 1,
        "related": 1,
        "offset": 8,
        "usually": 1,
        "requirerobust": 1,
        "detec": 1,
        "tion": 8,
        "subsequent": 7,
        "rely": 2,
        "fiducial": 1,
        "marker": 2,
        "special": 3,
        "equipment": 1,
        "and/or": 3,
        "invasive": 1,
        "procedure": 2,
        "anno": 1,
        "tation": 1,
        "expert": 3,
        "clinicalpractice": 1,
        "fully": 6,
        "difficult": 2,
        "workflow": 1,
        "reliability": 1,
        "complex": 1,
        "nature": 3,
        "long": 3,
        "computation": 2,
        "susceptibility": 1,
        "error": 23,
        "lack": 2,
        "generalization": 2,
        "miao": 2,
        "et": 18,
        "al": 20,
        "neural": 2,
        "networks": 2,
        "cnns": 7,
        "automatically": 2,
        "estimate": 5,
        "arrangement": 1,
        "land": 1,
        "mark": 2,
        "cnnto": 1,
        "regress": 8,
        "residual": 1,
        "refines": 1,
        "required": 1,
        "initially": 2,
        "assume": 3,
        "n=tini": 1,
        "iteratively": 1,
        "dig": 1,
        "itally": 1,
        "reconstructed": 4,
        "radiography": 1,
        "drr": 5,
        "generate": 13,
        "tn+1=tn+t": 1,
        "address": 2,
        "inaccurate": 1,
        "ppings": 1,
        "cause": 11,
        "direct": 1,
        "regres": 1,
        "sion": 1,
        "train": 22,
        "cnn": 8,
        "poseindex": 2,
        "feature": 9,
        "extract": 11,
        "pair": 3,
        "insensitive": 1,
        "tyet": 1,
        "sensitive": 1,
        "change": 1,
        "insensitivity": 1,
        "tcan": 1,
        "express": 1,
        "t1": 3,
        "it1+t": 1,
        "t2": 3,
        "it2+t": 1,
        "algorithm": 10,
        "specific": 3,
        "degrades": 1,
        "similarly": 2,
        "simonovsky": 1,
        "instead": 4,
        "transformationresiduals": 1,
        "scalar": 1,
        "dissimilarity": 1,
        "patch": 4,
        "leverage": 3,
        "backpropagation": 1,
        "update": 2,
        "parameters": 1,
        "end": 1,
        "operation": 1,
        "efficiently": 1,
        "compute": 10,
        "throughput": 1,
        "peiet": 1,
        "directly": 3,
        "without": 8,
        "extraction": 2,
        "network": 51,
        "sour": 1,
        "ce": 4,
        "conebeam": 1,
        "computed": 1,
        "tomography": 1,
        "cbct": 1,
        "volumehou": 1,
        "augmente": 1,
        "vary": 6,
        "level": 2,
        "anisotropic": 1,
        "diffusion": 1,
        "yield": 5,
        "new": 10,
        "enerate": 1,
        "converges": 1,
        "field": 4,
        "requir": 1,
        "gain": 3,
        "diagnostically": 1,
        "useful": 2,
        "algorithms": 1,
        "registrationmethods": 1,
        "via": 11,
        "gradient": 2,
        "descent": 1,
        "cost": 4,
        "conjunction": 1,
        "recreate": 1,
        "framework": 5,
        "develop": 1,
        "rousseau": 2,
        "introduce": 10,
        "scattered": 1,
        "interpolation": 1,
        "sdi": 1,
        "ascent": 1,
        "maximize": 1,
        "normalized": 1,
        "mutualinformation": 1,
        "nmi": 1,
        "jiang": 2,
        "propose": 10,
        "cross": 4,
        "correlation": 3,
        "cc": 5,
        "optimize": 1,
        "oversample": 1,
        "region": 3,
        "interest": 1,
        "roi": 11,
        "thin": 1,
        "ensure": 5,
        "sufficient": 2,
        "sampling": 12,
        "gholipour": 1,
        "mathematical": 1,
        "model": 14,
        "kuklisovamurgasova": 1,
        "add": 1,
        "bias": 5,
        "well": 6,
        "embased": 1,
        "unknown": 1,
        "free": 1,
        "reference/initial": 1,
        "successful": 2,
        "2d/3dregistration": 1,
        "obtainable": 1,
        "unpredictable": 1,
        "kim": 1,
        "regis": 1,
        "tration": 1,
        "minimize": 2,
        "energy": 1,
        "weighted": 2,
        "mean": 13,
        "square": 1,
        "difference": 1,
        "wmsd": 1,
        "intersection": 1,
        "profilesthis": 1,
        "intermediate": 1,
        "translation": 8,
        "rotation": 24,
        "need": 3,
        "focus": 5,
        "tackle": 3,
        "reasonable": 1,
        "scenariosthis": 1,
        "goal": 1,
        "relate": 2,
        "natural": 2,
        "kendall": 2,
        "posenet": 3,
        "6dof": 2,
        "camera": 2,
        "rgb": 2,
        "istrained": 1,
        "take": 9,
        "particular": 5,
        "scene": 1,
        "outdoor": 1,
        "street": 1,
        "corridor": 1,
        "infer": 4,
        "localiza": 2,
        "within": 10,
        "expanding": 1,
        "idea": 2,
        "would": 8,
        "like": 6,
        "relative": 6,
        "atlas": 16,
        "know": 2,
        "besides": 1,
        "potential": 1,
        "slicetovolume3d": 1,
        "promising": 1,
        "estimationof": 1,
        "incorrect": 3,
        "prediction": 41,
        "failing": 1,
        "account": 5,
        "grossly": 1,
        "constitute": 1,
        "outlying": 1,
        "sample": 21,
        "hinders": 1,
        "resultin": 1,
        "failure": 1,
        "extend": 1,
        "rigor": 1,
        "ous": 1,
        "evaluation": 4,
        "several": 5,
        "monte": 7,
        "carlo": 7,
        "dropout": 16,
        "purpose": 3,
        "aprediction": 1,
        "confidence": 12,
        "metric": 21,
        "contributions": 1,
        "arbitrarilysampled": 1,
        "ie": 11,
        "mapping": 2,
        "onlythe": 1,
        "predict": 18,
        "element": 1,
        "euclidean": 17,
        "se": 5,
        "predicting": 1,
        "orienta": 1,
        "tions": 3,
        "collection": 2,
        "cover": 3,
        "roiprovides": 1,
        "accurate": 6,
        "refinement": 3,
        "ecent": 1,
        "statistical": 1,
        "lie": 11,
        "incorporate": 4,
        "measure": 4,
        "predicted": 11,
        "ground": 18,
        "truth": 18,
        "combine": 3,
        "similarity": 6,
        "structural": 2,
        "report": 2,
        "quantitative": 1,
        "comparison": 3,
        "predic": 1,
        "tive": 1,
        "extreme": 3,
        "motionsynthetic": 1,
        "gestational": 2,
        "ga": 2,
        "additionally": 4,
        "qualitatively": 3,
        "volumesare": 1,
        "canonically": 1,
        "assess": 7,
        "improvement": 2,
        "forthe": 1,
        "implement": 5,
        "ence": 1,
        "consider": 5,
        "epistemic": 2,
        "uncertainty": 7,
        "pro": 1,
        "vide": 1,
        "confidentabout": 1,
        "generalize": 2,
        "3d3d": 1,
        "select": 4,
        "thorax": 2,
        "phantom": 2,
        "organ": 11,
        "segmenta": 1,
        "projective": 1,
        "highly": 3,
        "valuablefor": 1,
        "xray/ct": 1,
        "ii": 5,
        "ethod": 1,
        "it1740": 1,
        "fig": 46,
        "nb": 1,
        "test": 11,
        "n4": 2,
        "raw": 7,
        "approximate": 3,
        "localiz": 1,
        "ation": 1,
        "create": 3,
        "mask": 7,
        "desired": 4,
        "iii": 8,
        "iv": 8,
        "rescale": 5,
        "svrnet": 27,
        "crop": 1,
        "center": 7,
        "inference": 7,
        "vi": 2,
        "vii": 1,
        "optional": 1,
        "original": 5,
        "ference": 1,
        "three": 9,
        "modular": 1,
        "component": 5,
        "localization": 4,
        "rough": 1,
        "sequence": 1,
        "eu": 1,
        "eam": 1,
        "fi": 1,
        "superresolution": 1,
        "allow": 8,
        "remain": 2,
        "ments": 1,
        "inaccuracy": 1,
        "sufficiently": 1,
        "number": 9,
        "2dslices": 1,
        "ideally": 1,
        "modified": 2,
        "ofgenerating": 1,
        "orient": 1,
        "replace": 1,
        "continue": 1,
        "point": 32,
        "since": 2,
        "stateof": 1,
        "theart": 1,
        "remainder": 1,
        "section": 3,
        "specifically": 1,
        "usinga": 1,
        "variety": 2,
        "core": 1,
        "call": 3,
        "ti=": 1,
        "/theta1": 1,
        "/theta1are": 1,
        "iis": 2,
        "size": 10,
        "series": 2,
        "/omega1": 5,
        "/omega1encloses": 2,
        "i/omega1": 1,
        "cor": 2,
        "responding": 1,
        "exist": 2,
        "motionfree": 1,
        "preinterventional": 1,
        "successfully": 1,
        "partially": 1,
        "manu": 1,
        "ally": 2,
        "body": 2,
        "parameterization": 5,
        "six": 6,
        "degrees": 1,
        "freedom": 1,
        "dof": 6,
        "arameterization": 2,
        "defines": 9,
        "tx": 2,
        "ty": 1,
        "tz": 6,
        "rx": 3,
        "ry": 3,
        "rz": 3,
        "movement": 1,
        "divide": 1,
        "category": 1,
        "tyandrzand": 1,
        "outof": 1,
        "plane": 18,
        "rxand": 1,
        "dj": 2,
        "ten": 1,
        "interval": 8,
        "delineation": 1,
        "in10": 1,
        "6slices": 1,
        "per": 5,
        "define": 2,
        "basis": 1,
        "throughout": 2,
        "the3d": 1,
        "segment": 2,
        "vastly": 1,
        "decrease": 2,
        "valid": 1,
        "txandty": 1,
        "similar": 6,
        "reduce": 2,
        "createtraining": 1,
        "validation": 23,
        "set": 26,
        "simplify": 1,
        "constrain": 4,
        "ryand": 1,
        "discount": 1,
        "portion": 2,
        "little": 6,
        "content": 3,
        "extremity": 1,
        "tzrange": 1,
        "scantime": 1,
        "int": 1,
        "ensity": 1,
        "influenced": 2,
        "structure": 2,
        "radiologist": 1,
        "visualappeal": 1,
        "diagnostic": 1,
        "scanned": 2,
        "differently": 1,
        "minmax": 2,
        "normaliza": 1,
        "zscore": 6,
        "normalization": 11,
        "stepwhen": 1,
        "keep": 3,
        "scale": 4,
        "across": 1,
        "different": 12,
        "tozero": 1,
        "standard": 5,
        "deviation": 2,
        "knearest": 1,
        "neighbor": 1,
        "cluster": 1,
        "alte": 1,
        "rnatively": 1,
        "quicker": 1,
        "approxi": 1,
        "mation": 1,
        "pixel": 6,
        "training": 30,
        "ifrom": 2,
        "areregistered": 1,
        "2a": 3,
        "and2bshows": 1,
        "isotropic": 3,
        "spacing": 2,
        "manually": 2,
        "resulting": 1,
        "lll": 1,
        "enclose": 2,
        "centeraligned": 3,
        "first": 3,
        "affect": 5,
        "inhomogeneity": 1,
        "ev": 1,
        "normalize": 5,
        "individually": 1,
        "back": 2,
        "masked": 1,
        "centerd": 1,
        "ab": 2,
        "visualization": 1,
        "identity": 7,
        "flat": 2,
        "xyaxis": 2,
        "rotate": 5,
        "euler": 16,
        "angle": 10,
        "iterator": 6,
        "fibonacci": 4,
        "shift": 3,
        "normal": 14,
        "represent": 12,
        "red": 3,
        "arrow": 4,
        "ofplane": 1,
        "orange": 1,
        "curve": 2,
        "arrows": 1,
        "ryandrz": 1,
        "anchor": 32,
        "transformations": 2,
        "wrt": 1,
        "origin": 6,
        "generation": 5,
        "note": 4,
        "possible": 7,
        "thisvisualization": 1,
        "generating": 2,
        "comprehensive": 1,
        "permutation": 2,
        "in/omega1": 1,
        "parameterize": 1,
        "iand/omega1with": 1,
        "length": 1,
        "dimension": 2,
        "imatches": 1,
        "face": 1,
        "cubic": 1,
        "/omega1e": 1,
        "thebrain": 1,
        "and2b": 1,
        "rzandtz": 1,
        "axis": 3,
        "along": 2,
        "central": 3,
        "infig": 1,
        "final": 4,
        "straightforward": 1,
        "iterate": 3,
        "/2": 3,
        "balanced": 1,
        "distribution": 4,
        "3a": 1,
        "figure": 1,
        "2b": 1,
        "another": 4,
        "polar": 3,
        "uniform": 2,
        "mbalance": 1,
        "density": 1,
        "near": 1,
        "pole": 1,
        "3b": 1,
        "compromise": 1,
        "sphere": 3,
        "roughly": 1,
        "degree": 3,
        "separation": 1,
        "itsneighbors": 1,
        "3c": 1,
        "calculate": 7,
        "cos1": 1,
        "zi": 1,
        "i=2i//phi1andzi=1": 1,
        "2i+1": 1,
        "/n": 1,
        "i012": 1,
        "n1/phi1=": 1,
        "5+1": 1,
        "golden": 1,
        "ratio": 5,
        "/phi11=/phi11": 1,
        "impact": 1,
        "scheme": 1,
        "sect": 9,
        "defined": 10,
        "aonto": 1,
        "bw": 1,
        "start": 1,
        "unit": 1,
        "bis": 1,
        "transformed": 1,
        "around": 1,
        "zaxis": 2,
        "rzu": 1,
        "ar": 1,
        "co": 1,
        "ordinate": 1,
        "bound": 3,
        "setthis": 1,
        "continuous": 1,
        "discrete": 2,
        "tzis035ltz035l": 1,
        "edge": 5,
        "beneficial": 1,
        "ambiguous": 2,
        "precise": 1,
        "determine": 2,
        "extra": 1,
        "even": 2,
        "atrained": 1,
        "adverse": 1,
        "effect": 4,
        "missing": 1,
        "intersect": 1,
        "eventual": 1,
        "loss": 27,
        "functions": 1,
        "labels": 4,
        "used": 1,
        "norm": 1,
        "/vextenddouble/vextenddoublexx/vextenddouble/vextenddouble": 1,
        "nh": 1,
        "suitable": 1,
        "variable": 2,
        "manifold": 7,
        "noneuclidean": 3,
        "rigidly": 1,
        "slic": 1,
        "include": 6,
        "numerous": 1,
        "waysof": 1,
        "quaternion": 3,
        "etc": 2,
        "aforementioned": 1,
        "challenge": 2,
        "loss=/vextenddouble/vextenddoublexx/vextenddouble/vextenddouble": 1,
        "2+/vextenddouble/vextenddouble/vextenddouble/vextenddoubleqq": 1,
        "/bardblq/bardbl/vextenddouble/vextenddouble/vextenddouble/vextenddouble": 1,
        "xandqare": 2,
        "cartesian": 9,
        "whilst": 4,
        "respective": 2,
        "value": 2,
        "dis": 2,
        "tance": 2,
        "translational": 1,
        "distance": 22,
        "tuning": 3,
        "contribution": 2,
        "quaternions": 1,
        "four": 2,
        "+1a": 1,
        "span": 1,
        "and+t": 1,
        "imbalance": 2,
        "combined": 3,
        "requiresmanual": 1,
        "xuet": 1,
        "sep": 1,
        "arating": 1,
        "advantage": 1,
        "alleviating1742": 1,
        "overfitting": 4,
        "connect": 3,
        "layer": 6,
        "split": 1,
        "branch": 2,
        "wh": 1,
        "ere": 1,
        "terminate": 1,
        "separate": 2,
        "tune": 1,
        "lossfunction": 1,
        "connection": 1,
        "weight": 3,
        "representa": 1,
        "label": 19,
        "instance": 2,
        "eulercartesia": 1,
        "quaterni": 1,
        "oncartesian": 1,
        "novel": 2,
        "labelling": 1,
        "rota": 1,
        "combinedtogether": 1,
        "non": 1,
        "colinear": 2,
        "order": 4,
        "points": 13,
        "ac": 1,
        "anywhere": 1,
        "identical": 3,
        "inpane": 1,
        "simplicity": 1,
        "p1to": 1,
        "bottomleft": 1,
        "corner": 2,
        "l0": 2,
        "p2to": 1,
        "p3the": 1,
        "bottom": 3,
        "right": 3,
        "2c": 3,
        "destine": 1,
        "consequently": 1,
        "p1": 2,
        "p2": 2,
        "p3": 1,
        "balance": 1,
        "l2norm": 1,
        "incorporating": 1,
        "multiloss": 2,
        "p2and": 1,
        "p3are": 1,
        "independently": 1,
        "write": 1,
        "loss=/vextenddouble/vextenddouble/vextenddoublep": 1,
        "1p1/vextenddouble/vextenddouble/vextenddouble": 2,
        "2+/vextenddouble/vextenddouble/vextenddoublep": 4,
        "2p2/vextenddouble/vextenddouble/vextenddouble": 2,
        "3p3/vextenddouble/vextenddouble/vextenddouble": 2,
        "uncertainties": 1,
        "towards": 2,
        "choice": 3,
        "explore": 4,
        "caffenet": 2,
        "googlenet": 6,
        "inception": 2,
        "nin": 3,
        "resnet": 3,
        "vggnet": 6,
        "ia": 2,
        "meth": 1,
        "od": 1,
        "previously": 1,
        "state": 1,
        "oftheart": 1,
        "entail": 1,
        "mute": 1,
        "signal": 6,
        "neuron": 2,
        "essentially": 1,
        "formof": 1,
        "onstitutes": 1,
        "wellunderstood": 1,
        "regularization": 1,
        "ability": 2,
        "upon": 2,
        "successive": 1,
        "activation": 1,
        "usu": 1,
        "disable": 1,
        "consistency": 1,
        "undermine": 1,
        "deterministic": 1,
        "modelling": 1,
        "implementing": 1,
        "probabilistic": 2,
        "thataccount": 1,
        "aleatoric": 1,
        "pistemic": 1,
        "respec": 1,
        "tively": 1,
        "computational": 2,
        "gal": 2,
        "ghahramani": 2,
        "recently": 1,
        "interpret": 2,
        "bayesian": 2,
        "every": 5,
        "weightlayer": 1,
        "mathematically": 1,
        "equivalent": 1,
        "providesmodel": 1,
        "using": 2,
        "experimental": 2,
        "ive": 1,
        "consideration": 1,
        "inorder": 1,
        "gauge": 1,
        "realworld": 1,
        "precision": 1,
        "investigate": 1,
        "important": 2,
        "aid": 2,
        "screen": 1,
        "corrupted": 1,
        "bleeding": 1,
        "amniotic": 1,
        "fluid": 1,
        "predominately": 1,
        "artefacts": 1,
        "butnetwork": 1,
        "reject": 3,
        "kind": 1,
        "corruption": 4,
        "obscured": 1,
        "metrics": 3,
        "manifolds": 1,
        "rigidtransformations": 1,
        "constitutes": 1,
        "smooth": 1,
        "intrinsic": 2,
        "correspond": 1,
        "morecommonly": 1,
        "regard": 1,
        "considering": 1,
        "nrigid": 1,
        "net": 2,
        "i=1": 2,
        "riemannian": 4,
        "mass": 2,
        "geodesic": 13,
        "m=argmin": 1,
        "yme/bracketleftbig": 1,
        "dist": 2,
        "2/bracketrightbig": 1,
        "wheremis": 1,
        "xand": 1,
        "yon": 1,
        "gaussnewton": 1,
        "iby": 1,
        "leftinvariant": 3,
        "mt+1=mtexpid/parenleftbigg1": 1,
        "n/sigma1logid/parenleftbig": 1,
        "m1": 1,
        "txi/parenrightbig/parenrightbigg": 1,
        "expidand": 1,
        "logidare": 1,
        "exponential": 1,
        "logarith": 1,
        "mic": 1,
        "composition": 1,
        "operator": 2,
        "isstraightforward": 1,
        "=e": 1,
        "xm": 1,
        "logarithmic": 1,
        "xmas": 1,
        "logm": 1,
        "overview": 1,
        "notion": 2,
        "algorithmshou": 1,
        "recovery": 1,
        "quaternioncart": 1,
        "esian": 1,
        "corre": 1,
        "sponding": 1,
        "inferred": 1,
        "deviate": 2,
        "perfect": 1,
        "isoscelestriangle": 1,
        "formation": 1,
        "overcome": 1,
        "p2defines": 1,
        "world": 1,
        "join": 1,
        "p1andp3aligns": 1,
        "bot": 1,
        "tom": 1,
        "reorient": 1,
        "tequals": 1,
        "concaten": 1,
        "ating": 1,
        "thenewly": 1,
        "/vectorv": 1,
        "1=p3p1and/vectorv2=p2p1": 1,
        "blue": 1,
        "/vectorv1/vectorv2gives": 1,
        "/vectorn1": 1,
        "/vectorn1/vectorv1": 1,
        "yaxis": 1,
        "/vectorn2": 1,
        "/vectorv1itself": 1,
        "xaxis": 1,
        "finally": 1,
        "/vectorv2": 1,
        "/vectorn2and/vectorn1are": 1,
        "concatenate": 1,
        "get": 1,
        "unable": 1,
        "coincide": 2,
        "definition": 1,
        "isregressed": 1,
        "independent": 2,
        "wei": 1,
        "ghts": 1,
        "randomly": 2,
        "initialise": 1,
        "predefined": 1,
        "nonidentical": 1,
        "close": 1,
        "proximity": 2,
        "rare": 1,
        "cases": 1,
        "type": 2,
        "identified": 2,
        "check": 2,
        "constraintthat": 1,
        "adhere": 1,
        "preexisting": 1,
        "iand": 1,
        "ti": 1,
        "ithat": 1,
        "utilized": 2,
        "us": 1,
        "verifywhether": 1,
        "/omega1can": 1,
        "iandti": 1,
        "iwere": 1,
        "/omega1for": 1,
        "qualitymetrics": 1,
        "examine": 6,
        "ior": 1,
        "iare": 1,
        "top": 2,
        "prune": 1,
        "skew": 1,
        "quantizing": 2,
        "16bit": 1,
        "8bit": 1,
        "reduces": 1,
        "noisepower": 1,
        "snr": 3,
        "96db": 1,
        "48db": 2,
        "=20": 1,
        "log": 2,
        "=482db": 1,
        "identification": 1,
        "impor": 2,
        "tant": 1,
        "mplementation": 1,
        "caffe": 2,
        "library": 1,
        "intel": 1,
        "i7": 1,
        "6700k": 1,
        "cpu": 1,
        "titan": 1,
        "pascal": 1,
        "project": 2,
        "scans": 1,
        "philipsachieva": 1,
        "15t": 2,
        "st": 1,
        "thomas": 1,
        "hospital": 1,
        "mother": 1,
        "tilt": 1,
        "left": 3,
        "side": 1,
        "avoid": 1,
        "pressure": 1,
        "inferior": 1,
        "vena": 1,
        "cava": 1,
        "comfort": 1,
        "eachsubject": 1,
        "thickness": 1,
        "=24": 1,
        "stdev": 1,
        "=1": 2,
        "l=120": 1,
        "representation": 3,
        "gener": 2,
        "ated": 2,
        "eulercartesian": 2,
        "quaternioncartesian": 3,
        "intervals": 1,
        "90to+90": 1,
        "tzaxis": 1,
        "40tz+": 1,
        "middle": 1,
        "total": 2,
        "224m": 1,
        "choose": 1,
        "8separation": 1,
        "additional": 4,
        "180with": 1,
        "18interval": 1,
        "between40": 1,
        "+40": 1,
        "zwith": 1,
        "336m": 1,
        "fashion": 1,
        "except": 1,
        "python": 1,
        "xperimentation": 1,
        "naive": 1,
        "progress": 1,
        "monitor": 1,
        "detail": 1,
        "present": 4,
        "newslice": 1,
        "/omega1and": 1,
        "compare": 6,
        "outline": 1,
        "section1744": 1,
        "relation": 1,
        "peak": 1,
        "signaltonoise": 1,
        "psnr": 7,
        "squared": 1,
        "mse": 7,
        "ssim": 4,
        "definitively": 1,
        "3dspace": 1,
        "distan": 3,
        "unitless": 2,
        "twose": 1,
        "displacement": 1,
        "search": 2,
        "m1/summationdisplay": 1,
        "in1/summationdisplay": 2,
        "jf": 1,
        "nis": 1,
        "f=f": 1,
        "/radicalbig": 2,
        "/summationtext": 2,
        "2andg=g": 1,
        "fidelity": 1,
        "deltaerror": 1,
        "=10log10": 1,
        "max2": 1,
        "max": 2,
        "mnm1/summationdisplay": 1,
        "luminance": 1,
        "wide": 2,
        "ofdegraded": 1,
        "drastically": 1,
        "perceptual": 1,
        "undesirable": 1,
        "trait": 1,
        "fg+c1": 1,
        "2fg+c2": 1,
        "f+2g+c1": 1,
        "f+2g+c2": 1,
        "fandgare": 1,
        "fand": 3,
        "grespectively": 2,
        "fand2": 1,
        "gare": 1,
        "fgis": 1,
        "covariance": 1,
        "c1=": 1,
        "k1l": 1,
        "2and": 1,
        "c2=": 1,
        "k2l": 1,
        "2are": 1,
        "stabi": 1,
        "lizes": 1,
        "division": 1,
        "weak": 1,
        "de": 1,
        "nominator": 1,
        "f+2": 2,
        "g0o": 1,
        "r2": 1,
        "g0": 1,
        "lis": 1,
        "k1=001": 1,
        "k2=003": 1,
        "default": 1,
        "constant": 1,
        "ed=1": 1,
        "/vextenddouble/vextenddouble/vextenddoublep": 1,
        "rigidtransformation": 1,
        "yis": 1,
        "tangent": 1,
        "xcan": 1,
        "gd=dist": 1,
        "=/vextenddouble/vextenddoublelogx": 1,
        "/vextenddouble/vextenddouble": 1,
        "describe": 2,
        "iie": 2,
        "networkbases": 1,
        "arch": 1,
        "itectures": 1,
        "givesthe": 1,
        "performancetotrainingtime": 1,
        "adam": 1,
        "optimizer": 1,
        "batch": 4,
        "rate": 2,
        "momentum": 1,
        "decay": 1,
        "itera": 1,
        "exception": 1,
        "utilizeda": 1,
        "memory": 2,
        "testing": 1,
        "table": 10,
        "analyze": 1,
        "prede": 1,
        "fined": 1,
        "euclid": 1,
        "ean": 1,
        "obvious": 1,
        "slicepredictions": 1,
        "outside": 1,
        "possess": 1,
        "threescaled": 1,
        "median": 2,
        "absolute": 1,
        "deviations": 1,
        "mad": 2,
        "=kmedian": 1,
        "imedian": 1,
        "five": 2,
        "attain": 5,
        "geodesicdistance": 1,
        "closely": 1,
        "manage": 1,
        "averag": 1,
        "bad": 3,
        "performing": 1,
        "much": 2,
        "great": 5,
        "efficiency": 1,
        "ideal": 1,
        "almost": 2,
        "half": 2,
        "timeif": 1,
        "importance": 1,
        "literature": 1,
        "emphasize": 1,
        "widely": 1,
        "thissection": 1,
        "empirical": 1,
        "exploration": 1,
        "alternative": 2,
        "experiment": 5,
        "ofhou": 1,
        "graph": 2,
        "row": 2,
        "showing": 1,
        "meanerror": 1,
        "eachevaluation": 1,
        "count": 1,
        "duration": 1,
        "architectures": 1,
        "iin": 2,
        "background": 1,
        "thenetwork": 1,
        "run": 1,
        "280k": 2,
        "6a": 1,
        "peri": 1,
        "odicity": 1,
        "indicate": 1,
        "cycle": 1,
        "dat": 1,
        "abase": 1,
        "slightly": 1,
        "database": 1,
        "involved": 1,
        "igeneration": 1,
        "profile": 1,
        "para": 1,
        "meter": 1,
        "increase": 2,
        "200k": 2,
        "previous": 1,
        "setup": 1,
        "6b": 1,
        "rescaling": 1,
        "periodic": 1,
        "suggest": 1,
        "slight": 1,
        "/omega1are": 1,
        "seven": 2,
        "increasing1746": 1,
        "trained": 2,
        "histogram": 1,
        "avg": 2,
        "distanceerror": 1,
        "verage": 1,
        "errors": 1,
        "datasets": 1,
        "40k": 2,
        "80k": 1,
        "120k": 1,
        "160k": 1,
        "240k": 1,
        "epoch": 2,
        "=iterations": 1,
        "lices": 1,
        "box": 1,
        "plot": 1,
        "score": 1,
        "chart": 2,
        "geo": 1,
        "desic": 1,
        "iif": 1,
        "quartile": 1,
        "ready": 1,
        "10mm": 1,
        "discuss": 1,
        "look": 1,
        "understanding": 1,
        "construction": 1,
        "differs": 1,
        "ization": 1,
        "favorable": 1,
        "accuracyspeed": 1,
        "tradeoff": 1,
        "posse": 1,
        "adopt": 1,
        "methodology": 1,
        "asbefore": 1,
        "5k": 1,
        "1k": 1,
        "pass": 1,
        "settable": 1,
        "ttestscores": 1,
        "comparing": 1,
        "ofvolumes": 1,
        "compared": 1,
        "volumes": 1,
        "sequential": 2,
        "sagittal": 4,
        "observe": 1,
        "head90": 1,
        "coronal": 3,
        "view": 2,
        "twotails": 1,
        "ttest": 1,
        "conduct": 1,
        "statisticalsignificance": 1,
        "tab": 1,
        "rega": 1,
        "rded": 1,
        "infinity": 1,
        "pvalues": 1,
        "infinitesimally": 1,
        "downstream": 2,
        "dataalignment": 1,
        "hard": 1,
        "prerequisite": 1,
        "synthetically": 1,
        "calculatethe": 1,
        "gaussian": 2,
        "ners": 1,
        "dismiss": 1,
        "impossible": 1,
        "extensive": 2,
        "validate": 2,
        "10a": 1,
        "bandc": 1,
        "excessive": 1,
        "ambiguity": 2,
        "turn": 1,
        "head": 1,
        "behou": 1,
        "orthogonally": 1,
        "unexpected": 1,
        "fit": 1,
        "normally": 1,
        "rejecting": 1,
        "manyslices": 1,
        "10d": 2,
        "svrbased": 1,
        "feed": 1,
        "timesthe": 1,
        "ofthe": 1,
        "boundary": 1,
        "decision": 1,
        "whether": 1,
        "sub": 1,
        "sequent": 1,
        "chosen": 2,
        "thresholded": 1,
        "canmake": 1,
        "let": 1,
        "handle": 2,
        "margin": 2,
        "experimentally": 1,
        "find": 4,
        "study": 1,
        "approx": 2,
        "allows": 1,
        "reliable": 1,
        "distinction": 1,
        "confident": 5,
        "ne": 1,
        "twork": 1,
        "minimal": 1,
        "intersectio": 1,
        "surface": 1,
        "prove": 1,
        "forexperienced": 1,
        "practitioner": 1,
        "wit": 1,
        "hout": 1,
        "iscussion": 1,
        "greatly": 2,
        "interslice": 1,
        "pr": 1,
        "edictions": 1,
        "effi": 1,
        "cient": 1,
        "parameterizatio": 1,
        "parameteri": 1,
        "zations": 1,
        "notably": 1,
        "yet": 1,
        "increasethe": 1,
        "attainable": 1,
        "fixed": 1,
        "hyper": 1,
        "configurations": 1,
        "satisfactory": 1,
        "registrationaccuracy": 1,
        "evidence": 1,
        "typical": 1,
        "benefit": 1,
        "trade": 1,
        "offs": 1,
        "hyperparameter": 2,
        "extremely": 1,
        "consuming": 1,
        "expensive": 1,
        "ofparameters": 1,
        "retrain": 1,
        "strength": 1,
        "exposure": 1,
        "particularly": 1,
        "problematic": 1,
        "addition": 1,
        "3t": 2,
        "successf": 1,
        "ully": 1,
        "experimentation": 2,
        "intramodality": 1,
        "retraining/transfer": 1,
        "advisedto": 1,
        "format": 1,
        "way": 2,
        "removal": 1,
        "restrict": 1,
        "whole": 1,
        "valuable": 1,
        "thewhole": 1,
        "implementation": 1,
        "nonrigid": 2,
        "deformation": 2,
        "oforgans": 1,
        "expect": 1,
        "pvr": 3,
        "primary": 1,
        "func": 1,
        "shortlist": 1,
        "iva": 1,
        "differentiable": 1,
        "intend": 1,
        "primarily": 1,
        "could": 1,
        "formance": 1,
        "opposition": 1,
        "hold": 1,
        "significantinfluence": 1,
        "ee": 1,
        "tually": 1,
        "ease": 1,
        "steps": 1,
        "2mm": 1,
        "intuitively": 1,
        "than1748": 1,
        "t2weighted": 1,
        "amount": 2,
        "ef": 1,
        "fort": 1,
        "experienced": 1,
        "scientist": 1,
        "rection": 1,
        "axial": 1,
        "respectively": 1,
        "direction": 2,
        "stack0": 1,
        "perfectly": 1,
        "realign": 1,
        "area": 2,
        "insufficient": 1,
        "miss": 1,
        "patient": 1,
        "whereas": 1,
        "igher": 1,
        "card": 1,
        "originally": 1,
        "compete": 1,
        "correctable": 1,
        "desirable": 1,
        "sideeffect": 1,
        "issue": 2,
        "human": 1,
        "determin": 1,
        "leftright": 1,
        "asymmetry": 1,
        "oversampling": 1,
        "lot": 1,
        "formispredicted": 1,
        "statistics": 1,
        "wrong": 1,
        "hemisphere": 1,
        "formulate": 1,
        "classi": 1,
        "fication": 1,
        "quan": 1,
        "tized": 1,
        "class": 4,
        "ourexperiments": 1,
        "kto": 1,
        "kclasses": 1,
        "lead": 1,
        "diffi": 1,
        "culties": 1,
        "reducingthe": 1,
        "onclusion": 1,
        "veryyoung": 1,
        "incorporation": 1,
        "examination": 1,
        "relax": 1,
        "temporal": 1,
        "scanplane": 1,
        "popular": 1,
        "repeat": 1,
        "experimentsit": 1,
        "occupy": 1,
        "transforma": 1,
        "bebeneficial": 1,
        "man": 1,
        "ifold": 1,
        "transformationparameters": 1,
        "accurately": 1,
        "pave": 1,
        "propagate": 1,
        "taskshou": 1,
        "acknowledgements": 1,
        "thank": 2,
        "volunteer": 1,
        "radiog": 1,
        "raphers": 1,
        "allsop": 1,
        "fox": 1,
        "mitk": 1,
        "irtk": 1,
        "publiclicense": 1,
        "ixico": 1,
        "ltd": 1,
        "nihr": 1,
        "research": 1,
        "gstt": 1,
        "nina": 1,
        "miolane": 1,
        "fruitful": 1,
        "discussion": 1,
        "access": 1,
        "line": 1,
        "informed": 1,
        "consent": 1,
        "participant": 1,
        "approval": 1,
        "ethic": 1,
        "board": 1,
        "formal": 1,
        "sharingagreement": 1
    },
    "objective": [
        "in this paper , we presenta learning-based image registration method capable ofpredicting 3-d rigid transformation of arbitrarily oriented2-d image slice , with respect to a learned canonical atlasco-ordinate system .",
        "the propose method can also be formulate as a classi- ﬁcation task , where each rigid transformation can be quan- tized as a class ."
    ],
    "references": [
        "",
        "R EFERENCES [1] P. Aljabar, R. Heckemann, A. Hammers, J. Hajnal, and D. Rueckert, “Multi-atlas based segmentation of brain images: Atlas selection and its effect on accuracy,” NeuroImage , vol. 46, no. 3, pp. 726–738, 2009. [2] S. Miao, Z. J. Wang, and R. Liao, “A CNN regression approach for real-time 2D/3D registration,” I E E ET r a n s .M e d .I m a g . , vol. 35, no. 5, pp. 1352–1363, May 2016. [3] S. P. Constantinos, M. S. Pattichis, and E. Micheli-Tzanakou, “Medical imaging fusion applications: An overview,” in Proc. 35th Conf. Rec. Asilomar Signals, Syst. Comput. , vol. 2. Nov. 2001, pp. 1263–1267. [4] IXI. (2017). The IXI Dataset . [Online]. Available: http://brain- development.org/ [5] E. Ferrante and N. Paragios, “Slice-to-volume medical image registra- tion: A survey,” Med. Image Anal. , vol. 39, pp. 101–123, Jul. 2017. [6] F. Rousseau et al. , “Registration-based approach for reconstruction of high-resolution in utero fetal MR brain images,” Acad. Radiol. , vol. 13, no. 9, pp. 1072–1081, 2006. [7] S. Jiang, H. Xue, A. Glover, M. Rutherford, D. Rueckert, and J. V . Hajnal, “MRI of moving subjects using multislice snapshot images with volume reconstruction (SVR): Application to fetal, neonatal, and adult brain studies,” IEEE Trans. Med. Imag. , vol. 26, no. 7, pp. 967–980, Jul. 2007. [8] A. Gholipour, J. A. Estroff, and S. K. Warﬁeld, “Robust super-resolution volume reconstruction from slice acquisitions: Application to fetal brainMRI,” IEEE Trans. Med. Imag. , vol. 29, no. 10, pp. 1739–1758, Oct. 2010. [9] K. Kim, P. A. Habas, F. Rousseau, O. A. Glenn, A. J. Barkovich, and C. Studholme, “Intersection based motion correction of multislice MRI for 3-D in utero fetal brain image formation,” I E E ET r a n s .M e d .I m a g . , vol. 29, no. 1, pp. 146–158, Jan. 2010. [10] M. Kuklisova-Murgasova, G. Quaghebeur, M. A. Rutherford, J. V . Hajnal, and J. A. Schnabel, “Reconstruction of fetal brain MRI with intensity matching and complete outlier removal,” Med. Image Anal. , vol. 16, no. 8, pp. 60–1550, 2012. [11] B. Kainz et al. , “Fast volume reconstruction from motion corrupted stacks of 2D slices,” I E E ET r a n s .M e d .I m a g . , vol. 34, no. 9, pp. 1901–1913, Sep. 2015. [12] A. Alansary et al. , “PVR: Patch-to-volume reconstruction for large area motion correction of fetal MRI,” I E E ET r a n s .M e d .I m a g . , vol. 36, no. 10, pp. 2031–2044, Oct. 2017. [13] S. C. Park, M. K. Park, and M. G. Kang, “Super-resolution image reconstruction: A technical overview,” IEEE Signal Process. Mag. , vol. 20, no. 3, pp. 21–36, May 2003. [14] H. J. Johnson and G. E. Christensen, “Consistent landmark and intensity- based image registration,” IEEE Trans. Med. Imag. , vol. 21, no. 5, pp. 450–461, May 2002. [15] P. Markelj, D. Tomaževic, B. Likar, and F. Pernuš, “A review of 3D/2D registration methods for image -guided interventions,” Med. Image Anal. , vol. 16, no. 3, pp. 642–661, 2012. [16] F. P. M. Oliveira and J. M. R. S. Tavares, “Medical image registration: Ar e v i e w , ” Comput. Methods Biomech. Biomed. Eng. , vol. 17, no. 2, pp. 73–93, 2014. [17] G. P. Penney, J. Weese, J. A. Little, P. Desmedt, D. L. G. Hill, and D. J. Hawkes, “A comparison of similarity measures for use in 2-D-3-Dmedical image registration,” IEEE Trans. Med. Imag. , vol. 17, no. 4, pp. 586–595, Aug. 1998. [18] R. C. Susil et al. , “Transrectal prostate biopsy and ﬁducial marker placement in a standard 1.5 T magnetic resonance imaging scanner,” J. Urol. , vol. 175, no. 1, pp. 113–120, 2006.[19] B. Kainz, M. Grabner, and M. Rüther, “Fast marker based C-arm pose estimation,” in Medical Image Computing and Computer-Assisted Intervention . Berlin, Germany: Springer, 2008, pp. 652–659. [20] M. Simonovsky, B. Gutiérrez-Becker, D. Mateus, N. Navab, and N. Komodakis, “A deep metric for multimodal registration,” in Med- ical Image Computing and Com puter-Assisted Intervention .C h a m , Swizerland: Springer, 2016, pp. 10–18. [21] Y . Pei et al. , “Non-rigid craniofacial 2D-3D registration using CNN- based regression,” in Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support . Cham, Switzerland: Springer, 2017, pp. 117–125. [22] M. Fogtmann et al. , “A uniﬁed approach to diffusion direction sensitive slice registration and 3-D DTI reconstruction from moving fetal brain anatomy,” IEEE Trans. Med. Imag. , vol. 33, no. 2, pp. 272–289, Feb. 2014. [23] S. Tourbier, X. Bresson, P. Hagm ann, J.-P. Thiran, R. Meuli, and M. B. Cuadra, “An efﬁcient total variation algorithm for super-resolutionin fetal brain MRI with adaptive regularization,” NeuroImage , vol. 118, pp. 584–597, Sep. 2015. [24] A. Kendall, M. Grimes, and R. Cipolla, “PoseNet: A convolutional network for real-time 6-DOF camera relocalization,” in Proc. IEEE Int. Conf. Comput. Vis. (ICCV) , Dec. 2015, pp. 2938–2946. [25] B. Hou et al. , “Predicting slice-to-volume transformation in presence of arbitrary subject motion,” in Medical Image Computing and Computer- Assisted Intervention—MICCAI (Lecture Notes in Computer Science), vol. 10434, M. Descoteaux, L. Maie r-Hein, A. Franz, P. Jannin, D. Collins, and S. Duchesne, Eds. Cham, Switzerland: Springer, 2017. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3- 319-66185-8_34 [26] Y . Gal and Z. Ghahramani, “Dropout as a Bayesian approximation: Representing model uncertainty in deep learning,” in Proc. Mach. Learn. Res. (ICML) , vol. 48. Jun. 2016, pp. 1050–1059. [27] N. Miolane, “Deﬁning a mean on Lie group,” M.S. thesis, Imperial College London, London, U.K., Sep. 2013. [28] M. Rajchl et al. (2016). “Learning under distributed weak supervision.” [Online]. Available: https://arxiv.org/abs/1606.01100 [29] M. Rajchl et al. (Nov. 2017). Deep Learning Toolkit DLTK/Models . [Online]. Available: https://github.com/DLTK/ models/tree/master/fetal_brain_segmentation_mri [30] E. Konukoglu, B. Glocker, D. Zi kic, and A. Criminisi, “Neighbourhood approximation using randomized forests,” Med. Image Anal. , vol. 17, no. 7, pp. 790–804, Oct. 2013. [31] K. Keraudren et al. , “Automated fetal brain segmentation from 2D MRI slices for motion correction,” NeuroImage , vol. 101, pp. 633–643, Nov. 2014. [32] K. Keraudren et al. , “Automated localization of fetal organs in MRI using random forests with steerable features,” in Proc. MICCAI , 2015, pp. 620–627. [33] A. Gholipour et al. , “Maximum a posteriori estimation of isotropic high-resolution volumetric MRI fro m orthogonal thick-slice scans,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assisted Intervent. , 2010, pp. 109–116. [34] S. S. M. Salehi et al. (Oct. 2017). “Real-time automatic fetal brain extraction in fetal MRI by deep learning.” [Online]. Available: https:// arxiv.org/abs/1710.09338 [35] Á. González, “Measurement of areas on a sphere using Fibonacci and latitude–longitude lattices,” Math. Geosci. , vol. 42, no. 1, p. 49, 2009. [36] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation with deep convolutional neural networks,” in Proc. Adv. Neural Inf. Process. Syst. , 2012, pp. 1097–1105. [37] K. Simonyan and A. Zisserman. (2014). “Very deep convolutional networks for large-scale image recogn ition.” [Online]. Available: https:// arxiv.org/abs/1409.1556 [38] C. Xu et al. , “Multi-loss regularized deep neural network,” IEEE Trans. Circuits Syst. Video Technol. , vol. 26, no. 12, pp. 2273–2283, Dec. 2016. [39] Y . Jia et al. . (2014). “Caffe: Convolutional architecture for fast feature embedding.” [Online]. Available: https://arxiv.org/abs/1408.5093 [40] C. Szegedy et al. , “Going deeper with convolutions,” in Proc. Comput. Vis. Pattern Recognit. (CVPR) , Jun. 2015, pp. 1–9. [41] C. Szegedy et al. , “Inception-v4, inception-resnet and the impact of residual connections on learning,” in Proc. AAAI ,v o l .4 . 2017, pp. 4278–4284. [Online]. Available: http://www.aaai.org/ ocs/index.php/AAAI/AAAI17/paper/download/14806/143111750 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 37, NO. 8, AUGUST 2018 [42] M. Lin, Q. Chen, and S. Yan. (2013) “Network in network.” [Online]. Available: https://arxiv.org/abs/1312.4400 [43] K. He, X. Zhang, S. Ren, an d J. Sun, “Deep residual learning for image recognition,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2016, pp. 770–778. [Online]. Available: http:// openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_ Learning_CVPR_2016_paper.pdf [44] K. Simonyan and A. Zisserman. (Sep. 2014). “Very deep convolu- tional networks for large-scale image recognition.” [Online]. Available: https://arxiv.org/abs/1409.1556 [45] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: A simple way to prevent neural networks from overﬁtting,” J. Mach. Learn. Res. , vol. 15, no. 1, pp. 1929–1958, 2014. [46] A. Kendall and Y . Gal, “What uncertainties do we need in bayesian deep learning for computer vision?” in Proc. Adv. Neural Inf. Process. Syst. , 2017, pp. 5580–5590. [Online]. Available: http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in- bayesian-deep-learning-for-computer-vision[47] G. F. Cooper, “The computational complexity of probabilistic infer- ence using Bayesian belief networks,” Artif. Intell. , vol. 42, no. 2, pp. 393–405, 1990. [48] Y . Gal and Z. Ghahramani, “Bayesi an convolutional neural networks with Bernoulli approximate va riational inference,” in Proc. 4th Int. Conf. Learn. Represent. (ICLR) Workshop Track , 2016, pp. 1–12. [49] X. Pennec, “Intrinsic statistics o n Riemannian manifolds: Basic tools for geometric measurements,” J. Math. Imag. Vis. , vol. 25, no. 1, pp. 127–154, 2006. [50] X. Pennec, “Statistical computin g on manifolds for computational anatomy,” Ph.D. dissertation, De pt. Comput. Sci., Univ. Nice Sophia Antipolis, Nice, France, 2006. [51] (2017). iFIND: Intelligent Fetal Imaging and Diagnosis . [Online]. Available: http://www.iﬁndproject.com [52] J.-F. Pambrun and R. Noumeir, “Limitations of the SSIM quality metric in the context of diagnostic imaging,” in Proc. IEEE Int. Conf. Image Process. (ICIP) , Sep. 2015, pp. 2960–2963. [53] I. Wolf et al. , “The medical imaging interaction toolkit,” Med. Image Anal. , vol. 9, no. 6, pp. 594–604, 2005."
    ]
}{
    "name": "Anatomically Constrained Neural Networks (ACNNs): Application to Cardiac Image Enhancement and Segmentation",
    "paragraphs": [
        "384 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 anatomically constrained neural networks ( acnns ) : application to cardiac image enhancement and segmentation ozan oktay , enzo ferrante , konstantinos kamnitsas , mattias heinrich , wenjia bai , jose caballero , stuart a. cook , antonio de marvao , timothy dawes , declan p .",
        "o ’ regan , bernhard kainz , ben glocker , and daniel rueckert abstract —incorporation of prior knowledge about organ shape and location be key to improve performance of imageanalysis approach .",
        "in particular , prior can be useful inca where image be corrupt and contain artefact dueto limitation in image acquisition .",
        "the highly constrainednature of anatomical object can be well captured withlearning-based technique .",
        "however , in most recent andpromising technique such as cnn-based segmentationit be not obvious how to incorporate such prior knowl-edge .",
        "state-of-the-art method operate as pixel-wise clas-siﬁers where the training objective do not incorporate thestructure and inter-dependencies of the output .",
        "to over-come this limitation , we propose a generic training strategythat incorporate anatomical prior knowledge into cnnsthrough a new regularisation model , which be trained end-to-end .",
        "the new framework encourage model to followthe global anatomical property of the underlie anatomy ( e.g.shape , label structure ) via learnt non-linear represen- tations of the shape .",
        "we show that the propose approachcan be easily adapt to different analysis task ( e.g.image enhancement , segmentation ) and improve the predictionaccuracy of the state-of-the-art model .",
        "the applicability ofour approach be show on multi-modal cardiac data set andpublic benchmark .",
        "in addition , we demonstrate how thelearnt deep model of 3-d shape can be interpret andused as biomarkers for classiﬁcationof cardiacpathologies .",
        "index terms —shape prior , convolutional neural network , medical image segmentation , image super-resolution .",
        "i .",
        "introduction image segmentation technique aim to partition an image into meaningful part which be use for further analysis .",
        "the segmentation process be typically drive by both the manuscript receive july 26 , 2017 ; accept august 14 , 2017 .",
        "date of publication september 26 , 2017 ; date of current version february 1 , 2018 .",
        "this work be support in part by an epsrc program undergrant ep/p001009/1 , in part by the british heart foundation , u.k. , under grant pg/12/27/29489 , in part by the national institute for health research ( nihr ) biomedical research centre-based at imperial col-lege healthcare nhs trust .",
        "( corresponding author : ozan oktay . )",
        "o. oktay , e. ferrante , k. kamnitsas , w. bai , j. caballero , b. kainz , b. glocker , and d. rueckert be with the biomedical image analy- si group , imperial college london , london sw7 2az , u.k. ( e-mail : o.oktay13 @ imperial.ac.uk ) .",
        "m. heinrich be with the institute of medical informatics , university of lübeck , 23538 lübeck , germany .",
        "s. a. cook , a. de marvao , t. dawes , and d. p .",
        "o ’ regan be with the mrc clinical sciences centre , london w12 0nn , u.k. color version of one or more of the ﬁgures in this paper be available online at http : //ieeexplore.ieee.org .",
        "digital object identiﬁer 10.1109/tmi.2017.2743464underlying data and a prior on the solution space , where the latter be useful in case where the image be corrupt or con- tain artefact due to limitation in the image acquisition .",
        "for example , bias ﬁelds , shadow , signal drop-out , respiratory motion , and low-resolution acquisition be the few commonlimitations in ultrasound ( us ) and magnetic resonance ( mr ) imaging .",
        "incorporating prior knowledge into image segmentation algorithm have prove useful in order to obtain more accurate and plausible result as summarise in the recent survey [ 32 ] .",
        "prior information can take many form : boundary and edge polarity [ 10 ] ; shape model [ 13 ] , [ 14 ] ; topology speciﬁcation ; distance prior between region ; atlas model [ 5 ] , which werecommonly use as a regularisation term in energy optimisation base traditional segmentation method ( e.g .",
        "region grow ) .",
        "in particular , atlas prior be well suit for medical imagingapplications since they enforce both location and shape prior through a set of annotated anatomical atlas .",
        "similarly , auto- context model [ 45 ] have make use of label and image prior in segmentation , which require a cascade of model .",
        "in the context of neural network ( nns ) , early work on shape analysis have focus on learn generative mod- el through deep boltzmann machines ( dbms ) , namely shapebm [ 18 ] that use a form of dbm with sparse pixelconnectivity .",
        "follow-up work in [ 9 ] and [ 17 ] have demonstrate the application of dbms to binary segmentation problem in natural image contain vehicle and other type of object .",
        "however , fully connect dbm for image require a large number of parameter and consequently model train maybecome intractable depend on the size of image .",
        "for this reason , convolutional deep belief net [ 48 ] be recently propose for encode shape prior information .",
        "besides varia-tional model , cascade convolutional architecture [ 27 ] , [ 37 ] have be show to discover prior on shape and structure in label space without any a priori speciﬁcation .",
        "however , this come at the cost of increased model complexity and computational need .",
        "in the context of medical imaging and neural network , anatomical prior have not be study in much depth , particularly in the current state-of-the-art segmentation tech-niques [ 11 ] , [ 22 ] , [ 36 ] , [ 38 ] .",
        "recent work have show simple use case of prior through adjacency [ 7 ] and boundary [ 10 ] condition .",
        "inclusion of prior in medical imaging could this work be license under a creative commons attrib ution 3.0 license .",
        "for more information , see h ttp : //creativecommons.o rg/licenses/by/3.0/oktay et al .",
        ": acnns : application to cardiac image enhancement and segmentation 385 potentially have much more im pact compare to their use in natural image analysis sinc e anatomical object in medical image be naturally more constrained in term of their shape and location .",
        "as explain in a recent nn survey paper [ 28 ] , the majority of the classiﬁcation and regression model utilise a pixel- level loss function ( e.g.cross-entropy or mean square error ) which do not fully take into account the underlying semantic information and dependency in the output space ( e.g .",
        "class label ) .",
        "in this paper , we present a novel and generic way to incorporate global shape/label information into nns .",
        "the propose approach , namely anatomically constrain neuralnetworks ( acnn ) , be mainly motivate by the early work on shape prior and image segmentation , in particular pca base statistical [ 13 ] and active shape model [ 14 ] .",
        "our frameworklearns a non-linear compact representation of the underlying anatomy through a stacked convolutional autoencoder [ 31 ] and enforces network prediction to follow the learnt statistical shape/label distribution .",
        "in other word , it favour prediction that lie on the extract low dim ensional data manifold .",
        "more importantly , our approach be independent of the particular nn architecture or applicati on ; it can be combine with any of the state-of-the-art segmentation or super-resolution ( sr ) nn model and potentially impr ove its prediction accuracy and robustness without introduce any memory or computational complexity at inference time .",
        "lastly , acnn model , train with the propose prior term which act as a regulariser , remove the need for post-processing step such as conditionalrandom ﬁelds [ 24 ] which be often base on heuristic para- meter tune .",
        "in acnn , the regularisation be part of the end- to-end learning which can be a great advantage .",
        "the propose global training objective in sr corresponds to a prior on the space of feasible high-resolution ( hr ) solution , which be experimentally show to be useful since sr be an ill- posed problem .",
        "similar modiﬁcations of the objective function during training have be introduce to enhance the quality ofnatural image , such as perceptual [ 21 ] and adversarial [ 26 ] loss term , which be use to synthesise more realistic image in term of texture and object boundary .",
        "in thecontext of medical imaging , our prior enforce the synthesised hr image to be anatomically meaningful while minimise a traditional image reconstruction loss function .",
        "a .",
        "clinical motivation cardiac imaging have an important role in diagnosis , pre- operative planning , and post-ope rative management of patient with heart disease .",
        "imaging modality such as us and cardiacmr ( cmr ) be widely use to provide detailed assessment of cardiac function and morphology .",
        "each modality be suitable for particular clinical use case ; for instance , 2d-us be still theﬁrst line of choice due to its low cost and wide availability , whereas , cmr be a more comprehensive modality with excel- lent contrast for both anatomical and functional evaluation of the heart [ 23 ] .",
        "similarly , 3d-us be recommend over the use of 2d-us since it have be demonstrate to provide moreaccurate and reproducible volu metric measurement [ 25 ] .",
        "some of the standard clinical acquisition protocol in 3d-us and cmr still have limitation in visualise the fig .",
        "1 .",
        "results for cardiac mr super-resolution ( sr ) ( top ) , mr seg- mentation ( middle ) , and ultrasound ( us ) segmentation ( bottom ) .",
        "fromleft to right , we show the input image , a state-of-the-art competingmethod , the propose result , and the ground-truth .",
        "( a ) stack of 2d mr image with respiratory motion artefact , ( b ) sr base on cnns [ 34 ] , ( c ) the propose acnn-sr , ( d ) ground-truth high-resolution ( hr ) image , ( e ) low resolution mr image , ( f ) 2d segmentation result in blocky contour [ 44 ] , ( g ) 3d sub-pixel segmentation from stack of 2d mr image use acnn , ( h ) manual segmentation from hr image , ( i ) input 3d-us image , ( j ) fcn base segmentation [ 11 ] , ( k ) acnn , and ( l ) manual segmentation .",
        "underlie anatomy due to image artefact ( e.g .",
        "cardiac motion , low slice resolution , lack of slice coverage [ 35 ] ) or operator-dependent error ( e.g .",
        "shadow , signal drop-outs ) .",
        "in the clinical routine , these challenge be usually tack- lead through multiple acquisition of the same anatomy andrepeated patient breath-holds lead to long examination time .",
        "similar problem have be report in large cohort study such as the uk biobank [ 35 ] , which lead to inaccuratequantitative measurement or even the discarding of acquire image .",
        "as can be see in fig .",
        "1 , the exist state-of- the-art convolutional neural n etwork ( cnn ) approach for segmentation [ 11 ] , [ 44 ] and image enhancement [ 34 ] task perform poorly when the input data be not self-consistent forthe analysis .",
        "for this reason , incorporation of prior knowledge into cardiac image analysis c ould provide more accurate and reliable assessment of the anatomy , which be show in the thirdcolumn of the same ﬁgure .",
        "most importantly , the propose acnn model allow us to perform hr analysis via sub- pixel feature map generate from low resolution ( lr ) input data even in the presence of motion artefact .",
        "using the propose approach we can perform full 3d segmentationwithout explicit motion correction and do not have to rely on lr slice-by-slice 2d segmentation .",
        "we demonstrate the applicab ility of the propose approach for cine stack of 2d mr and 3d-us datasets compose of 1200 and 45 cardiac image sequence respectively .",
        "we show that the propose segmentation and sr model becomemore robust against image artefact mention early which be underline by our state-of-the-art result on the miccai ’ 14 cetus public benchmark [ 8 ] .",
        "we also demon- strate that the low dimensional representation learn by the propose acnn can be useful for classiﬁcation of pathologiessuch as dilated and hypertrophic cardiomyopathy , and it do not require point-wise correspondence search between sub- jects as in [ 39 ] .",
        "for the evaluation , the miccai ’ 17 ac/dc386 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 fig .",
        "2 .",
        "block diagram of the baseline segmentation ( seg ) and super-resolution ( sr ) model which be combine with the propose t-l regularisation block ( show in fig .",
        "3 ) to build the acnn-seg/sr framework .",
        "in sr , the illustrated model extract sr feature in low-resolution ( lr ) space , which increase computational efﬁciency .",
        "in segmentation , the model achieve sub-pixel accuracy for give lr input image .",
        "the skip connection between the layer be show in red .",
        "classiﬁcation benchmark be use .",
        "in that regard , the propose method be not only useful for image enhancement and segmen- tation but also for the study of anatomical shape variation in population study and their association with cardiac relatedpathologies .",
        "b .",
        "contributions in this study , we propose a generic and novel technique to incorporate prior on shape and label structure into nns formedical image analysis task .",
        "in this way , we can constrain the nn training process and guide the nn to make anatomically more meaningful prediction , in particular in case where the input image data be not informative or consistent enough ( e.g .",
        "miss object boundary ) .",
        "more importantly , to the best of our knowledge , this be one of the early study demonstrate the use of convolutional autoencoder network to learn anatomical shape var iations from medical image .",
        "the propose acnn model be evaluate on multi-modal cardiac datasets from mr and us .",
        "our evaluation show : ( i ) a sub-pixel cardiac mr image segmentation approachthat , in contrast to previous cnn approach [ 2 ] , [ 44 ] , be robust against slice misalignment and coverage problem ; ( ii ) an implicit statistical parametrisation of the left ventricu- lar shape via nns for pathology classiﬁcation ; ( iii ) an image sr technique that extend previous work [ 34 ] and that be robustagainst slice misalignment ; our approach be computationally more efﬁcient than the state-of-the-art sr-cnn model [ 34 ] as the feature extraction be pe rformed in the low-dimensional image space .",
        "( iv ) last , we demonstrate state-of-the-art 3d-us cardiac segmentation result on the cetus ’ 14 benchmark .",
        "ii .",
        "m ethodology in the next section , we brieﬂy summarise the state-of-the- art methodology for image segmentation ( seg ) and super- resolution ( sr ) , which be base on convolutional neural net- work ( cnns ) .",
        "we then present a novel methodology thatextends these cnn model with a global training objec- tive to constrain the output space by impose anatomical shape prior .",
        "for this , we propose a new regularisation networkthat be base on the t-l architecture which be use in computer graphic [ 19 ] to 3d render object from natural image .",
        "a .",
        "medical image segmentation with cnn models letys= { yi } i∈sbe an image of class label represent different tissue type with yi∈l= { 1,2 , ... c } .f u r t h e r m o r e letx= { xi∈ r , i∈s } be the observed intensity image .",
        "the aim of image segmentation be to estimate y have observe x .",
        "in cnn base segmentation model [ 22 ] , [ 29 ] , [ 38 ] , this task be perform by learn a discriminative function that model the underl ying conditional probability distribution p ( ys|x ) .",
        "the estimation of class density p ( ys|x ) consist in assign- ing to each xithe probability of belong to each of the cclasses , yield csets of class feature map fcthat be extract through learnt non-linear function .",
        "the ﬁnal decision for class label be then make by apply softmaxto the extracted class featur e map , in the case of cross- entropy l x=−/summationtextc c=1/summationtext i∈slog/parenleftbigg ef ( c , i ) /summationtext jef ( j , i ) /parenrightbigg these feature map correspond to log likelihood value .",
        "as in the u-net [ 38 ] and deepmedic [ 22 ] model , we learn the mapping between intensity and label φ ( x ) : x→lby optimise the average cross-entropy loss of each class lx=/summationtextc c=1l ( x , c ) use stochastic gradient descent .",
        "as show infig .",
        "2 , the mapping function φis compute by pass the input image through a series of convolution layer and rectiﬁed linear unit across diffe rent image scale to enlarge the model ’ s receptive ﬁeld .",
        "the presented model be com-posed of two part : feature extraction ( analysis ) similar to a vgg-net [ 42 ] and reconstruction ( synthesis ) as in the case of a 3d u-net [ 38 ] .",
        "however , in contrast to exist approach , we aim for sub-pixel segment ation accuracy by train up-sampling layer with high-resolution ground-truth maps.this enable 3d analysis of the underlie anatomy in case of thick slice 2d image stack acquisition such as cine cardiac mr imaging .",
        "in this way , it be possible to perform analysisoktay et al .",
        ": acnns : application to cardiac image enhancement and segmentation 387 fig .",
        "3 .",
        "block diagram of the stacked convolutional autoencoder ( ae ) net- work ( in grey ) , which be train with segmentation label .",
        "the ae model be couple with a predictor network ( in blue ) to obtain a compact non-linear representation that can be extract from both intensity andsegmentation image .",
        "the whole model be name as t-l network .",
        "on the high-resolution image grid without any precede upsampling operation with a sr model [ 34 ] .",
        "similar segmentation framework ( cf .",
        "[ 28 ] ) have be stud- ied in medical imaging .",
        "however , in most of the exist method , the model be supervise purely through a local loss function at pixel level ( e.g.cross-entropy , dice ) without exploit the global dependency and structure in the output space .",
        "for this reason , the global description of prediction be usually not adhere to shape , label , or atlas prior .",
        "in con-trast to this we propose a model that can incorporate the aforementioned prior in segmentation model .",
        "the propose framework relies on autoencoder and t-l network model to obtain a non-linear compact representation of the underlie anatomy , which be use as prior in segmentation .",
        "b. convolutional autoencoder model and acnn-seg an autoencoder ( ae ) [ 46 ] be a neural network that aim to learn an intermediate represent ation from which the original input can be reconstruct .",
        "internally , it have a hidden layer hwhose activation represent the input image , often refer ascodes .",
        "to avoid the ae to directly copy its output , the ae be often design to be undercomplete so that the size of the code be less than the input dimension as show in fig .",
        "3 .",
        "learning an ae force the network to capture the most salient feature of the training data .",
        "th e learning procedure minimise a loss function lx ( ys , g ( f ( ys ) ) ) , w h e r e lxis penalising g ( f ( ys ) ) be dissimilar from y .",
        "the function gand fare deﬁned as the decoder and encoder component of the ae .",
        "in the propose method , the ae be integrate into the stan- dard segmentation network , describe in sec .",
        "ii-a , as a regu- larisation model to constrain class label prediction ytowards anatomically meaningful an d accurate output .",
        "the cross- entropy loss function operate on individual pixel level class prediction , which do not guarantee global consistency and plausible anatomical shape even though the segmentation network have a receptive ﬁeld larg er than the size of structure to be segment .",
        "this be due to the fact that back-propagated gradient be parametrised only by pixel-wise individual prob- ability divergence term and thus provide little global context .",
        "fig .",
        "4 .",
        "training scheme of the propos ed anatomically constrain convolutional neural network ( acnn ) for image segmentation and super- resolution task .",
        "the propose t-l network be use as a regularisation model to enforce the model prediction to follow the distribution of thelearnt low dimensional representation or prior .",
        "to overcome this limitation , class prediction label map be pass through the ae to obtain a low dimensional ( e.g.64 dimension ) parametrisation of the segmentation and its underlying structure [ 40 ] .",
        "by perform ae-based non-linear low dimensional projection on both prediction and ground-truth label , as show in fig .",
        "4 , we can build our acnn-seg training objective function though a linear combi-nation of cross-entropy ( l x ) , shape regularisation loss ( lhe ) , and weight decay term as follow : lhe=/vextenddouble/vextenddoublef ( φ ( x ) ; θf ) −f ( y ; θf ) /vextenddouble/vextenddouble2 2 min θs/parenleftbigg lx ( φ ( x ; θs ) , y ) +λ1·lhe+λ2 2||w||2 2/parenrightbigg ( 1 ) herewcorresponds to weight of the convolution ﬁlters , andθsdenotes all trainable parameter of the segmentation model and only these parameter be update during training.the couple parameter λ 1andλ2determine the weight of shape regularisation loss and weight decay term use in the training .",
        "in this equation , the second term lheensures that the generated segmentation be in a similar low dimensional space ( e.g.shape manifold ) as the ground-truth label .",
        "in addi- tion to impose shape regularisation , this parametrisationencourages label consistency in model prediction , and reduce false-positive detection as th ey can inﬂuence the predicted code in the hidden layer .",
        "the third term corresponds to weight decay to limit the number of free parameter in the model to avoid over-ﬁtting .",
        "the propose ae model iscomposed of convolutional layer and a fully connect layer in the middle as show in fig .",
        "3 , which be similar to the stack convolutional autoencoder model propose in [ 31 ] .388 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 the ae model detail ( e.g .",
        "layer conﬁguration , parameter choice ) be provide in the supplementary material .",
        "c. medical image super-resolution ( sr ) with cnns super-resolution ( sr ) image generation be an inverse prob- lem where the goal be to recover spatial frequency information that be outside the spatial bandwidth of the low resolution ( lr ) observation x∈rnto predict a high resolution ( hr ) image yr∈rm ( n\u0004m ) , as illustrate in the top row of fig .",
        "1 .",
        "since the high frequency component be miss in the obser- vation space , usually train example be use to predict the most likely p ( yr|x ) hr output .",
        "image sr be an ill-posed problem as there be an inﬁnite number of solution for a give input sample but only a few would be anatomically meaningful and accurate .",
        "as for the case of image segmentation , learnt shape representation can be use to regularise image sr , constrain the model to make only anatomically meaningfulpredictions .",
        "similar to the sr framework describe in [ 34 ] , our propose sr model learn a mapping function \u0004 : x→yto estimate a high-resolution image ˆy r=\u0004 ( x ; θr ) where θrdenotes the model parameter such as con volution kernel and batch- normalisation statistic .",
        "the parameter be optimise by min-imising the smooth \u0005 1loss , also know as huber loss , between the ground-truth high resolution image and the corresponding prediction .",
        "the smooth \u00051norm be deﬁned as \u0006\u00051 ( k ) = { 0.5k2if|k| < 1 , |k|−0.5o t h e r w i s e } and the sr training objective becomes min θr/summationtext i∈s\u0006\u00051/parenleftbig \u0004 ( xi ; θr ) −yi/parenrightbig in the propose sr framework , we use the same model as show in fig .",
        "2 .",
        "it provide two main advantage over the state-of-the-art medical image sr model propose in [ 34 ] : ( i ) the network generate image feature in the lr image grid rather than early upsamp ling of the feature , which reduce memory and computation requirement signiﬁcantly .",
        "as highlight in [ 41 ] , early upsampling introduces redundantcomputations in the hr space since no additional information be add into the model by perform transpose convolu- tions [ 49 ] at an early stage .",
        "( ii ) the second advantage be theuse of a large receptive ﬁeld to learn the underlying anatomy , which be not the case in early sr method use in medical imaging [ 34 ] and natural imag e analysis [ 16 ] , [ 41 ] because these model usually operate on local patch level .",
        "capturing large context indeed help our model to good understand theunderlying anatomy and this enable us to enforce global shape constraint .",
        "this be achieve b y generate sr feature-maps in multiple scale use multi stride in the in-plane direction .",
        "similar to the acnn-seg model , it be possible to regu- larise sr model to synthesise anatomically more meaningful hr image .",
        "to achieve this goal , we extend the standard ae model to the t-l model which enable us to obtain shape representation code directly fro m the intensity space .",
        "the idea be motivate by the recent work [ 19 ] on 3d shape analysis in natural image .",
        "in the next section we will explain the training strategy and the use of the t-l model as a regulariser .",
        "d. t -l network model and sr-acnn shape encode ae model operate only on the segmen- tation mask and this limit its application to sr problemwhere the model output be an intensity image .",
        "to circumvent this problem , we extend the standard denoising ae to the t-l regularisation model by combine the ae with a pre- dictor network ( fig .",
        "3 ) p ( x ) : x→h .",
        "the predictor can map an input image into a low dimensional non-parametric representation of the underlie anatomy ( e.g.shape and class label information ) , which be learn by the ae .",
        "in other word , it enable us to learn a hidden rep resentation space that can be reach by non-linear mapping from both image label space yand image intensity space x .",
        "in this way , sr model can be regularise as well with respect to learn anatomical prior .",
        "this network architecture be useful in image analysis appli- cation for two main reason : ( i ) it enable us to build a regularisation network that could be use in application dif- ferent than image segmentation such as image sr. we proposeto use this new regularisation network at training time of sr to enforce the model to learn global information about the image besides the standard pixel-wise ( \u0005 1distance ) image reconstruction loss .",
        "in this way , the regressor sr model be guide by the additional segmentation information , and itbecomes robust against image artefact and miss infor- mation .",
        "( ii ) the second important feature of the t-l model be the generalisation of the learnt representation .",
        "joint trainingof the ae and predictor enables us to learn representation that could be extract from both intensity and label space .",
        "the learnt code will encode the variation that could be interpret from both manual annotation and intensity image .",
        "since a perfect mapping between the intensity and label space ispractically not achievable , the t-l learnt code be expect to be more representative due to the inclusion of additional information .",
        "the t-l model be train in two stage : in the ﬁrst stage , the ae be train separately with ground-truth segmentation mask and cross-entropy loss l x .",
        "later , the predictor model be train to match the learnt latent space hby minimise the euclidean distance lhbetween the code predict by the ae and predictor as show in fig .",
        "3 .",
        "once the loss function for both the ae and the predictor converge , the two model be train jointly in the second stage .",
        "the encoder fis update use two separate back-propagated gradient ( ∂lx ∂θf , ∂lh ∂θf ) and the two loss function be scale to match their range .",
        "the ﬁrst gradient encourage the encoder to generate code that couldbe easily extract by the predictor while the second gradient making sure that a good segmentation-reconstruction can be obtain at the output of the decoder .",
        "training detail be far discuss in section iii-b .",
        "it be important to note that the t-l regulariser model be use only at training time but notduring inference ; in other word , the fully convolutional ( fcn ) segmentation and super-resolution model can still be use for application use different image size .",
        "in this paper , the propose sr model be refer to as acnn-sr and its training scheme be show in the bottom part of fig .",
        "4 .",
        "l hp=/vextenddouble/vextenddoublep ( \u0004 ( x ) ; θp ) −p ( yr ; θp ) /vextenddouble/vextenddouble2 2 min θr/parenleftbigg \u0006\u00051/parenleftbig \u0004 ( x ; θr ) −yr/parenrightbig +λ1·lhp+λ2 2||w||2 2/parenrightbigg ( 2 ) oktay et al .",
        ": acnns : application to cardiac image enhancement and segmentation 389 fig .",
        "5 .",
        "histogram of the learnt low-dimensional latent representa- tions ( randomly select 16 component be show ) .",
        "the code in general follow a smooth and normal distribution which be important for the training of acnn model . )",
        "the training objective show above be compose of weight decay , pixel-wise and global loss term .",
        "here λ1andλ2 determine the weight of shape p riors and weight decay term while the smooth \u00051norm loss function \u0006quantiﬁes the recon- struction error .",
        "the global loss lhpis deﬁned as the euclidean distance between the code generate from the synthesise and ground-truth hr image .",
        "the t-l model be use only inthe network train phase as a regularisation term , similar to vgg feature [ 42 ] that be use for represent a perceptual loss function [ 21 ] .",
        "however , we be not interested in expand the output space to a large feature-map space , but instead obtain a compact representation of the underlie anatomy .",
        "e. learnt hidden representations the learnt low dimensional representation his use to constrain nn model .",
        "low dimensional encoding enables usto train model with global characteristic but also yield good generalisation power for the underlie anatomy as show in early work [ 43 ] .",
        "however , since we update our segmentationand sr model parameter with the g radients back-propagated from the global loss layer use the euclidean distance of these representation , it be essential to analyse the distribution of the extracted code .",
        "in fig .",
        "5 , due to space limitation , we show the histogram of 16 randomly choose code ( out of 64 ) of at-l model train with cardiac mr segmentation .",
        "note that each histogram be construct use the corresponding code for every sample in the full dataset .",
        "it be observe that the learntlatent representation in general follow a normal distribution and they be not separate in multi-clusters ( e.g.mixture of gaussians ) .",
        "a smooth distribution of the code ensure bettersupervision for the main nn model ( sr , seg ) since the global gradient be back-propagated by compute the euclidean distance between the obtained distribution .",
        "this observation can be explain by the fact that the propose t-l network be train with small gaussian inputnoise as in the case of denoising autoencoders .",
        "in [ 1 ] , alain and bengio show that the denoising reconstruction error be equivalent to contractive penalty , which force the featureextraction ( encoder ) function fresist perturbation of the input and contract these input sample to similar low dimensional code .",
        "the penalty be deﬁned as ( h ) =λ/vextenddouble/vextenddouble/vextenddouble ∂f ( x ) ∂x/vextenddouble/vextenddouble/vextenddouble2 f , w h e r e fdenotes the frobenius norm ( sum of squared element ) , and h=f ( x ) represent the code .",
        "the give penalty function promote the network to learn the underlying low-dimensional data manifold and capture its local smooth structure .",
        "in addi- tion to the smoothness of the latent distribution , the extractedcodes be expect to be correlate since the decoder merge some of the code along the three spatial dimension to construct input feature map for the transposed convolution , but this characteristic be not a limitation in our study .",
        "iii .",
        "a pplications and experiments in this section , we present three different application of the propose acnn model : 3d-us and cardiac mr image seg- mentation , as well as cardiac mr image sr .",
        "the experiment focus on demonstrate the importance of shape and labelpriors for image analysis .",
        "additionally , we analyse the salient information store in the learnt hidden representation and correlate them with clinical index , show their potential useas biomarkers for pathology classiﬁcation .",
        "the next subsection describe the clinical datasets use in our experiment .",
        "a .",
        "clinical datasets 1 ) uk digital heart project dataset : this dataset1is com- pose of 1200 pair of cine 2d stack short-axis ( sax ) and cine 3d high resolution ( hr ) cardi ac mr image .",
        "each image pair be acquire from a healthy subject use a standard imagingprotocol [ 4 ] , [ 15 ] .",
        "in more detail , the 2d stack be acquire in different breath-holds and therefore may contain motion artefact .",
        "similarly , 3d imaging be not always feasible in thestandard clinical setting due to the requirement for long image acquisition .",
        "the voxel resolution of the image be ﬁxed to 1.25×1.25×10.00 mm and 1 .25×1.25×2.00 mm for 2d stack low resolution ( lr ) and hr image respectively .",
        "dense segmentation annotation for hr image be obtainedby manually correct initial segmentation generate with a semi-automatic multi-atlas segmentation method [ 5 ] , and all the annotation be perform on the hr image to minimiseerrors introduce due to lr in through plane direction .",
        "since the ground-truth information be obtain from the hr motion- free image , the experimental result be expect to reﬂectthe performance of the method with respect to an appropriate reference .",
        "the annotation consist of pixel-wise labelling of endocardium and myocardium class .",
        "additionally , the resid- ual spatial misalignment between the 2d lr stack and hr volume be correct use a rigid transformation esti-mated by an intensity base image registration algorithm .",
        "2 ) cetus ’ 14 challenge dataset : cetus ’ 14 segmentation challenge [ 8 ] be a publicly available platform2to benchmark cardiac 3d ultrasound ( us ) left-ventricle ( lv ) segmentation method .",
        "the challenge dataset be compose of 3d +time us image sequence acquire from 15 healthy subject and 1https : //digital-heart.org/ 2https : //www.creatis.insa-lyon.fr/challenge/cetus/index.html390 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 30 patient diagnose with myocardial infarction or dilate cardiomyopathy .",
        "the image be acquire from apical win- dows and lv chamber be the main focus of analysis .",
        "resolution of the image be ﬁxed to 1 mm isotropic voxelsize through linear interpolation .",
        "the associated manual con- tour of the lv boundary be draw by three different expert cardiologist , and the annotation be perform onlyon the frame correspond to end-diastole ( ed ) and end- systole ( es ) phase .",
        "method evaluation be perform in a blinded fashion on the testing set ( 30 out of 45 ) use the midas web platform .",
        "3 ) acdc miccai ’ 17 challenge dataset : the aim of the acdc ’ 17 challenge3is to compare the performance of auto- matic method for the classiﬁcation of mr image examina- tions in term of healthy and pathological case : infarction , dilate cardiomyopathy , and hypertrophic cardiomyopathy.the publicly available dataset consist of 20 ( per class ) cine stack of 2d mr image sequence which be annotate at ed and es phase by a clinical expert .",
        "in the experiment , latent representation ( code ) extract with the propose t-l network be use to classify these image .",
        "b .",
        "training details of the proposed model in this section , we discuss the detail of data augmentation use in training , and also the optimisation scheme of the t-l model training .",
        "to improve the model ’ s generalisation capability , the input training sample be artiﬁcially aug-mented use afﬁne transformation , which be use in both the segmentation and t-l model .",
        "for the sr model , on the other hand , respiratory motio n artefact between the adjacent slice be simulated via in-pl ane rigid transformation that be deﬁned for each slice independently .",
        "the correspondingground-truth hr image be not spatially transform ; in this way , the model learn to output anatomically correct result when the input slice be motio n corrupt .",
        "additionally , additive gaussian noise be apply to input intensity image to make the segmentation and super-resolution model more robust against image noise .",
        "for the ae , the tissue class label be randomly swap with the probability of 0 .1t o encourage the model to map slightly different segmentationmasks to neighbour point in the low dimensional latent space .",
        "it ensure the smoothness of the learnt low-dimensional manifold space as explain in section ii-e .",
        "in the joint training of the t-l network , parameter of the encoder model ( f ) be update by the gradient originate from both the cross-entropy loss ( l x ) and euclidean distance term ( lh ) .",
        "instead of apply these two gradient descent update sequentially in an iterative fashion , we perform a jointupdate training scheme and experimentally observe good convergence .",
        "c. cardiac cine-mr image segmentation in this experiment , nn model be use to segment cardiac cine mr image in the dataset describe in sec .",
        "iii-a1 .",
        "as aninput to the model , only the 2d stack lr image be use , 3https : //www.creatis.insa-lyon.fr/challenge/acdc/ fig .",
        "6 .",
        "segmentation result on two different 2d stack cardiac mr image .",
        "the propose acnn model be insensitiv e to slice mis- alignment as it be anatomically constrain and it make less error in basal and apical slice compare to the 2d-fcn approach .",
        "the result generate from low resolution image be well correlate with the hrground-truth annotation ( green ) .",
        "which be a commonly used acquisition protocol for cardiac imaging , and the segmentation be perform only on the edphase of the sequence .",
        "the corresponding ground-truth label map , however , be project from the hr image space , which be annotate in the hr image grid .",
        "the dataset ( 1200 lrimages & hr label ) be randomly partition into three subset : training ( 900 ) , validation ( 100 ) , and test ( 200 ) .",
        "all the image be linearly intensity normalise and crop base on the automatically detect six anatomical landmark location [ 33 ] .",
        "the propose acnn-seg method be compare against : the current state-of-the-art cine mr 2d slice by slice segmenta- tion method ( 2d-fcn ) [ 44 ] , 3d-unet model [ 12 ] , cascaded3d-unet and convolutional ae model ( ae-seg ) [ 37 ] , sub- pixel 3d-cnn segmentation model ( 3d-seg ) propose in sec .",
        "ii-a , and the same model train with various type of motion augmentation ( 3d-seg-maug ) .",
        "as the model have a different layout , the number of trainable parameter ( par ) usedin each model be keep ﬁxed to avoid any bias .",
        "for the cascaded ae-seg model , however , additional convolutional kernel be use in the ae as suggest in [ 37 ] .",
        "to observe the inﬂuenceof the ae model ’ s capacity on the ae-seg model ’ s perfor- mance , we perform experiment use different number of ae par , and the large capacity case be denote by ae-seg-m .",
        "the result of the experiment be provide in table i together with the capacity of each model .",
        "statistical signif- icance of the result be veriﬁed by perform the wilcoxon signed-rank test between the top two perform method foreach evaluation metric .",
        "based on these result we can draw three main conclusion : ( i ) slice by slice analysis [ 2 ] , [ 44 ] signiﬁcantly under-performs compare to the propose sub-pixel and acnn-seg segmentation method .",
        "in particular , the dice score metric be observe to be low since 2d analysis can yield poor performance in basal and apical part of the heart as show in fig .",
        "6 .",
        "previous slice by slice segmentation approach validate their method onlr annotation ; however , we see that the produce label map be far off from the true underlying ventricular geom- etry and it can be a limiting factor for the analysis ofoktay et al .",
        ": acnns : application to cardiac image enhancement and segmentation 391 table i stacks of 2d c ardiac mr i mages ( 200 ) a resegmented intolv e ndocardium and myocardium , and the segmentation accuracy isevaluated in terms of dicemetric and surface to surface distances .theground -truth labels areobtained from high resolution 3d i mages acquired from same subjects , which do notcontain motion and blocky artefacts .theproposed approach ( acnn-s eg ) iscompared against state-of-the-artslice by slice segmentation ( 2d-fcn [ 44 ] ) m ethod , 3d-un et model [ 12 ] , c ascaded 3d-un et and convolutional ae m odel ( ae-s eg ) [ 37 ] , p roposed sub-pixel segmentation model ( 3d-s eg ) and the same model withmotion augmentation used in training ( 3d-s eg-ma ug ) ventricle morphology .",
        "similar result be obtain in clinical study [ 15 ] , which however require hr image acquisition technique .",
        "( ii ) the result also show that introduction of shape prior in segmentation model can be useful to tackle false-positive detection and motion-artefacts .",
        "as can be see in the bottom row of fig .",
        "6 , without the learnt shape prior , label map prediction be more prone to image artefact .",
        "indeed , it be the main reason why we observe such a large difference in term of hausdorff distance .",
        "for endocardiumlabels , on the other hand , the difference in dice score metric be observe to be less due to the large size of the lv blood pool compare to the myocardium .",
        "lastly ( iii ) , we observe a performance difference between the cascade ae base segmentation ( ae-seg [ 37 ] ) and theproposed acnn-seg model : the segmentation generate with the former model be strongly regularise due to the sec- ond stage ae .",
        "it result in reduced hausdorff distance withmarginal statistical signiﬁcance , but the model overlook ﬁne detail of the myocardium surface since the segmentation be generate only from the coarse level feature-maps .",
        "more importantly , cascade approach add additional computa- tional complexity due to the increase number of ﬁlters , whichcould be redundant give that the standard segmentation model be able to capture shape property of the organ as long as it have a large receptive ﬁeld an d be optimise with shape constraint .",
        "in other word , shape constraint can be learnt and utilised in standard segmentation model , as show in acnn-seg , without a need for additional model parame- ters and computational complexity .",
        "we also analyse the performance change in ae-seg with respect to the num-ber of parameter , which s hows that the small capacity ae-seg model ( 8 ×10 4pars ) be not suitable for cardiac image segmentation as the second stage in the cascaded model doesnot improve the performance signiﬁcantly .",
        "we perform additional segmentation experiment use only the t-l network .",
        "in detail , the input lr image be pass ﬁrst through the predictor network and then the extracted code fig .",
        "7 .",
        "( a ) cavity noise limit accurate delineation of the lv cavity in apical area .",
        "( b ) the segmentation model can be guide through learnt shape prior to output anatomically correct delineation .",
        "( c ) similarly , it can make accurate prediction even when the ventricle boundary be occlude .",
        "be feed to the decoder network show in fig .",
        "3 .",
        "label map prediction be collect at the output of the decoder and they be compare with the same ground-truth annotationsdescribed previously , which be similar to the ae base segmentation method propose in [ 2 ] and [ 3 ] .",
        "we observe that reconstruction of label-maps from low dimensional rep- resentations be limit since the ventricle boundary be not delineate properly but rather a rough segmentation wasgenerated ( dsc : .734 ) .",
        "we believe that this be probably the main reason why avendi et al .",
        "[ 2 ] propose the use of a sep- arate deformable model at the output of a nn .",
        "nevertheless , the propose acnn-seg do not require an additional post- processing step .",
        "d. cardiac 3d ultrasound image segmentation in the second experiment , the propose model be evalu- ated on 3d cardiac ultrasound data which be describe in sec iii-a2 .",
        "segmentation model be use to delineate endo- cardial boundary and the segmentation obtain on ed andes frame be later use to measure volumetric index such as ejection fraction ( ef ) .",
        "the model be compare also in term of surface to surface distance error of their corresponding endocardium segmentation .",
        "as a baseline cnn method , we utilise the fully convolu tional network model suggest by [ 11 ] for multi-view 3d-us image segmentation problem.392 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 table ii 3d-us c ardiac image sequences ( intotal 30 ) a resegmented intolv c avity and background .segmentation accuracy is evaluated in terms of dicescore ( dsc ) , s urface -to-surface distances .theconsistency of delineations on bothed and es p hases aremeasured in terms computed ejection fraction ( ef ) v alues .theproposed acnn-s egmethod is compared against state-of-theartdeformable shape fitting [ 6 ] and fully-convolutional 3d s egmentation [ 11 ] m ethods it be also observe to be more memory efﬁcient compare to the standard 3d-unet architecture [ 12 ] .",
        "additionally , we com- pare our propose model against the cetus ’ 14 challenge winner approach ( beas ) [ 6 ] that utilise deformable mod- el to segment the left ventricular cavity .",
        "the challenge result can be find in [ 8 ] .",
        "the experimental result , givenintable ii , show that neural network model outperform previous state-of-the-art approach in this public benchmark dataset although the training data size be limit to 15 imagesequences .",
        "the experimental result be evaluate in a blinded fashion by upload the generated segmentation from separate 30 sequence in to the cetus web platform .",
        "the main contribution of acnn model over the standard fcn approach be the improved shape delineation of thelv , as it can be see in term of the distance error metric .",
        "in particular , hausdorff distance be reduce signiﬁcantly as global regularisation reduce the amount of spurious falsepositive prediction and enforces abnormal lv segmentation shape to ﬁt into the learnt representation model .",
        "this situation be illustrate in fig .",
        "7 .",
        "similarly , we observe an improvement in term of normalised dice score , which be quantitatively not signiﬁcant due to large volumetric size of the lv cavity .",
        "lastly , we compare the extracted ejection fraction result to understand both the accuracy of segmentation and also the consistency of these prediction on both ed and esphases .",
        "it be observe that the acnn approach ensure good consistency between frame although none of the method have use temporal information .",
        "the reported result could be far improve by segment- ing both ed and es frame simultaneously or by extract the temporal content from the sequence .",
        "for instance , propaga- tion of ed mask to es frame through optical ﬂow have be show to be a promising way to achieve this goal .",
        "however , this study mainly focus on demonstrate the advantage of use prior in neural network model , and achieve the best possible segmentation accuracy be not our main focus .",
        "e. cardiac mr image enhancement the propose acnn model be also apply to the image sr problem and compare against the state-of-the-art cnn model use in medical imaging [ 34 ] .",
        "the cardiac mr dataset , describe in sec .",
        "iii-a1 , be split into two disjoint subset : table iii average inference time ( inf-t ) of the sr m odels perinput lr i mage ( 120×120×12 ) u sing a gpu ( gtx-1080 ) .",
        "acnn-sr and sr-cnn [ 34 ] m odels aregiven the same number of filters and capacity .",
        "mos [ 26 ] results , received from the clinicians ( r1 and r2 ) , a rereported separately training ( 1000 ) and test ( 200 ) .",
        "at test time , we evaluate our model with both lr-hr clinical image data .",
        "in training , however , lr image be synthetically generate from clinical hr data use the mr acquisition model discuss in [ 20 ] .more detail about the acquisition model can be find in [ 34 ] .",
        "the quality of the upsampled image be evaluate in term of ssim metric [ 47 ] between the clinical hr image dataand reconstruct hr image .",
        "ssim measure assess the correlation of local structure and be less sensitive to image noise than psnr which be not use in our experiment since small misalignment between lr-hr image pair could introduce large error in the evaluation due to pixel bypixel comparison .",
        "more importantly , intensity statistic of the image be observe to be different for this reason psnr measurement would not be accurate .",
        "in addition to the ssimmetric , we use the mean opinion score ( mos ) test [ 26 ] to quantify the quality and similarity of the synthesise and real hr cardiac image .",
        "two expert cardiologist be ask torate the upsampled image from 1 ( very poor ) to 5 ( excellent ) base on the accuracy of the reconstructed lv boundary and geometry .",
        "to serve as a reference , the corresponding clinical lr and hr image be display together with the upsampled image that be anonymis ed for a fair comparison .",
        "intable iii , ssim and mos score for the standard interpolation technique , sr-cnn , and the propose acnn- sr model be provide .",
        "in addition to the increase imageoktay et al .",
        ": acnns : application to cardiac image enhancement and segmentation 393 fig .",
        "8 .",
        "image super-resolution ( sr ) result .",
        "from leave to right , input low resolution mr image , baseline sr approach [ 34 ] ( no global loss ) , the propose anatomically constrai ned sr model , and the ground-truth high resolution acquisition .",
        "quality , the acnn-sr model be computationally more efﬁcient in term of run-time in comparison to the sr-cnn model [ 34 ] by a factor of 5 .",
        "this be due to the fact that acnn-sr performs feature extraction in the low dimensional image space .",
        "further- more , we investigate the contribution of shape regularisationterm in the application of sr , which be visualise in fig .",
        "8 .",
        "moreover , we investigate the use of sr as a pre-processing technique for subsequent analysis such as image segmentation , similar to the experiment report in [ 34 ] .",
        "in that regard , the propose sr model and u-net segmentation model be concatenate to obtain hr segmentation result .",
        "however , we observe that the propose baseline sub-pixel segmentation model ( 3d-seg ) , which merge both sr and segmentationtasks , performs well than the concatenated model .",
        "the 3d-seg approach use the convolution kernels more efﬁciently without require the model to output a high-dimensionalintensity image .",
        "for this reason , sr model should be train by take into account the ﬁnal goal and in some case it ’ s not require to reconstruct a hr intensity image for hr analysis .",
        "f .",
        "learnt latent representations and pathology classiﬁcation the jointly train t-l model and its latent representation be analyse and evaluate in the experiment of image pathol- ogy classiﬁcation .",
        "this experiment focus on understand the information store in the latent space and also investigateswhether they can be use to distinguish healthy subject from dilate and hypertrophic cardiomyopathy patient .",
        "for this , we collect 64 dimensional code from segmentationimages of the cardiac mr dataset explain in sec .",
        "iii-a3 .",
        "similarly , principal component analysis ( pca ) be apply to the same segmentation image ( contain lv blood-pool and myocardium label ) to gen erate 64 dimensional linear projection of the label , which require additional spatial-normalisation prior to linear mapping .",
        "the generated code be then use as feature to train an ensemble of deci- sion tree to categorise each im age .",
        "we use 10-fold cross- validation on 60 cmr sequence and obtain 76 .6 % vs 83.3 % accuracy use pca and t-l code extract from ed phase .",
        "by include the code from es phase , the clas-siﬁcation accuracy be improve to 86 .6 % vs 91 .6 % .",
        "this result show that although the ae and t-l model be not train with the classiﬁcation objective , they can still cap- ture anatomical shape variati ons that be link to cardiac related pathology .",
        "in particular , we observe that some latentdimensions be more commonly use than others in tree node split .",
        "by sample code from the latent space across these dimension , we observe that the network capture the fig .",
        "9 .",
        "anatomical variation capture by the latent representation in t-l network ( swipe from μ−2σtoμ+2σ ) .",
        "based on our observation , the ﬁrst and second dimension captur e the variation in the wall thickness of the myocardium ( x-axis ) and lateral wall of the ventricle ( y-axis ) .",
        "variation in wall thickness and blood pool size as show infig .",
        "9 .",
        "since we obtain a regular and smooth latent representation , it be possible to transverse along the latent space and generate lv shape by inter polating between data point .",
        "it be important to note that classiﬁcation accuracy can befurther improve by train the ae and t-l model with a classiﬁcation objective .",
        "our main goal in this experiment be to understand whether the enforced prior distribution contain anatomical information or the y be abstract representation only meaningful to the decoder of the ae .",
        "iv .",
        "d iscussion and conclusion in this work , we present a new image analysis framework that utilise autoencoder ( ae ) and t-l network as regularisers to train neural network ( nn ) model .",
        "with this new trainingobjective , at test time nns make prediction that be in agreement with the learnt shape model of the underlie anatomy , which be refer as image prior .",
        "the experimentalresults show that the state-of-the-art nn model can beneﬁt from the learnt prior in case wh ere the image be corrupt and contain artefact .",
        "the propose regulariser model can be see as an application-speci ﬁc training objective .",
        "in that regard , our model differentiate from the vgg-net [ 42 ] fea-ture base train objective [ 21 ] , [ 26 ] .",
        "vgg feature tend to be more general purpose representation that be learn from imagenet dataset contain natural image of a large varietyof object .",
        "in contrast to this , our ae model be train solely on cardiac segmentation mask and feature be customise to identify anatomical variation observe in the heart chambers.for this reason , we would expect the ae feature of the segmentation to be more distinctive and informative .",
        "as an alternative to the propose framework , label space dependency could be exploit also through adversarial loss ( al ) objective function .",
        "such approach have beenused successfully in natural image super-resolution ( sr ) [ 26 ] and segmentation [ 30 ] task .",
        "in sr application , al enable the sr network to hallucinate ﬁne texture detail , and the394 ieee transactions on medical imaging , vol .",
        "37 , no .",
        "2 , february 2018 synthesize hr image appear qualitatively more realistic .",
        "however , at the same time the psnr and ssim score be usually bad .",
        "for this reason , the author of [ 26 ] have point out that adversarial training may not be suitable formedical application , where the accuracy and ﬁdelity of the visual content more important than the qualitative appearance of the hr image .",
        "moreover , we believe that adversarialtraining come at the expense of less interpretability of the regularisation term and unstable model train behaviour , which still remain an open research problem .",
        "additionally , in the experiment we demonstrate that the learnt code can be use as biomarkers for classiﬁcationof cardiac relate pathology and we analyse the distrib- ution of the learnt latent space .",
        "this latent space can be far constrain to be gaussi an distribute by replace the propose regularisation model with a variational autoen- coder .",
        "however , this design choice be not consider in our acnn framework due to two main reason : ( i ) the additional k-l divergence term ( constraint ) would reduce the represen- tation power of the ae ; thus , the local anatomical variation would not be capture in detail .",
        "( ii ) a generative ae model be not essential for the regularisation of the propose segmenta- tion and sr model .",
        "a variational architecture would be usefulif it be require to sample random instance from the latent space and reconstruct anatomically meaningful segmentation mask ; however , in our framework we be only interested in the anatomy speciﬁc ae feature for model regularisation .",
        "the presented acnn framework be not only limited to the medical image segmentation and sr task but can be extend to other image analysis task where prior knowledge can provide model guidance and robustness .",
        "in that regard , future research will focus o n the application of acnn to the problem such as human pose estimation , anatomical and facial landmark localisation on partially occlude image data .",
        "a cknowledgements the view express be those of the author and not necessarily those of the nhs , the epsrc , the nihr or the department of health ."
    ],
    "processed_text": "384 ieee transactions medical imaging vol 37 2 february 2018 anatomically constrained neural networks acnns application cardiac image enhancement segmentation ozan oktay enzo ferrante konstantinos kamnitsas mattias heinrich wenjia bai jose caballero stuart cook antonio de marvao timothy dawes declan p regan bernhard kainz ben glocker daniel rueckert abstract incorporation prior knowledge organ shape location key improve performance imageanalysis approach particular prior useful inca image corrupt contain artefact dueto limitation image acquisition highly constrainednature anatomical object well captured withlearningbased technique however recent andpromising technique cnnbased segmentationit obvious incorporate prior knowledge stateoftheart method operate pixelwise classifiers training objective incorporate thestructure interdependencies output overcome limitation propose generic training strategythat incorporate anatomical prior knowledge cnnsthrough new regularisation model trained endtoend new framework encourage model followthe global anatomical property underlie anatomy egshape label structure via learnt nonlinear represen tations shape show propose approachcan easily adapt different analysis task egimage enhancement segmentation improve predictionaccuracy stateoftheart model applicability ofour approach show multimodal cardiac data set andpublic benchmark addition demonstrate thelearnt deep model 3d shape interpret andused biomarkers classificationof cardiacpathologies index terms shape prior convolutional neural network medical image segmentation image superresolution introduction image segmentation technique aim partition image meaningful part use analysis segmentation process typically drive manuscript receive july 26 2017 accept august 14 2017 date publication september 26 2017 date current version february 1 2018 work support part epsrc program undergrant ep/p001009/1 part british heart foundation uk grant pg/12/27/29489 part national institute health research nihr biomedical research centrebased imperial college healthcare nhs trust corresponding author ozan oktay oktay e ferrante k kamnitsas w bai j caballero b kainz b glocker rueckert biomedical image analy si group imperial college london london sw7 2az uk email ooktay13 @ imperialacuk heinrich institute medical informatics university lubeck 23538 lubeck germany cook de marvao dawes p regan mrc clinical sciences centre london w12 0nn uk color version one figures paper available online http //ieeexploreieeeorg digital object identifier 101109/tmi20172743464underlying data prior solution space latter useful case image corrupt con tain artefact due limitation image acquisition example bias fields shadow signal dropout respiratory motion lowresolution acquisition commonlimitations ultrasound us magnetic resonance mr imaging incorporating prior knowledge image segmentation algorithm prove useful order obtain accurate plausible result summarise recent survey 32 prior information take many form boundary edge polarity 10 shape model 13 14 topology specification distance prior region atlas model 5 werecommonly use regularisation term energy optimisation base traditional segmentation method eg region grow particular atlas prior well suit medical imagingapplications since enforce location shape prior set annotated anatomical atlas similarly auto context model 45 make use label image prior segmentation require cascade model context neural network nns early work shape analysis focus learn generative mod el deep boltzmann machines dbms namely shapebm 18 use form dbm sparse pixelconnectivity followup work 9 17 demonstrate application dbms binary segmentation problem natural image contain vehicle type object however fully connect dbm image require large number parameter consequently model train maybecome intractable depend size image reason convolutional deep belief net 48 recently propose encode shape prior information besides variational model cascade convolutional architecture 27 37 show discover prior shape structure label space without priori specification however come cost increased model complexity computational need context medical imaging neural network anatomical prior study much depth particularly current stateoftheart segmentation techniques 11 22 36 38 recent work show simple use case prior adjacency 7 boundary 10 condition inclusion prior medical imaging could work license creative commons attrib ution 30 license information see h ttp //creativecommonso rg/licenses/by/30/oktay et al acnns application cardiac image enhancement segmentation 385 potentially much im pact compare use natural image analysis sinc e anatomical object medical image naturally constrained term shape location explain recent nn survey paper 28 majority classification regression model utilise pixel level loss function egcrossentropy mean square error fully take account underlying semantic information dependency output space eg class label paper present novel generic way incorporate global shape/label information nns propose approach namely anatomically constrain neuralnetworks acnn mainly motivate early work shape prior image segmentation particular pca base statistical 13 active shape model 14 frameworklearns nonlinear compact representation underlying anatomy stacked convolutional autoencoder 31 enforces network prediction follow learnt statistical shape/label distribution word favour prediction lie extract low dim ensional data manifold importantly approach independent particular nn architecture applicati combine stateoftheart segmentation superresolution sr nn model potentially impr ove prediction accuracy robustness without introduce memory computational complexity inference time lastly acnn model train propose prior term act regulariser remove need postprocessing step conditionalrandom fields 24 often base heuristic para meter tune acnn regularisation part end toend learning great advantage propose global training objective sr corresponds prior space feasible highresolution hr solution experimentally show useful since sr ill posed problem similar modifications objective function training introduce enhance quality ofnatural image perceptual 21 adversarial 26 loss term use synthesise realistic image term texture object boundary thecontext medical imaging prior enforce synthesised hr image anatomically meaningful minimise traditional image reconstruction loss function clinical motivation cardiac imaging important role diagnosis pre operative planning postope rative management patient heart disease imaging modality us cardiacmr cmr widely use provide detailed assessment cardiac function morphology modality suitable particular clinical use case instance 2dus still thefirst line choice due low cost wide availability whereas cmr comprehensive modality excel lent contrast anatomical functional evaluation heart 23 similarly 3dus recommend use 2dus since demonstrate provide moreaccurate reproducible volu metric measurement 25 standard clinical acquisition protocol 3dus cmr still limitation visualise fig 1 results cardiac mr superresolution sr top mr seg mentation middle ultrasound us segmentation bottom fromleft right show input image stateoftheart competingmethod propose result groundtruth stack 2d mr image respiratory motion artefact b sr base cnns 34 c propose acnnsr groundtruth highresolution hr image e low resolution mr image f 2d segmentation result blocky contour 44 g 3d subpixel segmentation stack 2d mr image use acnn h manual segmentation hr image input 3dus image j fcn base segmentation 11 k acnn l manual segmentation underlie anatomy due image artefact eg cardiac motion low slice resolution lack slice coverage 35 operatordependent error eg shadow signal dropouts clinical routine challenge usually tack lead multiple acquisition anatomy andrepeated patient breathholds lead long examination time similar problem report large cohort study uk biobank 35 lead inaccuratequantitative measurement even discarding acquire image see fig 1 exist stateof theart convolutional neural n etwork cnn approach segmentation 11 44 image enhancement 34 task perform poorly input data selfconsistent forthe analysis reason incorporation prior knowledge cardiac image analysis c ould provide accurate reliable assessment anatomy show thirdcolumn figure importantly propose acnn model allow us perform hr analysis via sub pixel feature map generate low resolution lr input data even presence motion artefact using propose approach perform full 3d segmentationwithout explicit motion correction rely lr slicebyslice 2d segmentation demonstrate applicab ility propose approach cine stack 2d mr 3dus datasets compose 1200 45 cardiac image sequence respectively show propose segmentation sr model becomemore robust image artefact mention early underline stateoftheart result miccai 14 cetus public benchmark 8 also demon strate low dimensional representation learn propose acnn useful classification pathologiessuch dilated hypertrophic cardiomyopathy require pointwise correspondence search sub jects 39 evaluation miccai 17 ac/dc386 ieee transactions medical imaging vol 37 2 february 2018 fig 2 block diagram baseline segmentation seg superresolution sr model combine propose tl regularisation block show fig 3 build acnnseg/sr framework sr illustrated model extract sr feature lowresolution lr space increase computational efficiency segmentation model achieve subpixel accuracy give lr input image skip connection layer show red classification benchmark use regard propose method useful image enhancement segmen tation also study anatomical shape variation population study association cardiac relatedpathologies b contributions study propose generic novel technique incorporate prior shape label structure nns formedical image analysis task way constrain nn training process guide nn make anatomically meaningful prediction particular case input image data informative consistent enough eg miss object boundary importantly best knowledge one early study demonstrate use convolutional autoencoder network learn anatomical shape var iations medical image propose acnn model evaluate multimodal cardiac datasets mr us evaluation show subpixel cardiac mr image segmentation approachthat contrast previous cnn approach 2 44 robust slice misalignment coverage problem ii implicit statistical parametrisation left ventricu lar shape via nns pathology classification iii image sr technique extend previous work 34 robustagainst slice misalignment approach computationally efficient stateoftheart srcnn model 34 feature extraction pe rformed lowdimensional image space iv last demonstrate stateoftheart 3dus cardiac segmentation result cetus 14 benchmark ii ethodology next section briefly summarise stateofthe art methodology image segmentation seg super resolution sr base convolutional neural net work cnns present novel methodology thatextends cnn model global training objec tive constrain output space impose anatomical shape prior propose new regularisation networkthat base tl architecture use computer graphic 19 3d render object natural image medical image segmentation cnn models letys= { yi } isbe image class label represent different tissue type yil= { 12 c } f u r h e r r e letx= { xi r } observed intensity image aim image segmentation estimate observe x cnn base segmentation model 22 29 38 task perform learn discriminative function model underl ying conditional probability distribution p ysx estimation class density p ysx consist assign ing xithe probability belong cclasses yield csets class feature map fcthat extract learnt nonlinear function final decision class label make apply softmaxto extracted class featur e map case cross entropy l x=/summationtextc c=1/summationtext islog/parenleftbigg ef c /summationtext jef j /parenrightbigg feature map correspond log likelihood value unet 38 deepmedic 22 model learn mapping intensity label x xlby optimise average crossentropy loss class lx=/summationtextc c=1l x c use stochastic gradient descent show infig 2 mapping function compute pass input image series convolution layer rectified linear unit across diffe rent image scale enlarge model receptive field presented model composed two part feature extraction analysis similar vggnet 42 reconstruction synthesis case 3d unet 38 however contrast exist approach aim subpixel segment ation accuracy train upsampling layer highresolution groundtruth mapsthis enable 3d analysis underlie anatomy case thick slice 2d image stack acquisition cine cardiac mr imaging way possible perform analysisoktay et al acnns application cardiac image enhancement segmentation 387 fig 3 block diagram stacked convolutional autoencoder ae net work grey train segmentation label ae model couple predictor network blue obtain compact nonlinear representation extract intensity andsegmentation image whole model name tl network highresolution image grid without precede upsampling operation sr model 34 similar segmentation framework cf 28 stud ied medical imaging however exist method model supervise purely local loss function pixel level egcrossentropy dice without exploit global dependency structure output space reason global description prediction usually adhere shape label atlas prior contrast propose model incorporate aforementioned prior segmentation model propose framework relies autoencoder tl network model obtain nonlinear compact representation underlie anatomy use prior segmentation b convolutional autoencoder model acnnseg autoencoder ae 46 neural network aim learn intermediate represent ation original input reconstruct internally hidden layer hwhose activation represent input image often refer ascodes avoid ae directly copy output ae often design undercomplete size code less input dimension show fig 3 learning ae force network capture salient feature training data th e learning procedure minimise loss function lx ys g f ys w h e r e lxis penalising g f ys dissimilar function gand fare defined decoder encoder component ae propose method ae integrate stan dard segmentation network describe sec iia regu larisation model constrain class label prediction ytowards anatomically meaningful accurate output cross entropy loss function operate individual pixel level class prediction guarantee global consistency plausible anatomical shape even though segmentation network receptive field larg er size structure segment due fact backpropagated gradient parametrised pixelwise individual prob ability divergence term thus provide little global context fig 4 training scheme propos ed anatomically constrain convolutional neural network acnn image segmentation super resolution task propose tl network use regularisation model enforce model prediction follow distribution thelearnt low dimensional representation prior overcome limitation class prediction label map pass ae obtain low dimensional eg64 dimension parametrisation segmentation underlying structure 40 perform aebased nonlinear low dimensional projection prediction groundtruth label show fig 4 build acnnseg training objective function though linear combination crossentropy l x shape regularisation loss lhe weight decay term follow lhe=/vextenddouble/vextenddoublef x f f f /vextenddouble/vextenddouble2 2 min s/parenleftbigg lx x +1lhe+2 2w2 2/parenrightbigg 1 herewcorresponds weight convolution filters andsdenotes trainable parameter segmentation model parameter update trainingthe couple parameter 1and2determine weight shape regularisation loss weight decay term use training equation second term lheensures generated segmentation similar low dimensional space egshape manifold groundtruth label addi tion impose shape regularisation parametrisationencourages label consistency model prediction reduce falsepositive detection th ey influence predicted code hidden layer third term corresponds weight decay limit number free parameter model avoid overfitting propose ae model iscomposed convolutional layer fully connect layer middle show fig 3 similar stack convolutional autoencoder model propose 31 388 ieee transactions medical imaging vol 37 2 february 2018 ae model detail eg layer configuration parameter choice provide supplementary material c medical image superresolution sr cnns superresolution sr image generation inverse prob lem goal recover spatial frequency information outside spatial bandwidth low resolution lr observation xrnto predict high resolution hr image yrrm n\u0004m illustrate top row fig 1 since high frequency component miss obser vation space usually train example use predict likely p yrx hr output image sr illposed problem infinite number solution give input sample would anatomically meaningful accurate case image segmentation learnt shape representation use regularise image sr constrain model make anatomically meaningfulpredictions similar sr framework describe 34 propose sr model learn mapping function \u0004 xyto estimate highresolution image r=\u0004 x r rdenotes model parameter con volution kernel batch normalisation statistic parameter optimise minimising smooth \u0005 1loss also know huber loss groundtruth high resolution image corresponding prediction smooth \u00051norm defined \u0006\u00051 k = { 05k2ifk < 1 k05o h e r w e } sr training objective becomes min r/summationtext is\u0006\u00051/parenleftbig \u0004 xi r yi/parenrightbig propose sr framework use model show fig 2 provide two main advantage stateoftheart medical image sr model propose 34 network generate image feature lr image grid rather early upsamp ling feature reduce memory computation requirement significantly highlight 41 early upsampling introduces redundantcomputations hr space since additional information add model perform transpose convolu tions 49 early stage ii second advantage theuse large receptive field learn underlying anatomy case early sr method use medical imaging 34 natural imag e analysis 16 41 model usually operate local patch level capturing large context indeed help model good understand theunderlying anatomy enable us enforce global shape constraint achieve b generate sr featuremaps multiple scale use multi stride inplane direction similar acnnseg model possible regu larise sr model synthesise anatomically meaningful hr image achieve goal extend standard ae model tl model enable us obtain shape representation code directly fro intensity space idea motivate recent work 19 3d shape analysis natural image next section explain training strategy use tl model regulariser l network model sracnn shape encode ae model operate segmen tation mask limit application sr problemwhere model output intensity image circumvent problem extend standard denoising ae tl regularisation model combine ae pre dictor network fig 3 p x xh predictor map input image low dimensional nonparametric representation underlie anatomy egshape class label information learn ae word enable us learn hidden rep resentation space reach nonlinear mapping image label space yand image intensity space x way sr model regularise well respect learn anatomical prior network architecture useful image analysis appli cation two main reason enable us build regularisation network could use application dif ferent image segmentation image sr proposeto use new regularisation network training time sr enforce model learn global information image besides standard pixelwise \u0005 1distance image reconstruction loss way regressor sr model guide additional segmentation information itbecomes robust image artefact miss infor mation ii second important feature tl model generalisation learnt representation joint trainingof ae predictor enables us learn representation could extract intensity label space learnt code encode variation could interpret manual annotation intensity image since perfect mapping intensity label space ispractically achievable tl learnt code expect representative due inclusion additional information tl model train two stage first stage ae train separately groundtruth segmentation mask crossentropy loss l x later predictor model train match learnt latent space hby minimise euclidean distance lhbetween code predict ae predictor show fig 3 loss function ae predictor converge two model train jointly second stage encoder fis update use two separate backpropagated gradient lx f lh f two loss function scale match range first gradient encourage encoder generate code couldbe easily extract predictor second gradient making sure good segmentationreconstruction obtain output decoder training detail far discuss section iiib important note tl regulariser model use training time notduring inference word fully convolutional fcn segmentation superresolution model still use application use different image size paper propose sr model refer acnnsr training scheme show bottom part fig 4 l hp=/vextenddouble/vextenddoublep \u0004 x p p yr p /vextenddouble/vextenddouble2 2 min r/parenleftbigg \u0006\u00051/parenleftbig \u0004 x r yr/parenrightbig +1lhp+2 2w2 2/parenrightbigg 2 oktay et al acnns application cardiac image enhancement segmentation 389 fig 5 histogram learnt lowdimensional latent representa tions randomly select 16 component show code general follow smooth normal distribution important training acnn model training objective show compose weight decay pixelwise global loss term 1and2 determine weight shape p riors weight decay term smooth \u00051norm loss function \u0006quantifies recon struction error global loss lhpis defined euclidean distance code generate synthesise groundtruth hr image tl model use inthe network train phase regularisation term similar vgg feature 42 use represent perceptual loss function 21 however interested expand output space large featuremap space instead obtain compact representation underlie anatomy e learnt hidden representations learnt low dimensional representation use constrain nn model low dimensional encoding enables usto train model global characteristic also yield good generalisation power underlie anatomy show early work 43 however since update segmentationand sr model parameter g radients backpropagated global loss layer use euclidean distance representation essential analyse distribution extracted code fig 5 due space limitation show histogram 16 randomly choose code 64 atl model train cardiac mr segmentation note histogram construct use corresponding code every sample full dataset observe learntlatent representation general follow normal distribution separate multiclusters egmixture gaussians smooth distribution code ensure bettersupervision main nn model sr seg since global gradient backpropagated compute euclidean distance obtained distribution observation explain fact propose tl network train small gaussian inputnoise case denoising autoencoders 1 alain bengio show denoising reconstruction error equivalent contractive penalty force featureextraction encoder function fresist perturbation input contract input sample similar low dimensional code penalty defined h =/vextenddouble/vextenddouble/vextenddouble f x x/vextenddouble/vextenddouble/vextenddouble2 f w h e r e fdenotes frobenius norm sum squared element h=f x represent code give penalty function promote network learn underlying lowdimensional data manifold capture local smooth structure addi tion smoothness latent distribution extractedcodes expect correlate since decoder merge code along three spatial dimension construct input feature map transposed convolution characteristic limitation study iii pplications experiments section present three different application propose acnn model 3dus cardiac mr image seg mentation well cardiac mr image sr experiment focus demonstrate importance shape labelpriors image analysis additionally analyse salient information store learnt hidden representation correlate clinical index show potential useas biomarkers pathology classification next subsection describe clinical datasets use experiment clinical datasets 1 uk digital heart project dataset dataset1is com pose 1200 pair cine 2d stack shortaxis sax cine 3d high resolution hr cardi ac mr image image pair acquire healthy subject use standard imagingprotocol 4 15 detail 2d stack acquire different breathholds therefore may contain motion artefact similarly 3d imaging always feasible thestandard clinical setting due requirement long image acquisition voxel resolution image fixed 1251251000 mm 1 25125200 mm 2d stack low resolution lr hr image respectively dense segmentation annotation hr image obtainedby manually correct initial segmentation generate semiautomatic multiatlas segmentation method 5 annotation perform hr image minimiseerrors introduce due lr plane direction since groundtruth information obtain hr motion free image experimental result expect reflectthe performance method respect appropriate reference annotation consist pixelwise labelling endocardium myocardium class additionally resid ual spatial misalignment 2d lr stack hr volume correct use rigid transformation estimated intensity base image registration algorithm 2 cetus 14 challenge dataset cetus 14 segmentation challenge 8 publicly available platform2to benchmark cardiac 3d ultrasound us leftventricle lv segmentation method challenge dataset compose 3d +time us image sequence acquire 15 healthy subject 1https //digitalheartorg/ 2https //wwwcreatisinsalyonfr/challenge/cetus/indexhtml390 ieee transactions medical imaging vol 37 2 february 2018 30 patient diagnose myocardial infarction dilate cardiomyopathy image acquire apical win dows lv chamber main focus analysis resolution image fixed 1 mm isotropic voxelsize linear interpolation associated manual con tour lv boundary draw three different expert cardiologist annotation perform onlyon frame correspond enddiastole ed end systole es phase method evaluation perform blinded fashion testing set 30 45 use midas web platform 3 acdc miccai 17 challenge dataset aim acdc 17 challenge3is compare performance auto matic method classification mr image examina tions term healthy pathological case infarction dilate cardiomyopathy hypertrophic cardiomyopathythe publicly available dataset consist 20 per class cine stack 2d mr image sequence annotate ed es phase clinical expert experiment latent representation code extract propose tl network use classify image b training details proposed model section discuss detail data augmentation use training also optimisation scheme tl model training improve model generalisation capability input training sample artificially augmented use affine transformation use segmentation tl model sr model hand respiratory motio n artefact adjacent slice simulated via inpl ane rigid transformation defined slice independently correspondinggroundtruth hr image spatially transform way model learn output anatomically correct result input slice motio n corrupt additionally additive gaussian noise apply input intensity image make segmentation superresolution model robust image noise ae tissue class label randomly swap probability 0 1t encourage model map slightly different segmentationmasks neighbour point low dimensional latent space ensure smoothness learnt lowdimensional manifold space explain section iie joint training tl network parameter encoder model f update gradient originate crossentropy loss l x euclidean distance term lh instead apply two gradient descent update sequentially iterative fashion perform jointupdate training scheme experimentally observe good convergence c cardiac cinemr image segmentation experiment nn model use segment cardiac cine mr image dataset describe sec iiia1 aninput model 2d stack lr image use 3https //wwwcreatisinsalyonfr/challenge/acdc/ fig 6 segmentation result two different 2d stack cardiac mr image propose acnn model insensitiv e slice mis alignment anatomically constrain make less error basal apical slice compare 2dfcn approach result generate low resolution image well correlate hrgroundtruth annotation green commonly used acquisition protocol cardiac imaging segmentation perform edphase sequence corresponding groundtruth label map however project hr image space annotate hr image grid dataset 1200 lrimages & hr label randomly partition three subset training 900 validation 100 test 200 image linearly intensity normalise crop base automatically detect six anatomical landmark location 33 propose acnnseg method compare current stateoftheart cine mr 2d slice slice segmenta tion method 2dfcn 44 3dunet model 12 cascaded3dunet convolutional ae model aeseg 37 sub pixel 3dcnn segmentation model 3dseg propose sec iia model train various type motion augmentation 3dsegmaug model different layout number trainable parameter par usedin model keep fixed avoid bias cascaded aeseg model however additional convolutional kernel use ae suggest 37 observe influenceof ae model capacity aeseg model perfor mance perform experiment use different number ae par large capacity case denote aesegm result experiment provide table together capacity model statistical signif icance result verified perform wilcoxon signedrank test top two perform method foreach evaluation metric based result draw three main conclusion slice slice analysis 2 44 significantly underperforms compare propose subpixel acnnseg segmentation method particular dice score metric observe low since 2d analysis yield poor performance basal apical part heart show fig 6 previous slice slice segmentation approach validate method onlr annotation however see produce label map far true underlying ventricular geom etry limiting factor analysis ofoktay et al acnns application cardiac image enhancement segmentation 391 table stacks 2d c ardiac mr mages 200 resegmented intolv e ndocardium myocardium segmentation accuracy isevaluated terms dicemetric surface surface distances theground truth labels areobtained high resolution 3d mages acquired subjects notcontain motion blocky artefacts theproposed approach acnns eg iscompared stateoftheartslice slice segmentation 2dfcn 44 ethod 3dun et model 12 c ascaded 3dun et convolutional ae odel aes eg 37 p roposed subpixel segmentation model 3ds eg model withmotion augmentation used training 3ds egma ug ventricle morphology similar result obtain clinical study 15 however require hr image acquisition technique ii result also show introduction shape prior segmentation model useful tackle falsepositive detection motionartefacts see bottom row fig 6 without learnt shape prior label map prediction prone image artefact indeed main reason observe large difference term hausdorff distance endocardiumlabels hand difference dice score metric observe less due large size lv blood pool compare myocardium lastly iii observe performance difference cascade ae base segmentation aeseg 37 theproposed acnnseg model segmentation generate former model strongly regularise due sec ond stage ae result reduced hausdorff distance withmarginal statistical significance model overlook fine detail myocardium surface since segmentation generate coarse level featuremaps importantly cascade approach add additional computa tional complexity due increase number filters whichcould redundant give standard segmentation model able capture shape property organ long large receptive field optimise shape constraint word shape constraint learnt utilised standard segmentation model show acnnseg without need additional model parame ters computational complexity also analyse performance change aeseg respect number parameter hows small capacity aeseg model 8 10 4pars suitable cardiac image segmentation second stage cascaded model doesnot improve performance significantly perform additional segmentation experiment use tl network detail input lr image pass first predictor network extracted code fig 7 cavity noise limit accurate delineation lv cavity apical area b segmentation model guide learnt shape prior output anatomically correct delineation c similarly make accurate prediction even ventricle boundary occlude feed decoder network show fig 3 label map prediction collect output decoder compare groundtruth annotationsdescribed previously similar ae base segmentation method propose 2 3 observe reconstruction labelmaps low dimensional rep resentations limit since ventricle boundary delineate properly rather rough segmentation wasgenerated dsc 734 believe probably main reason avendi et al 2 propose use sep arate deformable model output nn nevertheless propose acnnseg require additional post processing step cardiac 3d ultrasound image segmentation second experiment propose model evalu ated 3d cardiac ultrasound data describe sec iiia2 segmentation model use delineate endo cardial boundary segmentation obtain ed andes frame later use measure volumetric index ejection fraction ef model compare also term surface surface distance error corresponding endocardium segmentation baseline cnn method utilise fully convolu tional network model suggest 11 multiview 3dus image segmentation problem392 ieee transactions medical imaging vol 37 2 february 2018 table ii 3dus c ardiac image sequences intotal 30 resegmented intolv c avity background segmentation accuracy evaluated terms dicescore dsc urface tosurface distances theconsistency delineations bothed es p hases aremeasured terms computed ejection fraction ef v alues theproposed acnns egmethod compared stateoftheartdeformable shape fitting 6 fullyconvolutional 3d egmentation 11 ethods also observe memory efficient compare standard 3dunet architecture 12 additionally com pare propose model cetus 14 challenge winner approach beas 6 utilise deformable mod el segment left ventricular cavity challenge result find 8 experimental result givenintable ii show neural network model outperform previous stateoftheart approach public benchmark dataset although training data size limit 15 imagesequences experimental result evaluate blinded fashion upload generated segmentation separate 30 sequence cetus web platform main contribution acnn model standard fcn approach improved shape delineation thelv see term distance error metric particular hausdorff distance reduce significantly global regularisation reduce amount spurious falsepositive prediction enforces abnormal lv segmentation shape fit learnt representation model situation illustrate fig 7 similarly observe improvement term normalised dice score quantitatively significant due large volumetric size lv cavity lastly compare extracted ejection fraction result understand accuracy segmentation also consistency prediction ed esphases observe acnn approach ensure good consistency frame although none method use temporal information reported result could far improve segment ing ed es frame simultaneously extract temporal content sequence instance propaga tion ed mask es frame optical flow show promising way achieve goal however study mainly focus demonstrate advantage use prior neural network model achieve best possible segmentation accuracy main focus e cardiac mr image enhancement propose acnn model also apply image sr problem compare stateoftheart cnn model use medical imaging 34 cardiac mr dataset describe sec iiia1 split two disjoint subset table iii average inference time inft sr odels perinput lr mage 12012012 u sing gpu gtx1080 acnnsr srcnn 34 odels aregiven number filters capacity mos 26 results received clinicians r1 r2 rereported separately training 1000 test 200 test time evaluate model lrhr clinical image data training however lr image synthetically generate clinical hr data use mr acquisition model discuss 20 detail acquisition model find 34 quality upsampled image evaluate term ssim metric 47 clinical hr image dataand reconstruct hr image ssim measure assess correlation local structure less sensitive image noise psnr use experiment since small misalignment lrhr image pair could introduce large error evaluation due pixel bypixel comparison importantly intensity statistic image observe different reason psnr measurement would accurate addition ssimmetric use mean opinion score mos test 26 quantify quality similarity synthesise real hr cardiac image two expert cardiologist ask torate upsampled image 1 poor 5 excellent base accuracy reconstructed lv boundary geometry serve reference corresponding clinical lr hr image display together upsampled image anonymis ed fair comparison intable iii ssim mos score standard interpolation technique srcnn propose acnn sr model provide addition increase imageoktay et al acnns application cardiac image enhancement segmentation 393 fig 8 image superresolution sr result leave right input low resolution mr image baseline sr approach 34 global loss propose anatomically constrai ned sr model groundtruth high resolution acquisition quality acnnsr model computationally efficient term runtime comparison srcnn model 34 factor 5 due fact acnnsr performs feature extraction low dimensional image space investigate contribution shape regularisationterm application sr visualise fig 8 moreover investigate use sr preprocessing technique subsequent analysis image segmentation similar experiment report 34 regard propose sr model unet segmentation model concatenate obtain hr segmentation result however observe propose baseline subpixel segmentation model 3dseg merge sr segmentationtasks performs well concatenated model 3dseg approach use convolution kernels efficiently without require model output highdimensionalintensity image reason sr model train take account final goal case require reconstruct hr intensity image hr analysis f learnt latent representations pathology classification jointly train tl model latent representation analyse evaluate experiment image pathol ogy classification experiment focus understand information store latent space also investigateswhether use distinguish healthy subject dilate hypertrophic cardiomyopathy patient collect 64 dimensional code segmentationimages cardiac mr dataset explain sec iiia3 similarly principal component analysis pca apply segmentation image contain lv bloodpool myocardium label gen erate 64 dimensional linear projection label require additional spatialnormalisation prior linear mapping generated code use feature train ensemble deci sion tree categorise im age use 10fold cross validation 60 cmr sequence obtain 76 6 vs 833 accuracy use pca tl code extract ed phase include code es phase classification accuracy improve 86 6 vs 91 6 result show although ae tl model train classification objective still cap ture anatomical shape variati ons link cardiac related pathology particular observe latentdimensions commonly use others tree node split sample code latent space across dimension observe network capture fig 9 anatomical variation capture latent representation tl network swipe 2to+2 based observation first second dimension captur e variation wall thickness myocardium xaxis lateral wall ventricle yaxis variation wall thickness blood pool size show infig 9 since obtain regular smooth latent representation possible transverse along latent space generate lv shape inter polating data point important note classification accuracy befurther improve train ae tl model classification objective main goal experiment understand whether enforced prior distribution contain anatomical information abstract representation meaningful decoder ae iv iscussion conclusion work present new image analysis framework utilise autoencoder ae tl network regularisers train neural network nn model new trainingobjective test time nns make prediction agreement learnt shape model underlie anatomy refer image prior experimentalresults show stateoftheart nn model benefit learnt prior case wh ere image corrupt contain artefact propose regulariser model see applicationspeci fic training objective regard model differentiate vggnet 42 feature base train objective 21 26 vgg feature tend general purpose representation learn imagenet dataset contain natural image large varietyof object contrast ae model train solely cardiac segmentation mask feature customise identify anatomical variation observe heart chambersfor reason would expect ae feature segmentation distinctive informative alternative propose framework label space dependency could exploit also adversarial loss al objective function approach beenused successfully natural image superresolution sr 26 segmentation 30 task sr application al enable sr network hallucinate fine texture detail the394 ieee transactions medical imaging vol 37 2 february 2018 synthesize hr image appear qualitatively realistic however time psnr ssim score usually bad reason author 26 point adversarial training may suitable formedical application accuracy fidelity visual content important qualitative appearance hr image moreover believe adversarialtraining come expense less interpretability regularisation term unstable model train behaviour still remain open research problem additionally experiment demonstrate learnt code use biomarkers classificationof cardiac relate pathology analyse distrib ution learnt latent space latent space far constrain gaussi distribute replace propose regularisation model variational autoen coder however design choice consider acnn framework due two main reason additional kl divergence term constraint would reduce represen tation power ae thus local anatomical variation would capture detail ii generative ae model essential regularisation propose segmenta tion sr model variational architecture would usefulif require sample random instance latent space reconstruct anatomically meaningful segmentation mask however framework interested anatomy specific ae feature model regularisation presented acnn framework limited medical image segmentation sr task extend image analysis task prior knowledge provide model guidance robustness regard future research focus n application acnn problem human pose estimation anatomical facial landmark localisation partially occlude image data cknowledgements view express author necessarily nhs epsrc nihr department health",
    "bag_of_words": {
        "ieee": 6,
        "transactions": 6,
        "medical": 21,
        "imaging": 18,
        "vol": 6,
        "february": 7,
        "anatomically": 14,
        "constrained": 2,
        "neural": 11,
        "networks": 1,
        "acnns": 8,
        "application": 15,
        "cardiac": 36,
        "image": 155,
        "enhancement": 10,
        "segmentation": 97,
        "ozan": 2,
        "oktay": 4,
        "enzo": 1,
        "ferrante": 2,
        "konstantinos": 1,
        "kamnitsas": 2,
        "mattias": 1,
        "heinrich": 2,
        "wenjia": 1,
        "bai": 2,
        "jose": 1,
        "caballero": 2,
        "stuart": 1,
        "cook": 2,
        "antonio": 1,
        "de": 2,
        "marvao": 2,
        "timothy": 1,
        "dawes": 2,
        "declan": 1,
        "regan": 2,
        "bernhard": 1,
        "kainz": 2,
        "ben": 1,
        "glocker": 2,
        "daniel": 1,
        "rueckert": 2,
        "abstract": 2,
        "incorporation": 2,
        "prior": 38,
        "knowledge": 7,
        "organ": 2,
        "shape": 42,
        "location": 4,
        "key": 1,
        "improve": 7,
        "performance": 7,
        "imageanalysis": 1,
        "approach": 21,
        "particular": 9,
        "useful": 8,
        "inca": 1,
        "corrupt": 4,
        "contain": 7,
        "artefact": 11,
        "dueto": 1,
        "limitation": 7,
        "acquisition": 12,
        "highly": 1,
        "constrainednature": 1,
        "anatomical": 19,
        "object": 8,
        "well": 6,
        "captured": 1,
        "withlearningbased": 1,
        "technique": 8,
        "however": 17,
        "recent": 5,
        "andpromising": 1,
        "cnnbased": 1,
        "segmentationit": 1,
        "obvious": 1,
        "incorporate": 6,
        "stateoftheart": 13,
        "method": 19,
        "operate": 4,
        "pixelwise": 5,
        "classifiers": 1,
        "training": 31,
        "objective": 11,
        "thestructure": 1,
        "interdependencies": 1,
        "output": 15,
        "overcome": 2,
        "propose": 49,
        "generic": 3,
        "strategythat": 1,
        "cnnsthrough": 1,
        "new": 6,
        "regularisation": 18,
        "model": 155,
        "trained": 1,
        "endtoend": 1,
        "framework": 11,
        "encourage": 3,
        "followthe": 1,
        "global": 17,
        "property": 2,
        "underlie": 8,
        "anatomy": 14,
        "egshape": 3,
        "label": 28,
        "structure": 8,
        "via": 4,
        "learnt": 22,
        "nonlinear": 7,
        "represen": 2,
        "tations": 1,
        "show": 33,
        "approachcan": 1,
        "easily": 2,
        "adapt": 1,
        "different": 11,
        "analysis": 23,
        "task": 8,
        "egimage": 1,
        "predictionaccuracy": 1,
        "applicability": 1,
        "ofour": 1,
        "multimodal": 2,
        "data": 15,
        "set": 3,
        "andpublic": 1,
        "benchmark": 6,
        "addition": 3,
        "demonstrate": 9,
        "thelearnt": 2,
        "deep": 3,
        "3d": 15,
        "interpret": 2,
        "andused": 1,
        "biomarkers": 3,
        "classificationof": 2,
        "cardiacpathologies": 1,
        "index": 3,
        "terms": 4,
        "convolutional": 16,
        "network": 36,
        "superresolution": 10,
        "introduction": 2,
        "aim": 5,
        "partition": 2,
        "meaningful": 8,
        "part": 8,
        "use": 65,
        "process": 2,
        "typically": 1,
        "drive": 1,
        "manuscript": 1,
        "receive": 1,
        "july": 1,
        "accept": 1,
        "august": 1,
        "date": 2,
        "publication": 1,
        "september": 1,
        "current": 3,
        "version": 2,
        "work": 12,
        "support": 1,
        "epsrc": 2,
        "program": 1,
        "undergrant": 1,
        "ep/p001009/1": 1,
        "british": 1,
        "heart": 6,
        "foundation": 1,
        "uk": 5,
        "grant": 1,
        "pg/12/27/29489": 1,
        "national": 1,
        "institute": 2,
        "health": 2,
        "research": 4,
        "nihr": 2,
        "biomedical": 2,
        "centrebased": 1,
        "imperial": 2,
        "college": 2,
        "healthcare": 1,
        "nhs": 2,
        "trust": 1,
        "corresponding": 6,
        "author": 3,
        "analy": 1,
        "si": 1,
        "group": 1,
        "london": 3,
        "sw7": 1,
        "2az": 1,
        "email": 1,
        "ooktay13": 1,
        "imperialacuk": 1,
        "informatics": 1,
        "university": 1,
        "lubeck": 2,
        "germany": 1,
        "mrc": 1,
        "clinical": 15,
        "sciences": 1,
        "centre": 1,
        "w12": 1,
        "0nn": 1,
        "color": 1,
        "one": 2,
        "figures": 1,
        "paper": 4,
        "available": 3,
        "online": 1,
        "http": 1,
        "//ieeexploreieeeorg": 1,
        "digital": 2,
        "identifier": 1,
        "101109/tmi20172743464underlying": 1,
        "solution": 3,
        "space": 32,
        "latter": 1,
        "case": 14,
        "con": 3,
        "tain": 1,
        "due": 15,
        "example": 2,
        "bias": 2,
        "fields": 2,
        "shadow": 2,
        "signal": 2,
        "dropout": 1,
        "respiratory": 3,
        "motion": 9,
        "lowresolution": 2,
        "commonlimitations": 1,
        "ultrasound": 5,
        "us": 12,
        "magnetic": 1,
        "resonance": 1,
        "mr": 25,
        "incorporating": 1,
        "algorithm": 2,
        "prove": 1,
        "order": 1,
        "obtain": 13,
        "accurate": 7,
        "plausible": 2,
        "result": 23,
        "summarise": 2,
        "survey": 2,
        "information": 16,
        "take": 3,
        "many": 1,
        "form": 2,
        "boundary": 9,
        "edge": 1,
        "polarity": 1,
        "topology": 1,
        "specification": 2,
        "distance": 11,
        "region": 2,
        "atlas": 4,
        "werecommonly": 1,
        "term": 23,
        "energy": 1,
        "optimisation": 2,
        "base": 14,
        "traditional": 2,
        "eg": 9,
        "grow": 1,
        "suit": 1,
        "imagingapplications": 1,
        "since": 15,
        "enforce": 5,
        "annotated": 1,
        "similarly": 6,
        "auto": 2,
        "context": 5,
        "make": 8,
        "require": 9,
        "cascade": 4,
        "nns": 5,
        "early": 9,
        "focus": 7,
        "learn": 16,
        "generative": 2,
        "mod": 2,
        "el": 2,
        "boltzmann": 1,
        "machines": 1,
        "dbms": 2,
        "namely": 2,
        "shapebm": 1,
        "dbm": 2,
        "sparse": 1,
        "pixelconnectivity": 1,
        "followup": 1,
        "binary": 1,
        "problem": 9,
        "natural": 7,
        "vehicle": 1,
        "type": 3,
        "fully": 5,
        "connect": 2,
        "large": 12,
        "number": 8,
        "parameter": 12,
        "consequently": 1,
        "train": 23,
        "maybecome": 1,
        "intractable": 1,
        "depend": 1,
        "size": 8,
        "reason": 11,
        "belief": 1,
        "net": 3,
        "recently": 1,
        "encode": 3,
        "besides": 2,
        "variational": 3,
        "architecture": 6,
        "discover": 1,
        "without": 7,
        "priori": 1,
        "come": 2,
        "cost": 2,
        "increased": 1,
        "complexity": 4,
        "computational": 4,
        "need": 3,
        "study": 9,
        "much": 2,
        "depth": 1,
        "particularly": 1,
        "techniques": 1,
        "simple": 1,
        "adjacency": 1,
        "condition": 1,
        "inclusion": 2,
        "could": 7,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attrib": 1,
        "ution": 2,
        "see": 6,
        "ttp": 1,
        "//creativecommonso": 1,
        "rg/licenses/by/30/oktay": 1,
        "et": 8,
        "al": 8,
        "potentially": 2,
        "im": 2,
        "pact": 1,
        "compare": 11,
        "sinc": 1,
        "naturally": 1,
        "explain": 5,
        "nn": 11,
        "majority": 1,
        "classification": 12,
        "regression": 1,
        "utilise": 4,
        "pixel": 6,
        "level": 5,
        "loss": 22,
        "function": 20,
        "egcrossentropy": 2,
        "mean": 2,
        "square": 1,
        "error": 8,
        "account": 2,
        "underlying": 6,
        "semantic": 1,
        "dependency": 3,
        "class": 14,
        "present": 4,
        "novel": 3,
        "way": 7,
        "shape/label": 2,
        "constrain": 9,
        "neuralnetworks": 1,
        "acnn": 19,
        "mainly": 2,
        "motivate": 2,
        "pca": 3,
        "statistical": 5,
        "active": 1,
        "frameworklearns": 1,
        "compact": 4,
        "representation": 22,
        "stacked": 2,
        "autoencoder": 8,
        "enforces": 2,
        "prediction": 18,
        "follow": 5,
        "distribution": 10,
        "word": 4,
        "favour": 1,
        "lie": 1,
        "extract": 9,
        "low": 22,
        "dim": 1,
        "ensional": 1,
        "manifold": 4,
        "importantly": 5,
        "independent": 1,
        "applicati": 1,
        "combine": 3,
        "sr": 50,
        "impr": 1,
        "ove": 1,
        "accuracy": 12,
        "robustness": 2,
        "introduce": 4,
        "memory": 3,
        "inference": 3,
        "time": 8,
        "lastly": 3,
        "act": 1,
        "regulariser": 4,
        "remove": 1,
        "postprocessing": 1,
        "step": 2,
        "conditionalrandom": 1,
        "often": 3,
        "heuristic": 1,
        "para": 1,
        "meter": 1,
        "tune": 1,
        "end": 2,
        "toend": 1,
        "learning": 3,
        "great": 1,
        "advantage": 4,
        "corresponds": 2,
        "feasible": 2,
        "highresolution": 5,
        "hr": 31,
        "experimentally": 2,
        "ill": 1,
        "posed": 1,
        "similar": 13,
        "modifications": 1,
        "enhance": 1,
        "quality": 4,
        "ofnatural": 1,
        "perceptual": 2,
        "adversarial": 3,
        "synthesise": 4,
        "realistic": 2,
        "texture": 2,
        "thecontext": 1,
        "synthesised": 1,
        "minimise": 3,
        "reconstruction": 5,
        "motivation": 1,
        "important": 6,
        "role": 1,
        "diagnosis": 1,
        "pre": 2,
        "operative": 1,
        "planning": 1,
        "postope": 1,
        "rative": 1,
        "management": 1,
        "patient": 4,
        "disease": 1,
        "modality": 3,
        "cardiacmr": 1,
        "cmr": 4,
        "widely": 1,
        "provide": 9,
        "detailed": 1,
        "assessment": 2,
        "morphology": 2,
        "suitable": 3,
        "instance": 3,
        "2dus": 2,
        "still": 5,
        "thefirst": 1,
        "line": 1,
        "choice": 3,
        "wide": 1,
        "availability": 1,
        "whereas": 1,
        "comprehensive": 1,
        "excel": 1,
        "lent": 1,
        "contrast": 5,
        "functional": 1,
        "evaluation": 6,
        "3dus": 8,
        "recommend": 1,
        "moreaccurate": 1,
        "reproducible": 1,
        "volu": 1,
        "metric": 6,
        "measurement": 3,
        "standard": 10,
        "protocol": 2,
        "visualise": 2,
        "fig": 25,
        "results": 2,
        "top": 3,
        "seg": 5,
        "mentation": 2,
        "middle": 2,
        "bottom": 3,
        "fromleft": 1,
        "right": 2,
        "input": 20,
        "competingmethod": 1,
        "groundtruth": 12,
        "stack": 12,
        "2d": 16,
        "cnns": 3,
        "acnnsr": 5,
        "resolution": 16,
        "blocky": 2,
        "contour": 1,
        "subpixel": 7,
        "manual": 4,
        "fcn": 3,
        "slice": 17,
        "lack": 1,
        "coverage": 2,
        "operatordependent": 1,
        "dropouts": 1,
        "routine": 1,
        "challenge": 7,
        "usually": 5,
        "tack": 1,
        "lead": 3,
        "multiple": 2,
        "andrepeated": 1,
        "breathholds": 2,
        "long": 3,
        "examination": 1,
        "report": 2,
        "cohort": 1,
        "biobank": 1,
        "inaccuratequantitative": 1,
        "even": 4,
        "discarding": 1,
        "acquire": 5,
        "exist": 3,
        "stateof": 1,
        "theart": 1,
        "etwork": 1,
        "cnn": 7,
        "perform": 16,
        "poorly": 1,
        "selfconsistent": 1,
        "forthe": 1,
        "ould": 1,
        "reliable": 1,
        "thirdcolumn": 1,
        "figure": 1,
        "allow": 1,
        "sub": 3,
        "feature": 19,
        "map": 12,
        "generate": 11,
        "lr": 14,
        "presence": 1,
        "using": 1,
        "full": 2,
        "segmentationwithout": 1,
        "explicit": 1,
        "correction": 1,
        "rely": 1,
        "slicebyslice": 1,
        "applicab": 1,
        "ility": 1,
        "cine": 7,
        "datasets": 4,
        "compose": 3,
        "sequence": 7,
        "respectively": 2,
        "becomemore": 1,
        "robust": 4,
        "mention": 1,
        "underline": 1,
        "miccai": 3,
        "cetus": 6,
        "public": 2,
        "also": 13,
        "demon": 1,
        "strate": 1,
        "dimensional": 14,
        "pathologiessuch": 1,
        "dilated": 1,
        "hypertrophic": 3,
        "cardiomyopathy": 4,
        "pointwise": 1,
        "correspondence": 1,
        "search": 1,
        "jects": 1,
        "ac/dc386": 1,
        "block": 3,
        "diagram": 2,
        "baseline": 4,
        "tl": 25,
        "build": 3,
        "acnnseg/sr": 1,
        "illustrated": 1,
        "increase": 3,
        "efficiency": 1,
        "achieve": 5,
        "give": 4,
        "skip": 1,
        "connection": 1,
        "layer": 9,
        "red": 1,
        "regard": 4,
        "segmen": 2,
        "tation": 3,
        "variation": 7,
        "population": 1,
        "association": 1,
        "relatedpathologies": 1,
        "contributions": 1,
        "formedical": 2,
        "guide": 3,
        "informative": 2,
        "consistent": 1,
        "enough": 1,
        "miss": 3,
        "best": 2,
        "var": 1,
        "iations": 1,
        "evaluate": 5,
        "approachthat": 1,
        "previous": 4,
        "misalignment": 4,
        "ii": 8,
        "implicit": 1,
        "parametrisation": 2,
        "left": 2,
        "ventricu": 1,
        "lar": 1,
        "pathology": 5,
        "iii": 5,
        "extend": 4,
        "robustagainst": 1,
        "computationally": 2,
        "efficient": 3,
        "srcnn": 4,
        "extraction": 3,
        "pe": 1,
        "rformed": 1,
        "lowdimensional": 4,
        "iv": 2,
        "last": 1,
        "ethodology": 1,
        "next": 3,
        "section": 6,
        "briefly": 1,
        "stateofthe": 1,
        "art": 1,
        "methodology": 2,
        "super": 2,
        "thatextends": 1,
        "objec": 1,
        "tive": 1,
        "impose": 2,
        "networkthat": 1,
        "computer": 1,
        "graphic": 1,
        "render": 1,
        "models": 1,
        "letys=": 1,
        "yi": 1,
        "isbe": 1,
        "represent": 5,
        "tissue": 2,
        "yil=": 1,
        "letx=": 1,
        "xi": 2,
        "observed": 1,
        "intensity": 14,
        "estimate": 2,
        "observe": 17,
        "discriminative": 1,
        "underl": 1,
        "ying": 1,
        "conditional": 1,
        "probability": 3,
        "ysx": 2,
        "estimation": 2,
        "density": 1,
        "consist": 3,
        "assign": 1,
        "ing": 2,
        "xithe": 1,
        "belong": 1,
        "cclasses": 1,
        "yield": 3,
        "csets": 1,
        "fcthat": 1,
        "final": 2,
        "decision": 1,
        "apply": 5,
        "softmaxto": 1,
        "extracted": 4,
        "featur": 1,
        "cross": 3,
        "entropy": 2,
        "x=/summationtextc": 1,
        "c=1/summationtext": 1,
        "islog/parenleftbigg": 1,
        "ef": 3,
        "/summationtext": 1,
        "jef": 1,
        "/parenrightbigg": 1,
        "correspond": 2,
        "log": 1,
        "likelihood": 1,
        "value": 1,
        "unet": 3,
        "deepmedic": 1,
        "mapping": 6,
        "xlby": 1,
        "optimise": 3,
        "average": 2,
        "crossentropy": 4,
        "lx=/summationtextc": 1,
        "c=1l": 1,
        "stochastic": 1,
        "gradient": 8,
        "descent": 2,
        "infig": 2,
        "compute": 2,
        "pass": 3,
        "series": 1,
        "convolution": 4,
        "rectified": 1,
        "linear": 5,
        "unit": 1,
        "across": 2,
        "diffe": 1,
        "rent": 1,
        "scale": 3,
        "enlarge": 1,
        "receptive": 4,
        "field": 4,
        "presented": 2,
        "composed": 1,
        "two": 13,
        "vggnet": 2,
        "synthesis": 1,
        "segment": 5,
        "ation": 2,
        "upsampling": 3,
        "mapsthis": 1,
        "enable": 6,
        "thick": 1,
        "possible": 4,
        "analysisoktay": 1,
        "ae": 38,
        "grey": 1,
        "couple": 2,
        "predictor": 8,
        "blue": 1,
        "andsegmentation": 1,
        "whole": 1,
        "name": 1,
        "grid": 3,
        "precede": 1,
        "operation": 1,
        "cf": 1,
        "stud": 1,
        "ied": 1,
        "supervise": 1,
        "purely": 1,
        "local": 5,
        "dice": 4,
        "exploit": 2,
        "description": 1,
        "adhere": 1,
        "aforementioned": 1,
        "relies": 1,
        "acnnseg": 8,
        "intermediate": 1,
        "original": 1,
        "reconstruct": 4,
        "internally": 1,
        "hidden": 5,
        "hwhose": 1,
        "activation": 1,
        "refer": 3,
        "ascodes": 1,
        "avoid": 3,
        "directly": 2,
        "copy": 1,
        "design": 2,
        "undercomplete": 1,
        "code": 24,
        "less": 5,
        "dimension": 5,
        "force": 2,
        "capture": 6,
        "salient": 2,
        "th": 2,
        "procedure": 1,
        "lx": 3,
        "ys": 3,
        "lxis": 1,
        "penalising": 1,
        "dissimilar": 1,
        "gand": 1,
        "fare": 1,
        "defined": 5,
        "decoder": 6,
        "encoder": 5,
        "component": 4,
        "integrate": 1,
        "stan": 1,
        "dard": 1,
        "describe": 6,
        "sec": 7,
        "iia": 2,
        "regu": 2,
        "larisation": 1,
        "ytowards": 1,
        "individual": 2,
        "guarantee": 1,
        "consistency": 4,
        "though": 2,
        "larg": 1,
        "er": 1,
        "fact": 3,
        "backpropagated": 4,
        "parametrised": 1,
        "prob": 2,
        "ability": 1,
        "divergence": 2,
        "thus": 2,
        "little": 1,
        "scheme": 4,
        "propos": 1,
        "ed": 9,
        "eg64": 1,
        "aebased": 1,
        "projection": 2,
        "combination": 1,
        "lhe": 1,
        "weight": 8,
        "decay": 5,
        "lhe=/vextenddouble/vextenddoublef": 1,
        "/vextenddouble/vextenddouble2": 2,
        "min": 3,
        "s/parenleftbigg": 1,
        "+1lhe+2": 1,
        "2w2": 2,
        "2/parenrightbigg": 2,
        "herewcorresponds": 1,
        "filters": 3,
        "andsdenotes": 1,
        "trainable": 2,
        "update": 5,
        "trainingthe": 1,
        "1and2determine": 1,
        "equation": 1,
        "second": 8,
        "lheensures": 1,
        "generated": 3,
        "addi": 2,
        "tion": 5,
        "parametrisationencourages": 1,
        "reduce": 5,
        "falsepositive": 3,
        "detection": 2,
        "ey": 1,
        "influence": 1,
        "predicted": 1,
        "third": 1,
        "limit": 5,
        "free": 2,
        "overfitting": 1,
        "iscomposed": 1,
        "detail": 9,
        "configuration": 1,
        "supplementary": 1,
        "material": 1,
        "generation": 1,
        "inverse": 1,
        "lem": 1,
        "goal": 5,
        "recover": 1,
        "spatial": 4,
        "frequency": 2,
        "outside": 1,
        "bandwidth": 1,
        "observation": 3,
        "xrnto": 1,
        "predict": 3,
        "high": 6,
        "yrrm": 1,
        "n\u0004m": 1,
        "illustrate": 2,
        "row": 2,
        "obser": 1,
        "vation": 1,
        "likely": 1,
        "yrx": 1,
        "illposed": 1,
        "infinite": 1,
        "sample": 6,
        "would": 6,
        "regularise": 3,
        "meaningfulpredictions": 1,
        "xyto": 1,
        "r=\u0004": 1,
        "rdenotes": 1,
        "volution": 1,
        "kernel": 2,
        "batch": 1,
        "normalisation": 1,
        "statistic": 2,
        "minimising": 1,
        "smooth": 7,
        "1loss": 1,
        "know": 1,
        "huber": 1,
        "\u00051norm": 2,
        "\u0006\u00051": 1,
        "05k2ifk": 1,
        "k05o": 1,
        "becomes": 1,
        "r/summationtext": 1,
        "is\u0006\u00051/parenleftbig": 1,
        "yi/parenrightbig": 1,
        "main": 11,
        "rather": 2,
        "upsamp": 1,
        "ling": 1,
        "computation": 1,
        "requirement": 2,
        "significantly": 4,
        "highlight": 1,
        "introduces": 1,
        "redundantcomputations": 1,
        "additional": 10,
        "add": 2,
        "transpose": 1,
        "convolu": 2,
        "tions": 3,
        "stage": 6,
        "theuse": 1,
        "imag": 1,
        "patch": 1,
        "capturing": 1,
        "indeed": 2,
        "help": 1,
        "good": 5,
        "understand": 4,
        "theunderlying": 1,
        "constraint": 4,
        "featuremaps": 2,
        "multi": 1,
        "stride": 1,
        "inplane": 1,
        "direction": 2,
        "larise": 1,
        "fro": 1,
        "idea": 1,
        "strategy": 1,
        "sracnn": 1,
        "mask": 5,
        "problemwhere": 1,
        "circumvent": 1,
        "denoising": 3,
        "dictor": 1,
        "xh": 1,
        "nonparametric": 1,
        "rep": 2,
        "resentation": 1,
        "reach": 1,
        "yand": 1,
        "respect": 3,
        "appli": 1,
        "cation": 1,
        "dif": 1,
        "ferent": 1,
        "proposeto": 1,
        "1distance": 1,
        "regressor": 1,
        "itbecomes": 1,
        "infor": 1,
        "mation": 1,
        "generalisation": 3,
        "joint": 2,
        "trainingof": 1,
        "enables": 2,
        "annotation": 7,
        "perfect": 1,
        "ispractically": 1,
        "achievable": 1,
        "expect": 4,
        "representative": 1,
        "first": 4,
        "separately": 2,
        "later": 2,
        "match": 2,
        "latent": 15,
        "hby": 1,
        "euclidean": 5,
        "lhbetween": 1,
        "converge": 1,
        "jointly": 2,
        "fis": 1,
        "separate": 3,
        "lh": 2,
        "range": 1,
        "couldbe": 1,
        "making": 1,
        "sure": 1,
        "segmentationreconstruction": 1,
        "far": 4,
        "discuss": 3,
        "iiib": 1,
        "note": 3,
        "notduring": 1,
        "hp=/vextenddouble/vextenddoublep": 1,
        "yr": 1,
        "r/parenleftbigg": 1,
        "\u0006\u00051/parenleftbig": 1,
        "yr/parenrightbig": 1,
        "+1lhp+2": 1,
        "histogram": 3,
        "representa": 1,
        "randomly": 4,
        "select": 1,
        "general": 3,
        "normal": 2,
        "1and2": 1,
        "determine": 1,
        "riors": 1,
        "\u0006quantifies": 1,
        "recon": 1,
        "struction": 1,
        "lhpis": 1,
        "inthe": 1,
        "phase": 5,
        "vgg": 2,
        "interested": 2,
        "expand": 1,
        "featuremap": 1,
        "instead": 2,
        "representations": 2,
        "encoding": 1,
        "usto": 1,
        "characteristic": 2,
        "power": 2,
        "segmentationand": 1,
        "radients": 1,
        "essential": 2,
        "analyse": 5,
        "choose": 1,
        "atl": 1,
        "construct": 2,
        "every": 1,
        "dataset": 12,
        "learntlatent": 1,
        "multiclusters": 1,
        "egmixture": 1,
        "gaussians": 1,
        "ensure": 3,
        "bettersupervision": 1,
        "obtained": 1,
        "small": 3,
        "gaussian": 2,
        "inputnoise": 1,
        "autoencoders": 1,
        "alain": 1,
        "bengio": 1,
        "equivalent": 1,
        "contractive": 1,
        "penalty": 3,
        "featureextraction": 1,
        "fresist": 1,
        "perturbation": 1,
        "contract": 1,
        "=/vextenddouble/vextenddouble/vextenddouble": 1,
        "x/vextenddouble/vextenddouble/vextenddouble2": 1,
        "fdenotes": 1,
        "frobenius": 1,
        "norm": 1,
        "sum": 1,
        "squared": 1,
        "element": 1,
        "h=f": 1,
        "promote": 1,
        "smoothness": 2,
        "extractedcodes": 1,
        "correlate": 3,
        "merge": 2,
        "along": 2,
        "three": 5,
        "transposed": 1,
        "pplications": 1,
        "experiments": 1,
        "experiment": 14,
        "importance": 1,
        "labelpriors": 1,
        "additionally": 5,
        "store": 2,
        "potential": 1,
        "useas": 1,
        "subsection": 1,
        "project": 2,
        "dataset1is": 1,
        "com": 2,
        "pose": 2,
        "pair": 3,
        "shortaxis": 1,
        "sax": 1,
        "cardi": 1,
        "ac": 1,
        "healthy": 4,
        "subject": 3,
        "imagingprotocol": 1,
        "therefore": 1,
        "may": 2,
        "always": 1,
        "thestandard": 1,
        "setting": 1,
        "voxel": 1,
        "fixed": 3,
        "mm": 3,
        "dense": 1,
        "obtainedby": 1,
        "manually": 1,
        "correct": 4,
        "initial": 1,
        "semiautomatic": 1,
        "multiatlas": 1,
        "minimiseerrors": 1,
        "plane": 1,
        "experimental": 3,
        "reflectthe": 1,
        "appropriate": 1,
        "reference": 2,
        "labelling": 1,
        "endocardium": 2,
        "myocardium": 6,
        "resid": 1,
        "ual": 1,
        "volume": 1,
        "rigid": 2,
        "transformation": 3,
        "estimated": 1,
        "registration": 1,
        "publicly": 2,
        "platform2to": 1,
        "leftventricle": 1,
        "lv": 10,
        "+time": 1,
        "1https": 1,
        "//digitalheartorg/": 1,
        "2https": 1,
        "//wwwcreatisinsalyonfr/challenge/cetus/indexhtml390": 1,
        "diagnose": 1,
        "myocardial": 1,
        "infarction": 2,
        "dilate": 3,
        "apical": 4,
        "win": 1,
        "dows": 1,
        "chamber": 1,
        "isotropic": 1,
        "voxelsize": 1,
        "interpolation": 2,
        "associated": 1,
        "tour": 1,
        "draw": 2,
        "expert": 3,
        "cardiologist": 2,
        "onlyon": 1,
        "frame": 5,
        "enddiastole": 1,
        "systole": 1,
        "es": 6,
        "blinded": 2,
        "fashion": 3,
        "testing": 1,
        "midas": 1,
        "web": 2,
        "platform": 2,
        "acdc": 2,
        "challenge3is": 1,
        "matic": 1,
        "examina": 1,
        "pathological": 1,
        "cardiomyopathythe": 1,
        "per": 1,
        "annotate": 2,
        "classify": 1,
        "details": 1,
        "proposed": 1,
        "augmentation": 3,
        "capability": 1,
        "artificially": 1,
        "augmented": 1,
        "affine": 1,
        "hand": 2,
        "motio": 2,
        "adjacent": 1,
        "simulated": 1,
        "inpl": 1,
        "ane": 1,
        "independently": 1,
        "correspondinggroundtruth": 1,
        "spatially": 1,
        "transform": 1,
        "additive": 1,
        "noise": 4,
        "swap": 1,
        "1t": 1,
        "slightly": 1,
        "segmentationmasks": 1,
        "neighbour": 1,
        "point": 3,
        "iie": 1,
        "originate": 1,
        "sequentially": 1,
        "iterative": 1,
        "jointupdate": 1,
        "convergence": 1,
        "cinemr": 1,
        "iiia1": 2,
        "aninput": 1,
        "3https": 1,
        "//wwwcreatisinsalyonfr/challenge/acdc/": 1,
        "insensitiv": 1,
        "mis": 1,
        "alignment": 1,
        "basal": 2,
        "2dfcn": 3,
        "hrgroundtruth": 1,
        "green": 1,
        "commonly": 2,
        "used": 2,
        "edphase": 1,
        "lrimages": 1,
        "subset": 2,
        "validation": 2,
        "test": 6,
        "linearly": 1,
        "normalise": 1,
        "crop": 1,
        "automatically": 1,
        "detect": 1,
        "six": 1,
        "landmark": 2,
        "segmenta": 2,
        "3dunet": 2,
        "cascaded3dunet": 1,
        "aeseg": 6,
        "3dcnn": 1,
        "3dseg": 3,
        "various": 1,
        "3dsegmaug": 1,
        "layout": 1,
        "par": 2,
        "usedin": 1,
        "keep": 1,
        "cascaded": 2,
        "suggest": 2,
        "influenceof": 1,
        "capacity": 5,
        "perfor": 1,
        "mance": 1,
        "denote": 1,
        "aesegm": 1,
        "table": 4,
        "together": 2,
        "signif": 1,
        "icance": 1,
        "verified": 1,
        "wilcoxon": 1,
        "signedrank": 1,
        "foreach": 1,
        "based": 2,
        "conclusion": 2,
        "underperforms": 1,
        "score": 6,
        "poor": 2,
        "validate": 1,
        "onlr": 1,
        "produce": 1,
        "true": 1,
        "ventricular": 2,
        "geom": 1,
        "etry": 1,
        "limiting": 1,
        "factor": 2,
        "ofoktay": 1,
        "stacks": 1,
        "ardiac": 2,
        "mages": 2,
        "resegmented": 2,
        "intolv": 2,
        "ndocardium": 1,
        "isevaluated": 1,
        "dicemetric": 1,
        "surface": 5,
        "distances": 2,
        "theground": 1,
        "truth": 1,
        "labels": 1,
        "areobtained": 1,
        "acquired": 1,
        "subjects": 1,
        "notcontain": 1,
        "artefacts": 1,
        "theproposed": 3,
        "iscompared": 1,
        "stateoftheartslice": 1,
        "ethod": 1,
        "3dun": 2,
        "ascaded": 1,
        "odel": 1,
        "aes": 1,
        "roposed": 1,
        "3ds": 2,
        "withmotion": 1,
        "egma": 1,
        "ug": 1,
        "ventricle": 4,
        "tackle": 1,
        "motionartefacts": 1,
        "prone": 1,
        "difference": 3,
        "hausdorff": 3,
        "endocardiumlabels": 1,
        "blood": 2,
        "pool": 2,
        "former": 1,
        "strongly": 1,
        "ond": 1,
        "reduced": 1,
        "withmarginal": 1,
        "significance": 1,
        "overlook": 1,
        "fine": 2,
        "coarse": 1,
        "computa": 1,
        "tional": 2,
        "whichcould": 1,
        "redundant": 1,
        "able": 1,
        "utilised": 1,
        "parame": 1,
        "ters": 1,
        "change": 1,
        "hows": 1,
        "4pars": 1,
        "doesnot": 1,
        "cavity": 4,
        "delineation": 3,
        "area": 1,
        "occlude": 2,
        "feed": 1,
        "collect": 2,
        "annotationsdescribed": 1,
        "previously": 1,
        "labelmaps": 1,
        "resentations": 1,
        "delineate": 2,
        "properly": 1,
        "rough": 1,
        "wasgenerated": 1,
        "dsc": 2,
        "believe": 2,
        "probably": 1,
        "avendi": 1,
        "sep": 1,
        "arate": 1,
        "deformable": 2,
        "nevertheless": 1,
        "post": 1,
        "processing": 1,
        "evalu": 1,
        "ated": 1,
        "iiia2": 1,
        "endo": 1,
        "cardial": 1,
        "andes": 1,
        "measure": 2,
        "volumetric": 2,
        "ejection": 3,
        "fraction": 3,
        "multiview": 1,
        "problem392": 1,
        "sequences": 1,
        "intotal": 1,
        "avity": 1,
        "background": 1,
        "evaluated": 1,
        "dicescore": 1,
        "urface": 1,
        "tosurface": 1,
        "theconsistency": 1,
        "delineations": 1,
        "bothed": 1,
        "hases": 1,
        "aremeasured": 1,
        "computed": 1,
        "alues": 1,
        "egmethod": 1,
        "compared": 1,
        "stateoftheartdeformable": 1,
        "fitting": 1,
        "fullyconvolutional": 1,
        "egmentation": 1,
        "ethods": 1,
        "pare": 1,
        "winner": 1,
        "beas": 1,
        "find": 2,
        "givenintable": 1,
        "outperform": 1,
        "although": 3,
        "imagesequences": 1,
        "upload": 1,
        "contribution": 2,
        "improved": 1,
        "thelv": 1,
        "amount": 1,
        "spurious": 1,
        "abnormal": 1,
        "fit": 1,
        "situation": 1,
        "improvement": 1,
        "normalised": 1,
        "quantitatively": 1,
        "significant": 1,
        "esphases": 1,
        "none": 1,
        "temporal": 2,
        "reported": 1,
        "simultaneously": 1,
        "content": 2,
        "propaga": 1,
        "optical": 1,
        "flow": 1,
        "promising": 1,
        "split": 2,
        "disjoint": 1,
        "inft": 1,
        "odels": 2,
        "perinput": 1,
        "mage": 1,
        "sing": 1,
        "gpu": 1,
        "gtx1080": 1,
        "aregiven": 1,
        "mos": 3,
        "received": 1,
        "clinicians": 1,
        "r1": 1,
        "r2": 1,
        "rereported": 1,
        "lrhr": 2,
        "synthetically": 1,
        "upsampled": 3,
        "ssim": 4,
        "dataand": 1,
        "assess": 1,
        "correlation": 1,
        "sensitive": 1,
        "psnr": 3,
        "bypixel": 1,
        "comparison": 3,
        "ssimmetric": 1,
        "opinion": 1,
        "quantify": 1,
        "similarity": 1,
        "real": 1,
        "ask": 1,
        "torate": 1,
        "excellent": 1,
        "reconstructed": 1,
        "geometry": 1,
        "serve": 1,
        "display": 1,
        "anonymis": 1,
        "fair": 1,
        "intable": 1,
        "imageoktay": 1,
        "leave": 1,
        "constrai": 1,
        "ned": 1,
        "runtime": 1,
        "performs": 2,
        "investigate": 2,
        "regularisationterm": 1,
        "moreover": 2,
        "preprocessing": 1,
        "subsequent": 1,
        "concatenate": 1,
        "segmentationtasks": 1,
        "concatenated": 1,
        "kernels": 1,
        "efficiently": 1,
        "highdimensionalintensity": 1,
        "pathol": 1,
        "ogy": 1,
        "investigateswhether": 1,
        "distinguish": 1,
        "segmentationimages": 1,
        "iiia3": 1,
        "principal": 1,
        "bloodpool": 1,
        "gen": 1,
        "erate": 1,
        "spatialnormalisation": 1,
        "ensemble": 1,
        "deci": 1,
        "sion": 1,
        "tree": 2,
        "categorise": 1,
        "age": 1,
        "10fold": 1,
        "vs": 2,
        "include": 1,
        "cap": 1,
        "ture": 1,
        "variati": 1,
        "ons": 1,
        "link": 1,
        "related": 1,
        "latentdimensions": 1,
        "others": 1,
        "node": 1,
        "swipe": 1,
        "2to+2": 1,
        "captur": 1,
        "wall": 3,
        "thickness": 2,
        "xaxis": 1,
        "lateral": 1,
        "yaxis": 1,
        "regular": 1,
        "transverse": 1,
        "inter": 1,
        "polating": 1,
        "befurther": 1,
        "whether": 1,
        "enforced": 1,
        "iscussion": 1,
        "regularisers": 1,
        "trainingobjective": 1,
        "agreement": 1,
        "experimentalresults": 1,
        "benefit": 1,
        "wh": 1,
        "ere": 1,
        "applicationspeci": 1,
        "fic": 1,
        "differentiate": 1,
        "tend": 1,
        "purpose": 1,
        "imagenet": 1,
        "varietyof": 1,
        "solely": 1,
        "customise": 1,
        "identify": 1,
        "chambersfor": 1,
        "distinctive": 1,
        "alternative": 1,
        "beenused": 1,
        "successfully": 1,
        "hallucinate": 1,
        "the394": 1,
        "synthesize": 1,
        "appear": 1,
        "qualitatively": 1,
        "bad": 1,
        "fidelity": 1,
        "visual": 1,
        "qualitative": 1,
        "appearance": 1,
        "adversarialtraining": 1,
        "expense": 1,
        "interpretability": 1,
        "unstable": 1,
        "behaviour": 1,
        "remain": 1,
        "open": 1,
        "relate": 1,
        "distrib": 1,
        "gaussi": 1,
        "distribute": 1,
        "replace": 1,
        "autoen": 1,
        "coder": 1,
        "consider": 1,
        "kl": 1,
        "usefulif": 1,
        "random": 1,
        "specific": 1,
        "limited": 1,
        "guidance": 1,
        "future": 1,
        "human": 1,
        "facial": 1,
        "localisation": 1,
        "partially": 1,
        "cknowledgements": 1,
        "view": 1,
        "express": 1,
        "necessarily": 1,
        "department": 1
    },
    "objective": [
        "we show that the propose approachcan be easily adapt to different analysis task ( e.g.image enhancement , segmentation ) and improve the predictionaccuracy of the state-of-the-art model .",
        "in this paper , we present a novel and generic way to incorporate global shape/label information into nns .",
        "the propose approach , namely anatomically constrain neuralnetworks ( acnn ) , be mainly motivate by the early work on shape prior and image segmentation , in particular pca base statistical [ 13 ] and active shape model [ 14 ] .",
        "fromleft to right , we show the input image , a state-of-the-art competingmethod , the propose result , and the ground-truth .",
        "using the propose approach we can perform full 3d segmentationwithout explicit motion correction and do not have to rely on lr slice-by-slice 2d segmentation .",
        "we demonstrate the applicab ility of the propose approach for cine stack of 2d mr and 3d-us datasets compose of 1200 and 45 cardiac image sequence respectively .",
        "in that regard , the propose method be not only useful for image enhancement and segmen- tation but also for the study of anatomical shape variation in population study and their association with cardiac relatedpathologies .",
        "in the propose method , the ae be integrate into the stan- dard segmentation network , describe in sec .",
        "in this paper , the propose sr model be refer to as acnn-sr and its training scheme be show in the bottom part of fig .",
        "the propose acnn model be insensitiv e to slice mis- alignment as it be anatomically constrain and it make less error in basal and apical slice compare to the 2d-fcn approach .",
        "the propose acnn-seg method be compare against : the current state-of-the-art cine mr 2d slice by slice segmenta- tion method ( 2d-fcn ) [ 44 ] , 3d-unet model [ 12 ] , cascaded3d-unet and convolutional ae model ( ae-seg ) [ 37 ] , sub- pixel 3d-cnn segmentation model ( 3d-seg ) propose in sec .",
        "based on these result we can draw three main conclusion : ( i ) slice by slice analysis [ 2 ] , [ 44 ] signiﬁcantly under-performs compare to the propose sub-pixel and acnn-seg segmentation method .",
        "from leave to right , input low resolution mr image , baseline sr approach [ 34 ] ( no global loss ) , the propose anatomically constrai ned sr model , and the ground-truth high resolution acquisition ."
    ],
    "references": [
        "",
        "REFERENCES [1] G. Alain and Y . Bengio, “What re gularized auto-encoders learn from the data-generating distribution,” J. Mach. Learn. Res. , vol. 15, no. 1, pp. 3563–3593, 2014. [2] M. R. Avendi, A. Kheradvar, and H. Jafarkhani, “A combined deep- learning and deformable-model appr oach to fully automatic segmenta- tion of the left ventricle in cardiac MRI,” MedIA Image Anal. , vol. 30, pp. 108–119, May 2016. [3] M. R. Avendi, A. Kheradvar, and H. Jafarkhani, “Automatic segmen- tation of the right ventricle from cardiac MRI using a learning-based approach,” in Magnetic Resonance in Medicine . New York, NY , USA: Wiley, Feb. 2017, doi: 10.1002/mrm.26631. [4] W. Bai et al. , “A bi-ventricular cardiac atlas built from 1000 +high resolution MR images of healthy subjects and an analysis of shape and motion,” MedIA Image Anal. , vol. 26, no. 1, pp. 133–145, 2015. [5] W. Bai et al. , “A probabilistic patch-based label fusion model for multi- atlas segmentation with registration reﬁnement: Application to cardiac MR images,” IEEE Trans. Med. Imag. , vol. 32, no. 7, pp. 1302–1315, Jul. 2013. [6] D. Barbosa et al. , “Fast and fully automatic 3-D echocardiographic segmentation using B-spline explicit active surfaces: Feasibility study and validation in a clinical setting,” Ultrasound Med. Biol. , vol. 39, no. 1, pp. 89–101, 2013.[7] A. BenTaieb and G. Hamarneh, “Topology aware fully convolutional networks for histology gland segmentation,” in Proc. Int. Conf. MICCAI , 2016, pp. 460–468. [8] O. Bernard et al. , “Standardized evaluation s ystem for left ventricular segmentation algorithms in 3D echocardiography,” IEEE Trans. Med. Imag. , vol. 35, no. 4, pp. 967–977, Apr. 2016. [9] F. Chen, H. Yu, R. Hu, and X. Zeng, “Deep learning shape priors for object segmentation,” in Proc. IEEE CVPR , Jun. 2013, pp. 1870–1877. [10] H. Chen, X. Qi, L. Yu, Q. Dou, J. Qin, and P.-A. Heng, “DCAN: Deep contour-aware networks for object instance segmentation from histology images,” MedIA Image Anal. , vol. 36, pp. 135–146, Feb. 2017. [11] H. Chen, Y . Zheng, J.-H. Park, P.-A. Heng, and S. K. Zhou, “Iterative multi-domain regularized deep learning for anatomical struc- ture detection and segmentation from ultrasound images,” in Proc. Int. Conf. MICCAI , 2016, pp. 487–495. [12] Ö. Çiçek, A. Abdulkadir, S. S. Lie nkamp, T. Brox, and O. Ronneberger, “3D U-Net: Learning dense volumet ric segmentation from sparse anno- tation,” in Proc. MICCAI , 2016, pp. 424–432. [13] T. F. Cootes and C. J. Taylor, “Combining point distribution models with shape models based on ﬁnite element analysis,” Image Vis. Comput. , vol. 13, no. 5, pp. 403–409, 1995. [14] C. Davatzikos, X. Tao, and D. Shen, “Hierarchical active shape models, using the wavelet transform,” I E E ET r a n s .M e d .I m a g . , vol. 22, no. 3, pp. 414–423, Mar. 2003. [15] A. de Marvao et al. , “Population-based studi es of myocardial hypertro- phy: High resolution cardiovascular m agnetic resonance atlases improve statistical power,” J. Cardiovascular Magn. Reson. , vol. 16, no. 1, p. 16, 2014. [16] C. Dong, C. C. Loy, and X. Tang, “Accelerating the super-resolution convolutional neural network,” in Proc. ECCV , 2016, pp. 391–407. [17] S. Eslami and C. Williams, “A generative model for parts-based object segmentation,” in Proc. NIPS , 2012, pp. 100–107. [18] S. M. A. Eslami, N. Heess, and J. Winn, “The shape Boltzmann machine: A strong model of object shape,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Jun. 2012, pp. 406–413. [19] R. Girdhar, D. F. Fouhey, M. Rodriguez, and A. Gupta, “Learning a predictable and generative vect or representation for objects,” in Proc. ECCV , 2016, pp. 484–499. [20] H. Greenspan, “Super-resolution in medical imaging,” Comput. J. , vol. 52, no. 1, pp. 43–63, 2009. [21] J. Johnson, A. Alahi, and L. Fei-Fei , “Perceptual losses for real-time style transfer and super-resolution,” in Proc. ECCV , 2016, pp. 694–711. [22] K. Kamnitsas et al. , “Efﬁcient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation,” MedIA Image Anal. , vol. 36, pp. 61–78, Feb. 2017. [23] T. D. Karamitsos, J. M. Francis, S. Myerson, J. B. Selvanayagam, and S. Neubauer, “The role of cardiovascu lar magnetic resonance imaging in heart failure,” J. Amer. College Cardiol. , vol. 54, no. 15, pp. 1407–1424, 2009. [24] J. Lafferty, A. McCallum, and F. C. N. Pereira, “Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data,”inProc. ICML , vol. 1. 2001, pp. 282–289. [25] R. M. Lang et al. , “EAE/ASE recommendations for image acquisition and display using three-dimensional echocardiography,” J. Amer. Soc. Echocardiogr. , vol. 25, no. 1, pp. 1–46, 2012. [26] C. Ledig et al. , (Sep. 2016). “Photo-realistic single image super- resolution using a generative adversarial network.” [Online]. Available:https://arxiv.org/abs/1609.04802 [27] K. Li, B. Hariharan, and J. Malik, “It erative instance segmentation,” in Proc. CVPR , 2016, pp. 3659–3667. [28] G. Litjens et al. , (2017). “A survey on deep learning in medical image analysis.” [Online]. Available: https://arxiv.org/abs/1702.05747 [29] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proc. CVPR , 2015, pp. 3431–3440. [30] P. Luc, C. Couprie, S. Chintala, and J. Verbeek. (Dec. 2016). “Seman- tic segmentation using adversarial networks.” [Online]. Available:https://arXiv preprint arXiv:1611.08408 [31] J. Masci, U. Meier, D. Cire¸ san, and J. Schmidhuber, “Stacked convo- lutional auto-encoders for hiera rchical feature extraction,” in Proc. Int. C o n f .A r t i f .N e u r a lN e t w . , 2011, pp. 52–59. [32] M. S. Nosrati and G. Hamarneh. ( 2016). “Incorporating prior knowl- edge in medical image segmentation: A survey.” [Online]. Available:https://arxiv.org/abs/1607.01092 [33] O. Oktay et al. , “Stratiﬁed decision forests for accurate anatomical landmark localization in cardiac images,” I E E ET r a n s .M e d .I m a g . , vol. 36, no. 1, pp. 332–342, Jan. 2017.OKTAY et al. : ACNNs: APPLICATION TO CARDIAC IMAGE ENHANCEMENT AND SEGMENTATION 395 [34] O. Oktay et al. , “Multi-input cardiac image super-resolution using convolutional neural networks,” in Proc. Int. Conf. MICCAI , 2016, pp. 246–254. [35] S. E. Petersen et al. , “UK Biobank’s cardiovascu lar magnetic resonance protocol,” J. Cardiovascular Magn. Reson. , vol. 18, no. 1, p. 8, 2016. [36] H. Ravishankar, S. Thiruvenkada m, R. Venkataramani, and V . Vaidya, “Joint deep learning of foreground, background and shape for robust contextual segmentation,” in Proc. IPMI , 2017, pp. 622–632. [37] H. Ravishankar, R. Venkatarama ni, S. Thiruvenkadam, P. Sudhakar, and V . Vaidya, “Learning and incorporating shape models for semantic segmentation,” in Proc. ResearchGate , 2017, pp. 203–211. [38] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in Proc. Int. Conf. MICCAI , 2015, pp. 234–241. [39] M. Shakeri, H. Lombaert, S. Tripathi, and S. Kadoury, “Deep spectral- based shape features for Alzheimer’s disease classiﬁcation,” in Proc. SASHIMI , 2016, pp. 15–24. [40] A. Sharma, O. Grau, and M. Fritz, “VConv-DAE: Deep volumetric shape learning without object labels,” in Proc. ECCV Workshops , 2016, pp. 236–250. [41] W. Shi et al. , “Real-time single image and video super-resolution using an efﬁcient sub-pixel convolutional neural network,” in Proc. CVPR , 2016, pp. 1874–1883.[42] K. Simonyan and A. Zisserman. (Sep. 2014). “Very deep convolu- tional networks for large-scale image recognition.” [Online]. Available:https://arxiv.org/abs/1409.1556 [43] A. Torralba and Y . Weiss, “Small codes and large image databases for recognition,” in Proc. CVPR , 2008, pp. 1–8. [44] P. V . Tran. (2016). “A fully convolutional neural network for cardiac segmentation in short-axis MRI.” [Online]. Available: https://arxiv.org/abs/1604.00494 [45] Z. Tu and X. Bai, “Auto-context and its application to high-level vision tasks and 3D brain image segmentation,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 32, no. 10, pp. 1744–1757, Oct. 2010. [46] P. Vincent, H. Larochelle, I. Laj oie, Y . Bengio, and P.-A. Manzagol, “Stacked denoising autoencoders: L earning useful representations in a deep network with a local denoising criterion,” J. Mach. Learn. Res. , vol. 11, pp. 3371–3408, Dec. 2010, [47] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image quality assessment: From error visibility to structural simi- larity,” IEEE Trans. Image Process. , vol. 13, no. 4, pp. 600–612, Apr. 2004. [48] Z. Wu et al. , “3D shapenets: A deep representation for volumetric shapes,” in Proc. CVPR , 2015, pp. 1912–1920. [49] M. D. Zeiler, D. Krishnan, G. W. Taylor, and R. Fergus, “Deconvolu- tional networks,” in Proc. CVPR , 2010, pp. 2528–2535."
    ]
}{
    "name": "Artificial Intelligence-Based Power Transformer Health Index for Handling Data Uncertainty",
    "paragraphs": [
        "received october 20 , 2021 , accept october 30 , 2021 , date of publication november 4 , 2021 , date of current version november 12 , 2021 .",
        "digital object identifier 10.1 109/access.2021.3125379 artificial intelligence-based power transformer health index for handling data uncertainty dhanu rediansyah 1,2 , ( graduate student member , ieee ) , rahman azis prasojo 1,3 , ( graduate student member , ieee ) , suwarno 1 , ( senior member , ieee ) , and a. abu-siada 4 , ( senior member , ieee ) 1school of electrical engineering and informatics , institut teknologi bandung , bandung 40132 , indonesia 2pt .",
        "pln ( persero ) head of ce , jakarta 12160 , indonesia 3electrical engineering department , politeknik negeri malang , malang 65141 , indonesia 4electrical and computer engineering discipline , curtin university , perth , wa 6102 , australia corresponding author : rahman azis prasojo ( rahmanazisp @ polinema.ac.id ) this work be support in part by pt .",
        "pln ( persero ) , and in part by the institut teknologi bandung .",
        "abstract power transformer be a critical and expensive asset in electric transmission and distribution network .",
        "it be essential to monitor the health condition of all power transformer eet in such network to avoid unwanted outage .",
        "the health index ( hi ) be a quick and ef cient way to assess the condition of power transformer base on multi-criteria .",
        "while power transformer hi method have be well present in the literature , not much attention be give to handle the uncertainty and reliability of this method due to unavailability of use data .",
        "therefore , this paper aim to tackle this issue through employ arti cial intelligence ( ai ) -based technique to reveal the health condition of power transformer with high accuracy and at the same time handle data uncertainty .",
        "the propose hi approach assess the power transformer insulation system base on oil quality , dissolve gas analysis ( dga ) , and paper condition .",
        "in this regard , collect data from 504 , 150-kv transformer be use to establish the propose ai-models .",
        "seven ai algorithms include k-nearest neighbor ( knn ) , support vector machine ( svm ) , random forest ( rf ) , naïve bayes ( nb ) , arti cial neural network ( ann ) , adaptive boosting ( adaboost ) , and decision tree be investigate .",
        "a performance comparison of the propose ai-based hi model be carry out use the scoring- weighting-based hi method as the reference .",
        "results show that rf model provide the best performance in predict power transformer hi with an accuracy of 97.3 % .",
        "index terms power transformer , health index , insulation system , condition monitoring , arti cial intelligence .",
        "i .",
        "introduction power transformer be among the most critical and expen- sive asset within the electrical transmission and distribution network .",
        "with the continous increase in the load demand , power transformer be operate close to their nominal rat- ings and become more prone to failure .",
        "therefore , power transformer need to be continuously monitor during their entire operational life to avoid sudden and catastrophic fail- ures .",
        "over the past two decade , several condition monitor technique have be develop for power transformer [ 1 ] .",
        "among these technique , insulation system have be a com- mon key component to identify transformer health state and estimate its useful rmnant life [ 2 ] .",
        "several paper to explain the associate editor coordinate the review of this manuscript and approve it for publication be zhouyang ren .the age mechanism of the transformer oil and paper insu- lation have be publish in the literature [ 3 ] \u0015 [ 7 ] .",
        "the health condition and remnant life of power transformer have be assess through various parameter of the insulation system [ 8 ] , [ 9 ] .",
        "reliable and cost effective condition monitoring and asset management technique be essential for electric utility in prepare an appropriate nancial plan to estimate the future cost of maintenance , repair , and replacement of their power transformer eet .",
        "in this regard , much research effort have be conduct to help utility company optimize their asset maintenance cost .",
        "transformer asset management ( tam ) practice have be explain in [ 10 ] \u0015 [ 12 ] in which strategic plan for future maintenance and replacement activity base on various diagnostic testing method be present .",
        "the diagnostic testing method can be generally categorize into volume 9 , 2021this work be license under a creative commons attribution 4.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/4.0/150637d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty condition monitoring ( cm ) and condition assessment ( ca ) technique .",
        "cm techniques employ electrical , chemical , and physical test to be collectively use by the ca tool to determine the health condition of the transformer .",
        "the transformer health index ( hi ) , as primarily explain in [ 13 ] , be a single factor that utilize the information from operating observation , eld inspection , and laboratory test to provide a reliable tam decision .",
        "majority of the data use in the hi model be base on the insulation system test .",
        "oil insulation test include dissolved gas analysis ( dga ) , oil quality analysis ( oqa ) , and furan analysis ( ffa ) .",
        "due to the high electric and thermal stress within operate trans- former , oil and paper insulation decomposes and release some gas that dissolve in the oil and decrease its dielectric strength .",
        "these gas include hydrogen ( h 2 ) , methane ( ch 4 ) , ethylene ( c 2h4 ) , acetylene ( c 2h2 ) , ethane ( c 2h6 ) , carbon monoxide ( co ) , and carbon dioxide ( co 2 ) .",
        "dga test be conduct to quantify these gas from which internal trans- former electrical and thermal fault can be identi ed [ 14 ] .",
        "considering the guideline in [ 15 ] , the oqa be determine by analyze the oil breakdown voltage ( bdv ) , acidity , water content , interfacial tension ( ift ) , dielectric dissipation fac- tor ( ddf ) , and color .",
        "ffa be conduct to measure furan compound that be generate due to cellulose degradation and dissolve in the transformer oil [ 16 ] .",
        "among the 5 furan compound , furfuraldehyde ( also know as furfural/2fal ) dominate the measurement and be correlate to the degree of polymerization of the paper insulation [ 17 ] .",
        "a scoring-weighting ( also call weighted-sum ) be the most commonly use method to calculate the hi of power transformer [ 13 ] , [ 18 ] \u0015 [ 23 ] .",
        "the approach start by com- par each parameter to a scoring table , then weight each parameter base on its importance .",
        "the weight be usually identi ed by expert personnel .",
        "the individual score be combine into a single index that reveal the overall health condition of the transformer .",
        "as the hi be a linear combination of different score and weight measurement data , it be a challenge task to deal with the uncertainty of the use data through the current utility practice to identify the hi .",
        "the rapid development of computer science and data processing have result in new hi approach base on machine learning algorithm for big data analysis [ 9 ] .",
        "arti- cial intelligence ( ai ) -based hi approach be present in [ 24 ] use dga , furan , and oil test data to assess the health condition of several in-service transformer .",
        "however , due to the limited available data , the prediction accuracy of the developed neuro-fuzzy model have only be 56.3 % .",
        "the study in [ 25 ] conduct a transformer hi sensitivity analysis use self adaptive neuro-fuzzy inference system ( anfis ) whose parameter be tune use particle swarm optimizer ( pso ) .",
        "in [ 26 ] , probabilistic markov chain model be use to predict the future condition of the transformer base on hi calculation use a non-linear optimization tech- nique .",
        "ai with a fuzzy-based support vector machine ( svm ) be employ in transformer hi-based condition assessmentusing several factor , industry standard , and utility expert judgment [ 27 ] .",
        "ai-based general regression neural network ( grnn ) be introduce in [ 28 ] to calculate the hi base on four-class transformer condition ; very poor , poor , fair , and good .",
        "in [ 29 ] , ai-based hi use bayesian network be propose to quantify the parameter contribution through score-probability and population failure statistic .",
        "in [ 30 ] , principal component analysis ( pca ) and analytical hierarchy process ( ahp ) be propose to determine the transformer health condition base on an expert empirical formula .",
        "the use of ai method to de ne transformer health index have be present in the literature .",
        "for instance , decision tree , random forest ( rf ) , static vector machine ( svm ) , arti cial neural network ( ann ) , and k-nearest neigh- bor ( knn ) method be use in [ 27 ] to automate the assess- ment process .",
        "a study in [ 31 ] compare several machine learn algorithm such as ann , svm , and gaussian bayesian network ( gbn ) , to evaluate the health condition of power transformer through probabilistic hi framework .",
        "an approach be present in [ 32 ] that compare the perfor- mance of various ai method such as naïve bayes ( nb ) , multinomial logistic regression ( mlr ) , ann , svm , knn , one rule ( oner ) , decision tree ( j48 ) , and rf in identify transformer health index .",
        "however , regardless the various ai method propose in the literature to calculate the transformer hi , more thorough study be still require to improve the accuracy of such method , in particular with the uncertainty or unavailability of the use data .",
        "as discuss in [ 9 ] , data uncertainty be the main shortcom- ing of the hi method which affect its reliability and accuracy .",
        "data unavailability be the main reason of uncertainty .",
        "the study in [ 33 ] report the effect of data unavailability and propose a remedial approach base on rf to predict the miss data and improve the scoring-weighting hi .",
        "how- ever , the development and investigation of ai-based hi model in handle data uncertainty have not yet discuss thoroughly with proven implementation feasibility .",
        "table 1 .",
        "summary of previous research .",
        "table 1 show the summary of the previous research .",
        "from the above discussion , the gap in this area of research can be summarize as below : \u000fdespite the several ai-based method use to identify the hi of power transformer , accuracy of such method be still relatively low .",
        "150638 volume 9 , 2021d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty \u000fthere be no reliable and widely accept technique to deal with data uncertainity which affect the reliability of the current hi practice .",
        "as such , the main contribution of this paper be tov \u000fconstruct an ai-based approach to enrich the current conventional hi scoring-weighting method for power transformer .",
        "\u000fimprove the accuracy of the hi calculation use multi- ai model to process most common routine testing data for power transformer insulation system .",
        "\u000fdevelop an effective correlation for all used parameter in calculate the transformer hi .",
        "\u000fidentify the best ai-based combination for deal with data uncertainty and miss value .",
        "figure 1 .",
        "flowchart of the propose methodology .",
        "ii .",
        "methodology the study in this paper be conduct in accordance to the work ow of figure 1 .",
        "diagnostic data of 504 , 150kv-power transformer include oil characteristic , furan content , and dga be collect from in-service unit of various life span and health condition .",
        "the assessment data be use to calculate the power transformer insulation system hi use the conventional scoring-weighting ( sw ) method .",
        "at the same time , data be use to establish the ai-based hi method .",
        "the performance of various ai algorithm be compare to identify the best performing ai algorithm through compar- ison with the sw method as a reference .",
        "the effect ofunavailable data on the accuracy of both conventional sw and the identi ed best perform ai-based hi be evaluate by adjust the complete data into 50 miss data scenario .",
        "a preprocessing approach be then propose to enhance the ability of the ai-based hi model to deal with such unavailable data and provide an accurate hi value .",
        "a. transformer population the data use in this study be collect from pt .",
        "pln persero , an indonesian state electricity company .",
        "data be collect from 504 unit , all with a speci c high voltage of 150 kv with a low voltage of either 70 kv or 20 kv .",
        "major- ity of these transformer use kraft paper insulation and they be periodically inspect in a condition-based maintenance scheme by check their insulation property through dga and dielectric characteristic ( oil quality analysis ) .",
        "dielec- tric characteristic include oil breakdown voltage ( bdv ) , water content , interfacial tension ( ift ) , acidity , and color .",
        "in addition , 2-fal measurement be provide for some unit .",
        "normally , the oil testing be conduct once a year or more frequent , if need .",
        "data use for the analysis in this paper be the same year data when hi be calculate , therefore omit the uncertainty cause by outdated data .",
        "the age classi ca- tion of the observed population sample be show in figure 2 .",
        "figure 2 .",
        "the age classification of the transformer population sample .",
        "b. transformer health index there be many method to calculate the transformer hi score that re ects the overall health condition of the power transformer .",
        "generally , there be two main approach to determine the hi : scoring-weighting : this approach start with a scoring and weight process conduct by expert personnel .",
        "as show in figure 3 , condition data be process into score by com- par them to the scoring table .",
        "then , individual score be weight and aggregate into a single index value reveal the overall transformer health condition .",
        "a nal health index be a linear combination of different score and weight mea- surement data .",
        "therefore it be a challenge task to conduct a consistent and reliable hi process in case of some of the data be unavailable .",
        "in this regard , this paper highlight the volume 9 , 2021 150639d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty figure 3 .",
        "the principle of conventional hi scoring-weighting method .",
        "drawback of the conventional scoring-weighting model in handle unavailable data use the certainty level and output accuracy as propose in [ 33 ] .",
        "arti cial intelligence : various ai method have be employ to estimate the transformer hi .",
        "the typical ai-based hi model development be as show in figure 4 .",
        "in this method , train database include various diagnostic measurement conduct on several transformer at differ- ent health condition level must be carefully prepared .",
        "the training dataset be use to establish the ai model to estimate the overall transformer health condition .",
        "as discuss above , various arti cial intelligence algorithm have be use to establish such model include ann , anfis , svm , grnn , decision tree [ 34 ] .",
        "the use of ai in power transformer condition assessment be useful especially for analyse large transformer datasets [ 35 ] .",
        "figure 4 .",
        "the principle of ai-based hi method .",
        "c. power transformer insulation system hi the hi be develop base on the transformer reliability survey publish by cigre tb 642 [ 36 ] that be discuss the failure mode of high voltage power transformer .",
        "the survey result show that the most common fault location for power transformer be the winding , with a dominant fault mode within the dielectric system .",
        "the main cause of failure include age and external short circuit .",
        "therefore , this study focus mainly on the integrity of the power transformer insulation system .",
        "the structure of the propose hi methodis divide into three-layers as show in figure 5 which be base on previously propose method in [ 20 ] .",
        "the hi be equip with score table to score each measurement , as well as weight factor base on the reliability and criticality of each parameter .",
        "these table and weight fac- tor can be continuously adapt base on new information , experience , and recent international guideline .",
        "the layer in figure 5 include : data layer : this layer consist of frequently measure diag- nostic data such as key gas of dga , bdv , water content , ift , acidity , oil color , 2fal , and transformer age .",
        "factor layer : this layer have three category that be derive from data layer/ measurement : 1.oil quality factor ( oqf ) that consist of oil parameter ; bdv , water content , ift , acidity , and color .",
        "2.faults factor ( ff ) , which consist of gas evolution , gas concentration level , and duval 's pentagon dga interpreta- tion method ( dpm ) , which be show in figure 6 .",
        "3.paper condition factor ( pcf ) : this factor consist of the operating age , co/co 2ratio , and 2fal concentration .",
        "health index layer : in this layer the hi calculation be conduct to provide a single value that reveal the overall health condition of the investigated transformer .",
        "figure 5 .",
        "layers of the propose ai method .",
        "d. scoring-weighting-based hi all of the data use to calculate the transformer hi be determine by international standard limit [ 37 ] , [ 38 ] .",
        "the scoring-weighting base hi for each factor be calculate as in ( 1 ) .",
        "hieach factordpn id1siwipn 1wi ( 1 ) where nis the number of parameter use in every factor .",
        "the value of siis base on the scoring for each parameter base on standard scoring table , and wiis the weighting factor that describe the importance of every parameter .",
        "150640 volume 9 , 2021d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty table 2 .",
        "the scoring-weighting for oil quality .",
        "table 3 .",
        "the level score for dga .",
        "table 4 .",
        "the rate scoring for dga .",
        "table 5 .",
        "the matrix of fault factor category .",
        "the assessment method be base on tables 2 through 7 , along with figure 6 .",
        "the nal hi value be calculate use ( 2 ) .",
        "hi naldpn jd1sfjwjpn jd14wjx100 % ( 2 ) where sfjis the parameter 's scoring factor and wjis the weighting factor .",
        "the weight parameter and factor be obtain by use ahp .",
        "this technique be build base on the judgment of ve expert with in-depth experience in transformertable 6 .",
        "the scoring-weighting paper condition .",
        "figure 6 .",
        "duval 's pentagon dga interpretation method .",
        "table 7 .",
        "the score for health index factor .",
        "table 8 .",
        "the health index category .",
        "condition monitoring , fault diagnosis and asset manage- ment [ 39 ] , [ 40 ] .",
        "the health index category and description be classi ed as show in table 8 .",
        "a more detailed explanation of the scoring- weighting method can be find in [ 20 ] .",
        "volume 9 , 2021 150641d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty figure 7 .",
        "a flowchart for the ai-based hi model 's development .",
        "figure 8 .",
        "flowchart of the propose multi-ai approach to calculate hi .",
        "e. ai-based hi development to establish the ai-based hi model , the collected transformer data have be divide into 354 training and 150 test data set .",
        "each set comprise data of transformer of different age , operate and health condition .",
        "the output of the ai model be the overall hi which be validate use the corresponding hi calculate by the scoring-weighting method .",
        "if the ai model do not providesatisfactorily accuracy , additional tuning process be conduct through more training .",
        "on the other hand , if the accuracy have meet the criterion , the nal hi be calculate as per the process show in figure 7 .",
        "various ai algorithm be employ to establish the propose hi model ; this include knn , svm , rf , nb , ann , adaptive boosting ( adaboost ) , and decision tree ( tree ) .",
        "the propose method to calculate the trans- former hi use multi-ai approach be show in figure 8 .",
        "the performance of these approach be compare base on : ai-sw : which be base on factor category stage ( oqf , ff , and pcf ) , then scoring-weighting-based in hi category stage .",
        "ai-ful : which be base on all classi cation stage ( oqf , ff , pcf , and hi category ) of the ai model .",
        "f. dealing with data uncertainty all assessment of transformer include a non-avoidable level of uncertainty .",
        "unavailability of the data , erroneous , or obsolete data will adversely affect the assessment result and increase the uncertainty of the obtain outcome .",
        "the uncertainty within available data be due to different reason such as incorrect data entry , erroneous or questionable test result , uncertainty in the condition assessment , and obsolete data [ 9 ] .",
        "a solution to manage the unavailability of the data be by employ machine learn to estimate the miss param- eters base on historical data and well train process .",
        "following the characteristic of the data , several method can be use to preprocess the miss value .",
        "in this study , the figure 9 .",
        "dealing the uncertainty with ai-based hi .",
        "150642 volume 9 , 2021d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty average/most frequent value be use to handle the issue of unavailable data as show in figure 9 .",
        "three method be use to implement the propose approach namely ; score weighting ( sw ) , random forest ( rf ) , and random forest with preprocessing-based ( rfwp ) .",
        "the certainty level ( cl ) be calculate as below [ 33 ] : clidwpixwfi ( 3 ) cldp ( availablecli ) max : clx100 ( 4 ) cliis the certainty level for each parameter ( i ) , wp iis the weighting parameter , and wfiis the weighting factor .",
        "g. proposed random forest random forest algorithm be a method consisting of a collec- tion of tree-structured classi er { h ( x , 2k ) , kd1 ; : : : } where { 2k } represent independent identically distributed random vector .",
        "each tree cast a unit vote for choose the most popular class at input x [ 41 ] .",
        "an ensemble of the classi er h 1 ( x ) , h 2 ( x ) ... h k ( x ) , be give , and the training data be draw randomly from the distribution of the random vector x , y and the margin function be de ned asv mg ( x ; y ) davki ( hk ( x ) dy ) \u0000max j6dyavki ( hk ( x ) dj ) ( 5 ) the generalization error be give byv pe\u0003dpx ; y ( mg ( x ; y ) < 0 ) ( 6 ) in rf , hk ( x ) dh ( x ; 2k ) .",
        "almost all sequence 21 ... pe\u0003 converge tov px ; y ( p2 ( h ( x ; 2 ) dy ) \u0000max j6dyp2 ( h ( x ; 2 ) dj ) < 0 ) ( 7 ) this explain why random forest do not over t as more tree be add and produce a limit value for the general- ization error [ 41 ] .",
        "h. evaluation the evaluation of the model be base on the accuracy of the prediction of the transformer hi category .",
        "the classi cation accuracy ( ca ) be the proportion of correctly classi ed data as give by ( 8 ) .",
        "accuracyd ( tpctn ) ( tpctncfpcfn ) ( 8 ) where tpis true positive , tnis true negative , fpis false positive , and fnis false negative .",
        "this calculation be base on the confusion matrix of binary classi cation in which the evaluation be consider as a multi-class classi cation problem .",
        "iii .",
        "results and discussion a. transformer health index the hi be calculate for the investigated 504 unit use the scoring-weighting method .",
        "as show in figure 10 , the most frequent category of hi transformer be very good condi- tion ( vg ) that represent 174 unit or 35 % of the population .",
        "figure 10 .",
        "hi category by scoring-weighting method .",
        "the other category be good condition ( g ) for 104 unit ( 21 % ) , caution condition ( c ) for 134 unit ( 27 % ) , poor con- dition ( p ) for 82 unit ( 16 % ) , and very poor condition ( vp ) for 10 unit ( 2 % ) .",
        "this hi assessment be use to highlight faulty transformer and to construct strategy for mainte- nance plan .",
        "b .",
        "data management the data use to develop the ai-based hi model be the same data classi ed in the above section to ensure the correctness and availability of all data .",
        "the distribution of the used parameter be show in figure 11 and a matrix correlat- ing these parameter be show in figure 12 .",
        "as show in figure 12 , the ift and color have the high correlation value of -0.69 .",
        "sequentially , the signi cant correlation be find between c 2h4and ch 4 ( 0.65 ) , 2fal and color ( 0.65 ) , ift and acidity ( \u00000.63 ) , color and acidity ( 0.55 ) , and age and color ( 0.53 ) .",
        "these result reveal that several parameter have a dependency relationship and in uences each other .",
        "furthermore , the correlation of parameter with hi score , as show in figure 13 , can be describe from the high to the low by apply a threshold limit above 0.2 , which be figure 11 .",
        "histogram of data collect parameter .",
        "volume 9 , 2021 150643d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty figure 12 .",
        "the correlation matrix of observed parameter .",
        "figure 13 .",
        "plot of the correlation between observed parameter .",
        "as follow : color ( \u00000.778 ) , ift ( c0.638 ) , 2fal ( \u00000.568 ) , age ( \u00000.51 ) , acidity ( \u00000.45 ) , co ( \u00000.413 ) , co 2 ( \u00000.335 ) , water content ( \u00000.278 ) , bdv ( c0.268 ) , and c 2h2 ( \u00000.218 ) .",
        "the hi score have a limit value of 1 , which mean hi category have an equal relationship with the hi score .",
        "therefore hi score and maximum level be derive from the value of the parameter ( data layer ) , then in the subsequent discus- sion , hi maximum score and lvmax will be ignore .",
        "the correlation of parameter help to reduce the number of fea- tures without reduce the accuracy signi cantly as will be elaborate below .",
        "c. evaluation of developed ai-based hi models to evaluate the performance of the developed ai-based hi model , the data be divide into training and test set .",
        "using the training data , random forest algorithm be find to produce the high classi cation accuracy ( ca ) of 91.2 % in oqf and 92.1 % in pcf .",
        "the tree decision excels at predict ff category with about 100 % of ca .",
        "in the hi-layer model , the adaboost algorithm produce the high ca of 97.2 % .",
        "figure 14 .",
        "performance comparison of data trainning multi-ai-based .",
        "when evaluate use the test data , as show in figure 14 , random forest excels with the pcf classi cation accuracy of 97 % .",
        "the decision tree excels with the oqf classi cation accuracy of 96 % , and the ff be 100 % accurate .",
        "the adaboost excels at predict hi category with about 100 % of ca .",
        "the result show that the best prediction model be the tree-based classi er such as random forest , decision tree and adaboost .",
        "table 9 .",
        "the confusion matrix of random forest ai-full-based .",
        "the performance of the rf classi er for the hi category be show in the confusion matrix .",
        "the comparison between actual and predicted value be use to evaluate the classi- cation accuracy of ai-based hi .",
        "the classi cation accu- racy for rf be 97.3 % .",
        "furthermore , the random forest model only have four incorrect classi cation , as show in table 9 .",
        "the accuracy of other model be : decision tree ( 96 % ) , adaboost ( 94.8 % ) , neural network ( 91.3 % ) , svm ( 89.3 % ) , naïve bayes ( 70.7 % ) , and knn ( 70 % ) .",
        "in addition , an ai-sw-based model , which use ai in the factor level , and weight-sum calculation in the hi level have be also devel- oped .",
        "the model provide a classi cation accuracy result of 98 % .",
        "figure 15 show a comparison of the performance of all developed model in term of the hi calculation accuracy .",
        "results attest that ai-based tree-structured classi er pro- duce well hi calculation accuracy than other algorithm .",
        "d. effects of unavailable data in this study , a comparison be do to evaluate the effect of uncertainty as a result of unavailable data to the accuracy of the hi calculation .",
        "three main method be compare : sw , rf , and rfwp .",
        "the miss data scenario in table 10 be assume to conduct this analysis .",
        "150644 volume 9 , 2021d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty figure 15 .",
        "accuracy of the ai method to predict hi .",
        "table 10 .",
        "missing value scenario of transformer health index .",
        "figure 16 show the accuracy with the certainty level of parameter .",
        "the result show that the rf be signi cantly in uenced by a low certainty level due to particular miss parameter .",
        "with a low certainty level , the accuracy of rf also decrease .",
        "in contrast , rf with preprocessing ( rfwp ) , due to miss value use the average or most frequent value , can maintain the classi cation accuracy at an acceptable level of at least 95 % .",
        "then , the effect of miss factor on the hi calculation accuracy be examine accord to the scenario show in table 11 .",
        "the uncertainty due to miss factor signi cantly affect the hi classi cation accuracy as show in figure 17 .",
        "in this case , the observed factor condition be divide into oqf , ff , and pcf .",
        "the most signi cant effect of miss value be observe in the rf-based paper condition factor ( pcf ) .",
        "the low accuracy value be 60.7 % use rf base on the missing of the paper condition factor .",
        "using rfwp , the classi cation accuracy can be increase to 82 % .",
        "therefore , it can be conclude that the rfwp model can maintain the classi cation accuracy of hi category with miss factor .",
        "after evaluate the effect of miss each parameter and factor on the hi accuracy , the next analysis be conduct to figure 16 .",
        "the accuracy with the certainty level of parameter .",
        "table 11 .",
        "scenarios of the factor availability .",
        "figure 17 .",
        "the accuracy with the certainty level of factor .",
        "investigate various scenario of unavailable data .",
        "the corre- lation of the certainty level and the classi cation accuracy of multi-parameters be construct , as show in appendix 1 .",
        "the aim be to measure the causal effect between certainty level and result hi accuracy for each of the three develop model : sw-based hi , rf-based hi , and rfwp-based hi .",
        "this analysis be help to de ne ef cient and precise way to deal with the data uncertainty .",
        "1 ) scoring-weighting ( sw ) -based health index when evaluate use the test data in appendix 1 , the sw-based hi be affect by the uncertainty due to unavailable data as show in figure 18 .",
        "this be indicate by the coef - cient of determination ( r2 ) of 0.917 .",
        "from figure 18 , the correlation of the accuracy ( y ) and certainty level ( x ) can be approximate use ( 9 ) .",
        "yd0:6554xc0:2573 ( 9 ) the challenge of this method be that if there be many miss value , the classi cation accuracy of the hi category volume 9 , 2021 150645d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty figure 18 .",
        "effect of certainty level due to unavailable data on the accuracy of sw-based hi .",
        "figure 19 .",
        "effect of certainty level due to unavailable data on the accuracy of rf-based hi .",
        "figure 20 .",
        "effect of certainty level due to unavailable data on the accuracy of rfwp-based hi .",
        "will be decrease signi cantly .",
        "the range of the classi cation accuracy in hi category will have a value above 80 % if the certainty level be above 85 % .table 12 .",
        "scenarios of data unavailability .",
        "the color category in term of the accuracy indicator be green for high ( h ) accuracy level , yellow for medium ( m ) accuracy level , and red for low ( l ) accuracy level .",
        "150646 volume 9 , 2021d .",
        "rediansyah et al .",
        ": artificial intelligence-based power transformer health index for handling data uncertainty 2 ) random forest-based the ai-based rf algorithm also suffer when predict transformer hi with many unavailable data as con rmed by figure 19 in which r2is 0.7614 .",
        "the correlation of the accu- racy and certainty level for this model can be approximate as below .",
        "yd0:7542xc0:1232 ( 10 ) in some case , rf model can predict the hi with an accu- racy above 80 % even though the certainty level be only 70 % .",
        "nevertheless , the accuracy will be well if the certainty level be above 80 % .",
        "3 ) random forest with preprocessing the rfwp be slightly affect by unavailable data .",
        "in this case r2is 0.8079 and the accuracy-certainty level correlation can be approximate from figure 19 as in ( 11 ) .",
        "yd0:5407xc0:4904 ( 11 ) the rfwp model have perform good than sw and rf , result in the high accuracy value in classify the hi category even at a low certainty level .",
        "when the certainty level be , in the worst-case below 10 % , the accuracy be still above 50 % .",
        "in some instance , the accuracy can reach a value above 80 % even with a certainty level of only 50 % .",
        "the best condition be when the certainty level be above 70 % which result in an accuracy reach 90 % .",
        "for instance for scenario hi-13 in the appendix , furan and ift parameter be unavailable .",
        "based on the data observation , furan and ift have the high frequency of data unavailability .",
        "the assessment value of the certainty level for hi-13 scenario be 79 % , and when evaluate base on 150 transformer data , the classi cation accuracy use the scoring-weighting method be 78 % .",
        "it can be observe that the rf model can achieve 80.7 % accuracy while the rfwp classi cation accuracy be 96 % .",
        "as show in figure 20 , the rfwp model achieve medium to high accuracy level in almost all instance .",
        "this reveal the ability of rfwp to solve the issue of data uncertainty in estimate the transformer hi .",
        "iv .",
        "conclusion the development and implementation of arti cial intelligence-based health index model to assess the power transformer insulation system condition have be present .",
        "the propose method be aim to simplify , speed up , and reduce error due to data uncertainty .",
        "a comparison of various ai algorithm be carry out and evaluate use the classi - cation accuracy in reference to the scoring-weighting-based hi calculation that be widely use by worldwide utility .",
        "based on this comparison , the random forest-based model be choose as the propose method with the high accuracy to predict the transformer hi .",
        "results show that random forest do not over t as it produce a limit value of generalization error .",
        "as such , random forest with prepro- cessing have be propose to handle the data uncertaintyby consider the miss value with the average or the most frequent value .",
        "the impact of miss data on the model have be evaluate , and the propose rfwp perform good than other investigated method and result in a satisfactory classi cation accuracy even with low certainity level .",
        "this solve the current common issue of calculate the transformer hi with unavailable data .",
        "results in this paper pave the way to adopt ai-based method in calculate the transformer hi .",
        "however , implement such technique call for more validation and feasibility study on large transformer population with several scenario of unavailable data .",
        "appendix scenarios of uncertainty multi-parameter see table 12 ."
    ],
    "processed_text": "received october 20 2021 accept october 30 2021 date publication november 4 2021 date current version november 12 2021 digital object identifier 101 109/access20213125379 artificial intelligencebased power transformer health index handling data uncertainty dhanu rediansyah 12 graduate student member ieee rahman azis prasojo 13 graduate student member ieee suwarno 1 senior member ieee abusiada 4 senior member ieee 1school electrical engineering informatics institut teknologi bandung bandung 40132 indonesia 2pt pln persero head ce jakarta 12160 indonesia 3electrical engineering department politeknik negeri malang malang 65141 indonesia 4electrical computer engineering discipline curtin university perth wa 6102 australia corresponding author rahman azis prasojo rahmanazisp @ polinemaacid work support part pt pln persero part institut teknologi bandung abstract power transformer critical expensive asset electric transmission distribution network essential monitor health condition power transformer eet network avoid unwanted outage health index hi quick ef cient way assess condition power transformer base multicriteria power transformer hi method well present literature much attention give handle uncertainty reliability method due unavailability use data therefore paper aim tackle issue employ arti cial intelligence ai based technique reveal health condition power transformer high accuracy time handle data uncertainty propose hi approach assess power transformer insulation system base oil quality dissolve gas analysis dga paper condition regard collect data 504 150kv transformer use establish propose aimodels seven ai algorithms include knearest neighbor knn support vector machine svm random forest rf naive bayes nb arti cial neural network ann adaptive boosting adaboost decision tree investigate performance comparison propose aibased hi model carry use scoring weightingbased hi method reference results show rf model provide best performance predict power transformer hi accuracy 973 index terms power transformer health index insulation system condition monitoring arti cial intelligence introduction power transformer among critical expen sive asset within electrical transmission distribution network continous increase load demand power transformer operate close nominal rat ings become prone failure therefore power transformer need continuously monitor entire operational life avoid sudden catastrophic fail ures past two decade several condition monitor technique develop power transformer 1 among technique insulation system com mon key component identify transformer health state estimate useful rmnant life 2 several paper explain associate editor coordinate review manuscript approve publication zhouyang ren age mechanism transformer oil paper insu lation publish literature 3 \u0015 7 health condition remnant life power transformer assess various parameter insulation system 8 9 reliable cost effective condition monitoring asset management technique essential electric utility prepare appropriate nancial plan estimate future cost maintenance repair replacement power transformer eet regard much research effort conduct help utility company optimize asset maintenance cost transformer asset management tam practice explain 10 \u0015 12 strategic plan future maintenance replacement activity base various diagnostic testing method present diagnostic testing method generally categorize volume 9 2021this work license creative commons attribution 40 license information see http //creativecommonsorg/licenses/by/40/150637d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty condition monitoring cm condition assessment ca technique cm techniques employ electrical chemical physical test collectively use ca tool determine health condition transformer transformer health index hi primarily explain 13 single factor utilize information operating observation eld inspection laboratory test provide reliable tam decision majority data use hi model base insulation system test oil insulation test include dissolved gas analysis dga oil quality analysis oqa furan analysis ffa due high electric thermal stress within operate trans former oil paper insulation decomposes release gas dissolve oil decrease dielectric strength gas include hydrogen h 2 methane ch 4 ethylene c 2h4 acetylene c 2h2 ethane c 2h6 carbon monoxide co carbon dioxide co 2 dga test conduct quantify gas internal trans former electrical thermal fault identi ed 14 considering guideline 15 oqa determine analyze oil breakdown voltage bdv acidity water content interfacial tension ift dielectric dissipation fac tor ddf color ffa conduct measure furan compound generate due cellulose degradation dissolve transformer oil 16 among 5 furan compound furfuraldehyde also know furfural/2fal dominate measurement correlate degree polymerization paper insulation 17 scoringweighting also call weightedsum commonly use method calculate hi power transformer 13 18 \u0015 23 approach start com par parameter scoring table weight parameter base importance weight usually identi ed expert personnel individual score combine single index reveal overall health condition transformer hi linear combination different score weight measurement data challenge task deal uncertainty use data current utility practice identify hi rapid development computer science data processing result new hi approach base machine learning algorithm big data analysis 9 arti cial intelligence ai based hi approach present 24 use dga furan oil test data assess health condition several inservice transformer however due limited available data prediction accuracy developed neurofuzzy model 563 study 25 conduct transformer hi sensitivity analysis use self adaptive neurofuzzy inference system anfis whose parameter tune use particle swarm optimizer pso 26 probabilistic markov chain model use predict future condition transformer base hi calculation use nonlinear optimization tech nique ai fuzzybased support vector machine svm employ transformer hibased condition assessmentusing several factor industry standard utility expert judgment 27 aibased general regression neural network grnn introduce 28 calculate hi base fourclass transformer condition poor poor fair good 29 aibased hi use bayesian network propose quantify parameter contribution scoreprobability population failure statistic 30 principal component analysis pca analytical hierarchy process ahp propose determine transformer health condition base expert empirical formula use ai method de ne transformer health index present literature instance decision tree random forest rf static vector machine svm arti cial neural network ann knearest neigh bor knn method use 27 automate assess ment process study 31 compare several machine learn algorithm ann svm gaussian bayesian network gbn evaluate health condition power transformer probabilistic hi framework approach present 32 compare perfor mance various ai method naive bayes nb multinomial logistic regression mlr ann svm knn one rule oner decision tree j48 rf identify transformer health index however regardless various ai method propose literature calculate transformer hi thorough study still require improve accuracy method particular uncertainty unavailability use data discuss 9 data uncertainty main shortcom ing hi method affect reliability accuracy data unavailability main reason uncertainty study 33 report effect data unavailability propose remedial approach base rf predict miss data improve scoringweighting hi ever development investigation aibased hi model handle data uncertainty yet discuss thoroughly proven implementation feasibility table 1 summary previous research table 1 show summary previous research discussion gap area research summarize \u000fdespite several aibased method use identify hi power transformer accuracy method still relatively low 150638 volume 9 2021d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty \u000fthere reliable widely accept technique deal data uncertainity affect reliability current hi practice main contribution paper tov \u000fconstruct aibased approach enrich current conventional hi scoringweighting method power transformer \u000fimprove accuracy hi calculation use multi ai model process common routine testing data power transformer insulation system \u000fdevelop effective correlation used parameter calculate transformer hi \u000fidentify best aibased combination deal data uncertainty miss value figure 1 flowchart propose methodology ii methodology study paper conduct accordance work ow figure 1 diagnostic data 504 150kvpower transformer include oil characteristic furan content dga collect inservice unit various life span health condition assessment data use calculate power transformer insulation system hi use conventional scoringweighting sw method time data use establish aibased hi method performance various ai algorithm compare identify best performing ai algorithm compar ison sw method reference effect ofunavailable data accuracy conventional sw identi ed best perform aibased hi evaluate adjust complete data 50 miss data scenario preprocessing approach propose enhance ability aibased hi model deal unavailable data provide accurate hi value transformer population data use study collect pt pln persero indonesian state electricity company data collect 504 unit speci c high voltage 150 kv low voltage either 70 kv 20 kv major ity transformer use kraft paper insulation periodically inspect conditionbased maintenance scheme check insulation property dga dielectric characteristic oil quality analysis dielec tric characteristic include oil breakdown voltage bdv water content interfacial tension ift acidity color addition 2fal measurement provide unit normally oil testing conduct year frequent need data use analysis paper year data hi calculate therefore omit uncertainty cause outdated data age classi ca tion observed population sample show figure 2 figure 2 age classification transformer population sample b transformer health index many method calculate transformer hi score ects overall health condition power transformer generally two main approach determine hi scoringweighting approach start scoring weight process conduct expert personnel show figure 3 condition data process score com par scoring table individual score weight aggregate single index value reveal overall transformer health condition nal health index linear combination different score weight mea surement data therefore challenge task conduct consistent reliable hi process case data unavailable regard paper highlight volume 9 2021 150639d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty figure 3 principle conventional hi scoringweighting method drawback conventional scoringweighting model handle unavailable data use certainty level output accuracy propose 33 arti cial intelligence various ai method employ estimate transformer hi typical aibased hi model development show figure 4 method train database include various diagnostic measurement conduct several transformer differ ent health condition level must carefully prepared training dataset use establish ai model estimate overall transformer health condition discuss various arti cial intelligence algorithm use establish model include ann anfis svm grnn decision tree 34 use ai power transformer condition assessment useful especially analyse large transformer datasets 35 figure 4 principle aibased hi method c power transformer insulation system hi hi develop base transformer reliability survey publish cigre tb 642 36 discuss failure mode high voltage power transformer survey result show common fault location power transformer winding dominant fault mode within dielectric system main cause failure include age external short circuit therefore study focus mainly integrity power transformer insulation system structure propose hi methodis divide threelayers show figure 5 base previously propose method 20 hi equip score table score measurement well weight factor base reliability criticality parameter table weight fac tor continuously adapt base new information experience recent international guideline layer figure 5 include data layer layer consist frequently measure diag nostic data key gas dga bdv water content ift acidity oil color 2fal transformer age factor layer layer three category derive data layer/ measurement 1oil quality factor oqf consist oil parameter bdv water content ift acidity color 2faults factor ff consist gas evolution gas concentration level duval 's pentagon dga interpreta tion method dpm show figure 6 3paper condition factor pcf factor consist operating age co/co 2ratio 2fal concentration health index layer layer hi calculation conduct provide single value reveal overall health condition investigated transformer figure 5 layers propose ai method scoringweightingbased hi data use calculate transformer hi determine international standard limit 37 38 scoringweighting base hi factor calculate 1 hieach factordpn id1siwipn 1wi 1 nis number parameter use every factor value siis base scoring parameter base standard scoring table wiis weighting factor describe importance every parameter 150640 volume 9 2021d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty table 2 scoringweighting oil quality table 3 level score dga table 4 rate scoring dga table 5 matrix fault factor category assessment method base tables 2 7 along figure 6 nal hi value calculate use 2 hi naldpn jd1sfjwjpn jd14wjx100 2 sfjis parameter 's scoring factor wjis weighting factor weight parameter factor obtain use ahp technique build base judgment expert indepth experience transformertable 6 scoringweighting paper condition figure 6 duval 's pentagon dga interpretation method table 7 score health index factor table 8 health index category condition monitoring fault diagnosis asset manage ment 39 40 health index category description classi ed show table 8 detailed explanation scoring weighting method find 20 volume 9 2021 150641d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty figure 7 flowchart aibased hi model 's development figure 8 flowchart propose multiai approach calculate hi e aibased hi development establish aibased hi model collected transformer data divide 354 training 150 test data set set comprise data transformer different age operate health condition output ai model overall hi validate use corresponding hi calculate scoringweighting method ai model providesatisfactorily accuracy additional tuning process conduct training hand accuracy meet criterion nal hi calculate per process show figure 7 various ai algorithm employ establish propose hi model include knn svm rf nb ann adaptive boosting adaboost decision tree tree propose method calculate trans former hi use multiai approach show figure 8 performance approach compare base aisw base factor category stage oqf ff pcf scoringweightingbased hi category stage aiful base classi cation stage oqf ff pcf hi category ai model f dealing data uncertainty assessment transformer include nonavoidable level uncertainty unavailability data erroneous obsolete data adversely affect assessment result increase uncertainty obtain outcome uncertainty within available data due different reason incorrect data entry erroneous questionable test result uncertainty condition assessment obsolete data 9 solution manage unavailability data employ machine learn estimate miss param eters base historical data well train process following characteristic data several method use preprocess miss value study figure 9 dealing uncertainty aibased hi 150642 volume 9 2021d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty average/most frequent value use handle issue unavailable data show figure 9 three method use implement propose approach namely score weighting sw random forest rf random forest preprocessingbased rfwp certainty level cl calculate 33 clidwpixwfi 3 cldp availablecli max clx100 4 cliis certainty level parameter wp iis weighting parameter wfiis weighting factor g proposed random forest random forest algorithm method consisting collec tion treestructured classi er { h x 2k kd1 } { 2k } represent independent identically distributed random vector tree cast unit vote choose popular class input x 41 ensemble classi er h 1 x h 2 x h k x give training data draw randomly distribution random vector x margin function de ned asv mg x davki hk x dy \u0000max j6dyavki hk x dj 5 generalization error give byv pe\u0003dpx mg x < 0 6 rf hk x dh x 2k almost sequence 21 pe\u0003 converge tov px p2 h x 2 dy \u0000max j6dyp2 h x 2 dj < 0 7 explain random forest tree add produce limit value general ization error 41 h evaluation evaluation model base accuracy prediction transformer hi category classi cation accuracy ca proportion correctly classi ed data give 8 accuracyd tpctn tpctncfpcfn 8 tpis true positive tnis true negative fpis false positive fnis false negative calculation base confusion matrix binary classi cation evaluation consider multiclass classi cation problem iii results discussion transformer health index hi calculate investigated 504 unit use scoringweighting method show figure 10 frequent category hi transformer good condi tion vg represent 174 unit 35 population figure 10 hi category scoringweighting method category good condition g 104 unit 21 caution condition c 134 unit 27 poor con dition p 82 unit 16 poor condition vp 10 unit 2 hi assessment use highlight faulty transformer construct strategy mainte nance plan b data management data use develop aibased hi model data classi ed section ensure correctness availability data distribution used parameter show figure 11 matrix correlat ing parameter show figure 12 show figure 12 ift color high correlation value 069 sequentially signi cant correlation find c 2h4and ch 4 065 2fal color 065 ift acidity \u0000063 color acidity 055 age color 053 result reveal several parameter dependency relationship uences furthermore correlation parameter hi score show figure 13 describe high low apply threshold limit 02 figure 11 histogram data collect parameter volume 9 2021 150643d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty figure 12 correlation matrix observed parameter figure 13 plot correlation observed parameter follow color \u00000778 ift c0638 2fal \u00000568 age \u0000051 acidity \u0000045 co \u00000413 co 2 \u00000335 water content \u00000278 bdv c0268 c 2h2 \u00000218 hi score limit value 1 mean hi category equal relationship hi score therefore hi score maximum level derive value parameter data layer subsequent discus sion hi maximum score lvmax ignore correlation parameter help reduce number fea tures without reduce accuracy signi cantly elaborate c evaluation developed aibased hi models evaluate performance developed aibased hi model data divide training test set using training data random forest algorithm find produce high classi cation accuracy ca 912 oqf 921 pcf tree decision excels predict ff category 100 ca hilayer model adaboost algorithm produce high ca 972 figure 14 performance comparison data trainning multiaibased evaluate use test data show figure 14 random forest excels pcf classi cation accuracy 97 decision tree excels oqf classi cation accuracy 96 ff 100 accurate adaboost excels predict hi category 100 ca result show best prediction model treebased classi er random forest decision tree adaboost table 9 confusion matrix random forest aifullbased performance rf classi er hi category show confusion matrix comparison actual predicted value use evaluate classi cation accuracy aibased hi classi cation accu racy rf 973 furthermore random forest model four incorrect classi cation show table 9 accuracy model decision tree 96 adaboost 948 neural network 913 svm 893 naive bayes 707 knn 70 addition aiswbased model use ai factor level weightsum calculation hi level also devel oped model provide classi cation accuracy result 98 figure 15 show comparison performance developed model term hi calculation accuracy results attest aibased treestructured classi er pro duce well hi calculation accuracy algorithm effects unavailable data study comparison evaluate effect uncertainty result unavailable data accuracy hi calculation three main method compare sw rf rfwp miss data scenario table 10 assume conduct analysis 150644 volume 9 2021d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty figure 15 accuracy ai method predict hi table 10 missing value scenario transformer health index figure 16 show accuracy certainty level parameter result show rf signi cantly uenced low certainty level due particular miss parameter low certainty level accuracy rf also decrease contrast rf preprocessing rfwp due miss value use average frequent value maintain classi cation accuracy acceptable level least 95 effect miss factor hi calculation accuracy examine accord scenario show table 11 uncertainty due miss factor signi cantly affect hi classi cation accuracy show figure 17 case observed factor condition divide oqf ff pcf signi cant effect miss value observe rfbased paper condition factor pcf low accuracy value 607 use rf base missing paper condition factor using rfwp classi cation accuracy increase 82 therefore conclude rfwp model maintain classi cation accuracy hi category miss factor evaluate effect miss parameter factor hi accuracy next analysis conduct figure 16 accuracy certainty level parameter table 11 scenarios factor availability figure 17 accuracy certainty level factor investigate various scenario unavailable data corre lation certainty level classi cation accuracy multiparameters construct show appendix 1 aim measure causal effect certainty level result hi accuracy three develop model swbased hi rfbased hi rfwpbased hi analysis help de ne ef cient precise way deal data uncertainty 1 scoringweighting sw based health index evaluate use test data appendix 1 swbased hi affect uncertainty due unavailable data show figure 18 indicate coef cient determination r2 0917 figure 18 correlation accuracy certainty level x approximate use 9 yd06554xc02573 9 challenge method many miss value classi cation accuracy hi category volume 9 2021 150645d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty figure 18 effect certainty level due unavailable data accuracy swbased hi figure 19 effect certainty level due unavailable data accuracy rfbased hi figure 20 effect certainty level due unavailable data accuracy rfwpbased hi decrease signi cantly range classi cation accuracy hi category value 80 certainty level 85 table 12 scenarios data unavailability color category term accuracy indicator green high h accuracy level yellow medium accuracy level red low l accuracy level 150646 volume 9 2021d rediansyah et al artificial intelligencebased power transformer health index handling data uncertainty 2 random forestbased aibased rf algorithm also suffer predict transformer hi many unavailable data con rmed figure 19 r2is 07614 correlation accu racy certainty level model approximate yd07542xc01232 10 case rf model predict hi accu racy 80 even though certainty level 70 nevertheless accuracy well certainty level 80 3 random forest preprocessing rfwp slightly affect unavailable data case r2is 08079 accuracycertainty level correlation approximate figure 19 11 yd05407xc04904 11 rfwp model perform good sw rf result high accuracy value classify hi category even low certainty level certainty level worstcase 10 accuracy still 50 instance accuracy reach value 80 even certainty level 50 best condition certainty level 70 result accuracy reach 90 instance scenario hi13 appendix furan ift parameter unavailable based data observation furan ift high frequency data unavailability assessment value certainty level hi13 scenario 79 evaluate base 150 transformer data classi cation accuracy use scoringweighting method 78 observe rf model achieve 807 accuracy rfwp classi cation accuracy 96 show figure 20 rfwp model achieve medium high accuracy level almost instance reveal ability rfwp solve issue data uncertainty estimate transformer hi iv conclusion development implementation arti cial intelligencebased health index model assess power transformer insulation system condition present propose method aim simplify speed reduce error due data uncertainty comparison various ai algorithm carry evaluate use classi cation accuracy reference scoringweightingbased hi calculation widely use worldwide utility based comparison random forestbased model choose propose method high accuracy predict transformer hi results show random forest produce limit value generalization error random forest prepro cessing propose handle data uncertaintyby consider miss value average frequent value impact miss data model evaluate propose rfwp perform good investigated method result satisfactory classi cation accuracy even low certainity level solve current common issue calculate transformer hi unavailable data results paper pave way adopt aibased method calculate transformer hi however implement technique call validation feasibility study large transformer population several scenario unavailable data appendix scenarios uncertainty multiparameter see table 12",
    "bag_of_words": {
        "received": 1,
        "october": 2,
        "accept": 2,
        "date": 2,
        "publication": 2,
        "november": 2,
        "current": 5,
        "version": 1,
        "digital": 1,
        "object": 1,
        "identifier": 1,
        "109/access20213125379": 1,
        "artificial": 11,
        "intelligencebased": 12,
        "power": 38,
        "transformer": 86,
        "health": 42,
        "index": 29,
        "handling": 11,
        "data": 97,
        "uncertainty": 33,
        "dhanu": 1,
        "rediansyah": 11,
        "graduate": 2,
        "student": 2,
        "member": 4,
        "ieee": 4,
        "rahman": 2,
        "azis": 2,
        "prasojo": 2,
        "suwarno": 1,
        "senior": 2,
        "abusiada": 1,
        "1school": 1,
        "electrical": 4,
        "engineering": 3,
        "informatics": 1,
        "institut": 2,
        "teknologi": 2,
        "bandung": 3,
        "indonesia": 3,
        "2pt": 1,
        "pln": 3,
        "persero": 3,
        "head": 1,
        "ce": 1,
        "jakarta": 1,
        "3electrical": 1,
        "department": 1,
        "politeknik": 1,
        "negeri": 1,
        "malang": 2,
        "4electrical": 1,
        "computer": 2,
        "discipline": 1,
        "curtin": 1,
        "university": 1,
        "perth": 1,
        "wa": 1,
        "australia": 1,
        "corresponding": 2,
        "author": 1,
        "rahmanazisp": 1,
        "polinemaacid": 1,
        "work": 3,
        "support": 3,
        "part": 2,
        "pt": 2,
        "abstract": 1,
        "critical": 2,
        "expensive": 1,
        "asset": 6,
        "electric": 3,
        "transmission": 2,
        "distribution": 4,
        "network": 9,
        "essential": 2,
        "monitor": 3,
        "condition": 39,
        "eet": 2,
        "avoid": 2,
        "unwanted": 1,
        "outage": 1,
        "hi": 106,
        "quick": 1,
        "ef": 2,
        "cient": 3,
        "way": 3,
        "assess": 6,
        "base": 27,
        "multicriteria": 1,
        "method": 44,
        "well": 5,
        "present": 6,
        "literature": 4,
        "much": 2,
        "attention": 1,
        "give": 4,
        "handle": 6,
        "reliability": 5,
        "due": 13,
        "unavailability": 8,
        "use": 50,
        "therefore": 7,
        "paper": 15,
        "aim": 3,
        "tackle": 1,
        "issue": 4,
        "employ": 6,
        "arti": 8,
        "cial": 8,
        "intelligence": 5,
        "ai": 21,
        "based": 5,
        "technique": 8,
        "reveal": 6,
        "high": 13,
        "accuracy": 59,
        "time": 2,
        "propose": 21,
        "approach": 14,
        "insulation": 15,
        "system": 12,
        "oil": 16,
        "quality": 5,
        "dissolve": 3,
        "gas": 8,
        "analysis": 12,
        "dga": 11,
        "regard": 3,
        "collect": 5,
        "150kv": 1,
        "establish": 6,
        "aimodels": 1,
        "seven": 1,
        "algorithms": 1,
        "include": 11,
        "knearest": 2,
        "neighbor": 1,
        "knn": 5,
        "vector": 5,
        "machine": 6,
        "svm": 8,
        "random": 19,
        "forest": 15,
        "rf": 19,
        "naive": 3,
        "bayes": 3,
        "nb": 3,
        "neural": 4,
        "ann": 6,
        "adaptive": 3,
        "boosting": 2,
        "adaboost": 6,
        "decision": 10,
        "tree": 12,
        "investigate": 2,
        "performance": 8,
        "comparison": 7,
        "aibased": 23,
        "model": 38,
        "carry": 2,
        "scoring": 9,
        "weightingbased": 1,
        "reference": 3,
        "results": 5,
        "show": 30,
        "provide": 6,
        "best": 6,
        "predict": 9,
        "terms": 1,
        "monitoring": 4,
        "introduction": 1,
        "among": 3,
        "expen": 1,
        "sive": 1,
        "within": 4,
        "continous": 1,
        "increase": 3,
        "load": 1,
        "demand": 1,
        "operate": 3,
        "close": 1,
        "nominal": 1,
        "rat": 1,
        "ings": 1,
        "become": 1,
        "prone": 1,
        "failure": 4,
        "need": 2,
        "continuously": 2,
        "entire": 1,
        "operational": 1,
        "life": 4,
        "sudden": 1,
        "catastrophic": 1,
        "fail": 1,
        "ures": 1,
        "past": 1,
        "two": 2,
        "decade": 1,
        "several": 10,
        "develop": 4,
        "com": 3,
        "mon": 1,
        "key": 2,
        "component": 2,
        "identify": 5,
        "state": 2,
        "estimate": 6,
        "useful": 2,
        "rmnant": 1,
        "explain": 4,
        "associate": 1,
        "editor": 1,
        "coordinate": 1,
        "review": 1,
        "manuscript": 1,
        "approve": 1,
        "zhouyang": 1,
        "ren": 1,
        "age": 9,
        "mechanism": 1,
        "insu": 1,
        "lation": 2,
        "publish": 2,
        "remnant": 1,
        "various": 12,
        "parameter": 29,
        "reliable": 4,
        "cost": 3,
        "effective": 2,
        "management": 3,
        "utility": 5,
        "prepare": 1,
        "appropriate": 1,
        "nancial": 1,
        "plan": 3,
        "future": 3,
        "maintenance": 4,
        "repair": 1,
        "replacement": 2,
        "research": 4,
        "effort": 1,
        "conduct": 13,
        "help": 3,
        "company": 2,
        "optimize": 1,
        "tam": 2,
        "practice": 3,
        "strategic": 1,
        "activity": 1,
        "diagnostic": 4,
        "testing": 4,
        "generally": 2,
        "categorize": 1,
        "volume": 10,
        "2021this": 1,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "information": 3,
        "see": 2,
        "http": 1,
        "//creativecommonsorg/licenses/by/40/150637d": 1,
        "et": 10,
        "al": 10,
        "cm": 2,
        "assessment": 9,
        "ca": 8,
        "techniques": 1,
        "chemical": 1,
        "physical": 1,
        "test": 11,
        "collectively": 1,
        "tool": 1,
        "determine": 5,
        "primarily": 1,
        "single": 4,
        "factor": 28,
        "utilize": 1,
        "operating": 2,
        "observation": 2,
        "eld": 1,
        "inspection": 1,
        "laboratory": 1,
        "majority": 1,
        "dissolved": 1,
        "oqa": 2,
        "furan": 7,
        "ffa": 2,
        "thermal": 2,
        "stress": 1,
        "trans": 3,
        "former": 3,
        "decomposes": 1,
        "release": 1,
        "decrease": 3,
        "dielectric": 4,
        "strength": 1,
        "hydrogen": 1,
        "methane": 1,
        "ch": 2,
        "ethylene": 1,
        "2h4": 1,
        "acetylene": 1,
        "2h2": 2,
        "ethane": 1,
        "2h6": 1,
        "carbon": 2,
        "monoxide": 1,
        "co": 4,
        "dioxide": 1,
        "quantify": 2,
        "internal": 1,
        "fault": 5,
        "identi": 3,
        "ed": 6,
        "considering": 1,
        "guideline": 2,
        "analyze": 1,
        "breakdown": 2,
        "voltage": 5,
        "bdv": 5,
        "acidity": 7,
        "water": 5,
        "content": 6,
        "interfacial": 2,
        "tension": 2,
        "ift": 9,
        "dissipation": 1,
        "fac": 2,
        "tor": 2,
        "ddf": 1,
        "color": 10,
        "measure": 3,
        "compound": 2,
        "generate": 1,
        "cellulose": 1,
        "degradation": 1,
        "furfuraldehyde": 1,
        "also": 5,
        "know": 1,
        "furfural/2fal": 1,
        "dominate": 1,
        "measurement": 6,
        "correlate": 1,
        "degree": 1,
        "polymerization": 1,
        "scoringweighting": 15,
        "call": 2,
        "weightedsum": 1,
        "commonly": 1,
        "calculate": 18,
        "start": 2,
        "par": 2,
        "table": 22,
        "weight": 9,
        "importance": 2,
        "usually": 1,
        "expert": 5,
        "personnel": 2,
        "individual": 2,
        "score": 16,
        "combine": 1,
        "overall": 6,
        "linear": 2,
        "combination": 3,
        "different": 4,
        "challenge": 3,
        "task": 2,
        "deal": 5,
        "rapid": 1,
        "development": 6,
        "science": 1,
        "processing": 1,
        "result": 13,
        "new": 2,
        "learning": 1,
        "algorithm": 12,
        "big": 1,
        "inservice": 2,
        "however": 3,
        "limited": 1,
        "available": 2,
        "prediction": 3,
        "developed": 4,
        "neurofuzzy": 2,
        "study": 10,
        "sensitivity": 1,
        "self": 1,
        "inference": 1,
        "anfis": 2,
        "whose": 1,
        "tune": 1,
        "particle": 1,
        "swarm": 1,
        "optimizer": 1,
        "pso": 1,
        "probabilistic": 2,
        "markov": 1,
        "chain": 1,
        "calculation": 10,
        "nonlinear": 1,
        "optimization": 1,
        "tech": 1,
        "nique": 1,
        "fuzzybased": 1,
        "hibased": 1,
        "assessmentusing": 1,
        "industry": 1,
        "standard": 3,
        "judgment": 2,
        "general": 2,
        "regression": 2,
        "grnn": 2,
        "introduce": 1,
        "fourclass": 1,
        "poor": 4,
        "fair": 1,
        "good": 5,
        "bayesian": 2,
        "contribution": 2,
        "scoreprobability": 1,
        "population": 6,
        "statistic": 1,
        "principal": 1,
        "pca": 1,
        "analytical": 1,
        "hierarchy": 1,
        "process": 9,
        "ahp": 2,
        "empirical": 1,
        "formula": 1,
        "de": 3,
        "ne": 2,
        "instance": 4,
        "static": 1,
        "neigh": 1,
        "bor": 1,
        "automate": 1,
        "ment": 2,
        "compare": 5,
        "learn": 2,
        "gaussian": 1,
        "gbn": 1,
        "evaluate": 11,
        "framework": 1,
        "perfor": 1,
        "mance": 1,
        "multinomial": 1,
        "logistic": 1,
        "mlr": 1,
        "one": 1,
        "rule": 1,
        "oner": 1,
        "j48": 1,
        "regardless": 1,
        "thorough": 1,
        "still": 3,
        "require": 1,
        "improve": 2,
        "particular": 2,
        "discuss": 4,
        "main": 6,
        "shortcom": 1,
        "ing": 2,
        "affect": 6,
        "reason": 2,
        "report": 1,
        "effect": 10,
        "remedial": 1,
        "miss": 16,
        "ever": 1,
        "investigation": 1,
        "yet": 1,
        "thoroughly": 1,
        "proven": 1,
        "implementation": 2,
        "feasibility": 2,
        "summary": 2,
        "previous": 2,
        "discussion": 2,
        "gap": 1,
        "area": 1,
        "summarize": 1,
        "\u000fdespite": 1,
        "relatively": 1,
        "low": 9,
        "2021d": 5,
        "\u000fthere": 1,
        "widely": 2,
        "uncertainity": 1,
        "tov": 2,
        "\u000fconstruct": 1,
        "enrich": 1,
        "conventional": 5,
        "\u000fimprove": 1,
        "multi": 1,
        "common": 3,
        "routine": 1,
        "\u000fdevelop": 1,
        "correlation": 10,
        "used": 2,
        "\u000fidentify": 1,
        "value": 26,
        "figure": 45,
        "flowchart": 3,
        "methodology": 2,
        "ii": 1,
        "accordance": 1,
        "ow": 1,
        "150kvpower": 1,
        "characteristic": 4,
        "unit": 10,
        "span": 1,
        "sw": 7,
        "performing": 1,
        "compar": 1,
        "ison": 1,
        "ofunavailable": 1,
        "perform": 3,
        "adjust": 1,
        "complete": 1,
        "scenario": 8,
        "preprocessing": 3,
        "enhance": 1,
        "ability": 2,
        "unavailable": 16,
        "accurate": 2,
        "indonesian": 1,
        "electricity": 1,
        "speci": 1,
        "kv": 3,
        "either": 1,
        "major": 1,
        "ity": 1,
        "kraft": 1,
        "periodically": 1,
        "inspect": 1,
        "conditionbased": 1,
        "scheme": 1,
        "check": 1,
        "property": 1,
        "dielec": 1,
        "tric": 1,
        "addition": 2,
        "2fal": 5,
        "normally": 1,
        "year": 2,
        "frequent": 5,
        "omit": 1,
        "cause": 2,
        "outdated": 1,
        "classi": 31,
        "tion": 4,
        "observed": 4,
        "sample": 2,
        "classification": 1,
        "many": 3,
        "ects": 1,
        "aggregate": 1,
        "nal": 3,
        "mea": 1,
        "surement": 1,
        "consistent": 1,
        "case": 4,
        "highlight": 2,
        "150639d": 1,
        "principle": 2,
        "drawback": 1,
        "certainty": 23,
        "level": 37,
        "output": 2,
        "typical": 1,
        "train": 2,
        "database": 1,
        "differ": 1,
        "ent": 1,
        "must": 1,
        "carefully": 1,
        "prepared": 1,
        "training": 6,
        "dataset": 1,
        "especially": 1,
        "analyse": 1,
        "large": 2,
        "datasets": 1,
        "survey": 2,
        "cigre": 1,
        "tb": 1,
        "mode": 2,
        "location": 1,
        "winding": 1,
        "dominant": 1,
        "external": 1,
        "short": 1,
        "circuit": 1,
        "focus": 1,
        "mainly": 1,
        "integrity": 1,
        "structure": 1,
        "methodis": 1,
        "divide": 4,
        "threelayers": 1,
        "previously": 1,
        "equip": 1,
        "criticality": 1,
        "adapt": 1,
        "experience": 2,
        "recent": 1,
        "international": 2,
        "layer": 8,
        "consist": 4,
        "frequently": 1,
        "diag": 1,
        "nostic": 1,
        "three": 4,
        "category": 20,
        "derive": 2,
        "layer/": 1,
        "1oil": 1,
        "oqf": 6,
        "2faults": 1,
        "ff": 6,
        "evolution": 1,
        "concentration": 2,
        "duval": 2,
        "pentagon": 2,
        "interpreta": 1,
        "dpm": 1,
        "3paper": 1,
        "pcf": 7,
        "co/co": 1,
        "2ratio": 1,
        "investigated": 3,
        "layers": 1,
        "scoringweightingbased": 3,
        "limit": 5,
        "hieach": 1,
        "factordpn": 1,
        "id1siwipn": 1,
        "1wi": 1,
        "nis": 1,
        "number": 2,
        "every": 2,
        "siis": 1,
        "wiis": 1,
        "weighting": 6,
        "describe": 2,
        "rate": 1,
        "matrix": 6,
        "tables": 1,
        "along": 1,
        "naldpn": 1,
        "jd1sfjwjpn": 1,
        "jd14wjx100": 1,
        "sfjis": 1,
        "wjis": 1,
        "obtain": 2,
        "build": 1,
        "indepth": 1,
        "transformertable": 1,
        "interpretation": 1,
        "diagnosis": 1,
        "manage": 2,
        "description": 1,
        "detailed": 1,
        "explanation": 1,
        "find": 3,
        "150641d": 1,
        "multiai": 2,
        "collected": 1,
        "set": 3,
        "comprise": 1,
        "validate": 1,
        "providesatisfactorily": 1,
        "additional": 1,
        "tuning": 1,
        "hand": 1,
        "meet": 1,
        "criterion": 1,
        "per": 1,
        "aisw": 1,
        "stage": 3,
        "aiful": 1,
        "cation": 22,
        "dealing": 2,
        "nonavoidable": 1,
        "erroneous": 2,
        "obsolete": 2,
        "adversely": 1,
        "outcome": 1,
        "incorrect": 2,
        "entry": 1,
        "questionable": 1,
        "solution": 1,
        "param": 1,
        "eters": 1,
        "historical": 1,
        "following": 1,
        "preprocess": 1,
        "average/most": 1,
        "implement": 2,
        "namely": 1,
        "preprocessingbased": 1,
        "rfwp": 11,
        "cl": 1,
        "clidwpixwfi": 1,
        "cldp": 1,
        "availablecli": 1,
        "max": 1,
        "clx100": 1,
        "cliis": 1,
        "wp": 1,
        "iis": 1,
        "wfiis": 1,
        "proposed": 1,
        "consisting": 1,
        "collec": 1,
        "treestructured": 2,
        "er": 5,
        "2k": 3,
        "kd1": 1,
        "represent": 2,
        "independent": 1,
        "identically": 1,
        "distributed": 1,
        "cast": 1,
        "vote": 1,
        "choose": 2,
        "popular": 1,
        "class": 1,
        "input": 1,
        "ensemble": 1,
        "draw": 1,
        "randomly": 1,
        "margin": 1,
        "function": 1,
        "ned": 1,
        "asv": 1,
        "mg": 2,
        "davki": 1,
        "hk": 3,
        "dy": 2,
        "\u0000max": 2,
        "j6dyavki": 1,
        "dj": 2,
        "generalization": 2,
        "error": 4,
        "byv": 1,
        "pe\u0003dpx": 1,
        "dh": 1,
        "almost": 2,
        "sequence": 1,
        "pe\u0003": 1,
        "converge": 1,
        "px": 1,
        "p2": 1,
        "j6dyp2": 1,
        "add": 1,
        "produce": 4,
        "ization": 1,
        "evaluation": 4,
        "proportion": 1,
        "correctly": 1,
        "accuracyd": 1,
        "tpctn": 1,
        "tpctncfpcfn": 1,
        "tpis": 1,
        "true": 2,
        "positive": 2,
        "tnis": 1,
        "negative": 2,
        "fpis": 1,
        "false": 2,
        "fnis": 1,
        "confusion": 3,
        "binary": 1,
        "consider": 2,
        "multiclass": 1,
        "problem": 1,
        "iii": 1,
        "condi": 1,
        "vg": 1,
        "caution": 1,
        "con": 2,
        "dition": 1,
        "vp": 1,
        "faulty": 1,
        "construct": 2,
        "strategy": 1,
        "mainte": 1,
        "nance": 1,
        "section": 1,
        "ensure": 1,
        "correctness": 1,
        "availability": 2,
        "correlat": 1,
        "sequentially": 1,
        "signi": 6,
        "cant": 2,
        "2h4and": 1,
        "\u0000063": 1,
        "dependency": 1,
        "relationship": 2,
        "uences": 1,
        "furthermore": 2,
        "apply": 1,
        "threshold": 1,
        "histogram": 1,
        "150643d": 1,
        "plot": 1,
        "follow": 1,
        "\u00000778": 1,
        "c0638": 1,
        "\u00000568": 1,
        "\u0000051": 1,
        "\u0000045": 1,
        "\u00000413": 1,
        "\u00000335": 1,
        "\u00000278": 1,
        "c0268": 1,
        "\u00000218": 1,
        "mean": 1,
        "equal": 1,
        "maximum": 2,
        "subsequent": 1,
        "discus": 1,
        "sion": 1,
        "lvmax": 1,
        "ignore": 1,
        "reduce": 3,
        "fea": 1,
        "tures": 1,
        "without": 1,
        "cantly": 4,
        "elaborate": 1,
        "models": 1,
        "using": 2,
        "excels": 4,
        "hilayer": 1,
        "trainning": 1,
        "multiaibased": 1,
        "treebased": 1,
        "aifullbased": 1,
        "actual": 1,
        "predicted": 1,
        "accu": 3,
        "racy": 3,
        "four": 1,
        "aiswbased": 1,
        "weightsum": 1,
        "devel": 1,
        "oped": 1,
        "term": 2,
        "attest": 1,
        "pro": 1,
        "duce": 1,
        "effects": 1,
        "assume": 1,
        "missing": 2,
        "uenced": 1,
        "contrast": 1,
        "average": 2,
        "maintain": 2,
        "acceptable": 1,
        "least": 1,
        "examine": 1,
        "accord": 1,
        "observe": 2,
        "rfbased": 3,
        "conclude": 1,
        "next": 1,
        "scenarios": 3,
        "corre": 1,
        "multiparameters": 1,
        "appendix": 4,
        "causal": 1,
        "swbased": 3,
        "rfwpbased": 2,
        "precise": 1,
        "indicate": 1,
        "coef": 1,
        "determination": 1,
        "r2": 1,
        "approximate": 3,
        "yd06554xc02573": 1,
        "150645d": 1,
        "range": 1,
        "indicator": 1,
        "green": 1,
        "yellow": 1,
        "medium": 2,
        "red": 1,
        "forestbased": 2,
        "suffer": 1,
        "rmed": 1,
        "r2is": 2,
        "yd07542xc01232": 1,
        "even": 4,
        "though": 1,
        "nevertheless": 1,
        "slightly": 1,
        "accuracycertainty": 1,
        "yd05407xc04904": 1,
        "classify": 1,
        "worstcase": 1,
        "reach": 2,
        "hi13": 2,
        "frequency": 1,
        "achieve": 2,
        "solve": 2,
        "iv": 1,
        "conclusion": 1,
        "simplify": 1,
        "speed": 1,
        "worldwide": 1,
        "prepro": 1,
        "cessing": 1,
        "uncertaintyby": 1,
        "impact": 1,
        "satisfactory": 1,
        "certainity": 1,
        "pave": 1,
        "adopt": 1,
        "validation": 1,
        "multiparameter": 1
    },
    "objective": [
        "the propose hi approach assess the power transformer insulation system base on oil quality , dissolve gas analysis ( dga ) , and paper condition .",
        "a performance comparison of the propose ai-based hi model be carry out use the scoring- weighting-based hi method as the reference .",
        "flowchart of the propose methodology .",
        "the structure of the propose hi methodis divide into three-layers as show in figure 5 which be base on previously propose method in [ 20 ] .",
        "layers of the propose ai method .",
        "flowchart of the propose multi-ai approach to calculate hi .",
        "the propose method to calculate the trans- former hi use multi-ai approach be show in figure 8 .",
        "three method be use to implement the propose approach namely ; score weighting ( sw ) , random forest ( rf ) , and random forest with preprocessing-based ( rfwp ) .",
        "the propose method be aim to simplify , speed up , and reduce error due to data uncertainty .",
        "based on this comparison , the random forest-based model be choose as the propose method with the high accuracy to predict the transformer hi .",
        "the impact of miss data on the model have be evaluate , and the propose rfwp perform good than other investigated method and result in a satisfactory classi cation accuracy even with low certainity level ."
    ],
    "references": [
        "",
        "REFERENCES [1] A. Abu-Siada, Power Transformer Condition Monitoring and Diagnosis: Concepts and Challenges. London, U.K.: IET, 2018. [2] N. A. Bakar and A. Abu-Siada, ``Fuzzy logic approach for transformer remnant life prediction and asset management decision,'' IEEE Trans. Dielectr. Electr. Insul., vol. 23, no. 5, pp. 3199\u00153208, Oct. 2016. [3] L. E. Lundgaard, W. Hansen, D. Linhjell, and T. J. Painter, ``Aging of oil-impregnated paper in power transformers,'' IEEE Trans. Power Del., vol. 19, no. 1, pp. 230\u0015239, Jan. 2004. [4] M. Wang, A. J. Vandermaar, and K. D. Srivastava, ``Review of condition assessment of power transformers in service,'' IEEE Elect. Insul. Mag., vol. 18, no. 6, pp. 12\u001525, Nov./Dec. 2002. [5] D. Martin, Y. Cui, C. Ekanayake, H. Ma, and T. Saha, ``An updated model to determine the life remaining of transformer insulation,'' IEEE Trans. Power Del., vol. 30, no. 1, pp. 395\u0015402, Feb. 2015. [6] M. Ali, C. Eley, A. M. Emsley, R. Heywood, and X. dan Xaio, ``Measuring and understanding the ageing of Kraft insulating paper in power transform- ers,'' IEEE Elect. Insul. Mag., vol. 12, no. 3, pp. 28\u001534, May/Jun. 1996. [7] M. Arshad and S. M. Islam, ``Signi\u001ccance of cellulose power transformer condition assessment,'' IEEE Trans. Dielectr. Electr. Insul., vol. 18, no. 15, pp. 1591\u00151598, Oct. 2011. [8] S. Forouhari and A. Abu-Siada, ``Remnant life estimation of power trans- former based on IFT and acidity number of transformer oil,'' in Proc. IEEE 11st Int. Conf. Properties Appl. Dielectric Mater. (ICPADM) , Jul. 2015, pp. 552\u0015555. [9]Condition Assessment of Power Transformers, CIGRE, document 761, Mar. 2019. [10] X. E. Zhang dan Gockenbach, ``Asset-management of transformers based on condition monitoring and standard diagnosis [feature article],'' IEEE Elect. Insul. Mag., vol. 24, no. 4, pp. 26\u001540, Jul./Aug. 2008. [11] A. E. B. Abu-Elanien and M. M. A. Salama, ``Asset management tech- niques for transformers,'' Electr. Pow. Syst. Res., vol. 80, pp. 456\u0015464, Apr. 2010. [12] A. Azmi, J. Jasni, N. Azis, and M. Z. A. A. Kadir, ``Evolution of trans- former health index in the form of mathematical equation,'' Renew. Sustain. Energy Rev., vol. 76, pp. 687\u0015700, Sep. 2017. [13] A. Jahromi, R. Piercy, S. Cress, J. Service, and W. Fan, ``An approach to power transformer asset management using health index,'' IEEE Elect. Insul. Mag., vol. 25, no. 2, pp. 20\u001534, Mar. 2009. [14] N. Bakar, A. Abu-Siada, and S. Islam, ``A review of dissolved gas analysis measurement and interpretation techniques,'' IEEE Elect. Insul. Mag., vol. 30, no. 3, pp. 39\u001549, May/Jun. 2014. [15] IEEE Guide for Acceptance and Maintenance of Insulating Mineral Oil in Electrical Equipment, IEEE Standard C57.106-2015, Jun. 2015. [16] A. J. Kachler and I. Höhlein, ``Aging of cellulose at transformer service temperatures. Part 1: In\u001duence of type of oil and air on the degree of polymerization of pressboard, dissolved gases, and furanic compounds in oil,'' IEEE Electr. Insul. Mag., vol. 21, no. 2, pp. 15\u001521, Mar./Apr. 2005. [17] A. Abu-Siada, S. P. Lai, and S. M. Islam, ``A novel fuzzy-logic approach for furan estimation in transformer oil,'' IEEE Trans. Power Del., vol. 27, no. 2, pp. 469\u0015474, Apr. 2012. VOLUME 9, 2021 150647D. Rediansyah et al.: Artificial Intelligence-Based Power Transformer Health Index for Handling Data Uncertainty [18] A. Naderian, S. Cress, R. Piercy, F. Wang, and J. Service, ``An approach to determine the health index of power transformers,'' in Proc. Conf. Rec. IEEE Int. Symp. Electr. Insul., Jun. 2008, pp. 192\u0015196. [19] I. G. N. S. Hernanda, A. C. Mulyana, D. A. Asfani, I. M. Y. Negara, and D. Fahmi, ``Application of health index method for transformer condition assessment,'' in Proc. IEEE Region 10 Conf. (TENCON), Oct. 2014, pp. 1\u00156. [20] W. R. Tamma, R. A. Prasojo, and Suwarno, ``High voltage power trans- former condition assessment considering the health index value and its decreasing rate,'' High Voltage, vol. 6, no. 2, pp. 314\u0015327, Apr. 2021. [21] W. R. Tamma, R. Azis Prasojo, and S. Suwarno, ``Assessment of high voltage power transformer aging condition based on health index value considering its apparent and actual age,'' in Proc. 12nd Int. Conf. Inf. Technol. Electr. Eng. (ICITEE), Oct. 2020, pp. 292\u0015296. [22] L. En-Wen and S. Bin, ``Transformer health status evaluation model based on multi-feature factors,'' in Proc. Int. Conf. Power Syst. Technol., Oct. 2014, pp. 1417\u00151422. [23] K. Taengko and P. Damrongkulkamjorn, ``Risk assessment for power trans- formers in PEA substations using health index,'' in Proc. 10th Int. Conf. Electr. Eng./Electron., Comput., Telecommun. Inf. Technol., May 2013, pp. 1\u00156. [24] E. Kadim, N. Azis, J. Jasni, S. Ahmad, and M. Talib, ``Transformers health index assessment based on neural-fuzzy network,'' Energies, vol. 11, no. 4, p. 710, Mar. 2018. [25] K. Ibrahim, R. M. Sharkawy, H. K. Temraz, and M. M. A. dan Salama, ``Transformer health index sensitivity analysis using neuro-fuzzy mod- elling,'' in Proc. 2nd Int. Conf. Adv. Technol. Appl. Sci. (ICaTAS), 2017, pp. 1\u00157. [26] M. Yahaya, N. Azis, M. Ab Kadir, J. Jasni, M. Hairi, and M. Talib, ``Estimation of transformers health index based on the Markov chain,'' Energies, vol. 10, no. 11, p. 1824, Nov. 2017. [27] A. D. Ashkezari, H. Ma, T. K. Saha, and C. Ekanayake, ``Application of fuzzy support vector machine for determining the health index of the insulation system of in-service power transformers,'' IEEE Trans. Dielectr. Electr. Insul., vol. 20, no. 3, pp. 965\u0015973, Jun. 2013. [28] M. M. Islam, G. Lee, and S. N. Hettiwatte, ``Application of a general regres- sion neural network for health index calculation of power transformers,'' Int. J. Electr. Power Energy Syst., vol. 93, pp. 308\u0015315, Dec. 2017. [29] S. Li, G. Wu, H. Dong, L. Yang, and X. Zhen, ``Probabilistic health index- based apparent age estimation for power transformers,'' IEEE Access, vol. 8, pp. 9692\u00159701, 2020. [30] S. Tee, Q. Liu, and Z. Wang, ``Insulation condition ranking of transformers through principal component analysis and analytic hierarchy process,'' IET Gener., Transmiss. Distrib., vol. 11, no. 1, pp. 110\u0015117, Jan. 2017. [31] J. I. Aizpurua, B. G. Stewart, S. D. J. McArthur, B. Lambert, J. G. Cross, and V. M. Catterson, ``Improved power transformer condition monitoring under uncertainty through soft computing and probabilistic health index,'' Appl. Soft Comput., vol. 85, Dec. 2019, Art. no. 105530. [32] A. A. Alqudsi dan El-Hag, ``Application of machine learning in trans- former health index prediction,'' Energies, vol. 12, no. 14, p. 2694, 2019. [33] R. A. Prasojo and A. Abu-Siada, ``Dealing with data uncertainty for transformer insulation system health index,'' IEEE Access, vol. 9, pp. 74703\u001574712, 2021. [34] Z. Li, Y. Zhang, A. Abu-Siada, X. Chen, Z. Li, Y. Xu, L. Zhang, and Y. Tong, ``Fault diagnosis of transformer windings based on decision tree and fully connected neural network,'' Energies, vol. 14, no. 6, p. 1531, Mar. 2021. [35] A. Abu-Siada, M. Arshad, and S. Islam, ``Fuzzy logic approach to identify transformer criticality using dissolved gas analysis,'' in Proc. IEEE PES Gen. Meeting, Jul. 2010, pp. 1\u00155. [36] Transformer Reliability Survey, CIGRE WG, document A2.37, TB642, Dec. 2015. [37] IEEE Guide for the Interpretation of Gases Generated in Mineral Oil- Immersed Transformers, IEEE Standard C57.104-2019, 2019. [38] Mineral Insulating Oils in Electrical Equipment\u0016Supervision and Main- tenance Guidance, IEC Standard 60422:2013, 2013. [39] R. A. Prasojo, A. Setiawan, Suwarno, N. U. Maulidevi, and B. Anggoro Soedjarno, ``Development of analytic hierarchy process technique in deter- mining weighting factor for power transformer health index,'' in Proc. 2nd Int. Conf. High Voltage Eng. Power Syst. (ICHVEPS), Oct. 2019. [40] R. Azis Prasojo, Suwarno, N. Ulfa Maulidevi, and B. Anggoro Soedjarno, ``A multiple expert consensus model for transformer assessment index weighting factor determination,'' in Proc. 8th Int. Conf. Condition Monitor. Diagnosis (CMD), Oct. 2020, pp. 234\u0015237.[41] L. Breiman, ``Random forests\u0015random features,'' Statistic Dept., Univ. California, Berkeley, CA, USA, Tech. Rep. 567, 1999, pp. 1\u001529. [Online]. Available: https://www.stat.berkeley.edu/~breiman/random-forests.pdf DHANU REDIANSYAH (Graduate Student Member, IEEE) received the B.Sc. degree from the Department of Mechanical Engineering, Insti- tut Teknologi Indonesia, in 2009, and the M.Sc. degree from the School of Electrical Engineer- ing and Informatics, Institut Teknologi Bandung, Indonesia, in 2021. Since 2011, he has been working at PT. PLN (Persero), the Indonesian state of electricity company. He has experienced at a generation power plant, distribution, and trans- mission. His research interests include high voltage equipment condition monitoring and diagnostic, renewable energy power plant, and power quality. RAHMAN AZIS PRASOJO (Graduate Student Member, IEEE) received the B.Sc. degree from the Department of Electrical Engineering, Politeknik Negeri Malang, Malang, Indonesia, in 2015, and the M.Sc. degree from the School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia, in 2017, where he is currently pursuing the Ph.D. degree. Since 2019, he has been an Assistant Professor with the Depart- ment of Electrical Engineering, Politeknik Negeri Malang. He has published various conference papers and journal articles regarding high voltage power transformer condition monitoring and diag- nostics. He has reviewed several reputable journals. SUWARNO (Senior Member, IEEE) received the B.Sc. and M.Sc. degrees from the Depart- ment of Electrical Engineering, Institut Teknologi Bandung, Indonesia, in 1988 and 1991, respec- tively, and the Ph.D. degree from Nagoya University, Japan, in 1996. He is currently a Pro- fessor and the Emeritus Dean of the School of Electrical Engineering and Informatics, Institut Teknologi Bandung. He serves as the Head for the Electrical Power Engineering Research Group. He has published over 200 international journal articles or conference papers. His research interests include high voltage insulating materials and technol- ogy and diagnostics of HV equipment. He was the General Chairperson of several international conferences, such as ICPADM 2006, ICEEI 2007, CMD 2012, ICHVEPS 2017, and ICHVEPS 2019. He serves as the Editor-in-Chief for the International Journal on Electrical Engineering and Informatics. A. ABU-SIADA (Senior Member, IEEE) received the B.Sc. and M.Sc. degrees in electrical engineer- ing from Ain Shams University, Egypt, in 1998, and the Ph.D. degree in electrical engineering from Curtin University, Australia, in 2004. He is currently the Discipline Lead of electrical and computer engineering with Curtin University. His research interests include power electron- ics, power system stability, condition monitor- ing, and power quality. He is the Vice Chair of the IEEE Computation Intelligence Society, WA Chapter. He is also the Editor-in-Chief for the International Journal of Electrical and Electronic Engineering and a regular reviewer for various IEEE TRANSACTIONS. 150648 VOLUME 9, 2021"
    ]
}{
    "name": null,
    "paragraphs": [
        "received december 29 , 2019 , accept january 2 , 2020 , date of publication january 7 , 2020 , date of current version january 15 , 2020 .",
        "digital object identifier 10.1 109/access.2020.2964621 bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios hong zhang , yawei li , yujie wu , and zeyu zhang image processing center , beihang university , beijing 100191 , china corresponding author : yawei li ( lyw3074 @ buaa.edu.cn ) this work be support in part by the national natural science foundation of china under grant 61872019 and grant 61571026 , and in part by the national key research and development program of china under grant 2016yfe0108100 .",
        "abstract in recent year , image deblurring have be widely investigate .",
        "in order to solve this ill-posed problem , a variety of prior model have be propose successively .",
        "the two-tone prior have be successfully apply to text image deblurring and achieve signi cant result .",
        "however , the natural image with rich color cluster do not meet the two-tone prior , which require only two color cluster in the image .",
        "in this paper , a local two-tone prior be propose for image with complex color cluster , which decompose the image with complex color cluster into patch with simple color cluster .",
        "we also nd that the process of image blurring be a weighted average of pixel value , which will lead to an increase of intermediate pixel value .",
        "therefore , a new measure of the dynamic range of the image be propose , which indicate the difference of the color cluster use the average value of the color cluster , and it be rigorously prove in mathematics .",
        "besides , we analyze the effectiveness of the propose prior in image deblurring in detail .",
        "experimental result on the widely use datasets show that the propose method perform favorably against the state-of-the-art algorithm , both qualitatively and quantitatively .",
        "index terms image deblurring , ill-posed problem , local two-tone prior , dynamic range .",
        "i .",
        "introduction image blurring be the main challenge of a camera system and it severely affect the de nition of photo .",
        "with the popularity of hand-held camera phone , blur image be grow exponentially , which make it more important to restore a sharp image from a blurred one .",
        "besides , blur image will cause many advanced vision application system to fail , such as target detection , track [ 1 ] \u0015 [ 3 ] , classi cation [ 4 ] , [ 5 ] , and recognition [ 6 ] , which will result in serious consequence .",
        "blind image deblurring technology , which be still a hot topic in the eld of image processing and computer vision , be the most effective method for solve these prob- lem .",
        "the goal of blind deblurring be usually to estimate both a sharp latent image and a blur kernel from a blurred image .",
        "blind deblurring be obviously a severely ill-posed problem for which there be in nite set of solution .",
        "when the blur be linear shift-invariant , a simpli ed mathematical model of the the associate editor coordinate the review of this manuscript and approve it for publication be inês domingues .image formation process can be model as bdi kcn ; ( 1 ) where b , i , kandndenote the observed blurred image , the corresponding latent image , the blur kernel , and the addi- tive noise , respectively .",
        "represent the convolution oper- ator .",
        "in general , the problem of blind image deblurring be solve in two step .",
        "the rst step be to estimate the blur kernel .",
        "the second step be to solve the latent image with a know blur kernel .",
        "this paper mainly discuss the rst step , that be , the estimation of the blur kernel .",
        "in recent year , a series of excellent algorithm have be propose to solve the problem of image deblurring .",
        "jiang et al .",
        "[ 9 ] propose an excellent text image deblurring algorithm base on the two-tone prior .",
        "however , it be not applicable to other scenario because a text image enjoy its unique characteristic : all the pixel be concentrate in two cluster , while other image always have multiple gray level .",
        "according to our observation , the two-tone prior be still valid for local image patch of various scenario as the image patch always contain one or two gray level .",
        "therefore , volume 8 , 2020this work be license under a creative commons attribution 4.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/4.0/9185h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios figure 1 .",
        "deblurred result on a challenging saturate image from lai dataset [ 7 ] .",
        "( a ) input blur image .",
        "( b ) intermediate latent image of our algorithm .",
        "( c ) our result .",
        "( d ) result of pan et al .",
        "[ 8 ] .",
        "figure 1 ( b ) show that the salient edge and the structure be recover accurately , and that the detail and noise be suppress .",
        "our result ( c ) be superior to that of pan ( d ) in detail .",
        "a new local two-tone prior that be effective in estimate the blur kernel for diverse scenario such as natural , man- make , text , face , and saturate be propose .",
        "the image be divide into small patch that consist of one cluster or two cluster which follow the two-tone prior .",
        "this paper demon- strates how the local two-tone prior work on image patch and its effectiveness in detail .",
        "as show in figure 1 ( b ) , the propose method base on the local two-tone prior can observably preserve salient edge and subdue weak gradient in the intermediate latent image .",
        "figure 1 ( c ) and ( d ) show that our result be superior to that of pan in detail .",
        "compared to the state-of-the-art deblurring method , our algorithm be simple but effective without any edge selection step and achieves competitive result on widely use image deblurring benchmark [ 7 ] , [ 10 ] , [ 11 ] .",
        "in this paper , the main contribution be as followsv \u000fa local two-tone prior be propose for image with com- plex color cluster , which decompose the image with complex color cluster into patch with simple color cluster and be effective for multiple scenario .",
        "\u000fbased on the observation of the contrast loss of the blurred image patch , a new measure of the dynamic range of the image be propose use the average value of the color cluster , which can effectively distinguish a blurred image from a clear image .",
        "we have a tight mathematical proof of this measure and propose a new regularized term to enhance the local contrast of latent image .",
        "experimental result prove the effectiveness of the propose regularized term .",
        "\u000fcompared with the most advanced deblurring method , our method have competitive performance in both the widely used natural image deblurring benchmark and the speci c task , especially in the case of large blur kernel , and its performance be well than the current deep learning-based method in the case of approximate global uniform blurring .",
        "the rest of this paper be organize as follow .",
        "section ii propose an overview of the state-of-the-art deblurring mod- el .",
        "in section iii , the local two-tone prior and the color cluster dynamic contrast be introduce to the bid scheme and the half-quadratic splitting method be propose for solve the result .",
        "in section iv , extensive analysis , discussion and var- ious experiment be conduct to evaluate the effectivenessof the propose prior .",
        "section vconcludes this paper and identi es future direction .",
        "ii .",
        "related work recently , most state-of-the-art deblurring method produce an intermediate latent image with sharp edge , rely on explicit edge prediction [ 12 ] \u0015 [ 14 ] , sparse statistical prior regularization [ 9 ] , [ 10 ] , [ 15 ] , [ 16 ] and patch-based prior [ 14 ] , [ 17 ] .",
        "besides , learning-based approach [ 18 ] \u0015 [ 21 ] of deblurring have see signi cant advance .",
        "in this section , the main model most related to this work be discuss in detail .",
        "a .",
        "explicit edge extraction methods of select explicit salient edge for kernel esti- mation have be extensively validate in single image blind deblurring .",
        "cho and lee [ 12 ] introduce the bilateral ltering , shock ltering and gradient magnitude thresholding method to predict a strong edge map in kernel estimation .",
        "xu and jia [ 13 ] show that trivial edge make psf estimation vul- nerable to noise .",
        "meanwhile , they propose a new criterion to select salient edge and restrain spike or a at region for kernel estimation .",
        "cai et al .",
        "[ 22 ] propose a joint deblurring method , which extract reliable edge and suppress noise at the same time .",
        "although these method perform well on several kind of blur image , extra computation be need to extract edge and the deblurring result heavily depend on the accuracy of the correct edge selection .",
        "b .",
        "sparse statistical priors sparse statistical prior can well re ect the statistical infor- mation of a natural image , so they be usually use for sharp edge restoration .",
        "the most relevant algorithm to this work be [ 9 ] .",
        "algorithm [ 9 ] propose a two-tone prior model base on the characteristic that the text image always contain two color cluster , and propose a two-stage deblurring algorithm base on this model for text image .",
        "levin et al .",
        "[ 10 ] propose that the image gradient sparsity be more inclined to blur image in the image deblurring algorithm , especially in the framework of maximum posterior ( map ) .",
        "to address this problem , various natural image prior have be propose in deblurring method to remove harmful structure , gradu- ally enhance resolution and approximate the latent image in 9186 volume 8 , 2020h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios iteration .",
        "krishnan et al .",
        "[ 23 ] present a normalized sparse prior ( l 1=l2regularization ) which be scale-invariant to solve series problem relate to the l1prior .",
        "sun et al .",
        "[ 24 ] propose a weighted l0regularized gradient prior for blind image deblurring .",
        "dou et al .",
        "[ 25 ] propose a smoothing-enhancing regularizer and a fast optimization scheme .",
        "the regularizer can simultaneously suppress small detail and enhance reli- able edge .",
        "pan et al .",
        "[ 8 ] present an effective blind image deblurring algorithm base on the dark channel prior .",
        "how- ever , the sparsity statistical prior ignore the most salient image structure and geometry which be critical in kernel estimation .",
        "c. patch-based priors patch-based prior have be widely use in many eld , such as texture synthesis , denoising , super-resolution [ 26 ] , and deblurring [ 14 ] , [ 17 ] .",
        "michaeli and irani [ 17 ] develop an image prior base on the patch recurrence property that favor clear image over blurred image .",
        "similarly , sun et al .",
        "[ 14 ] explore a new edge-based approach use the patch prior for kernel estimation from a single image .",
        "they estimate a `` trusted '' subset of latent image by impose a patch prior speci cally tailor towards model the appearance of image edge and corner primitive .",
        "compared to the prior base on pixel , patch-based prior result in a signi cant improvement in the performance of blind deblurring .",
        "how- ever , it also require an extra training process to learn a prior from a set of patch or extra computation to extract useful edge .",
        "d. learning-based methods with the extensive application of deep learning in the eld of computer vision , learning-based method have also be propose for image deblurring .",
        "sun et al .",
        "[ 18 ] propose a patch-level prior use deep cnns to remove non-uniform motion blur .",
        "nah et al .",
        "[ 19 ] achieve state-of-the-art result use a multiscale convolutional neural network ( cnn ) .",
        "this framework follow a coarse-to- ne pipeline that recover the latent image until the full resolution be reach .",
        "tao et al .",
        "[ 20 ] propose a new scale-recurrent network ( srn ) , which can reduce the number of trainable parameter and incorporate recurrent module in cnn-based deblurring system .",
        "in addi- tion , kupyn et al .",
        "[ 21 ] develop an end-to-end learn method for motion deblurring base on a conditional gan net and content loss .",
        "the deblurring method base on end-to-end deep learning can effectively avoid image deconvolution and deal with non-uniform blur image .",
        "nevertheless , it need additional training data in pair and the performance of deep learning on blind image deblurring be highly dependent on the completeness of the training dataset .",
        "iii .",
        "our proposed bid scheme the two-tone prior have be successfully apply to the text image deblurring [ 9 ] .",
        "while the color cluster of the natural image be much rich than that of the text image .",
        "the original two-tone prior be not applicable to image with more thantwo cluster .",
        "but for a local image patch , it typically have only one color cluster in a smooth region or two color cluster in an edge region , as long as the patch size be appropriate .",
        "intuitively , the blur process of an image be a process of weighted summation of local pixel value such that the num- ber of intermediate intensity value between the two-color cluster increase .",
        "the contrast range of the blurred image patch with edge be reduce .",
        "based on these observation , the local two-tone prior be propose to restrict intermediate pixel and restore the original image patch contrast .",
        "we put forward the following proposition and give strict proof in mathematics .",
        "proposition 1 : letidenotes an image patch ; kdenotes a blur kernel such that kkk1d1 and k ( x ) \u00150 , for all x .",
        "the color cluster dynamic contrast cdynfigdmean x2c2fig\u0000 mean x2c1figis the difference between the mean pixel value ofc2cluster and c1cluster in the input image and it be give byv cdynfi kg\u0014cdynfig : ( 2 ) proof : 1 ) in the smooth patch , accord to the de - nition of image convolution , the mean value of the blurred image equal to the clear one which have only one color cluster ( c 1dc2 ) .",
        "the proof be as followsv bmdnx xd1x z2ki\u0010 xchs 2i \u0000z\u0011 k.z/=n dx z2knx xd1i\u0010 xchs 2i \u0000z\u0011 k.z/=n dx z2knimk.z/=n dnimx z2kk.z/=n dim ( 3 ) where bmandimdenote the mean value of the blurred image patch and the clear image patch , nis the number of pixel of the image patch i , [ \u0001 ] denote the rounding operator , k denote the domain of the blur kernel kandsdenotes its dimension .",
        "so we have cdynfi kgdcdynfig .",
        "2 ) in the patch of edge , without loss of generality , suppose an image patch icontains npixels of c1cluster and npixels ofc2cluster , we have c1dx1cx2c : : : cxn n ; c2dy1cy2c : : : cyn n ; ( 4 ) where c1andc2denote the mean value of the c1cluster and the c2cluster , respectively .",
        "x\u0003andy\u0003denote the pixel value of the c1cluster and the c2cluster , and y\u0003 > x\u0003for anyx\u0003 ; y\u0003 .",
        "volume 8 , 2020 9187h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios for a blurred image patch , a pixel value be equal to the weighted sum of the surround pixel value , so we have c0 1dx0 1cx0 2c : : : cx0 n n ; c0 2dy0 1cy0 2c : : : cy0 n n ; ( 5 ) where c0 1 ; c0 2 ; x0 \u0003andy0 \u0003denote the mean value and the pixel value of the blurred image patch , respectively .",
        "x0 \u0003 ; y0 \u0003can be solve use the following formulasv x0 1dk1x1c : : : cknxncknc1y1c : : : ck2nyn ; x0 2dk2x1c : : : cknc1xncknc2y1c : : : ck1yn ; : : : x0 ndknx1c : : : ck2n\u00001xnck2ny1c : : : ckn\u00001yn ; ( 6 ) where k1 ; k2 ; : : : ; k2ndenote the weighting coef cients , k1c k2c : : : ck2nd1 , we have x0 1cx0 2c : : : cx0 nd ( k1ck2c : : : ckn ) x1 c ( k2ck3c : : : cknc1 ) x2c : : : c ( knc1cknc2c : : : ck2n ) y1c : : : c ( k2nck1c : : : ckn\u00001 ) yn > ( k1ck2c : : : ck2n ) x1 c ( k1ck2c : : : ck2n ) x2c : : : c ( k1ck2c : : : ck2n ) xn dx1cx2c : : : cxn ( 7 ) hence x0 1cx0 2c : : : cx0 n > x1cx2c : : : cxn , soc0 1 > c1 .",
        "similarly , c0 2 < c2 .",
        "we have cdynfi kg < cdynfig .",
        "so proposition 1 hold .",
        "property 1vfrom the above-mentioned analysis and prov- ing , we havev kb ( x ) \u0000c1k1\u0015ki ( x ) \u0000c1k1 ; x2c1 ; kb ( x ) \u0000c2k1\u0015ki ( x ) \u0000c2k1 ; x2c2 ; ( 8 ) where b ( x ) ; i ( x ) denote the blurred and clear image pixel , c1 ; c2denote the mean value of c1 ; c2clusters of image i .",
        "based on the property 1 , we propose a local two-tone prior , which be de ned by p ( x ) dx x2 !",
        "1ki ( x ) \u0000c1k1c !",
        "2ki ( x ) \u0000c2k1 ; ( 9 ) where xdenote pixel location ; denotes an image patch ; c1 , c2represent the center of two gray level cluster of  , !",
        "\u0003d1 if i ( x ) belong to the c\u0003cluster , and !",
        "\u0003d0 otherwise .",
        "in addition , the proposition prompt us to propose a new regularized term to enhance the local contrast of latent image .",
        "c1andc2can be derive by apply k-means clus- tering ( kd2 ) to the gray level of an image patch  , yield two cluster center : c1 < c2 .",
        "than c1andc2updatewith formula 10and11to enhance the contrast of the image patch .",
        "ci 1dm ( i ( x ) < ci\u00001 1 ) cci\u00001 1 2 ; ( 10 ) ci 2dm ( i ( x ) > ci\u00001 2 ) cci\u00001 2 2 ; ( 11 ) where m ( i ( x ) < c1 ) and m ( i ( x ) > c2 ) denote the mean value of the pixel that be less than c1and large than c2in the image patch , respectively .",
        "the value of the new c\u0003is between m ( i ( x ) ?",
        "c\u0003 ) and the previous c\u0003 .",
        "thus , the contrast of the patch be enhance while keep c1and c2in a reasonable range .",
        "p ( i ) be introduce as a regularizer in the conventional formulation for image deblurring min i ; kki k\u0000bk2 2c kkk2 2c\u0016kr ik0c\u0015p ( i ) ; ( 12 ) where the rst term be data term , the second and third term be use to regularize the blur kernel and image gradient , and , \u0016 , and\u0015are weight parameter .",
        "our approach be a map-based framework that adopt a coarse-to- ne manner to iteratively solve i min iki k\u0000bk2 2c\u0016kr ik0c\u0015p ( i ) ; ( 13 ) andk min kki k\u0000bk2 2c kkk2 2 : ( 14 ) after the nal blur kernel be estimate , the latent image can be restore use the advanced nonblind deconvolution algo- rithm .",
        "figure 2shows the whole pipeline of our algorithm .",
        "a. estimating latent image i in this step , the goal be to solve iwith a xed k. formula 13 be a nonlinear minimization problem and be intractable to deal with directly , so the half-quadratic splitting method and alternate solve algorithm be adopt .",
        "this paper introduce auxiliary variable uto replace iinp ( i ) and gd ( gh ; gv ) corresponding to image gradient in the hori- zontal and vertical direction .",
        "the cost function ( 13 ) can be rewrite asv min i ; u ; gki k\u0000bk2 2c kri\u0000gk2 2c\u0016kgk 0 c x \u00032f1 ; 2g !",
        "\u0003ki\u0000c\u0003\u0000uk2 2c\u0015x \u00032f1 ; 2g !",
        "\u0003kuk1 ; ( 15 ) where and be penalty parameter .",
        "when and be close to in nity , the solution of 15approaches to that of 13 .",
        "( 15 ) can be optimize by alternatively solve i , u , and gby xing the others .",
        "1 ) solve u for the usubproblem , the objective function be predigest tov minu x \u00032f1 ; 2g !",
        "\u0003ki\u0000c\u0003\u0000uk2 2c\u0015x \u00032f1 ; 2g !",
        "\u0003kuk1 ; ( 16 ) 9188 volume 8 , 2020h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios figure 2 .",
        "the pipeline of our algorithm .",
        "in this algorithm , i-step and k-step be solve iteratively to restore the latent image and estimate the blur kernel for each image scale by a coarse-to-fine pyramid framework .",
        "more specifically , our prior steer the salient edge to become sharp and restore the local contrast .",
        "then the blur kernel and latent image be update .",
        "after the final blur kernel be estimate , any non-blind deconvolution algorithm can be apply to restore latent image .",
        "( 16 ) can be solve by an one-dimensional shrinkage oper- ator and its solution be give by udx \u00032f1 ; 2g !",
        "\u0003sign ( i\u0000c\u0003 ) max ( ki\u0000c\u0003k\u0000\u0015 ; 0 ) ; ( 17 ) where !",
        "1d1 ; !",
        "2d0 ifki ( x ) \u0000c1k < ki ( x ) \u0000c2k , and !",
        "1d0 ; !",
        "2d1 otherwise .",
        "this optimization algorithm be repeat on each image patch until the whole image be optimize .",
        "uis solve patch by patch , and the solution can be calculate in parallel as patch be not relate to each other .",
        "2 ) solve g with iandu xed , gi update by minimize ming kri\u0000gk2 2c\u0016kgk 0 : ( 18 ) we use the same method to solve gas solve uin the inner loop , which produce clear result with few ring artifact in the latent image .",
        "the solution to gi gd ( ri ; jrij2\u0015\u0016 ; 0 ; otherwise : ( 19 ) 3 ) solve i by xing the value of gandu , ( 15 ) be simpli ed to min iki k\u0000bk2 2c kri\u0000gk2 2c ki\u0000u0k2 2 : ( 20 ) wherw u0dp \u00032f1 ; 2g !",
        "\u0003 ( c\u0003cu ) .fourier transform and fourier inverse transform be apply to all term , and the closed-form solution for this least-squares minimization problem be idf\u00001 ( f ( k ) f ( b ) c f ( u0 ) c fg f ( k ) f ( k ) c c ( p i2fh ; vgf ( ri ) f ( ri ) ) ) ; ( 21 ) where f ( \u0001 ) denote the fourier transform and f\u00001 ( \u0001 ) denote the fourier inverse transform ; f ( \u0001 ) be the complex conjugate operator ; and fgdf ( rh ) f ( gh ) cf ( rv ) f ( gv ) , where rhandrvdenote the horizontal and vertical differential operator , respectively .",
        "the main step for solve ( 12 ) be summarize in algorithm 1 .",
        "b. estimating blur kernel k in this section , the blur kernel kis optimize with a xed intermediate image i .",
        "consistent with exist method [ 12 ] , this paper apply the kernel estimation method base on gradient which have be show to be more accurate .",
        "to solve k , the objective function can be write asv min kkri k\u0000rbk2 2c kkk2 2 : ( 22 ) this least-squares problem be solve in the fourier domain and its closed-form solution be obtain by kdf\u00001 f ( rhi ) f ( rhb ) cf ( rvi ) f ( rvb ) f ( rhi ) 2cf ( rvi ) 2c !",
        ": ( 23 ) after obtain k , it be normalize to keep the sum of its element equal to 1 , and its negative element be set to 0 .",
        "volume 8 , 2020 9189h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios algorithm 1 latent image iestimation algorithm input : blurred image band blur kernel k. 1 : i b ; 2\u0015 .",
        "2 : forjd1 ; 2 ; : : : ; 5dodo 3 : repeat 4 : solve for uusing ( 17 ) .",
        "5 : 2\u0016 .",
        "6 : apply k-means cluster ( k = 2 ) to the gray level of image patch  , yield two cluster center : c1 < c2 .",
        "7 : forid1 !",
        "2do 8 : update c1 ; c2using ( 10 ) , ( 11 ) .",
        "9 : end for 10 : repeat 11 : solve for gusing ( 19 ) .",
        "12 : solve for iusing ( 21 ) .",
        "13 : 2 .",
        "14 : until > max .",
        "15 : 2 .",
        "16 : until > max .",
        "17 : solve for kusing ( 23 ) .",
        "18 : \u0015 maxf\u0015=1:1 ; 1e\u00004g .",
        "19 : end for output : intermediate latent image i. c. implementation details this paper adopt the iterative coarse-to- ne optimization framework to accelerate the convergence of the algorithm and avoid trivial solution of the kernel estimation .",
        "algorithm 1 present the main step in an image pyramid level .",
        "the blurred image y and blur kernel size be downsampled with a scale factor of 1=p 2 until the blur kernel size become 7 \u00027 .",
        "in all experiment , the parameter ( \u0015 d\u0016d4e\u00003 ; d2 ; maxd1e5 ; maxd8 , and patchsized25 ) have be set empirically .",
        "the effect of the parameter on the blur kernel estimation will be analyze in the next section in detail .",
        "the max_iterd5 have be set by weigh accuracy and speed .",
        "in the nal stage , any nonblind deconvolution method can be use to recover the latent image .",
        "iv .",
        "performance analysis to show the effectiveness of our algorithm , suf cient com- parisons against the state-of-the-art deblurring method be perform on three widely use datasets [ 7 ] , [ 10 ] , [ 11 ] .",
        "in addition , the convergence and the computational complex- ity of the propose algorithm be discuss .",
        "the effect of patch size and parameter of the algorithm be also evaluate with experiment .",
        "a .",
        "the effectiveness of the local two-tone prior and the contrast enhancement constraint without use the local two-tone prior , the propose method degenerate into the deblurring scheme with only the l0prior .",
        "for intuitive comparison , the local two-tone prior and the figure 3 .",
        "the effectiveness of the propose prior .",
        "( a ) blurry input .",
        "deblurred result on a challenging image with a large blur kernel from the köhler dataset [ 11 ] be show in ( b ) - ( d ) .",
        "the coarse-to-fine intermediate result be show in ( e ) - ( h ) , which show that the propose prior be truly effective for kernel estimation .",
        "in figure 3 ( d ) , our method achieve a good solution contain more sharp detail and few ring artifact .",
        "contrast enhancement constraint be remove one by one in the comparison experiment to the most advanced algorithm [ 8 ] .",
        "figure 3 ( e ) ( f ) ( g ) and ( h ) show the coarse-to- ne inter- mediate result of pan et al .",
        "[ 8 ] , ours without p ( i ) , ours without the contrast enhancement constraint and ours .",
        "as indicated in figure 3 ( f ) and ( g ) , intermediate result without use the local two-tone prior and the contrast enhancement constraint contain more ringing artifact , and the estimate kernel be far from the true value .",
        "on the contrary , inter- mediate result use the local two-tone prior be clear and contain more sharp edge ( figure 3 ( h ) ) .",
        "quantitative evaluation with and without the two-tone prior and contrast enhancement constraint on the benchmark dataset [ 11 ] be propose in figure 4 ( a ) .",
        "the result demonstrate that our model with the local two-tone prior and contrast enhancement constraint generates well result than the one without them .",
        "however , our model performs poorly if only with the local two-tone prior .",
        "this be mainly because our prior indicate the trend of the image color cluster , which can effectively 9190 volume 8 , 2020h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios figure 4 .",
        "( a ) quantitative evaluation of the propose algorithm with and without the local two-tone prior and the contrast enhancement constraint on dataset [ 11 ] .",
        "the local two-tone prior truly help to improve the result .",
        "( b ) average kernel similarity of every iteration on dataset [ 10 ] .",
        "figure 5 .",
        "( a ) quantitative evaluation on dataset [ 11 ] use the psnr measure .",
        "( b ) performance comparison use the success rate measure on dataset [ 7 ] .",
        "the propose algorithm perform well against state-of-the-art method .",
        "avoid fall into the local minimum , but the precision be not high when use alone .",
        "furthermore , in the case of a large blur kernel , our method achieve signi cant result over those without the local two-tone prior and the contrast enhancement constraint ( table 1 ) .",
        "b .",
        "results on synthesized images 1 ) dataset by köhler et al .",
        "[ 11 ] to evaluate the performance of deblurring quantitatively , we test our algorithm with the state-of-the-art method on the synthesized datasets [ 11 ] .",
        "the köhler et al .",
        "[ 11 ] dataset include 12 motion blur kernel and 4 ground-truth image .",
        "the blurred test image be generate by synthesize mul- tiple image on the motion path .",
        "the ground-truth image be capture along the camera motion trajectory step by step .",
        "every restored image need to be compare with 199 clear image to compute the psnr .",
        "the result of [ 12 ] , [ 13 ] , [ 15 ] , [ 23 ] , [ 27 ] \u0015 [ 30 ] and [ 8 ] be achieve from dataset [ 11 ] which be provide with their best deblurring result by their author .",
        "we take the same nonblind deconvolution method with [ 8 ] to get our result .",
        "figure 5 ( a ) report the mean psnr performance on dataset [ 11 ] , in which our method outperform all compete meth- od .",
        "figure 6 show the deblurred result of a challenging image with a large blur kernel from dataset [ 11 ] obtain by various method .",
        "although the most advanced algorithm [ 8 ] , [ 13 ] , and [ 29 ] be able to address most of blur image , there be still dif culties when address large blur kernel ( kernel 8-11 ) and there be signi cant ring artifact in theirtable 1 .",
        "the average psnr value of large blur kernel ( kernel 8-11 ) on dataset [ 11 ] .",
        "table 2 .",
        "quantitative comparison on the köhler dataset [ 11 ] with the deep learning-based method in term of psnr/mssim .",
        "result .",
        "in contrast , the propose result contain few ringing artifact and more ne detail .",
        "according to table 1 , our result relate to the large blur kernel ( kernel 8-11 ) perform favorably against those of the state-of-the-art method .",
        "in addition , we also compare our method with the lat- est deep learning-based deblurring method [ 18 ] \u0015 [ 21 ] .",
        "deep learning-based method be generally evaluate on gopro dataset ( non-uniform ) [ 19 ] and köhler dataset ( uniform ) [ 11 ] .",
        "our method be design for a global uniform blur , so we just do the comparison on the global uniform dataset [ 11 ] .",
        "although in the global uniform dataset [ 11 ] , the blur kernel 2,6,7,10,12 be still spatially vary , which be where the deep learning method be especially good at .",
        "the result of [ 18 ] \u0015 [ 21 ] be generate by the end-to-end neural net- work instead of a deconvolution algorithm .",
        "we make com- parisons with the deep learning-based method in term of psnr/mssim .",
        "the result in table 2show that our algo- rithm performs well against recent deep learning deblurring method in the two term .",
        "2 ) dataset by lai et al .",
        "[ 7 ] the lai dataset [ 7 ] contains 100 uniform synthetic blur image , 100 nonuniform synthetic blur image , and 100 real blur image .",
        "as our algorithm be design for uniform blur , only 100 uniform synthetic blur image and 100 real blur image be evaluate with 13 representative state-of-the-art blind deconvolution method [ 12 ] \u0015 [ 17 ] , [ 23 ] , [ 29 ] , [ 31 ] \u0015 [ 35 ] .",
        "the image in this dataset cover various scenario , such as man-made , natural , face , saturate , and text and truly rep- resent the actual challenge of image deblurring .",
        "for fair comparison , all the result of this experiment be generate with the same nonblind deconvolution method [ 36 ] .",
        "the result of other method be obtain from the dataset of lai et al .",
        "[ 7 ] .",
        "as show in table 3 , our method achieve the best performance in term of the mean psnr in every volume 8 , 2020 9191h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios figure 6 .",
        "deblurred result on a challenging image with a large blur kernel .",
        "our result ( f ) perform good than the others .",
        "figure 7 .",
        "deblurred result on a synthetic text image .",
        "the propose method generate visually competitive result relative to those of the most advanced method [ 13 ] , [ 14 ] , [ 31 ] , [ 32 ] , although ( e ) be specially design for text image .",
        "table 3 .",
        "quantitative comparison on the lai dataset [ 7 ] with 100 uniform synthetic image .",
        "performance be measure in average psnr value .",
        "different row denote different category of image .",
        "scenario .",
        "figure 5 ( b ) present the cumulative distribution of the error ratio .",
        "as show in figure 5 ( b ) , our method have a slightly good performance than that of xu and jia [ 13 ] , but signi cantly outperform the other state-of-the-art meth- od .",
        "figure 7shows a qualitative comparison of text image deblurring from different algorithm [ 13 ] , [ 14 ] , [ 31 ] , [ 32 ] .",
        "our result be much good than those of others , although [ 32 ] be design specially for text image .",
        "c. results on real images for further comparison , we compare our algorithm against the state-of-the-art image deblurring method [ 14 ] , [ 17 ] , [ 31 ] on real blurring image .",
        "in this experiment , all the result be generate with the same nonblind deconvolution method [ 36 ] .",
        "since the ground-truth image and kernel be unknown , we can only analyze the deblurring result qualitatively .",
        "figure 8shows deblurring result for some real blurry photo with unknown blur kernel .",
        "there be few ring artifact and sharp detail in our result .",
        "compared with other meth- od , our result be stable and competitive .",
        "d. convergence of our method the propose algorithm be an alternate minimization pro- ce .",
        "in each sub-problem , the cost function decrease so that it can converge to a local minimum .",
        "figure 4 ( b ) showstable 4 .",
        "the average psnr value for different patch size on dataset [ 10 ] .",
        "that the average kernel similarity value vary with respect to the iteration on the benchmark dataset [ 10 ] .",
        "with more iteration , the kernel similarity of the estimate kernel and the original kernel become high which mean that the propose optimization method converges well .",
        "e. effect of patch size on algorithm stability the effect of patch size on the stability of the algorithm be also analyze as it play a crucial role in kernel estimation .",
        "for the image resolution of 255 \u0002255 pixel in the dataset [ 10 ] , different patch size be choose for the experiment .",
        "as show in table 4 , the average psnr value of different patch size be quite stable .",
        "thus , the propose method be not sensitive to the patch size within a suitable range .",
        "f. computational complexity we execute our algorithm in a coarse-to- ne pyramid frame- work .",
        "the number of layer in the pyramid be determined 9192 volume 8 , 2020h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios figure 8 .",
        "deblurred result [ 14 ] , [ 17 ] , [ 31 ] on a real blurred image with an unknown blur kernel .",
        "our result contain more sharp edge and few ring artifact .",
        "figure 9 .",
        "the effect of parameter \u0015 , \u0016 , and on the stability of the propose algorithm .",
        "by the size of the blur kernel .",
        "the number of loop in each layer be xed , depend on the parameter ( \u0015 , \u0016 , , maxand max ) .",
        "compared to the l0-based algorithm [ 16 ] , the propose algorithm need more computation to sub- divide image and make k-means classi cation .",
        "the com- plexities of these step be both o ( n ) where nis the volume 8 , 2020 9193h .",
        "zhang et al .",
        ": bid : an effective blind image deblurring scheme to estimate the blur kernel for various scenarios table 5 .",
        "time complexity of each formula .",
        "table 6 .",
        "run time performance .",
        "number of image pixel and they be independent of the patch size .",
        "as show in table 5 , we summarize the time complexity of the main formula in this paper .",
        "since for- mula ( 21 ) , ( 21 ) contain the fft operation , their time com- plexities be o ( nlog 2n ) .",
        "the evaluation of the run time of our algorithm relative to that of the state-of-the-art method [ 8 ] , [ 14 ] , [ 17 ] , [ 31 ] be perform on the same machine with an intel core i5\u00004430 processor and 12 gb of ram .",
        "all the algorithm be implement on matlab .",
        "table 6shows the run time result on datasets [ 10 ] , [ 11 ] .",
        "g. parameter analysis there be three main parameter , namely \u0015 , \u0016and , that affect the stability of the algorithm .",
        "in this subsection , eval- uations on the effect of these parameter on the kernel estimation be present .",
        "the algorithm vary one parameter and xes the others , and evaluate the accuracy of estimate kernel on dataset [ 10 ] within the kernel similarity metric .",
        "figure 9shows that the propose deblurring algorithm be insensitive to the parameter setting .",
        "v. conclusion and future work motivated by the analysis of the process of image blurring and the local intensity characteristic , the local two-tone prior be propose for single image blind deblurring .",
        "we decompose the image with complex color cluster into image patch with simple color cluster to apply the local two-tone prior .",
        "moreover , a new color cluster dynamic range be propose base on the average value of the color cluster to distinguish between two color level and be prove in mathematics .",
        "com- bin the l0gradient sparse prior with the local two-tone prior , an effective optimization algorithm base on the half- quadratic splitting approach be develop .",
        "the experimental result show that the propose algorithm perform favor- ably against the state-of-the-art method for the single image deblurring of various scenario .",
        "in future work , we will try to extend this method to image with noise and outlier .",
        "anotherfuture direction be to improve the computational ef ciency to implement real-time processing on an embedded platform ."
    ],
    "processed_text": "received december 29 2019 accept january 2 2020 date publication january 7 2020 date current version january 15 2020 digital object identifier 101 109/access20202964621 bid effective blind image deblurring scheme estimate blur kernel various scenarios hong zhang yawei li yujie wu zeyu zhang image processing center beihang university beijing 100191 china corresponding author yawei li lyw3074 @ buaaeducn work support part national natural science foundation china grant 61872019 grant 61571026 part national key research development program china grant 2016yfe0108100 abstract recent year image deblurring widely investigate order solve illposed problem variety prior model propose successively twotone prior successfully apply text image deblurring achieve signi cant result however natural image rich color cluster meet twotone prior require two color cluster image paper local twotone prior propose image complex color cluster decompose image complex color cluster patch simple color cluster also nd process image blurring weighted average pixel value lead increase intermediate pixel value therefore new measure dynamic range image propose indicate difference color cluster use average value color cluster rigorously prove mathematics besides analyze effectiveness propose prior image deblurring detail experimental result widely use datasets show propose method perform favorably stateoftheart algorithm qualitatively quantitatively index terms image deblurring illposed problem local twotone prior dynamic range introduction image blurring main challenge camera system severely affect de nition photo popularity handheld camera phone blur image grow exponentially make important restore sharp image blurred one besides blur image cause many advanced vision application system fail target detection track 1 \u0015 3 classi cation 4 5 recognition 6 result serious consequence blind image deblurring technology still hot topic eld image processing computer vision effective method solve prob lem goal blind deblurring usually estimate sharp latent image blur kernel blurred image blind deblurring obviously severely illposed problem nite set solution blur linear shiftinvariant simpli ed mathematical model associate editor coordinate review manuscript approve publication ines domingues image formation process model bdi kcn 1 b kandndenote observed blurred image corresponding latent image blur kernel addi tive noise respectively represent convolution oper ator general problem blind image deblurring solve two step rst step estimate blur kernel second step solve latent image know blur kernel paper mainly discuss rst step estimation blur kernel recent year series excellent algorithm propose solve problem image deblurring jiang et al 9 propose excellent text image deblurring algorithm base twotone prior however applicable scenario text image enjoy unique characteristic pixel concentrate two cluster image always multiple gray level according observation twotone prior still valid local image patch various scenario image patch always contain one two gray level therefore volume 8 2020this work license creative commons attribution 40 license information see http //creativecommonsorg/licenses/by/40/9185h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios figure 1 deblurred result challenging saturate image lai dataset 7 input blur image b intermediate latent image algorithm c result result pan et al 8 figure 1 b show salient edge structure recover accurately detail noise suppress result c superior pan detail new local twotone prior effective estimate blur kernel diverse scenario natural man make text face saturate propose image divide small patch consist one cluster two cluster follow twotone prior paper demon strates local twotone prior work image patch effectiveness detail show figure 1 b propose method base local twotone prior observably preserve salient edge subdue weak gradient intermediate latent image figure 1 c show result superior pan detail compared stateoftheart deblurring method algorithm simple effective without edge selection step achieves competitive result widely use image deblurring benchmark 7 10 11 paper main contribution followsv \u000fa local twotone prior propose image com plex color cluster decompose image complex color cluster patch simple color cluster effective multiple scenario \u000fbased observation contrast loss blurred image patch new measure dynamic range image propose use average value color cluster effectively distinguish blurred image clear image tight mathematical proof measure propose new regularized term enhance local contrast latent image experimental result prove effectiveness propose regularized term \u000fcompared advanced deblurring method method competitive performance widely used natural image deblurring benchmark speci c task especially case large blur kernel performance well current deep learningbased method case approximate global uniform blurring rest paper organize follow section ii propose overview stateoftheart deblurring mod el section iii local twotone prior color cluster dynamic contrast introduce bid scheme halfquadratic splitting method propose solve result section iv extensive analysis discussion var ious experiment conduct evaluate effectivenessof propose prior section vconcludes paper identi es future direction ii related work recently stateoftheart deblurring method produce intermediate latent image sharp edge rely explicit edge prediction 12 \u0015 14 sparse statistical prior regularization 9 10 15 16 patchbased prior 14 17 besides learningbased approach 18 \u0015 21 deblurring see signi cant advance section main model related work discuss detail explicit edge extraction methods select explicit salient edge kernel esti mation extensively validate single image blind deblurring cho lee 12 introduce bilateral ltering shock ltering gradient magnitude thresholding method predict strong edge map kernel estimation xu jia 13 show trivial edge make psf estimation vul nerable noise meanwhile propose new criterion select salient edge restrain spike region kernel estimation cai et al 22 propose joint deblurring method extract reliable edge suppress noise time although method perform well several kind blur image extra computation need extract edge deblurring result heavily depend accuracy correct edge selection b sparse statistical priors sparse statistical prior well ect statistical infor mation natural image usually use sharp edge restoration relevant algorithm work 9 algorithm 9 propose twotone prior model base characteristic text image always contain two color cluster propose twostage deblurring algorithm base model text image levin et al 10 propose image gradient sparsity inclined blur image image deblurring algorithm especially framework maximum posterior map address problem various natural image prior propose deblurring method remove harmful structure gradu ally enhance resolution approximate latent image 9186 volume 8 2020h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios iteration krishnan et al 23 present normalized sparse prior l 1=l2regularization scaleinvariant solve series problem relate l1prior sun et al 24 propose weighted l0regularized gradient prior blind image deblurring dou et al 25 propose smoothingenhancing regularizer fast optimization scheme regularizer simultaneously suppress small detail enhance reli able edge pan et al 8 present effective blind image deblurring algorithm base dark channel prior ever sparsity statistical prior ignore salient image structure geometry critical kernel estimation c patchbased priors patchbased prior widely use many eld texture synthesis denoising superresolution 26 deblurring 14 17 michaeli irani 17 develop image prior base patch recurrence property favor clear image blurred image similarly sun et al 14 explore new edgebased approach use patch prior kernel estimation single image estimate trusted subset latent image impose patch prior speci cally tailor towards model appearance image edge corner primitive compared prior base pixel patchbased prior result signi cant improvement performance blind deblurring ever also require extra training process learn prior set patch extra computation extract useful edge learningbased methods extensive application deep learning eld computer vision learningbased method also propose image deblurring sun et al 18 propose patchlevel prior use deep cnns remove nonuniform motion blur nah et al 19 achieve stateoftheart result use multiscale convolutional neural network cnn framework follow coarseto ne pipeline recover latent image full resolution reach tao et al 20 propose new scalerecurrent network srn reduce number trainable parameter incorporate recurrent module cnnbased deblurring system addi tion kupyn et al 21 develop endtoend learn method motion deblurring base conditional gan net content loss deblurring method base endtoend deep learning effectively avoid image deconvolution deal nonuniform blur image nevertheless need additional training data pair performance deep learning blind image deblurring highly dependent completeness training dataset iii proposed bid scheme twotone prior successfully apply text image deblurring 9 color cluster natural image much rich text image original twotone prior applicable image thantwo cluster local image patch typically one color cluster smooth region two color cluster edge region long patch size appropriate intuitively blur process image process weighted summation local pixel value num ber intermediate intensity value twocolor cluster increase contrast range blurred image patch edge reduce based observation local twotone prior propose restrict intermediate pixel restore original image patch contrast put forward following proposition give strict proof mathematics proposition 1 letidenotes image patch kdenotes blur kernel kkk1d1 k x \u00150 x color cluster dynamic contrast cdynfigdmean x2c2fig\u0000 mean x2c1figis difference mean pixel value ofc2cluster c1cluster input image give byv cdynfi kg\u0014cdynfig 2 proof 1 smooth patch accord de nition image convolution mean value blurred image equal clear one one color cluster c 1dc2 proof followsv bmdnx xd1x z2ki\u0010 xchs 2i \u0000z\u0011 kz/=n dx z2knx xd1i\u0010 xchs 2i \u0000z\u0011 kz/=n dx z2knimkz/=n dnimx z2kkz/=n dim 3 bmandimdenote mean value blurred image patch clear image patch nis number pixel image patch \u0001 denote rounding operator k denote domain blur kernel kandsdenotes dimension cdynfi kgdcdynfig 2 patch edge without loss generality suppose image patch icontains npixels c1cluster npixels ofc2cluster c1dx1cx2c cxn n c2dy1cy2c cyn n 4 c1andc2denote mean value c1cluster c2cluster respectively x\u0003andy\u0003denote pixel value c1cluster c2cluster y\u0003 > x\u0003for anyx\u0003 y\u0003 volume 8 2020 9187h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios blurred image patch pixel value equal weighted sum surround pixel value c0 1dx0 1cx0 2c cx0 n n c0 2dy0 1cy0 2c cy0 n n 5 c0 1 c0 2 x0 \u0003andy0 \u0003denote mean value pixel value blurred image patch respectively x0 \u0003 y0 \u0003can solve use following formulasv x0 1dk1x1c cknxncknc1y1c ck2nyn x0 2dk2x1c cknc1xncknc2y1c ck1yn x0 ndknx1c ck2n\u00001xnck2ny1c ckn\u00001yn 6 k1 k2 k2ndenote weighting coef cients k1c k2c ck2nd1 x0 1cx0 2c cx0 nd k1ck2c ckn x1 c k2ck3c cknc1 x2c c knc1cknc2c ck2n y1c c k2nck1c ckn\u00001 yn > k1ck2c ck2n x1 c k1ck2c ck2n x2c c k1ck2c ck2n xn dx1cx2c cxn 7 hence x0 1cx0 2c cx0 n > x1cx2c cxn soc0 1 > c1 similarly c0 2 < c2 cdynfi kg < cdynfig proposition 1 hold property 1vfrom abovementioned analysis prov ing havev kb x \u0000c1k1\u0015ki x \u0000c1k1 x2c1 kb x \u0000c2k1\u0015ki x \u0000c2k1 x2c2 8 b x x denote blurred clear image pixel c1 c2denote mean value c1 c2clusters image based property 1 propose local twotone prior de ned p x dx x2 1ki x \u0000c1k1c 2ki x \u0000c2k1 9 xdenote pixel location denotes image patch c1 c2represent center two gray level cluster  \u0003d1 x belong c\u0003cluster \u0003d0 otherwise addition proposition prompt us propose new regularized term enhance local contrast latent image c1andc2can derive apply kmeans clus tering kd2 gray level image patch  yield two cluster center c1 < c2 c1andc2updatewith formula 10and11to enhance contrast image patch ci 1dm x < ci\u00001 1 cci\u00001 1 2 10 ci 2dm x > ci\u00001 2 cci\u00001 2 2 11 x < c1 x > c2 denote mean value pixel less c1and large c2in image patch respectively value new c\u0003is x c\u0003 previous c\u0003 thus contrast patch enhance keep c1and c2in reasonable range p introduce regularizer conventional formulation image deblurring min kki k\u0000bk2 2c kkk2 2c\u0016kr ik0c\u0015p 12 rst term data term second third term use regularize blur kernel image gradient \u0016 and\u0015are weight parameter approach mapbased framework adopt coarseto ne manner iteratively solve min iki k\u0000bk2 2c\u0016kr ik0c\u0015p 13 andk min kki k\u0000bk2 2c kkk2 2 14 nal blur kernel estimate latent image restore use advanced nonblind deconvolution algo rithm figure 2shows whole pipeline algorithm estimating latent image step goal solve iwith xed k formula 13 nonlinear minimization problem intractable deal directly halfquadratic splitting method alternate solve algorithm adopt paper introduce auxiliary variable uto replace iinp gd gh gv corresponding image gradient hori zontal vertical direction cost function 13 rewrite asv min u gki k\u0000bk2 2c kri\u0000gk2 2c\u0016kgk 0 c x \u00032f1 2g \u0003ki\u0000c\u0003\u0000uk2 2c\u0015x \u00032f1 2g \u0003kuk1 15 penalty parameter close nity solution 15approaches 13 15 optimize alternatively solve u gby xing others 1 solve u usubproblem objective function predigest tov minu x \u00032f1 2g \u0003ki\u0000c\u0003\u0000uk2 2c\u0015x \u00032f1 2g \u0003kuk1 16 9188 volume 8 2020h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios figure 2 pipeline algorithm algorithm istep kstep solve iteratively restore latent image estimate blur kernel image scale coarsetofine pyramid framework specifically prior steer salient edge become sharp restore local contrast blur kernel latent image update final blur kernel estimate nonblind deconvolution algorithm apply restore latent image 16 solve onedimensional shrinkage oper ator solution give udx \u00032f1 2g \u0003sign i\u0000c\u0003 max ki\u0000c\u0003k\u0000\u0015 0 17 1d1 2d0 ifki x \u0000c1k < ki x \u0000c2k 1d0 2d1 otherwise optimization algorithm repeat image patch whole image optimize uis solve patch patch solution calculate parallel patch relate 2 solve g iandu xed gi update minimize ming kri\u0000gk2 2c\u0016kgk 0 18 use method solve gas solve uin inner loop produce clear result ring artifact latent image solution gi gd ri jrij2\u0015\u0016 0 otherwise 19 3 solve xing value gandu 15 simpli ed min iki k\u0000bk2 2c kri\u0000gk2 2c ki\u0000u0k2 2 20 wherw u0dp \u00032f1 2g \u0003 c\u0003cu fourier transform fourier inverse transform apply term closedform solution leastsquares minimization problem idf\u00001 f k f b c f u0 c fg f k f k c c p i2fh vgf ri f ri 21 f \u0001 denote fourier transform f\u00001 \u0001 denote fourier inverse transform f \u0001 complex conjugate operator fgdf rh f gh cf rv f gv rhandrvdenote horizontal vertical differential operator respectively main step solve 12 summarize algorithm 1 b estimating blur kernel k section blur kernel kis optimize xed intermediate image consistent exist method 12 paper apply kernel estimation method base gradient show accurate solve k objective function write asv min kkri k\u0000rbk2 2c kkk2 2 22 leastsquares problem solve fourier domain closedform solution obtain kdf\u00001 f rhi f rhb cf rvi f rvb f rhi 2cf rvi 2c 23 obtain k normalize keep sum element equal 1 negative element set 0 volume 8 2020 9189h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios algorithm 1 latent image iestimation algorithm input blurred image band blur kernel k 1 b 2\u0015 2 forjd1 2 5dodo 3 repeat 4 solve uusing 17 5 2\u0016 6 apply kmeans cluster k = 2 gray level image patch  yield two cluster center c1 < c2 7 forid1 2do 8 update c1 c2using 10 11 9 end 10 repeat 11 solve gusing 19 12 solve iusing 21 13 2 14 > max 15 2 16 > max 17 solve kusing 23 18 \u0015 maxf\u0015=11 1e\u00004g 19 end output intermediate latent image c implementation details paper adopt iterative coarseto ne optimization framework accelerate convergence algorithm avoid trivial solution kernel estimation algorithm 1 present main step image pyramid level blurred image blur kernel size downsampled scale factor 1=p 2 blur kernel size become 7 \u00027 experiment parameter \u0015 d\u0016d4e\u00003 d2 maxd1e5 maxd8 patchsized25 set empirically effect parameter blur kernel estimation analyze next section detail max_iterd5 set weigh accuracy speed nal stage nonblind deconvolution method use recover latent image iv performance analysis show effectiveness algorithm suf cient com parisons stateoftheart deblurring method perform three widely use datasets 7 10 11 addition convergence computational complex ity propose algorithm discuss effect patch size parameter algorithm also evaluate experiment effectiveness local twotone prior contrast enhancement constraint without use local twotone prior propose method degenerate deblurring scheme l0prior intuitive comparison local twotone prior figure 3 effectiveness propose prior blurry input deblurred result challenging image large blur kernel kohler dataset 11 show b coarsetofine intermediate result show e h show propose prior truly effective kernel estimation figure 3 method achieve good solution contain sharp detail ring artifact contrast enhancement constraint remove one one comparison experiment advanced algorithm 8 figure 3 e f g h show coarseto ne inter mediate result pan et al 8 without p without contrast enhancement constraint indicated figure 3 f g intermediate result without use local twotone prior contrast enhancement constraint contain ringing artifact estimate kernel far true value contrary inter mediate result use local twotone prior clear contain sharp edge figure 3 h quantitative evaluation without twotone prior contrast enhancement constraint benchmark dataset 11 propose figure 4 result demonstrate model local twotone prior contrast enhancement constraint generates well result one without however model performs poorly local twotone prior mainly prior indicate trend image color cluster effectively 9190 volume 8 2020h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios figure 4 quantitative evaluation propose algorithm without local twotone prior contrast enhancement constraint dataset 11 local twotone prior truly help improve result b average kernel similarity every iteration dataset 10 figure 5 quantitative evaluation dataset 11 use psnr measure b performance comparison use success rate measure dataset 7 propose algorithm perform well stateoftheart method avoid fall local minimum precision high use alone furthermore case large blur kernel method achieve signi cant result without local twotone prior contrast enhancement constraint table 1 b results synthesized images 1 dataset kohler et al 11 evaluate performance deblurring quantitatively test algorithm stateoftheart method synthesized datasets 11 kohler et al 11 dataset include 12 motion blur kernel 4 groundtruth image blurred test image generate synthesize mul tiple image motion path groundtruth image capture along camera motion trajectory step step every restored image need compare 199 clear image compute psnr result 12 13 15 23 27 \u0015 30 8 achieve dataset 11 provide best deblurring result author take nonblind deconvolution method 8 get result figure 5 report mean psnr performance dataset 11 method outperform compete meth od figure 6 show deblurred result challenging image large blur kernel dataset 11 obtain various method although advanced algorithm 8 13 29 able address blur image still dif culties address large blur kernel kernel 811 signi cant ring artifact theirtable 1 average psnr value large blur kernel kernel 811 dataset 11 table 2 quantitative comparison kohler dataset 11 deep learningbased method term psnr/mssim result contrast propose result contain ringing artifact ne detail according table 1 result relate large blur kernel kernel 811 perform favorably stateoftheart method addition also compare method lat est deep learningbased deblurring method 18 \u0015 21 deep learningbased method generally evaluate gopro dataset nonuniform 19 kohler dataset uniform 11 method design global uniform blur comparison global uniform dataset 11 although global uniform dataset 11 blur kernel 2671012 still spatially vary deep learning method especially good result 18 \u0015 21 generate endtoend neural net work instead deconvolution algorithm make com parisons deep learningbased method term psnr/mssim result table 2show algo rithm performs well recent deep learning deblurring method two term 2 dataset lai et al 7 lai dataset 7 contains 100 uniform synthetic blur image 100 nonuniform synthetic blur image 100 real blur image algorithm design uniform blur 100 uniform synthetic blur image 100 real blur image evaluate 13 representative stateoftheart blind deconvolution method 12 \u0015 17 23 29 31 \u0015 35 image dataset cover various scenario manmade natural face saturate text truly rep resent actual challenge image deblurring fair comparison result experiment generate nonblind deconvolution method 36 result method obtain dataset lai et al 7 show table 3 method achieve best performance term mean psnr every volume 8 2020 9191h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios figure 6 deblurred result challenging image large blur kernel result f perform good others figure 7 deblurred result synthetic text image propose method generate visually competitive result relative advanced method 13 14 31 32 although e specially design text image table 3 quantitative comparison lai dataset 7 100 uniform synthetic image performance measure average psnr value different row denote different category image scenario figure 5 b present cumulative distribution error ratio show figure 5 b method slightly good performance xu jia 13 signi cantly outperform stateoftheart meth od figure 7shows qualitative comparison text image deblurring different algorithm 13 14 31 32 result much good others although 32 design specially text image c results real images comparison compare algorithm stateoftheart image deblurring method 14 17 31 real blurring image experiment result generate nonblind deconvolution method 36 since groundtruth image kernel unknown analyze deblurring result qualitatively figure 8shows deblurring result real blurry photo unknown blur kernel ring artifact sharp detail result compared meth od result stable competitive convergence method propose algorithm alternate minimization pro ce subproblem cost function decrease converge local minimum figure 4 b showstable 4 average psnr value different patch size dataset 10 average kernel similarity value vary respect iteration benchmark dataset 10 iteration kernel similarity estimate kernel original kernel become high mean propose optimization method converges well e effect patch size algorithm stability effect patch size stability algorithm also analyze play crucial role kernel estimation image resolution 255 \u0002255 pixel dataset 10 different patch size choose experiment show table 4 average psnr value different patch size quite stable thus propose method sensitive patch size within suitable range f computational complexity execute algorithm coarseto ne pyramid frame work number layer pyramid determined 9192 volume 8 2020h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios figure 8 deblurred result 14 17 31 real blurred image unknown blur kernel result contain sharp edge ring artifact figure 9 effect parameter \u0015 \u0016 stability propose algorithm size blur kernel number loop layer xed depend parameter \u0015 \u0016 maxand max compared l0based algorithm 16 propose algorithm need computation sub divide image make kmeans classi cation com plexities step n nis volume 8 2020 9193h zhang et al bid effective blind image deblurring scheme estimate blur kernel various scenarios table 5 time complexity formula table 6 run time performance number image pixel independent patch size show table 5 summarize time complexity main formula paper since mula 21 21 contain fft operation time com plexities nlog 2n evaluation run time algorithm relative stateoftheart method 8 14 17 31 perform machine intel core i5\u00004430 processor 12 gb ram algorithm implement matlab table 6shows run time result datasets 10 11 g parameter analysis three main parameter namely \u0015 \u0016and affect stability algorithm subsection eval uations effect parameter kernel estimation present algorithm vary one parameter xes others evaluate accuracy estimate kernel dataset 10 within kernel similarity metric figure 9shows propose deblurring algorithm insensitive parameter setting v conclusion future work motivated analysis process image blurring local intensity characteristic local twotone prior propose single image blind deblurring decompose image complex color cluster image patch simple color cluster apply local twotone prior moreover new color cluster dynamic range propose base average value color cluster distinguish two color level prove mathematics com bin l0gradient sparse prior local twotone prior effective optimization algorithm base half quadratic splitting approach develop experimental result show propose algorithm perform favor ably stateoftheart method single image deblurring various scenario future work try extend method image noise outlier anotherfuture direction improve computational ef ciency implement realtime processing embedded platform",
    "bag_of_words": {
        "received": 1,
        "december": 1,
        "accept": 1,
        "january": 3,
        "date": 2,
        "publication": 2,
        "current": 2,
        "version": 1,
        "digital": 1,
        "object": 1,
        "identifier": 1,
        "109/access20202964621": 1,
        "bid": 12,
        "effective": 17,
        "blind": 21,
        "image": 162,
        "deblurring": 58,
        "scheme": 14,
        "estimate": 20,
        "blur": 59,
        "kernel": 64,
        "various": 15,
        "scenarios": 10,
        "hong": 1,
        "zhang": 11,
        "yawei": 2,
        "li": 2,
        "yujie": 1,
        "wu": 1,
        "zeyu": 1,
        "processing": 3,
        "center": 4,
        "beihang": 1,
        "university": 1,
        "beijing": 1,
        "china": 3,
        "corresponding": 3,
        "author": 2,
        "lyw3074": 1,
        "buaaeducn": 1,
        "work": 10,
        "support": 1,
        "part": 2,
        "national": 2,
        "natural": 8,
        "science": 1,
        "foundation": 1,
        "grant": 3,
        "key": 1,
        "research": 1,
        "development": 1,
        "program": 1,
        "2016yfe0108100": 1,
        "abstract": 1,
        "recent": 3,
        "year": 2,
        "widely": 6,
        "investigate": 1,
        "order": 1,
        "solve": 27,
        "illposed": 3,
        "problem": 10,
        "variety": 1,
        "prior": 55,
        "model": 9,
        "propose": 48,
        "successively": 1,
        "twotone": 31,
        "successfully": 2,
        "apply": 8,
        "text": 13,
        "achieve": 6,
        "signi": 6,
        "cant": 5,
        "result": 49,
        "however": 3,
        "rich": 2,
        "color": 24,
        "cluster": 32,
        "meet": 1,
        "require": 2,
        "two": 12,
        "paper": 10,
        "local": 31,
        "complex": 6,
        "decompose": 3,
        "patch": 43,
        "simple": 4,
        "also": 6,
        "nd": 2,
        "process": 6,
        "blurring": 5,
        "weighted": 4,
        "average": 10,
        "pixel": 17,
        "value": 26,
        "lead": 1,
        "increase": 2,
        "intermediate": 10,
        "therefore": 2,
        "new": 10,
        "measure": 6,
        "dynamic": 6,
        "range": 7,
        "indicate": 2,
        "difference": 2,
        "use": 21,
        "rigorously": 1,
        "prove": 3,
        "mathematics": 3,
        "besides": 3,
        "analyze": 4,
        "effectiveness": 6,
        "detail": 11,
        "experimental": 3,
        "datasets": 4,
        "show": 17,
        "method": 54,
        "perform": 8,
        "favorably": 2,
        "stateoftheart": 14,
        "algorithm": 47,
        "qualitatively": 2,
        "quantitatively": 2,
        "index": 1,
        "terms": 1,
        "introduction": 1,
        "main": 7,
        "challenge": 2,
        "camera": 3,
        "system": 3,
        "severely": 2,
        "affect": 2,
        "de": 3,
        "nition": 2,
        "photo": 2,
        "popularity": 1,
        "handheld": 1,
        "phone": 1,
        "grow": 1,
        "exponentially": 1,
        "make": 5,
        "important": 1,
        "restore": 6,
        "sharp": 9,
        "blurred": 16,
        "one": 10,
        "cause": 1,
        "many": 2,
        "advanced": 6,
        "vision": 3,
        "application": 2,
        "fail": 1,
        "target": 1,
        "detection": 1,
        "track": 1,
        "classi": 2,
        "cation": 2,
        "recognition": 1,
        "serious": 1,
        "consequence": 1,
        "technology": 1,
        "still": 4,
        "hot": 1,
        "topic": 1,
        "eld": 3,
        "computer": 2,
        "prob": 1,
        "lem": 1,
        "goal": 2,
        "usually": 2,
        "latent": 20,
        "obviously": 1,
        "nite": 1,
        "set": 5,
        "solution": 9,
        "linear": 1,
        "shiftinvariant": 1,
        "simpli": 2,
        "ed": 2,
        "mathematical": 2,
        "associate": 1,
        "editor": 1,
        "coordinate": 1,
        "review": 1,
        "manuscript": 1,
        "approve": 1,
        "ines": 1,
        "domingues": 1,
        "formation": 1,
        "bdi": 1,
        "kcn": 1,
        "kandndenote": 1,
        "observed": 1,
        "addi": 2,
        "tive": 1,
        "noise": 5,
        "respectively": 5,
        "represent": 1,
        "convolution": 2,
        "oper": 2,
        "ator": 2,
        "general": 1,
        "step": 11,
        "rst": 3,
        "second": 2,
        "know": 1,
        "mainly": 2,
        "discuss": 3,
        "estimation": 12,
        "series": 2,
        "excellent": 2,
        "jiang": 1,
        "et": 27,
        "al": 27,
        "base": 12,
        "applicable": 2,
        "scenario": 7,
        "enjoy": 1,
        "unique": 1,
        "characteristic": 3,
        "concentrate": 1,
        "always": 3,
        "multiple": 2,
        "gray": 5,
        "level": 7,
        "according": 2,
        "observation": 3,
        "valid": 1,
        "contain": 8,
        "volume": 9,
        "2020this": 1,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "information": 1,
        "see": 2,
        "http": 1,
        "//creativecommonsorg/licenses/by/40/9185h": 1,
        "figure": 26,
        "deblurred": 6,
        "challenging": 4,
        "saturate": 3,
        "lai": 5,
        "dataset": 28,
        "input": 4,
        "pan": 5,
        "salient": 6,
        "edge": 23,
        "structure": 3,
        "recover": 3,
        "accurately": 1,
        "suppress": 3,
        "superior": 2,
        "diverse": 1,
        "man": 1,
        "face": 2,
        "divide": 2,
        "small": 2,
        "consist": 1,
        "follow": 3,
        "demon": 1,
        "strates": 1,
        "observably": 1,
        "preserve": 1,
        "subdue": 1,
        "weak": 1,
        "gradient": 7,
        "compared": 4,
        "without": 10,
        "selection": 2,
        "achieves": 1,
        "competitive": 4,
        "benchmark": 4,
        "contribution": 1,
        "followsv": 2,
        "\u000fa": 1,
        "com": 6,
        "plex": 1,
        "\u000fbased": 1,
        "contrast": 19,
        "loss": 3,
        "effectively": 3,
        "distinguish": 2,
        "clear": 8,
        "tight": 1,
        "proof": 4,
        "regularized": 3,
        "term": 11,
        "enhance": 6,
        "\u000fcompared": 1,
        "performance": 12,
        "used": 1,
        "speci": 2,
        "task": 1,
        "especially": 3,
        "case": 3,
        "large": 9,
        "well": 7,
        "deep": 11,
        "learningbased": 8,
        "approximate": 2,
        "global": 4,
        "uniform": 9,
        "rest": 1,
        "organize": 1,
        "section": 7,
        "ii": 2,
        "overview": 1,
        "mod": 1,
        "el": 1,
        "iii": 2,
        "introduce": 4,
        "halfquadratic": 2,
        "splitting": 3,
        "iv": 2,
        "extensive": 2,
        "analysis": 5,
        "discussion": 1,
        "var": 1,
        "ious": 1,
        "experiment": 7,
        "conduct": 1,
        "evaluate": 6,
        "effectivenessof": 1,
        "vconcludes": 1,
        "identi": 1,
        "es": 1,
        "future": 3,
        "direction": 3,
        "related": 2,
        "recently": 1,
        "produce": 2,
        "rely": 1,
        "explicit": 3,
        "prediction": 1,
        "sparse": 5,
        "statistical": 5,
        "regularization": 1,
        "patchbased": 4,
        "approach": 4,
        "advance": 1,
        "extraction": 1,
        "methods": 2,
        "select": 2,
        "esti": 1,
        "mation": 2,
        "extensively": 1,
        "validate": 1,
        "single": 4,
        "cho": 1,
        "lee": 1,
        "bilateral": 1,
        "ltering": 2,
        "shock": 1,
        "magnitude": 1,
        "thresholding": 1,
        "predict": 1,
        "strong": 1,
        "map": 2,
        "xu": 2,
        "jia": 2,
        "trivial": 2,
        "psf": 1,
        "vul": 1,
        "nerable": 1,
        "meanwhile": 1,
        "criterion": 1,
        "restrain": 1,
        "spike": 1,
        "region": 3,
        "cai": 1,
        "joint": 1,
        "extract": 3,
        "reliable": 1,
        "time": 7,
        "although": 5,
        "several": 1,
        "kind": 1,
        "extra": 3,
        "computation": 3,
        "need": 4,
        "heavily": 1,
        "depend": 2,
        "accuracy": 3,
        "correct": 1,
        "priors": 2,
        "ect": 1,
        "infor": 1,
        "restoration": 1,
        "relevant": 1,
        "twostage": 1,
        "levin": 1,
        "sparsity": 2,
        "inclined": 1,
        "framework": 5,
        "maximum": 1,
        "posterior": 1,
        "address": 3,
        "remove": 3,
        "harmful": 1,
        "gradu": 1,
        "ally": 1,
        "resolution": 3,
        "2020h": 4,
        "iteration": 4,
        "krishnan": 1,
        "present": 5,
        "normalized": 1,
        "1=l2regularization": 1,
        "scaleinvariant": 1,
        "relate": 3,
        "l1prior": 1,
        "sun": 3,
        "l0regularized": 1,
        "dou": 1,
        "smoothingenhancing": 1,
        "regularizer": 3,
        "fast": 1,
        "optimization": 5,
        "simultaneously": 1,
        "reli": 1,
        "able": 2,
        "dark": 1,
        "channel": 1,
        "ever": 2,
        "ignore": 1,
        "geometry": 1,
        "critical": 1,
        "texture": 1,
        "synthesis": 1,
        "denoising": 1,
        "superresolution": 1,
        "michaeli": 1,
        "irani": 1,
        "develop": 3,
        "recurrence": 1,
        "property": 3,
        "favor": 2,
        "similarly": 2,
        "explore": 1,
        "edgebased": 1,
        "trusted": 1,
        "subset": 1,
        "impose": 1,
        "cally": 1,
        "tailor": 1,
        "towards": 1,
        "appearance": 1,
        "corner": 1,
        "primitive": 1,
        "improvement": 1,
        "training": 3,
        "learn": 2,
        "useful": 1,
        "learning": 5,
        "patchlevel": 1,
        "cnns": 1,
        "nonuniform": 4,
        "motion": 5,
        "nah": 1,
        "multiscale": 1,
        "convolutional": 1,
        "neural": 2,
        "network": 2,
        "cnn": 1,
        "coarseto": 5,
        "ne": 6,
        "pipeline": 3,
        "full": 1,
        "reach": 1,
        "tao": 1,
        "scalerecurrent": 1,
        "srn": 1,
        "reduce": 2,
        "number": 5,
        "trainable": 1,
        "parameter": 13,
        "incorporate": 1,
        "recurrent": 1,
        "module": 1,
        "cnnbased": 1,
        "tion": 1,
        "kupyn": 1,
        "endtoend": 3,
        "conditional": 1,
        "gan": 1,
        "net": 2,
        "content": 1,
        "avoid": 3,
        "deconvolution": 9,
        "deal": 2,
        "nevertheless": 1,
        "additional": 1,
        "data": 2,
        "pair": 1,
        "highly": 1,
        "dependent": 1,
        "completeness": 1,
        "proposed": 1,
        "much": 2,
        "original": 3,
        "thantwo": 1,
        "typically": 1,
        "smooth": 2,
        "long": 1,
        "size": 12,
        "appropriate": 1,
        "intuitively": 1,
        "summation": 1,
        "num": 1,
        "ber": 1,
        "intensity": 2,
        "twocolor": 1,
        "based": 2,
        "restrict": 1,
        "put": 1,
        "forward": 1,
        "following": 2,
        "proposition": 4,
        "give": 3,
        "strict": 1,
        "letidenotes": 1,
        "kdenotes": 1,
        "kkk1d1": 1,
        "\u00150": 1,
        "cdynfigdmean": 1,
        "x2c2fig\u0000": 1,
        "mean": 11,
        "x2c1figis": 1,
        "ofc2cluster": 2,
        "c1cluster": 4,
        "byv": 1,
        "cdynfi": 3,
        "kg\u0014cdynfig": 1,
        "accord": 1,
        "equal": 3,
        "1dc2": 1,
        "bmdnx": 1,
        "xd1x": 1,
        "z2ki\u0010": 1,
        "xchs": 2,
        "2i": 2,
        "\u0000z\u0011": 2,
        "kz/=n": 2,
        "dx": 3,
        "z2knx": 1,
        "xd1i\u0010": 1,
        "z2knimkz/=n": 1,
        "dnimx": 1,
        "z2kkz/=n": 1,
        "dim": 1,
        "bmandimdenote": 1,
        "nis": 2,
        "denote": 7,
        "rounding": 1,
        "operator": 3,
        "domain": 2,
        "kandsdenotes": 1,
        "dimension": 1,
        "kgdcdynfig": 1,
        "generality": 1,
        "suppose": 1,
        "icontains": 1,
        "npixels": 2,
        "c1dx1cx2c": 1,
        "cxn": 3,
        "c2dy1cy2c": 1,
        "cyn": 1,
        "c1andc2denote": 1,
        "c2cluster": 2,
        "x\u0003andy\u0003denote": 1,
        "y\u0003": 2,
        "x\u0003for": 1,
        "anyx\u0003": 1,
        "9187h": 1,
        "sum": 2,
        "surround": 1,
        "c0": 5,
        "1dx0": 1,
        "1cx0": 3,
        "2c": 11,
        "cx0": 3,
        "2dy0": 1,
        "1cy0": 1,
        "cy0": 1,
        "x0": 7,
        "\u0003andy0": 1,
        "\u0003denote": 1,
        "y0": 1,
        "\u0003can": 1,
        "formulasv": 1,
        "1dk1x1c": 1,
        "cknxncknc1y1c": 1,
        "ck2nyn": 1,
        "2dk2x1c": 1,
        "cknc1xncknc2y1c": 1,
        "ck1yn": 1,
        "ndknx1c": 1,
        "ck2n\u00001xnck2ny1c": 1,
        "ckn\u00001yn": 1,
        "k1": 1,
        "k2": 1,
        "k2ndenote": 1,
        "weighting": 1,
        "coef": 1,
        "cients": 1,
        "k1c": 1,
        "k2c": 1,
        "ck2nd1": 1,
        "k1ck2c": 4,
        "ckn": 1,
        "x1": 2,
        "k2ck3c": 1,
        "cknc1": 1,
        "x2c": 2,
        "knc1cknc2c": 1,
        "ck2n": 4,
        "y1c": 1,
        "k2nck1c": 1,
        "ckn\u00001": 1,
        "yn": 1,
        "xn": 1,
        "dx1cx2c": 1,
        "hence": 1,
        "x1cx2c": 1,
        "soc0": 1,
        "c1": 8,
        "c2": 4,
        "kg": 1,
        "cdynfig": 1,
        "hold": 1,
        "1vfrom": 1,
        "abovementioned": 1,
        "prov": 1,
        "ing": 1,
        "havev": 1,
        "kb": 2,
        "\u0000c1k1\u0015ki": 1,
        "\u0000c1k1": 1,
        "x2c1": 1,
        "\u0000c2k1\u0015ki": 1,
        "\u0000c2k1": 2,
        "x2c2": 1,
        "c2denote": 1,
        "c2clusters": 1,
        "ned": 1,
        "x2": 1,
        "1ki": 1,
        "\u0000c1k1c": 1,
        "2ki": 1,
        "xdenote": 1,
        "location": 1,
        "denotes": 1,
        "c2represent": 1,
        "\u0003d1": 1,
        "belong": 1,
        "c\u0003cluster": 1,
        "\u0003d0": 1,
        "otherwise": 3,
        "addition": 3,
        "prompt": 1,
        "us": 1,
        "c1andc2can": 1,
        "derive": 1,
        "kmeans": 3,
        "clus": 1,
        "tering": 1,
        "kd2": 1,
        "yield": 2,
        "c1andc2updatewith": 1,
        "formula": 4,
        "10and11to": 1,
        "ci": 2,
        "1dm": 1,
        "ci\u00001": 2,
        "cci\u00001": 2,
        "2dm": 1,
        "less": 1,
        "c1and": 2,
        "c2in": 2,
        "c\u0003is": 1,
        "c\u0003": 2,
        "previous": 1,
        "thus": 2,
        "keep": 2,
        "reasonable": 1,
        "conventional": 1,
        "formulation": 1,
        "min": 6,
        "kki": 2,
        "k\u0000bk2": 5,
        "kkk2": 3,
        "2c\u0016kr": 2,
        "ik0c\u0015p": 2,
        "third": 1,
        "regularize": 1,
        "and\u0015are": 1,
        "weight": 1,
        "mapbased": 1,
        "adopt": 3,
        "manner": 1,
        "iteratively": 2,
        "iki": 2,
        "andk": 1,
        "nal": 2,
        "nonblind": 6,
        "algo": 2,
        "rithm": 2,
        "2shows": 1,
        "whole": 2,
        "estimating": 2,
        "iwith": 1,
        "xed": 4,
        "nonlinear": 1,
        "minimization": 3,
        "intractable": 1,
        "directly": 1,
        "alternate": 2,
        "auxiliary": 1,
        "variable": 1,
        "uto": 1,
        "replace": 1,
        "iinp": 1,
        "gd": 2,
        "gh": 2,
        "gv": 2,
        "hori": 1,
        "zontal": 1,
        "vertical": 2,
        "cost": 2,
        "function": 4,
        "rewrite": 1,
        "asv": 2,
        "gki": 1,
        "kri\u0000gk2": 3,
        "2c\u0016kgk": 2,
        "\u00032f1": 6,
        "2g": 6,
        "\u0003ki\u0000c\u0003\u0000uk2": 2,
        "2c\u0015x": 2,
        "\u0003kuk1": 2,
        "penalty": 1,
        "close": 1,
        "nity": 1,
        "15approaches": 1,
        "optimize": 3,
        "alternatively": 1,
        "gby": 1,
        "xing": 2,
        "others": 4,
        "usubproblem": 1,
        "objective": 2,
        "predigest": 1,
        "tov": 1,
        "minu": 1,
        "istep": 1,
        "kstep": 1,
        "scale": 2,
        "coarsetofine": 2,
        "pyramid": 4,
        "specifically": 1,
        "steer": 1,
        "become": 3,
        "update": 3,
        "final": 1,
        "onedimensional": 1,
        "shrinkage": 1,
        "udx": 1,
        "\u0003sign": 1,
        "i\u0000c\u0003": 1,
        "max": 4,
        "ki\u0000c\u0003k\u0000\u0015": 1,
        "1d1": 1,
        "2d0": 1,
        "ifki": 1,
        "\u0000c1k": 1,
        "ki": 1,
        "\u0000c2k": 1,
        "1d0": 1,
        "2d1": 1,
        "repeat": 3,
        "uis": 1,
        "calculate": 1,
        "parallel": 1,
        "iandu": 1,
        "gi": 2,
        "minimize": 1,
        "ming": 1,
        "gas": 1,
        "uin": 1,
        "inner": 1,
        "loop": 2,
        "ring": 5,
        "artifact": 7,
        "ri": 3,
        "jrij2\u0015\u0016": 1,
        "gandu": 1,
        "ki\u0000u0k2": 1,
        "wherw": 1,
        "u0dp": 1,
        "c\u0003cu": 1,
        "fourier": 5,
        "transform": 4,
        "inverse": 2,
        "closedform": 2,
        "leastsquares": 2,
        "idf\u00001": 1,
        "u0": 1,
        "fg": 1,
        "i2fh": 1,
        "vgf": 1,
        "f\u00001": 1,
        "conjugate": 1,
        "fgdf": 1,
        "rh": 1,
        "cf": 2,
        "rv": 1,
        "rhandrvdenote": 1,
        "horizontal": 1,
        "differential": 1,
        "summarize": 2,
        "kis": 1,
        "consistent": 1,
        "exist": 1,
        "accurate": 1,
        "write": 1,
        "kkri": 1,
        "k\u0000rbk2": 1,
        "obtain": 4,
        "kdf\u00001": 1,
        "rhi": 2,
        "rhb": 1,
        "rvi": 2,
        "rvb": 1,
        "2cf": 1,
        "normalize": 1,
        "element": 2,
        "negative": 1,
        "9189h": 1,
        "iestimation": 1,
        "band": 1,
        "2\u0015": 1,
        "forjd1": 1,
        "5dodo": 1,
        "uusing": 1,
        "2\u0016": 1,
        "forid1": 1,
        "2do": 1,
        "c2using": 1,
        "end": 2,
        "gusing": 1,
        "iusing": 1,
        "kusing": 1,
        "maxf\u0015=11": 1,
        "1e\u00004g": 1,
        "output": 1,
        "implementation": 1,
        "details": 1,
        "iterative": 1,
        "accelerate": 1,
        "convergence": 3,
        "downsampled": 1,
        "factor": 1,
        "1=p": 1,
        "\u00027": 1,
        "d\u0016d4e\u00003": 1,
        "d2": 1,
        "maxd1e5": 1,
        "maxd8": 1,
        "patchsized25": 1,
        "empirically": 1,
        "effect": 6,
        "next": 1,
        "max_iterd5": 1,
        "weigh": 1,
        "speed": 1,
        "stage": 1,
        "suf": 1,
        "cient": 1,
        "parisons": 2,
        "three": 2,
        "computational": 3,
        "ity": 1,
        "enhancement": 8,
        "constraint": 8,
        "degenerate": 1,
        "l0prior": 1,
        "intuitive": 1,
        "comparison": 9,
        "blurry": 2,
        "kohler": 5,
        "truly": 3,
        "good": 5,
        "inter": 2,
        "mediate": 2,
        "indicated": 1,
        "ringing": 2,
        "far": 1,
        "true": 1,
        "contrary": 1,
        "quantitative": 5,
        "evaluation": 4,
        "demonstrate": 1,
        "generates": 1,
        "performs": 2,
        "poorly": 1,
        "trend": 1,
        "help": 1,
        "improve": 2,
        "similarity": 4,
        "every": 3,
        "psnr": 8,
        "success": 1,
        "rate": 1,
        "fall": 1,
        "minimum": 2,
        "precision": 1,
        "high": 2,
        "alone": 1,
        "furthermore": 1,
        "table": 11,
        "results": 2,
        "synthesized": 2,
        "images": 2,
        "test": 2,
        "include": 1,
        "groundtruth": 3,
        "generate": 5,
        "synthesize": 1,
        "mul": 1,
        "tiple": 1,
        "path": 1,
        "capture": 1,
        "along": 1,
        "trajectory": 1,
        "restored": 1,
        "compare": 3,
        "compute": 1,
        "provide": 1,
        "best": 2,
        "take": 1,
        "get": 1,
        "report": 1,
        "outperform": 2,
        "compete": 1,
        "meth": 3,
        "od": 3,
        "dif": 1,
        "culties": 1,
        "theirtable": 1,
        "psnr/mssim": 2,
        "lat": 1,
        "est": 1,
        "generally": 1,
        "gopro": 1,
        "design": 4,
        "spatially": 1,
        "vary": 3,
        "instead": 1,
        "2show": 1,
        "contains": 1,
        "synthetic": 5,
        "real": 6,
        "representative": 1,
        "cover": 1,
        "manmade": 1,
        "rep": 1,
        "resent": 1,
        "actual": 1,
        "fair": 1,
        "9191h": 1,
        "visually": 1,
        "relative": 2,
        "specially": 2,
        "different": 6,
        "row": 1,
        "category": 1,
        "cumulative": 1,
        "distribution": 1,
        "error": 1,
        "ratio": 1,
        "slightly": 1,
        "cantly": 1,
        "7shows": 1,
        "qualitative": 1,
        "since": 2,
        "unknown": 3,
        "8shows": 1,
        "stable": 2,
        "pro": 1,
        "ce": 1,
        "subproblem": 1,
        "decrease": 1,
        "converge": 1,
        "showstable": 1,
        "respect": 1,
        "converges": 1,
        "stability": 4,
        "play": 1,
        "crucial": 1,
        "role": 1,
        "\u0002255": 1,
        "choose": 1,
        "quite": 1,
        "sensitive": 1,
        "within": 2,
        "suitable": 1,
        "complexity": 3,
        "execute": 1,
        "frame": 1,
        "layer": 2,
        "determined": 1,
        "maxand": 1,
        "l0based": 1,
        "sub": 1,
        "plexities": 2,
        "9193h": 1,
        "run": 3,
        "independent": 1,
        "mula": 1,
        "fft": 1,
        "operation": 1,
        "nlog": 1,
        "2n": 1,
        "machine": 1,
        "intel": 1,
        "core": 1,
        "i5\u00004430": 1,
        "processor": 1,
        "gb": 1,
        "ram": 1,
        "implement": 2,
        "matlab": 1,
        "6shows": 1,
        "namely": 1,
        "\u0016and": 1,
        "subsection": 1,
        "eval": 1,
        "uations": 1,
        "xes": 1,
        "metric": 1,
        "9shows": 1,
        "insensitive": 1,
        "setting": 1,
        "conclusion": 1,
        "motivated": 1,
        "moreover": 1,
        "bin": 1,
        "l0gradient": 1,
        "half": 1,
        "quadratic": 1,
        "ably": 1,
        "try": 1,
        "extend": 1,
        "outlier": 1,
        "anotherfuture": 1,
        "ef": 1,
        "ciency": 1,
        "realtime": 1,
        "embedded": 1,
        "platform": 1
    },
    "objective": [
        "in this paper , a local two-tone prior be propose for image with complex color cluster , which decompose the image with complex color cluster into patch with simple color cluster .",
        "experimental result on the widely use datasets show that the propose method perform favorably against the state-of-the-art algorithm , both qualitatively and quantitatively .",
        "as show in figure 1 ( b ) , the propose method base on the local two-tone prior can observably preserve salient edge and subdue weak gradient in the intermediate latent image .",
        "in section iii , the local two-tone prior and the color cluster dynamic contrast be introduce to the bid scheme and the half-quadratic splitting method be propose for solve the result .",
        "to address this problem , various natural image prior have be propose in deblurring method to remove harmful structure , gradu- ally enhance resolution and approximate the latent image in 9186 volume 8 , 2020h .",
        "d. learning-based methods with the extensive application of deep learning in the eld of computer vision , learning-based method have also be propose for image deblurring .",
        "the effectiveness of the local two-tone prior and the contrast enhancement constraint without use the local two-tone prior , the propose method degenerate into the deblurring scheme with only the l0prior .",
        "the propose algorithm perform well against state-of-the-art method .",
        "the propose method generate visually competitive result relative to those of the most advanced method [ 13 ] , [ 14 ] , [ 31 ] , [ 32 ] , although ( e ) be specially design for text image .",
        "d. convergence of our method the propose algorithm be an alternate minimization pro- ce .",
        "with more iteration , the kernel similarity of the estimate kernel and the original kernel become high which mean that the propose optimization method converges well .",
        "thus , the propose method be not sensitive to the patch size within a suitable range .",
        "the experimental result show that the propose algorithm perform favor- ably against the state-of-the-art method for the single image deblurring of various scenario ."
    ],
    "references": [
        "",
        "REFERENCES [1] Y. Chen, J. Wang, R. Xia, Q. Zhang, Z. Cao, and K. Yang, ``The visual object tracking algorithm research based on adaptive combination ker- nel,'' J. Ambient Intell. Hum. Comput., vol. 10, no. 12, pp. 4855\u00154867, Dec. 2019. [2] J. Zhang, Y. Wu, W. Feng, and J. Wang, ``Spatially attentive visual track- ing using multi-model adaptive response fusion,'' IEEE Access, vol. 7, pp. 83873\u001583887, 2019. [3] J. Zhang, X. Jin, J. Sun, J. Wang, and A. K. Sangaiah, ``Spatial and semantic convolutional features for robust visual object tracking,'' Multimedia Tools Appl., Aug. 2018, doi: 10.1007/s11042-018-6562-8. [4] J. Zhang, W. Wang, C. Lu, J. Wang, and A. K. Sangaiah, ``Lightweight deep network for traf\u001cc sign classi\u001ccation,'' Ann. Telecommun., Jul. 2019, doi:10.1007/s12243-019-00731-9. [5] J. Zhang, C. Lu, X. Li, H.-J. Kim, and J. Wang, ``A full convolutional network based on DenseNet for remote sensing scene classi\u001ccation,'' Math. Biosci. Eng., vol. 16, no. 5, pp. 3345\u00153367, 2019. [6] Y. Chen, W. Xu, J. Zuo, and K. Yang, ``The \u001cre recognition algorithm using dynamic feature fusion and IV-SVM classi\u001cer,'' Cluster Comput, vol. 22, no. S3, pp. 7665\u00157675, May 2019. [7] W.-S. Lai, J.-B. Huang, Z. Hu, N. Ahuja, and M.-H. Yang, ``A comparative study for single image blind deblurring,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 1701\u00151709. [8] J. Pan, D. Sun, H. P\u001cster, and M.-H. Yang, ``Blind image deblurring using dark channel prior,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 1628\u00151636. [9] X. Jiang, H. Yao, and S. Zhao, ``Text image deblurring via two-tone prior,'' Neurocomputing, vol. 242, pp. 1\u001514, Jun. 2017. [10] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman, ``Understanding and evaluating blind deconvolution algorithms,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2009, pp. 1964\u00151971. [11] R. Köhler, M. Hirsch, B. Mohler, B. Schölkopf, and S. Harmeling, ``Recording and playback of camera shake: Benchmarking blind decon- volution with a real-world database,'' in Computer Vision , A. Fitzgibbon, S. Lazebnik, P. Perona, Y. Sato, and C. Schmid, Eds. Berlin, Heidelberg: Springer, 2012, pp. 27\u001540. [12] S. Cho and S. Lee, ``Fast motion deblurring,'' TOGACM Trans. Graph., vol. 28, no. 5, p. 1, Dec. 2009. [13] L. Xu and J. Jia, ``Two-phase kernel estimation for robust motion deblur- ring,'' in Proc. Eur. Conf. Comput. Vis., Heraklion, Greece, Sep. 2010, pp. 157\u0015170. [14] L. Sun, S. Cho, J. Wang, and J. Hays, ``Edge-based blur kernel estima- tion using patch priors,'' in Proc. IEEE Int. Conf. Comput. Photography (ICCP), Apr. 2013, pp. 1\u00158. [15] R. Fergus, B. Singh, A. Hertzmann, S. T. Roweis, and W. T. Freeman, ``Removing camera shake from a single photograph,'' TOGACM Trans. Graph., vol. 25, no. 3, p. 787, Jul. 2006. [16] L. Xu, S. Zheng, and J. Jia, ``Unnatural `0sparse representation for natural image deblurring,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2013, pp. 1107\u00151114. [17] T. Michaeli and M. Irani, ``Blind deblurring using internal patch recur- rence,'' in Proc. Eur. Conf. Comput. Vis., 2014, pp. 783\u0015798. [18] J. Sun, W. Cao, Z. Xu, and J. Ponce, ``Learning a convolutional neural network for non-uniform motion blur removal,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015, pp. 769\u0015777. [19] S. Nah, T. H. Kim, and K. M. Lee, ``Deep multi-scale convolutional neural network for dynamic scene deblurring,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 3883\u00153891. [20] X. Tao, H. Gao, X. Shen, J. Wang, and J. Jia, ``Scale-recurrent network for deep image deblurring,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 8174\u00158182. [21] O. Kupyn, V. Budzan, M. Mykhailych, D. Mishkin, and J. Matas, ``Deblur- GAN: Blind motion deblurring using conditional adversarial networks,'' inProc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , Jun. 2018, pp. 8183\u00158192. [22] C. Cai, H. Meng, and Q. Zhu, ``Blind deconvolution for image deblurring based on edge enhancement and noise suppression,'' IEEE Access, vol. 6, pp. 58710\u001558718, 2018. [23] D. Krishnan, T. Tay, and R. Fergus, ``Blind deconvolution using a normal- ized sparsity measure,'' in Proc. CVPR, Jun. 2011, pp. 233\u0015240. 9194 VOLUME 8, 2020H. Zhang et al.: BID: An Effective Blind Image Deblurring Scheme to Estimate the Blur Kernel for Various Scenarios [24] G. Sun, J. Leng, and T. Huang, ``An ef\u001ccient sparse optimization algo- rithm for weighted `0shearlet-based method for image deblurring,'' IEEE Access, vol. 5, pp. 3085\u00153094, 2017. [25] Z. Dou, K. Gao, X. Zhang, and H. Wang, ``Fast blind image deblur- ring using smoothing-enhancing regularizer,'' IEEE Access , vol. 7, pp. 90904\u001590915, 2019. [26] Y. Chen, J. Wang, X. Chen, M. Zhu, K. Yang, Z. Wang, and R. Xia, ``Single- image super-resolution algorithm based on structural self-similarity and deformation block features,'' IEEE Access, vol. 7, pp. 58791\u001558801, 2019. [27] Q. Shan, J. Jia, and A. Agarwala, ``High-quality motion deblurring from a single image,'' TOGACM Trans. Graph., vol. 27, no. 3, p. 1, Aug. 2008. [28] W. Zuo, D. Ren, D. Zhang, S. Gu, and L. Zhang, ``Learning iteration-wise generalized shrinkage\u0015thresholding operators for blind deconvolution,'' IEEE Trans. Image Process., vol. 25, no. 4, pp. 1751\u00151764, Feb. 2016. [29] O. Whyte, J. Sivic, and A. Zisserman, ``Deblurring shaken and partially saturated images,'' in Proc. IEEE Int. Conf. Comput. Vis. Workshops (ICCV), Nov. 2011, pp. 745\u0015752. [30] L. Pan, R. Hartley, M. Liu, and Y. Dai, ``Phase-only image based kernel estimation for single image blind deblurring,'' in Proc. IEEE Conf. Com- put. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 6034\u00156043. [31] D. Perrone and P. Favaro, ``Total variation blind deconvolution: The devil is in the details,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 2909\u00152916. [32] J. Pan, Z. Hu, Z. Su, and M.-H. Yang, ``Deblurring text images via `0- Regularized Intensity and Gradient Prior,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 2901\u00152908. [33] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman, ``Ef\u001ccient marginal likelihood optimization in blind deconvolution,'' in Proc. CVPR, Jun. 2011, pp. 2657\u00152664. [34] H. Zhang, D. Wipf, and Y. Zhang, ``Multi-image blind deblurring using a coupled adaptive sparse prior,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2013, pp. 1051\u00151058. [35] L. Zhong, S. Cho, D. Metaxas, S. Paris, and J. Wang, ``Handling noise in single image deblurring using directional \u001clters,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2013, pp. 612\u0015619. [36] D. Krishnan and R. Fergus, ``Fast image deconvolution using hyper- laplacian priors,'' in Proc. Int. Conf. Neural Inf. Process. Syst., 2009, pp. 1033\u00151041. HONG ZHANG received the B.S. degree from the Hebei University of Technology, China, in 1988, the M.S. degree from the Harbin University of Science and Technology, China, in 1993, and the Ph.D. degree from the Beijing Institute of Technol- ogy, China, in 2002, all in electrical engineering. She was a Visiting Scholar with the Department of Neurosurgery, University of Pittsburgh, from 2007 to 2008. She is currently a Professor with the School of Astronautics, Beihang University, Beijing, China. Her research interests include activity recognition, image restoration, image indexing, object detection, and stereovision. YAWEI LI received the B.S. degree from Xidian University, Xi'an, China, in 2013. He is currently pursuing the Ph.D. degree with the Image Processing Center, Beihang University, Beijing, China. His research interests include computer vision and machine learning and in particular on image restoration and image deblurring. YUJIE WU received the B.S. degree from Beihang University, Beijing, China, in 2014, where he is currently pursuing the Ph.D. degree with the Image Processing Center. His research interests include image deblurring, object detection, and computer vision. ZEYU ZHANG received the B.S. degree from Southeast University, China, in 2013, and the M.S. degree in electrical and electronic engineer- ing from Northwestern University, USA, in 2015. He is currently pursuing the Ph.D. degree with the Image Processing Center, Beihang University, Bei- jing, China. His research interests include pattern recognition, object detection, and object tracking. VOLUME 8, 2020 9195"
    ]
}{
    "name": "Blind Color Decomposition of Histological Images",
    "paragraphs": [
        "ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 983 blind color decomposition of histological images milan gavrilovic * , member , ieee , jimmy c. azar , joakim lindblad , carolina wählby , ewert bengtsson , senior member , ieee , christer busch , and ingrid b. carlbom , member , ieee abstract— cancer diagnosis be base on visual examinatio n under a microscope of tissue section from biopsy .",
        "but whereaspathologists rely on tissue stain to identify morphological fea-tures , automate tissue recognition use color be fra ught with problem that stem from image inte nsity variation due to varia- tions in tissue preparation , variation in spectral signature of thestained tissue , spectral overlap and spatial aliasing in acquisition , and noise at image acquisition .",
        "we present a blind method forcolor decomposition of histological image .",
        "the method decouplesintensity from color information and base the decomposition only on the tissue absorption characteristic of each stain .",
        "by modelingthe charge-coupled device sensor noise , we improve the methodaccuracy .",
        "we extend current linear decom position method to include stained tissue where one spectral signature can not beseparated from all combination of the other tissue ’ spectralsignatures .",
        "we demonstrate both q ualitatively and quantitatively that our method result in more accurate decomposition thanmethods base on non-negative mat rix factorization and indepen- dent component analysis .",
        "the re sult be one density map for each stained tissue type that classi ﬁes portion of pixel into the correct stain tissue allowi ng accurate identi ﬁcation of morphological feature that may be link to cancer .",
        "index terms— blind source separation , gastrointestinal tract , image restoration , microscopy , prostate , quanti ﬁcation .",
        "i .",
        "introduction detection , diagnosis , and s everity-grading of cancer be base on visual examination under a microscope of histopathological section from tissue biopsy .",
        "this practice isprone to subjectivity , result in signi ﬁcant variation between experienced pathologist .",
        "studies show that inter- and intra-ob-server variation for prostat e cancer grading can be as high as 30 % –40 % [ 1 ] .",
        "but quantitative tissue analysis base on auto- manuscript receive september 24 , 2012 ; revise december 25 , 2012 ; ac- cepted january 01 , 2013 .",
        "date of publication january 11 , 2013 ; date of currentversion may 29 , 2013 .",
        "this work be support in part by the swedish researchcouncil under grant 2009-5418 .",
        "asterisk indicate correspond author .",
        "* m. gavrilovic be with the centre for image analysis of uppsala uni- versity and swedish university of agri cultural sciences , s-75105 uppsala , sweden .",
        "he be now with hotswap engineering consultants , s-17263 stock-holm , sweden ( e-mail : gavrilovic @ ieee.org ) .",
        "j .c .a z a r , e .b e n g t s s o n , a n di .b .c a r l b o ma r ew i t ht h ec e n t r ef o ri m a g e analysis , uppsala university and swedish university of agricultural sciences , s-75105 uppsala , sweden .",
        "j. lindblad be with the centre for image analysis , uppsala university and swedish university of agricultural scie nces , s-75105 uppsala , sweden .",
        "he be now with the faculty of technical sciences , university of novi sad , 21000novi sad , serbia .",
        "c. wählby be with the centre for image analysis , uppsala university and swedish university of agricultural s ciences , s-75105 uppsala , sweden and also with the broad institute of harvard and mit , cambridge , ma 02142 usa .",
        "c. busch be with the department of immunology , genetics and pathology , uppsala university , s-75185 uppsala , sweden .",
        "digital object identi ﬁer 10.1109/tmi.2013.2239655mated image analysis have the potential to reduce or elimin ate subjectivity in cancer diagno si , yield a more objec tive basis for a course of treatment .",
        "quantitative tissue analysi sa l s oh a s a large potential role in re earch , allow for rapid throughput of large amount of histopathological data , as be req u i r e db yf o r example the human protein atlas project [ 2 ] .",
        "pathologists rely on multiple , contrast st ains for tissue analysis .",
        "for example hematoxylin , which sta in cell nuclei blue , be usually combine with the counter-s tain eosin that stain cytoplasm in pink and stromal compon ents in various grade of red/pink , provide local color- contrast .",
        "but whereas pathologist can effectively use col or in combination with tex- ture and morphologi cal feature for visual analysis , automate tissue recognition base on color be fraught with problem .",
        "first , there can be large inter- and intra-specimen variation in stained tissue color due to tissue preparation fact or , include variation in stain concentrati on , stain duration , tissue thick- ness , and in ﬁxation .",
        "tabesh et al .",
        "[ 3 ] argue that color do not contain much informatio n regard the severity grade ( in prostate cancer ) since int ra-grade color variation be often great than inter-grade c olor variation .",
        "in order to use color for severity grading , it i s essential that tissue classi ﬁcation be base solely on the ti sue absorption characteristic for a speci ﬁc stain without t he in ﬂuence of variation that be introduce during sp ecimen preparation [ 4 ] .",
        "a second set of problem s be the result of aliasing in the image acquisition process , both in the spectral and spatial domain .",
        "different stain may have overlap absorption spectrum , re- quiring a decomposi tion method that classi ﬁes portion of pixel into the correct ti ssue class .",
        "instead of classify a pixel that contain two or mor e stain tissue type into only one type ( binary classi ﬁcation ) , soft classi ﬁcation separate the relative contribution of the stained tissue to each pixel yield a more accurate class iﬁcation .",
        "similarly , aliasing due to limited spatial resolution or tissue thickness may result in multiple tissue com- ponents , e.g .",
        ", cell nucleus and cytoplasm , to be collocate within as i n g l ep i x e l. again , for a more accurate classi ﬁcation , we need to separat e the relative contribution of each stain tissue type within pix el .",
        "at h i r dp r o blem be the result of noise at image acquisition .",
        "standard t hree-channel charge-coupled device ( ccd ) sensor h a v eal i n ear response to the number of incident photon and the domin ant noise be poisson-distri buted photon noise [ 5 ] , [ 6 ] .",
        "introdu ction of noise modeling into the decomposition increase the acc uracy of the result .",
        "another type of noise be due to vari- ations in the spectral signature of the stained tissue , i.e.",
        ", color sampl e of the same tissue type stain with the same stain and with t he same optical density can exhi bit different spectral prop- erties .",
        "in ﬂuorescence microscopy this be sometimes refer to as biochemical noise [ 7 ] .",
        "0278-0062/ $ 31.00 © 2013 ieee984 ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 color decomposition be a technique develop in ﬂuores- cence microscopy base on idea from remote sense .",
        "keshavaand mustard [ 8 ] describe spectral unmixing as a procedurerequiring determination of ref erence spectrum , or color , and decomposition , i.e.",
        ", the extraction of a set of gray-level imagesshowing individual contributi ons of the pixel to each spectral band .",
        "whereas multispectral solution offer the advantage that ﬁl- ters may be match to several stained tissue type [ 9 ] , multi-spectral imaging be more costly and more time consume thanthree channel [ red–green–blue ( rgb ) ] imaging , which be thestandard in bright- ﬁeld microscopy .",
        "reference [ 10 ] show that multi-spectral imaging do not give a statistically signi ﬁcant increase in performance in hist opathological image analysis .",
        "therefore , we focus on rgb imag e , but the extension to mul- tiple spectrum be straightforward .",
        "in this paper , we develop a new method , refer to as the blind color decomposition ( bcd ) method , for stain tissueseparation in transmission light microscopy base on the ideathat intensity should be decouple from color information .",
        "un-like many exist solution our me thod be blind , also sometimes refer to as unsupervised , i.e.",
        ", it do not require input by theuser in the form of train set or special specimen to extractinformation prior to process .",
        "we use statistical technique fornoise modeling of the ccd array and also devise a measure forbiochemical noise .",
        "we assume that stain be light absorb , as be generally the case , and model the relationship between thestain and its absorption use the beer–lambert law [ 11 ] , [ 12 ] .we map the color information in the image to the maxwelliancolor space and use pattern analysis technique to estimate thestained tissue color , also know as the reference color .",
        "existing color decomposition technique depend on the in- version of a color mixing matrix which require that the refer-ence color be linearly indepe ndent in color space [ 13 ] .",
        "more- over cluster around the reference color ( chromaticity cluster ) need to be fully separable , that i s both pair-wise separable and one-against-all separable , for the inversion of the color mix matrix to give a good result [ 14 ] .",
        "however , when chromaticityclusters be pair-wise separable , but one of the cluster be notseparable from all the others , we call the cluster partially sep-arable ( which be the case for trichrome stain such as gomoritrichrome [ 15 ] , a stain that be use to separate smooth muscleand collagen ) .",
        "we extend current linear decomposition methodsto include color cluster that be partially separable by divide the inversion into a set of linear problem , and then invertingone color mix matrix at a time .",
        "we refer to this as piece-wiselinear decomposition .",
        "the bcd method , as all linear decomposition method , require that the data be linearize use the beer–lambertlaw of absorption , which apply only to light-absorbing stains.if a specimen contain stain that do not absorb light but ratherscatter light [ 4 ] , [ 12 ] , as be the case for diaminobenzidine ( dab ) , we suggest removal of the dab-stained area from theimage prior to color decomposition .",
        "the presentation of our color decomposition proceeds as fol- low .",
        "first we derive the theoretical underpinnings of a linearmixture model .",
        "this be follow by an algorithm to remove in-tensity variation by map the image data to the maxwellianchromaticity plane .",
        "after the intensity variation be remove , we identify the reference color and use these to formulate the decomposition rule .",
        "section i v discus method that can im- prove blind decomposition by estimate noise in the image dataand how to use this noise in a practical solution to the patternclassi ﬁcation problem which identi ﬁes the reference color in the maxwellian plane .",
        "in section v , we show quantitative com-parisons of our method with method in the literature use largedata set of hematoxylin-and-eosin-stained ( h & e ) bladder neckand stomach tissue [ 16 ] , and prostate tissue stain with hema-toxylin-and-herovici ( h & h ) [ 17 ] , and with giemsa-and-eosin ( g & e ) [ 18 ] .",
        "aﬁrst quantitative comparison use the relative root-mean- square error ( rrmse ) of the mi xing matrix produce by in- dependent component analysis ( ica ) , non-negative matrix fac-torization ( nmf ) , bcd , and a ground truth mix matrix asdeﬁned by an experienced pathologist reveals that our method outperforms nmf by between 20 % and 40 % and ica at greatermargins .",
        "a second quantitative comparison of the same method use the pearson correlation coef ﬁcient demonstrate that our density map give on average a 91 % median correlation withground truth for the weak stain eosin in h & e , compare toother publish method that give up to an 81 % median cor-relation for eosin .",
        "for the less common stain , h & h and g & e , our density map give a 98 % median correlation with the groundtruth for the weak stain , comp ared to other publish method that give less than a 90 % median correlation .",
        "in the case whenthe chromaticity cluster be on ly partially separable , our piece- wise linear decomposition give density map with a mediancorrelation of 95 % , compare to 40 % for linear decomposition.qualitative comparison support the quantitative result , clearlyillustrating that our density map yield result superior to those of publish method .",
        "we end with a few observation on stainquality and limitation of the bcd method .",
        "ii .",
        "b ackground and related work color decomposition method in the literature differ in term of the imaging sensor type employ , whether they model tissuelight absorption or determine the reference color in color space , by the method of parameter estimation , and whether the resultis a binary map indicate whether a stain be present in a pixelor not , a density map give the proportion of a stained tissuein each pixel , or a probability map where each pixel indicatesthe probability of the presence of one stained tissue type versusother tissue type .",
        "some reference color determination methodsmay require user input , whereas others be completely auto-mated .",
        "finally , only some method handle partially separablereference color cluster .",
        "reference color determination in histological application often rely on cluster tech niques implement directly in color space , without any consider ation for stain–tissue interac- tions or sensor property .",
        "su ch method [ 19 ] , [ 20 ] result only in binary classi ﬁcation and do not give a quantitative density classi ﬁcation lead to “ loss of information ” [ 21 ] .",
        "color deconvolution [ 21 ] be a decomposition method for transmission bright- ﬁeld microscopy similar to castleman ’ s color compensation use in ﬂuorescence microscopy [ 22 ] .",
        "ingavrilovic et al .",
        ": blind color decomposition of histological images 985 table i overview of reference color determination methods color deconvolution the relativ e absorption of the three chan- nels be measure on slide with a single stain .",
        "this be followedby a transformation of the data by the beer–lambert law andthe computation of normali zed average rgb value for each select tissue .",
        "these normalized color vector be then use tobuild a mixing matrix for the decomposition of the color imageinto density image , one for each stained tissue type .",
        "blind method , borrow fro m remote sense for deter- mining reference spectrum or tissue color , be base on nmf , ica , or principal component analysis ( pca ) , with the ﬁrst two result in density map and the last in a probability map .",
        "ref-erence [ 23 ] us ica and nmf to analyze multispectral data.reference [ 24 ] show excellent result for sparse hyperspectraldata use pca for dimensionality reduction follow by therelative newton method , a blin d source separation algorithm .",
        "this method rely on the number of wavelength to exceed byat least two the number of stain present in the slide , and henceit be not applicable to three-channel data in histopathology .",
        "onlynmf [ 25 ] and pca [ 26 ] have be test use three-colorimage data .",
        "following decomposition , soft pixel classi ﬁcation be often implement as a matrix multiplication by the pseudo inverseof the mixing matrix [ 8 ] , [ 21 ] , [ 25 ] , [ 27 ] ( note that the last ref-erence deal with ﬂuorescence microscopy ) .",
        "this require all reference spectra or color of the identi ﬁed tissue type to be linearly independent , but it gi f good decomposition result only when the stain tissue be fully separable .",
        "spectral angle mapping , often use in ﬂuoresce microscopy [ 4 ] , [ 28 ] , [ 29 ] , offer a stable solution even when the clustersaround the reference color be onl y partially separable and it al- low for a great number of tissu e type than color channel .",
        "however , the output image of spectral angle mapping be bi-nary , that be the mapping do not use linear decomposition butrather near neighbor pixel classi ﬁcation by spectral angle .",
        "the major feature of the ref erenced work be summarize in table i .",
        "in summary the bcd method 1 ) be blind , that be it do not require that the user manually identify individual stain tissuetypes , 2 ) it model absorption use the beer–lambert law , and3 ) it result in density map , one for each stained tissue type , for both fully and partially separab le chromaticity cluster .",
        "these quantitative density map can be far process use well-known , grey-level image analy si technique for extract fea- tures , such as texture and shape [ 30 ] – [ 32 ] .",
        "iii .",
        "m ethods for color decomposition a .",
        "notation the color sample in , the input color image of a histological specimen , and , w h e r e , a n d , denote the red–green–blue sample value at each spatial coordinate ( pixel ) .",
        "the reference color unit vector ( in space ) for each of the stained tissue type .",
        "the contribution of the stained tissue type add to one .",
        "the estimated relative proportion of the stainedtissue for in the imaged histological specimen , .",
        "each density map indicate how much of the stained tissue be present in pixel .",
        "what follow be similar to the derivation of the optical density in [ 24 ] , but for sensor with wide wavelength bandwidth , such asin three-channel rgb camera .",
        "n ote that we apply logarithmic and exponential function to a vector element-wise .",
        "b .",
        "image formation and linearization by the beer–lambert law we denote the intensity of the light source in a microscope that illuminate a histological specimen by the continuous func- tion , w h e r e be the wavelength .",
        "the transfer function of the microscope be denote by , where , be the transfer function of the indi- vidual red–green–blue color channel , respectively .",
        "the spec-tral distribution of the measured light intensity be represent by the spectral signature over wavelength range from to [ 33 ] .",
        "the color sample at each pixel , , can be de ﬁned by the spectral signature and the transfer func- tions as ( 1 ) the color distribution for an image ( fig .",
        "1 ) be often visualize as a 3-d scatter plot ( fig .",
        "2 ) .",
        "this image be a stomach tissue sec-tion stain with gomori trichrome that be use for illustrationpurposes in this section ; in late section we demonstrate ourmethod on several stain and tissue type include the gomoritrichrome-stained stomach tissue .",
        "most stain light absorption follow the beer–lambert law that describe the relationship between stain concentration and its absorption [ 11 ] .",
        "from the beer–lambert law it follow that986 ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 fig .",
        "1 .",
        "an example of an input color image with stained tissue types—a stomach section stain with gomori trichrome .",
        "erythrocytes appear as red , cell nucleus of ﬁbroblasts and lymphocytes as purple , smooth muscle as grayish- purple , and collagen as turquoise .",
        "fig .",
        "2 .",
        "scatter-plots show the 3-d distribution in the red–green–blue colorcube .",
        "this ﬁgure show the scatter-plot of the input image in fig .",
        "1. the spectral signature for a specimen contain light-ab- sorbing stain tissue type be ( 2 ) where be the absorption spectrum for the stained tissue , and be the total amount of stained tissue in pixel .f r o m ( 1 ) and ( 2 ) , we derive the intensity acquire in the individualcolor channel of ( 3 ) fig .",
        "3 .",
        "three-dimensional scatter plot of the beer–lambert-transformed input image ( show in fig .",
        "1 ) .",
        "three reference color vector , a n d be highlight .",
        "which can be rewrite as ( 4 ) fig .",
        "2 show that the color for each stained tissue , , be cluster along an arc that start at one end of the achromatic axis whereno light be absorb , i.e.",
        ", , which correspond to the color of the illumination source ( 5 ) and bend to the other end of the achromatic axis where the light source be fully attenuate , i.e.",
        ", , which correspond to .a c c o r d i n gt ot h e ﬁrst mean value theorem , there exist wavelength for each channel , such that , transform ( 4 ) into ( 6 ) w h i c hb yu s i n g ( 5 ) b e c o m e s ( 7 ) applying the logarithm to each si de yield the optical density ( 8 ) for each stained tissue type , th e vector on the left hand side of ( 8 ) b e l o n gt oc o n e - l i k ev o l u m e s center about the vector that deﬁne the reference color in the s catter plot transform by the beer–lambert law as see in fig .",
        "3.gavrilovic et al .",
        ": blind color decomposition of histological images 987 fig .",
        "4 .",
        "the initial transformation of input rgb data i sb a s e do nt h e beer–lambert law , follow by a perspective projection to the maxwellianchromaticity plane .",
        "the three vertex be associate with the pure color , a n d , which we refer to as beer–lambert red , green , and blue , res pectively .",
        "( these color correspond to cyan , magenta , and yellow in the or iginal red–green–blue space . )",
        "the coordinate , a n d in the plane determine the three reference color .",
        "in the next section , we transform the input image data to a pure color representation in the so called maxwellian chro-maticity plane , which allow pattern analysis technique to iden-tify the reference color from th e information contain in the image .",
        "c. maxwellian chromaticity plane the maxwell chromaticity plane or the maxwell color tri- angle have the property that the distance between two point inthe plane represent the chromaticity difference between thecorresponding color .",
        "furthermore , pure rgb color ( in ourcase , a n d project onto vertex of an equilateral t riangle , and point on the achro- matic axis ( from to project to the triangle ’ s circum- center , at an equal distance from the three pure color [ 34 ] , [ 35 ] .",
        "the transformation from rgb-s pace to the max wellian chro- maticity space can be express as a perspective transformation [ 36 ] with the center of projection at the origin and the projec- tion plane at the distance of from the origin , yield the following transformation : ( 9 ) where and be coordinate in the maxwellian plane .",
        "d. reference color determination the project color data for m cluster in the maxwellian chromaticity plane , with each cluster correspond to onestained tissue type .",
        "without knowledge about the exact datadistribution , we assume that the cluster follow a gaussiandistribution with mean ( [ 37 ] .",
        "the variance of the gaussians be measure of the biochemical noise of the corre-sponding stain tissue type .",
        "in fig .",
        "4 we show the projectedcolor data as a histogram over t he maxwellian color triangle , where the height indicate the number of color sample in thebeer–lambert space at each coordinate in the maxwellianplane ; in fig .",
        "5 we show the refer ence color in the maxwellian chromaticity plane for the image data in fig .",
        "1 .",
        "fig .",
        "5 .",
        "position of the three reference color in the maxwellian chro- maticity plane .",
        "s i n c ew eh a v en o ap r i o r i knowledge about the shape and size of the cluster , we must rule out simple method , such ask-means and mean-shi ft for cluster identi ﬁcation .",
        "we rely on the gaussian assumption and empl oy expectation maximization toﬁnd the cluster in the maxwellian chromaticity plane .",
        "from the mean of these gaussian distri butions , we calculate the ref- erence color vector use the inv erse of ( 9 ) , note that the ref- erence color vector be unit vector in space ( 10 ) we use the result reference color vector , , to decom- pose the original image into its density map , as describe in the following section .",
        "e. linear decomposition we use the reference color vector to blindly estimate the absorption spectrum in ( 8 ) , up to a constant .",
        "thus , we refor- mulate ( 8 ) in vector form as ( 11 ) where each be a unit reference color vector , and contain the estimated relative proportion of the stained tissue .",
        "weﬁnd the relative density by solve ( 11 ) as a least-squares problem , the method know as linear decomposi-tion .",
        "we multiply the optical density with the pseudo-inverseof the mixing matrix yield the density map ( 12 ) when one of the resulting element of be less than zero , the element be set to zero .",
        "this method of inversion assumes that thechromaticity cluster be fully separable .",
        "when the chromaticity cluster be partially separable , that be when only one of the cluster ( e.g.",
        ", index ) have a poor one-988 ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 against-all cluster separation , i.e.",
        ", poor separation with clus- ters and , we use piece-wise linear decomposition .",
        "in this case we apply pseudo-inverse transformation of mix sub-matrices , comprise reference color vector and , a n d and , respectively .",
        "the two subm atrices be multiply with the optical density data and the result be combine to form thedensity map .",
        "the density map be de ﬁned by ( 13 ) the minimum in the third equation in ( 13 ) be motivate by the fact that choose t he decomposition ( stain pair ) which be best align with the observed color corresponds to select thedecomposition where or have maximal density , i.e.",
        ", be minimal .",
        "both the linear deco mposition and the piece-wise linear decomposition result i n quantitative density map .",
        "iv .",
        "i mplementation a. overview in contrast to supervise method where an expert , e.g.",
        ", a pathologist , provide a training set of reference color [ 10 ] or sample region [ 21 ] , our appr oach automatically estimate the linear model parameter in ( 11 ) from the image data .",
        "ourmethod require only the following minimal prior knowledgeabout the tissue specimen , 1 ) the number of light absorbingstained tissue type , , and 2 ) a stored blank image from the microscope for measure photon noise .",
        "should the blankimage not be available for the microscope , it can be estimatedfrom the image .",
        "fig .",
        "6 show the process pipeline from acquisition to the result density map .",
        "for the bladder neck and stomach datawe use an olympus bright- ﬁeld microscope for image acqui- sition ; the microscope be accompany by a ccd camera and , a n d objective , with standard red–green–blue optical ﬁlters .",
        "for the prostate data set we use an aperio scanscope , model xt , with an olympus planapochromatic objective .",
        "the ﬁrst step remove area affect by light scatter stain .",
        "next , we measure the photon noise parameter for mod-eling uncertainty in measured intensity value .",
        "this be followedby a transformation of the image data use the beer–lambertlaw of absorption , and a projection of the result data tothe maxwellian chromaticity plane , where we ﬁnd cluster .",
        "thereafter , base on the mean of these gaussian-like cluster , ( , w h e r e , we generate reference color vector that make up the column of the mixing matrix , andapply linear decomposition to produce density map .",
        "all linear decomposition method require that the data be linearize use the beer–lambert law of absorption , whichassumes that stain tissue absorb photon from the lightsource .",
        "however polymer , such as dab , be commonly use fig .",
        "6 .",
        "flowchart of the bcd method .",
        "in histopathology but they do not obey the beer–lambert lawas they scatter rather than absorb light [ 4 ] , [ 12 ] .",
        "we suggestremoval of the dab-stained area from the image prior to colordecomposition with standard image analysis technique , sogavrilovic et al .",
        ": blind color decomposition of histological images 989 that the color decomposition will be base solely on the light absorbing stain .",
        "b .",
        "the noise model standard three-channel ccd sensor have a linear response to the number of incident photon , and the dominant noise ispoisson-distributed photon noise [ 5 ] , [ 6 ] .",
        "in the maxwellianplane the area with high optical density create distinct peak with a high signal-to-noise ratio .",
        "the low optical densityareas , on the other hand , tend to create spurious peak , andthe signal-to-noise level be low .",
        "as a result the photon noisehas signi ﬁcant effect on these area around “ white.",
        "” accurate estimation of the noise parameter of the sensor can be usedto smooth the data and to aid in the extraction of the distinctpeaks correspond to the reference color .",
        "the imaging device , that be the light source and the ccd array , be calibrate by acquire ab l a n ki m a g ea n dad a r kf r a m e .",
        "first , we use the blank image to automatically set the ampli ﬁer gain so that the image be perceive as “ white.",
        "” second , we usethese image to estimate the photon noise for any input colorsample .",
        "for each color channel in the blank image , we derive the mean value of the intensity over the image , , a n d their standard deviation , , from the intensity histogram for each channel .",
        "for the dark frame , the mean value of the mea-surements be set to be less than one quantization level , that be [ 13 ] .",
        "however , due to the ampli ﬁer gain , the standard deviation , , be generally not zero and can be estimate from the dark frame , also from the intensity histogram .",
        "the standard deviation , , over all intensity level be d e r i v e db y [ 5 ] ( 14 ) should the blank image and the dark frame not be available , we estimate from the intensity histogram of a white area in t h ei m a g e , a n d e t to the root mean square of the quantiza- tion noise .",
        "we make this assumption as precise noise measure-ments in very dark region be not important due to the highsignal-to-noise level .",
        "as show in [ 38 ] the root mean square ofthe quantization noise become .",
        "in the next section , we show how to use the estimated noise parameter to smooth the image data .",
        "c. parameter estimation we use the noise model to aid in the parameter estimation .",
        "for each color sample present in the original image , we gen- erate a cloud of point , center around in 3-d color space .",
        "since only for high intensity value the noise have a signi ﬁcant effect on the transformation in ( 9 ) , we approximate the 3-d poisson distribution by a gaussian dis-tribution , with standard deviation as derive in the previous section .",
        "all cloud point be then transform via the beer–lambert law , result in an increase in the numberof point by a factor of .when select the reference color , we give more weight to data with high optical density by assign each point a scoreu s i n gah e u r i s t i cs i m i l a rt ot h a tu s e di n [ 2 9 ] ( 15 ) where be a random variable drawn from a uniform distri- bution in [ 0,1 ] , and .",
        "next , in order to reduce the number of data point back to the number of the originalmeasurements , we retain of the point with high score .",
        "it be important to introduce randomization into the score whenweighting the data point as be do in ( 15 ) , otherwise the selec-tion of the point with the great optical density value would be equivalent to intensity thresholding and would omitweaker stain such as eosin fro m the analysis .",
        "the next sec- tion show that the noise model improve the solution with in-creasing , until reach between ﬁve and seven and it do not improve the solution far up to .",
        "in all our exper- iments discuss below we set .",
        "as describe earlier , we use expectation maximization to ﬁt gaussian distribution to the color data in the maxwellian plane.the mean value of these distribution allow us to estimate thereference color vector that form the mixing matrix in the lineardecomposition .",
        "the mix mat rice in ( 12 ) and ( 13 ) give the required density map .",
        "separability of chromaticity cluster , whether they be fully separable or partially separable , determine whether a linear orpiece-wise linear decomposition i s applicable .",
        "one-against-one separability can be measure with statistical technique , suchas the fisher criterion [ 14 ] .",
        "a high value of the fisher crite-rion corresponds to cluster that be well separate , and lowerfisher criterion yield bad cluste r separation .",
        "in the case of three stained tissue type , the cluster must be both one-against-oneseparable and one-against-all separable .",
        "in the case when thereis one cluster that have a poor one-ag ainst-all separation to other cluster , but the others be fully separable , piece-wise linear de-composition will give a good decomposition result than simplelinear decomposition .",
        "v. e xperimental results this section show both quantitative and qualitative compar- isons of the bcd method with exist method for three tissuetypes and four different stain .",
        "we also demonstrate the im-portance of piecewise linear deco mposition when stain tissue color be only partially separable .",
        "we begin by describe howwe acquire ground truth data .",
        "a .",
        "ground truth and validation to produce ground truth data , we do not use the multiple histological staining method us ed in , for example [ 21 ] and [ 23 ] , s i n c em o s t t a i n sm i xa n da l s ob i n dt ot h es a m et i s s u ec o m p o -nents , just in different degree ( this be not the case for dab and hematoxylin , use in [ 21 ] and [ 23 ] ) .",
        "in other word ground truth data for h & e be hematoxylin in the presence of eosin , and viceversa .",
        "we demonstrate this by stain three adjoin prostatetissue section with 1 ) hematoxylin alone , 2 ) eosin alone , and3 ) both h & e , respectively .",
        "our expert then pick in each of990 ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 table ii reference color vectors the three section 1 ) tissue that should be stain by hema- toxylin ( i.e.",
        ", cell nuclei ) , and 2 ) tissue that should be stain by eosin ( i.e.",
        ", stroma ) .",
        "in table ii we show the reference colorvectors that be the result of the decomposition of all three sec-tions , hematoxylin alone , eosin alone , and h & e .",
        "we note thatthe reference color value parti cularly for eosin alone be dif- ferent from the reference color for the h & e combination .",
        "thisdemonstrates the necessity of select the ground truth usingthe combination of the stain component , as can be do onlymanually .",
        "for our ground truth an experienced pathologist pick refer- ence color by select a number of pixel of each stain tissuetype from a series of ﬁelds of view of each tissue .",
        "please note that when the expert pick the stain , he do not use color asa guide but rather the morphological component that be knownto be primarily stain , such as cell nucleus for hematoxylin .",
        "inwhat follow we use both the median of the pixel select ineach individual ﬁe l do fv i e w ( f o vg r o u n dt r u t h ) a n da l s ot h e median of all fov value ( total ground truth ) as ground truthreference color for that particular stain tissue , which makeup the column in ground truth mix matrix .",
        "b .",
        "comparisons of mixing mat rix estimation using rrmse ourﬁrst comparison of the bcd method with other method in the literature be base on the relative rrmse of the mixingmatrices derive by ica , nmf , and bcd as compare to thetotal ground truth mix matri x .",
        "in all three case the color image data be linearize use the beer–lambert law prior to the calculation of the mixing matri x .",
        "we also compute the rrmse for the fov ground truth mix matrix as compare to thetotal ground truth mix matrix to illustrate the variation inthe ground truth over a tissue section .",
        "the rrmse be derive by ( 16 ) where be the number of ﬁelds of view ( in this experiment ) , be the estimated mixing matrix for the thﬁeld of view , and be the total ground truth mix matrix , and denote the matrix trace .",
        "table iii show the result for 21–23 ( depend on tissue type ) randomly choose ﬁelds of view and reveals that our method outperforms nmf by between 20 % and 40 % and icawith a much great margin , for bladder neck tissue stainedwith h & e , stomach tissue stain with h & e , and prostatetissue stain with , h & h , and g & e , respectively .",
        "the rowlabeled “ pathologist ” show that the rrmse for an expert isle than that for all the method ; the variation between stainscan be attribute both to variation in stain quality over thesections and to minor error by the expert.table iii rrmse ofmixing matrix estimation fig .",
        "7 .",
        "the robustness with respect to the size of the point cloud , , when the bcd method be apply to four di fferent stain tissue type .",
        "however , this comparison do not tell the whole story since an error in one reference color be partially transfer to the othercolor .",
        "therefore , we need to also compare the resulting density map , as be do in section v-e below .",
        "c. noise compensation stability tests as discuss earlier , ccd noise model can improve the result of the parameter estimation .",
        "in fig .",
        "7 we show for eachstained tissue type how the size of the point cloud that modelthe photon noise for each quanti zation level affect the rrmse value .",
        "from point , that be no noise model , the relative root-mean-square error improve with increase , u n t i l reach between ﬁve and seven , when the rrmse level off .",
        "d. qualitative comparisons of bcd and nmf fig .",
        "8 show qualitative difference between the density map from nmf ( b , c ) and the bcd ( d , e ) on one ﬁe l do fv i e wo fa prostate tissue section stain with h & h ( a ) ( this ﬁeld of view represent an average rrmse of the whole tissue section ) .",
        "thevisual result show a signi ﬁcant difference in , for example , the appearance of the nucleus ( b and d ) , as a result of the bleed- through of the hematoxylin to the nmf eosin density map ( c ) .we also notice bleed-through in th e other direction for nmf ; the stroma be not as well delineate i n ( c ) a si ti si n ( e ) , m a k i n ga segmentation of the prostate gland easier from the bcd densitymap ( e ) .",
        "e. comparisons using the pearson correlation coef ﬁcient as we mention in an early section , a comparison base solely on mix matrix do not tell the whole story , sincegavrilovic et al .",
        ": blind color decomposition of histological images 991 fig .",
        "8 .",
        "color decomposition of h & h stain ( a ) into density map use nmf ( b , c ) and bcd ( d , e ) .",
        "an error in estimation of one reference color vector be trans- ferred to the other color ( this be illustrate in the qualitativeexample above ) .",
        "therefore , in this section we compare the re-sulting density map for the identical tissue ﬁelds of view for the s a m e t a i n e dt i s s u et y p e sa su s e di ns e c t i o nv - ba b o v e .t h et w o fig .",
        "9 .",
        "box plot with the result of comparison of the bcd method and other blind method implement with identical preprocessing and linear de-composition .",
        "the density map be derive by manual selection by a pathologist ( pathologist ) , ica , nmf , and color decomposition base on reference color ex-tracted from the maxwellian chromaticity plane .",
        "the ﬁgure show correlation for bladder neck tissue stain with h & e , stomach tissue stain with h & e , and prostate tissue stain with h & h , and g & e , respectively .",
        "comparison combine give a complete analysis of our method as compare to other method , bo th with regard to model pa- rameter estimation and the signi ﬁcance of the estimation when the inverse model be apply to clinical data .",
        "all the blind method be randomly initialize and imple- mented with the same convergence criterion ( residual change byless than , the number of iteration ( 1000 ) , and number of replicates ( one ) .",
        "fig .",
        "9 show pearson correlation box plot of the ground truth density map , with the density map for the bcd method , ica with assumed hyperbolic tangent non-gaussian proba-bility distribution function , and nmf .",
        "the experiment shows992 ieee transactions on medical imaging , vol .",
        "32 , no .",
        "6 , june 2013 that in these case hematoxylin bind much good to the tissue than eosin , and the challenge fo r blind algorithms becomes to accurately detect eosin .",
        "whereas all three method identify the strong stain , hematoxylin or giemsa , only nmf and bcdgive satisfactory result for the weak stain , eosin or herovici , with median correlation of 72 % and 85 % , respectively , for the bladder neck , and 88 % and 96 % , respectively , for the stomachtissue section , 88 % and 97 % , res pectively , for prostate tissue with herovici , and 79 % and 99 % , respectively , for prostatetissue with eosin .",
        "the experimental result show that the me-dian correlation for the bcd method performs well than boththe other blind method .",
        "this evaluation method may also be suitable for correlate density map with decomposition result derive by pca .",
        "itsprobability map yield the following median correlation forthe weak stain : 71 % for the bl adder neck tissue stain with h & e , 70 % for the stomach tissue stain with h & e , 75 % forthe prostate tissue stain with h & h , and 90 % for the prostatetissue stain with g & e .",
        "thus we also conclude that pca isoutperformed by both nmf and bcd .",
        "f. validation of piece-wise linear decomposition we also compare the difference between the two bcd decomposition strat egies , linear decomposition and piece-wise linear decomposition , use identical reference color determi-nation approach .",
        "we generate the data for the comparisonas follow .",
        "1 ) the pathologist pick the r eference color for all three stain tissue type in 16 ﬁelds of view in the same manner as for other ground truth data , which result in a mixingmatrix .",
        "2 ) we perform a standard linear decomposition with all three stain tissue type use this mixing matrix .",
        "3 ) we perform a piece-wise linear decomposition , accord to ( 13 ) , also use this mixing matrix .",
        "in fig .",
        "10 we show the qualitative difference between two decomposition of stomach tissue section stain by gomoritrichrome ; in the left column the result from linear decomposi-tion and in the right column fro m piece-wise linear decomposi- tion .",
        "it be easy to see that the piece-wise linear decompositiongives more accurate density map in particular for separation ofcollagen and connective tissue cell ( ﬁbroblasts ) .",
        "to make a quantitative comparison of the same data , we must choose section where the linear decomposition will give a correct answer , that be on ﬁelds of view that contain only two stain tissue type , in this case cell nucleus and collagen.the select ﬁelds of view yield density map that act as the ground truth in this quantitati ve comparison ( we do not select erythrocyte as one of the tissue type since they be few andspatially separable ) .",
        "in fig .",
        "11 the comparison between the density map produce by linear and piece-wise linear decomposition use pearson correlation coef ﬁcients show a difference in median correla- tion to ground truth of 35 % and 80 % for collagen and cell nuclei , respectively .",
        "the statistical co mparisons in fig .",
        "11 support the very large difference in the qualitative comparison in fig .",
        "10 .",
        "fig .",
        "10 .",
        "pseudo color result of decomposition of gomori trichrome stain ( a ) to density map use : in b , c , and d linear decomposition , and in e , f , and gpiece-wise linear decomposition rule .",
        "i n b and e erythrocyte appear red , and in c and f cell nucleus of ﬁbroblasts , lymphocyte and smooth muscle be purple , and in d and g collagen be turquoise .",
        "fig .",
        "11 .",
        "box plot with the result of the comparison of the linear decomposi-tion ( ld ) and piece-wise linear decomposition ( pw-ld ) to ground truth for 16ﬁelds of view of stomach tissue section stain with gomori trichrome .",
        "vi .",
        "d iscussion and conclusion in this paper , we describe a blind method for color decom- position of histopathological tissue image base on a physicalmodel of light absorption .",
        "we have demonstrate quantitativelygavrilovic et al .",
        ": blind color decomposition of histological images 993 that in comparison to other blind method , bcd give good re- sults when the stain tissue be fully separable .",
        "bcd , in con-trast to other blind method , al o work for partially separable trichrome stain , such as gomori trichrome .",
        "we observe that poisson noise be particularly dominant near “ white ” region , where stain c oncentrations be low , as can be see around in fig .",
        "2 .",
        "on the other hand , at high concentra- tions , towards , the dominant source of variation be biochem- ical noise [ 7 ] .",
        "it originate from variation in spectral signaturesof stain .",
        "the transformation of color sample to the maxwellian chro- maticity plane allow us to describe a perfect stain from a colortheory point of view : its referenc e color be compact , separable , and all tissue type absorb a similar amount of stain ( no over-saturation , no weak stain ) .",
        "in addition to enable quanti ﬁca- tion of stain quality by measur ing the distance between refer- ence color in the maxwellian ch romaticity plane , we notice the following : 1 ) variance of detected gaussian distribution represent a measure of biochemical noise for each stained tissue type ; 2 ) the fisher separation criterion can measure stain quality .",
        "the bcd method have some shortcoming : it fail , as do other blind method , if a stain be not present in the image data , orthe stain absorption be poor , and thus specimen preparation andimaging artifact may obscure t he estimation .",
        "the bcd method , as other linear decomposition method , apply only to light ab-sorbing stain .",
        "polymers scatter light rather than absorb lightand hence do not obey the beer–l ambert law , and darkly stain dab have a different spectral signature than lightly stain dab [ 12 ] .",
        "therefore , we suggest the removal of area affect bylight scatter stain with mo rphological technique prior to the use of bcd [ 39 ] .",
        "the highly accurate density map that result from the bcd method lend themselves to further processing usingwell-known , grey-level image analysis technique for ex-tracting morphological feature , such as texture and shape that be know to distinguish cancer from normal tissue [ 40 ] .",
        "a cknowledgment the author would like to thank u .",
        "a. larsson at the uppsala university hospital for prepare the tissue sample .",
        "the au-thors be also grateful to v. curi c at the centre for image anal- ysis , uppsala university , for valuable discussion on the linearmixture model , and t. marzetta at bell laboratories , nj , forhis help with the statistical analysis ."
    ],
    "processed_text": "ieee transactions medical imaging vol 32 6 june 2013 983 blind color decomposition histological images milan gavrilovic member ieee jimmy c azar joakim lindblad carolina wahlby ewert bengtsson senior member ieee christer busch ingrid b carlbom member ieee abstract cancer diagnosis base visual examinatio n microscope tissue section biopsy whereaspathologists rely tissue stain identify morphological features automate tissue recognition use color fra ught problem stem image inte nsity variation due varia tions tissue preparation variation spectral signature thestained tissue spectral overlap spatial aliasing acquisition noise image acquisition present blind method forcolor decomposition histological image method decouplesintensity color information base decomposition tissue absorption characteristic stain modelingthe chargecoupled device sensor noise improve methodaccuracy extend current linear decom position method include stained tissue one spectral signature beseparated combination tissue spectralsignatures demonstrate q ualitatively quantitatively method result accurate decomposition thanmethods base nonnegative mat rix factorization indepen dent component analysis sult one density map stained tissue type classi fies portion pixel correct stain tissue allowi ng accurate identi fication morphological feature may link cancer index terms blind source separation gastrointestinal tract image restoration microscopy prostate quanti fication introduction detection diagnosis everitygrading cancer base visual examination microscope histopathological section tissue biopsy practice isprone subjectivity result signi ficant variation experienced pathologist studies show inter intraobserver variation prostat e cancer grading high 30 40 1 quantitative tissue analysis base auto manuscript receive september 24 2012 revise december 25 2012 ac cepted january 01 2013 date publication january 11 2013 date currentversion may 29 2013 work support part swedish researchcouncil grant 20095418 asterisk indicate correspond author gavrilovic centre image analysis uppsala uni versity swedish university agri cultural sciences s75105 uppsala sweden hotswap engineering consultants s17263 stockholm sweden email gavrilovic @ ieeeorg j c z r e b e n g n n di b c r l b r ew ht h ec e n r ef ri g e analysis uppsala university swedish university agricultural sciences s75105 uppsala sweden j lindblad centre image analysis uppsala university swedish university agricultural scie nces s75105 uppsala sweden faculty technical sciences university novi sad 21000novi sad serbia c wahlby centre image analysis uppsala university swedish university agricultural ciences s75105 uppsala sweden also broad institute harvard mit cambridge 02142 usa c busch department immunology genetics pathology uppsala university s75185 uppsala sweden digital object identi fier 101109/tmi20132239655mated image analysis potential reduce elimin ate subjectivity cancer diagno si yield objec tive basis course treatment quantitative tissue analysi sa l oh large potential role earch allow rapid throughput large amount histopathological data req u r e db yf r example human protein atlas project 2 pathologists rely multiple contrast st ains tissue analysis example hematoxylin sta cell nuclei blue usually combine counters tain eosin stain cytoplasm pink stromal compon ents various grade red/pink provide local color contrast whereas pathologist effectively use col combination tex ture morphologi cal feature visual analysis automate tissue recognition base color fraught problem first large inter intraspecimen variation stained tissue color due tissue preparation fact include variation stain concentrati stain duration tissue thick ness fixation tabesh et al 3 argue color contain much informatio n regard severity grade prostate cancer since int ragrade color variation often great intergrade c olor variation order use color severity grading essential tissue classi fication base solely ti sue absorption characteristic speci fic stain without fluence variation introduce sp ecimen preparation 4 second set problem result aliasing image acquisition process spectral spatial domain different stain may overlap absorption spectrum quiring decomposi tion method classi fies portion pixel correct ti ssue class instead classify pixel contain two mor e stain tissue type one type binary classi fication soft classi fication separate relative contribution stained tissue pixel yield accurate class ification similarly aliasing due limited spatial resolution tissue thickness may result multiple tissue com ponents eg cell nucleus cytoplasm collocate within n g l ep x e l accurate classi fication need separat e relative contribution stain tissue type within pix el h r dp r blem result noise image acquisition standard hreechannel chargecoupled device ccd sensor h v eal n ear response number incident photon domin ant noise poissondistri buted photon noise 5 6 introdu ction noise modeling decomposition increase acc uracy result another type noise due vari ations spectral signature stained tissue ie color sampl e tissue type stain stain optical density exhi bit different spectral prop erties fluorescence microscopy sometimes refer biochemical noise 7 02780062/ $ 3100 2013 ieee984 ieee transactions medical imaging vol 32 6 june 2013 color decomposition technique develop fluores cence microscopy base idea remote sense keshavaand mustard 8 describe spectral unmixing procedurerequiring determination ref erence spectrum color decomposition ie extraction set graylevel imagesshowing individual contributi ons pixel spectral band whereas multispectral solution offer advantage fil ters may match several stained tissue type 9 multispectral imaging costly time consume thanthree channel redgreenblue rgb imaging thestandard bright field microscopy reference 10 show multispectral imaging give statistically signi ficant increase performance hist opathological image analysis therefore focus rgb imag e extension mul tiple spectrum straightforward paper develop new method refer blind color decomposition bcd method stain tissueseparation transmission light microscopy base ideathat intensity decouple color information unlike many exist solution thod blind also sometimes refer unsupervised ie require input theuser form train set special specimen extractinformation prior process use statistical technique fornoise modeling ccd array also devise measure forbiochemical noise assume stain light absorb generally case model relationship thestain absorption use beerlambert law 11 12 map color information image maxwelliancolor space use pattern analysis technique estimate thestained tissue color also know reference color existing color decomposition technique depend version color mixing matrix require reference color linearly indepe ndent color space 13 cluster around reference color chromaticity cluster need fully separable pairwise separable oneagainstall separable inversion color mix matrix give good result 14 however chromaticityclusters pairwise separable one cluster notseparable others call cluster partially separable case trichrome stain gomoritrichrome 15 stain use separate smooth muscleand collagen extend current linear decomposition methodsto include color cluster partially separable divide inversion set linear problem invertingone color mix matrix time refer piecewiselinear decomposition bcd method linear decomposition method require data linearize use beerlambertlaw absorption apply lightabsorbing stainsif specimen contain stain absorb light ratherscatter light 4 12 case diaminobenzidine dab suggest removal dabstained area theimage prior color decomposition presentation color decomposition proceeds fol low first derive theoretical underpinnings linearmixture model follow algorithm remove intensity variation map image data maxwellianchromaticity plane intensity variation remove identify reference color use formulate decomposition rule section v discus method im prove blind decomposition estimate noise image dataand use noise practical solution patternclassi fication problem identi fies reference color maxwellian plane section v show quantitative comparisons method method literature use largedata set hematoxylinandeosinstained h & e bladder neckand stomach tissue 16 prostate tissue stain hematoxylinandherovici h & h 17 giemsaandeosin g & e 18 afirst quantitative comparison use relative rootmean square error rrmse mi xing matrix produce dependent component analysis ica nonnegative matrix factorization nmf bcd ground truth mix matrix asdefined experienced pathologist reveals method outperforms nmf 20 40 ica greatermargins second quantitative comparison method use pearson correlation coef ficient demonstrate density map give average 91 median correlation withground truth weak stain eosin h & e compare toother publish method give 81 median correlation eosin less common stain h & h g & e density map give 98 median correlation groundtruth weak stain comp ared publish method give less 90 median correlation case whenthe chromaticity cluster ly partially separable piece wise linear decomposition give density map mediancorrelation 95 compare 40 linear decompositionqualitative comparison support quantitative result clearlyillustrating density map yield result superior publish method end observation stainquality limitation bcd method ii b ackground related work color decomposition method literature differ term imaging sensor type employ whether model tissuelight absorption determine reference color color space method parameter estimation whether resultis binary map indicate whether stain present pixelor density map give proportion stained tissuein pixel probability map pixel indicatesthe probability presence one stained tissue type versusother tissue type reference color determination methodsmay require user input whereas others completely automated finally method handle partially separablereference color cluster reference color determination histological application often rely cluster tech niques implement directly color space without consider ation staintissue interac tions sensor property su ch method 19 20 result binary classi fication give quantitative density classi fication lead loss information 21 color deconvolution 21 decomposition method transmission bright field microscopy similar castleman color compensation use fluorescence microscopy 22 ingavrilovic et al blind color decomposition histological images 985 table overview reference color determination methods color deconvolution relativ e absorption three chan nels measure slide single stain followedby transformation data beerlambert law andthe computation normali zed average rgb value select tissue normalized color vector use tobuild mixing matrix decomposition color imageinto density image one stained tissue type blind method borrow fro remote sense deter mining reference spectrum tissue color base nmf ica principal component analysis pca first two result density map last probability map reference 23 us ica nmf analyze multispectral datareference 24 show excellent result sparse hyperspectraldata use pca dimensionality reduction follow therelative newton method blin source separation algorithm method rely number wavelength exceed byat least two number stain present slide henceit applicable threechannel data histopathology onlynmf 25 pca 26 test use threecolorimage data following decomposition soft pixel classi fication often implement matrix multiplication pseudo inverseof mixing matrix 8 21 25 27 note last reference deal fluorescence microscopy require reference spectra color identi fied tissue type linearly independent gi f good decomposition result stain tissue fully separable spectral angle mapping often use fluoresce microscopy 4 28 29 offer stable solution even clustersaround reference color onl partially separable al low great number tissu e type color channel however output image spectral angle mapping binary mapping use linear decomposition butrather near neighbor pixel classi fication spectral angle major feature ref erenced work summarize table summary bcd method 1 blind require user manually identify individual stain tissuetypes 2 model absorption use beerlambert law and3 result density map one stained tissue type fully partially separab le chromaticity cluster quantitative density map far process use wellknown greylevel image analy si technique extract fea tures texture shape 30 32 iii ethods color decomposition notation color sample input color image histological specimen w h e r e n denote redgreenblue sample value spatial coordinate pixel reference color unit vector space stained tissue type contribution stained tissue type add one estimated relative proportion stainedtissue imaged histological specimen density map indicate much stained tissue present pixel follow similar derivation optical density 24 sensor wide wavelength bandwidth asin threechannel rgb camera n ote apply logarithmic exponential function vector elementwise b image formation linearization beerlambert law denote intensity light source microscope illuminate histological specimen continuous func tion w h e r e wavelength transfer function microscope denote transfer function indi vidual redgreenblue color channel respectively spectral distribution measured light intensity represent spectral signature wavelength range 33 color sample pixel de fined spectral signature transfer func tions 1 color distribution image fig 1 often visualize 3d scatter plot fig 2 image stomach tissue section stain gomori trichrome use illustrationpurposes section late section demonstrate ourmethod several stain tissue type include gomoritrichromestained stomach tissue stain light absorption follow beerlambert law describe relationship stain concentration absorption 11 beerlambert law follow that986 ieee transactions medical imaging vol 32 6 june 2013 fig 1 example input color image stained tissue typesa stomach section stain gomori trichrome erythrocytes appear red cell nucleus fibroblasts lymphocytes purple smooth muscle grayish purple collagen turquoise fig 2 scatterplots show 3d distribution redgreenblue colorcube figure show scatterplot input image fig 1 spectral signature specimen contain lightab sorbing stain tissue type 2 absorption spectrum stained tissue total amount stained tissue pixel f r 1 2 derive intensity acquire individualcolor channel 3 fig 3 threedimensional scatter plot beerlamberttransformed input image show fig 1 three reference color vector n highlight rewrite 4 fig 2 show color stained tissue cluster along arc start one end achromatic axis whereno light absorb ie correspond color illumination source 5 bend end achromatic axis light source fully attenuate ie correspond c c r n gt ot h e first mean value theorem exist wavelength channel transform 4 6 w h c hb yu n g 5 b e c e 7 applying logarithm si de yield optical density 8 stained tissue type th e vector left hand side 8 b e l n gt oc n e l k ev l u e center vector define reference color catter plot transform beerlambert law see fig 3gavrilovic et al blind color decomposition histological images 987 fig 4 initial transformation input rgb data sb e nt h e beerlambert law follow perspective projection maxwellianchromaticity plane three vertex associate pure color n refer beerlambert red green blue res pectively color correspond cyan magenta yellow iginal redgreenblue space coordinate n plane determine three reference color next section transform input image data pure color representation called maxwellian chromaticity plane allow pattern analysis technique identify reference color th e information contain image c maxwellian chromaticity plane maxwell chromaticity plane maxwell color tri angle property distance two point inthe plane represent chromaticity difference thecorresponding color furthermore pure rgb color ourcase n project onto vertex equilateral riangle point achro matic axis project triangle circum center equal distance three pure color 34 35 transformation rgbs pace max wellian chro maticity space express perspective transformation 36 center projection origin projec tion plane distance origin yield following transformation 9 coordinate maxwellian plane reference color determination project color data cluster maxwellian chromaticity plane cluster correspond onestained tissue type without knowledge exact datadistribution assume cluster follow gaussiandistribution mean 37 variance gaussians measure biochemical noise corresponding stain tissue type fig 4 show projectedcolor data histogram maxwellian color triangle height indicate number color sample thebeerlambert space coordinate maxwellianplane fig 5 show refer ence color maxwellian chromaticity plane image data fig 1 fig 5 position three reference color maxwellian chro maticity plane n c ew eh v en ap r r knowledge shape size cluster must rule simple method askmeans meanshi ft cluster identi fication rely gaussian assumption empl oy expectation maximization tofind cluster maxwellian chromaticity plane mean gaussian distri butions calculate ref erence color vector use inv erse 9 note ref erence color vector unit vector space 10 use result reference color vector decom pose original image density map describe following section e linear decomposition use reference color vector blindly estimate absorption spectrum 8 constant thus refor mulate 8 vector form 11 unit reference color vector contain estimated relative proportion stained tissue wefind relative density solve 11 leastsquares problem method know linear decomposition multiply optical density pseudoinverseof mixing matrix yield density map 12 one resulting element less zero element set zero method inversion assumes thechromaticity cluster fully separable chromaticity cluster partially separable one cluster eg index poor one988 ieee transactions medical imaging vol 32 6 june 2013 againstall cluster separation ie poor separation clus ters use piecewise linear decomposition case apply pseudoinverse transformation mix submatrices comprise reference color vector n respectively two subm atrices multiply optical density data result combine form thedensity map density map de fined 13 minimum third equation 13 motivate fact choose decomposition stain pair best align observed color corresponds select thedecomposition maximal density ie minimal linear deco mposition piecewise linear decomposition result n quantitative density map iv mplementation overview contrast supervise method expert eg pathologist provide training set reference color 10 sample region 21 appr oach automatically estimate linear model parameter 11 image data ourmethod require following minimal prior knowledgeabout tissue specimen 1 number light absorbingstained tissue type 2 stored blank image microscope measure photon noise blankimage available microscope estimatedfrom image fig 6 show process pipeline acquisition result density map bladder neck stomach datawe use olympus bright field microscope image acqui sition microscope accompany ccd camera n objective standard redgreenblue optical filters prostate data set use aperio scanscope model xt olympus planapochromatic objective first step remove area affect light scatter stain next measure photon noise parameter modeling uncertainty measured intensity value followedby transformation image data use beerlambertlaw absorption projection result data tothe maxwellian chromaticity plane find cluster thereafter base mean gaussianlike cluster w h e r e generate reference color vector make column mixing matrix andapply linear decomposition produce density map linear decomposition method require data linearize use beerlambert law absorption whichassumes stain tissue absorb photon lightsource however polymer dab commonly use fig 6 flowchart bcd method histopathology obey beerlambert lawas scatter rather absorb light 4 12 suggestremoval dabstained area image prior colordecomposition standard image analysis technique sogavrilovic et al blind color decomposition histological images 989 color decomposition base solely light absorbing stain b noise model standard threechannel ccd sensor linear response number incident photon dominant noise ispoissondistributed photon noise 5 6 maxwellianplane area high optical density create distinct peak high signaltonoise ratio low optical densityareas hand tend create spurious peak andthe signaltonoise level low result photon noisehas signi ficant effect area around white accurate estimation noise parameter sensor usedto smooth data aid extraction distinctpeaks correspond reference color imaging device light source ccd array calibrate acquire ab l n ki g ea n dad r kf r e first use blank image automatically set ampli fier gain image perceive white second usethese image estimate photon noise input colorsample color channel blank image derive mean value intensity image n standard deviation intensity histogram channel dark frame mean value measurements set less one quantization level 13 however due ampli fier gain standard deviation generally zero estimate dark frame also intensity histogram standard deviation intensity level e r v e db 5 14 blank image dark frame available estimate intensity histogram white area h ei g e n e root mean square quantiza tion noise make assumption precise noise measurements dark region important due highsignaltonoise level show 38 root mean square ofthe quantization noise become next section show use estimated noise parameter smooth image data c parameter estimation use noise model aid parameter estimation color sample present original image gen erate cloud point center around 3d color space since high intensity value noise signi ficant effect transformation 9 approximate 3d poisson distribution gaussian distribution standard deviation derive previous section cloud point transform via beerlambert law result increase numberof point factor select reference color give weight data high optical density assign point scoreu n gah e u r cs l rt ot h tu e di n 2 9 15 random variable drawn uniform distri bution 01 next order reduce number data point back number originalmeasurements retain point high score important introduce randomization score whenweighting data point 15 otherwise selection point great optical density value would equivalent intensity thresholding would omitweaker stain eosin fro analysis next sec tion show noise model improve solution increasing reach five seven improve solution far exper iments discuss set describe earlier use expectation maximization fit gaussian distribution color data maxwellian planethe mean value distribution allow us estimate thereference color vector form mixing matrix lineardecomposition mix mat rice 12 13 give required density map separability chromaticity cluster whether fully separable partially separable determine whether linear orpiecewise linear decomposition applicable oneagainstone separability measure statistical technique suchas fisher criterion 14 high value fisher criterion corresponds cluster well separate lowerfisher criterion yield bad cluste r separation case three stained tissue type cluster must oneagainstoneseparable oneagainstall separable case thereis one cluster poor oneag ainstall separation cluster others fully separable piecewise linear decomposition give good decomposition result simplelinear decomposition v e xperimental results section show quantitative qualitative compar isons bcd method exist method three tissuetypes four different stain also demonstrate importance piecewise linear deco mposition stain tissue color partially separable begin describe howwe acquire ground truth data ground truth validation produce ground truth data use multiple histological staining method us ed example 21 23 n c em n sm xa n da l ob n dt ot h es et u ec p nents different degree case dab hematoxylin use 21 23 word ground truth data h & e hematoxylin presence eosin viceversa demonstrate stain three adjoin prostatetissue section 1 hematoxylin alone 2 eosin alone and3 h & e respectively expert pick of990 ieee transactions medical imaging vol 32 6 june 2013 table ii reference color vectors three section 1 tissue stain hema toxylin ie cell nuclei 2 tissue stain eosin ie stroma table ii show reference colorvectors result decomposition three sections hematoxylin alone eosin alone h & e note thatthe reference color value parti cularly eosin alone dif ferent reference color h & e combination thisdemonstrates necessity select ground truth usingthe combination stain component onlymanually ground truth experienced pathologist pick refer ence color select number pixel stain tissuetype series fields view tissue please note expert pick stain use color asa guide rather morphological component knownto primarily stain cell nucleus hematoxylin inwhat follow use median pixel select ineach individual fie l fv e w f vg r u n dt r u h n da l ot h e median fov value total ground truth ground truthreference color particular stain tissue makeup column ground truth mix matrix b comparisons mixing mat rix estimation using rrmse ourfirst comparison bcd method method literature base relative rrmse mixingmatrices derive ica nmf bcd compare thetotal ground truth mix matri x three case color image data linearize use beerlambert law prior calculation mixing matri x also compute rrmse fov ground truth mix matrix compare thetotal ground truth mix matrix illustrate variation inthe ground truth tissue section rrmse derive 16 number fields view experiment estimated mixing matrix thfield view total ground truth mix matrix denote matrix trace table iii show result 2123 depend tissue type randomly choose fields view reveals method outperforms nmf 20 40 icawith much great margin bladder neck tissue stainedwith h & e stomach tissue stain h & e prostatetissue stain h & h g & e respectively rowlabeled pathologist show rrmse expert isle method variation stainscan attribute variation stain quality thesections minor error experttable iii rrmse ofmixing matrix estimation fig 7 robustness respect size point cloud bcd method apply four di fferent stain tissue type however comparison tell whole story since error one reference color partially transfer othercolor therefore need also compare resulting density map section c noise compensation stability tests discuss earlier ccd noise model improve result parameter estimation fig 7 show eachstained tissue type size point cloud modelthe photon noise quanti zation level affect rrmse value point noise model relative rootmeansquare error improve increase u n l reach five seven rrmse level qualitative comparisons bcd nmf fig 8 show qualitative difference density map nmf b c bcd e one fie l fv e wo fa prostate tissue section stain h & h field view represent average rrmse whole tissue section thevisual result show signi ficant difference example appearance nucleus b result bleed hematoxylin nmf eosin density map c also notice bleedthrough th e direction nmf stroma well delineate n c si ti si n e k n ga segmentation prostate gland easier bcd densitymap e e comparisons using pearson correlation coef ficient mention early section comparison base solely mix matrix tell whole story sincegavrilovic et al blind color decomposition histological images 991 fig 8 color decomposition h & h stain density map use nmf b c bcd e error estimation one reference color vector trans ferred color illustrate qualitativeexample therefore section compare resulting density map identical tissue fields view e n e dt u et p e sa su e di ns e c nv ba b v e h et w fig 9 box plot result comparison bcd method blind method implement identical preprocessing linear decomposition density map derive manual selection pathologist pathologist ica nmf color decomposition base reference color extracted maxwellian chromaticity plane figure show correlation bladder neck tissue stain h & e stomach tissue stain h & e prostate tissue stain h & h g & e respectively comparison combine give complete analysis method compare method bo th regard model pa rameter estimation signi ficance estimation inverse model apply clinical data blind method randomly initialize imple mented convergence criterion residual change byless number iteration 1000 number replicates one fig 9 show pearson correlation box plot ground truth density map density map bcd method ica assumed hyperbolic tangent nongaussian probability distribution function nmf experiment shows992 ieee transactions medical imaging vol 32 6 june 2013 case hematoxylin bind much good tissue eosin challenge fo r blind algorithms becomes accurately detect eosin whereas three method identify strong stain hematoxylin giemsa nmf bcdgive satisfactory result weak stain eosin herovici median correlation 72 85 respectively bladder neck 88 96 respectively stomachtissue section 88 97 res pectively prostate tissue herovici 79 99 respectively prostatetissue eosin experimental result show median correlation bcd method performs well boththe blind method evaluation method may also suitable correlate density map decomposition result derive pca itsprobability map yield following median correlation forthe weak stain 71 bl adder neck tissue stain h & e 70 stomach tissue stain h & e 75 forthe prostate tissue stain h & h 90 prostatetissue stain g & e thus also conclude pca isoutperformed nmf bcd f validation piecewise linear decomposition also compare difference two bcd decomposition strat egies linear decomposition piecewise linear decomposition use identical reference color determination approach generate data comparisonas follow 1 pathologist pick r eference color three stain tissue type 16 fields view manner ground truth data result mixingmatrix 2 perform standard linear decomposition three stain tissue type use mixing matrix 3 perform piecewise linear decomposition accord 13 also use mixing matrix fig 10 show qualitative difference two decomposition stomach tissue section stain gomoritrichrome left column result linear decomposition right column fro piecewise linear decomposi tion easy see piecewise linear decompositiongives accurate density map particular separation ofcollagen connective tissue cell fibroblasts make quantitative comparison data must choose section linear decomposition give correct answer fields view contain two stain tissue type case cell nucleus collagenthe select fields view yield density map act ground truth quantitati comparison select erythrocyte one tissue type since andspatially separable fig 11 comparison density map produce linear piecewise linear decomposition use pearson correlation coef ficients show difference median correla tion ground truth 35 80 collagen cell nuclei respectively statistical co mparisons fig 11 support large difference qualitative comparison fig 10 fig 10 pseudo color result decomposition gomori trichrome stain density map use b c linear decomposition e f gpiecewise linear decomposition rule n b e erythrocyte appear red c f cell nucleus fibroblasts lymphocyte smooth muscle purple g collagen turquoise fig 11 box plot result comparison linear decomposition ld piecewise linear decomposition pwld ground truth 16fields view stomach tissue section stain gomori trichrome vi iscussion conclusion paper describe blind method color decom position histopathological tissue image base physicalmodel light absorption demonstrate quantitativelygavrilovic et al blind color decomposition histological images 993 comparison blind method bcd give good sults stain tissue fully separable bcd contrast blind method al work partially separable trichrome stain gomori trichrome observe poisson noise particularly dominant near white region stain c oncentrations low see around fig 2 hand high concentra tions towards dominant source variation biochem ical noise 7 originate variation spectral signaturesof stain transformation color sample maxwellian chro maticity plane allow us describe perfect stain colortheory point view referenc e color compact separable tissue type absorb similar amount stain oversaturation weak stain addition enable quanti fica tion stain quality measur ing distance refer ence color maxwellian ch romaticity plane notice following 1 variance detected gaussian distribution represent measure biochemical noise stained tissue type 2 fisher separation criterion measure stain quality bcd method shortcoming fail blind method stain present image data orthe stain absorption poor thus specimen preparation andimaging artifact may obscure estimation bcd method linear decomposition method apply light absorbing stain polymers scatter light rather absorb lightand hence obey beerl ambert law darkly stain dab different spectral signature lightly stain dab 12 therefore suggest removal area affect bylight scatter stain mo rphological technique prior use bcd 39 highly accurate density map result bcd method lend processing usingwellknown greylevel image analysis technique extracting morphological feature texture shape know distinguish cancer normal tissue 40 cknowledgment author would like thank u larsson uppsala university hospital prepare tissue sample authors also grateful v curi c centre image anal ysis uppsala university valuable discussion linearmixture model marzetta bell laboratories nj forhis help statistical analysis",
    "bag_of_words": {
        "ieee": 9,
        "transactions": 6,
        "medical": 6,
        "imaging": 11,
        "vol": 6,
        "june": 6,
        "blind": 21,
        "color": 116,
        "decomposition": 62,
        "histological": 12,
        "images": 6,
        "milan": 1,
        "gavrilovic": 3,
        "member": 3,
        "jimmy": 1,
        "azar": 1,
        "joakim": 1,
        "lindblad": 2,
        "carolina": 1,
        "wahlby": 2,
        "ewert": 1,
        "bengtsson": 1,
        "senior": 1,
        "christer": 1,
        "busch": 2,
        "ingrid": 1,
        "carlbom": 1,
        "abstract": 1,
        "cancer": 7,
        "diagnosis": 2,
        "base": 16,
        "visual": 3,
        "examinatio": 1,
        "microscope": 8,
        "tissue": 92,
        "section": 25,
        "biopsy": 2,
        "whereaspathologists": 1,
        "rely": 5,
        "stain": 85,
        "identify": 5,
        "morphological": 4,
        "features": 1,
        "automate": 2,
        "recognition": 2,
        "use": 47,
        "fra": 1,
        "ught": 1,
        "problem": 6,
        "stem": 1,
        "image": 48,
        "inte": 1,
        "nsity": 1,
        "variation": 16,
        "due": 6,
        "varia": 1,
        "tions": 4,
        "preparation": 4,
        "spectral": 17,
        "signature": 7,
        "thestained": 2,
        "overlap": 2,
        "spatial": 4,
        "aliasing": 3,
        "acquisition": 5,
        "noise": 33,
        "present": 6,
        "method": 59,
        "forcolor": 1,
        "decouplesintensity": 1,
        "information": 5,
        "absorption": 16,
        "characteristic": 2,
        "modelingthe": 1,
        "chargecoupled": 2,
        "device": 3,
        "sensor": 7,
        "improve": 5,
        "methodaccuracy": 1,
        "extend": 2,
        "current": 2,
        "linear": 37,
        "decom": 3,
        "position": 3,
        "include": 4,
        "stained": 21,
        "one": 18,
        "beseparated": 1,
        "combination": 4,
        "spectralsignatures": 1,
        "demonstrate": 6,
        "ualitatively": 1,
        "quantitatively": 1,
        "result": 36,
        "accurate": 7,
        "thanmethods": 1,
        "nonnegative": 2,
        "mat": 3,
        "rix": 2,
        "factorization": 2,
        "indepen": 1,
        "dent": 1,
        "component": 5,
        "analysis": 19,
        "sult": 1,
        "density": 43,
        "map": 38,
        "type": 32,
        "classi": 10,
        "fies": 3,
        "portion": 2,
        "pixel": 15,
        "correct": 3,
        "allowi": 1,
        "ng": 1,
        "identi": 5,
        "fication": 12,
        "feature": 4,
        "may": 7,
        "link": 1,
        "index": 2,
        "terms": 1,
        "source": 7,
        "separation": 8,
        "gastrointestinal": 1,
        "tract": 1,
        "restoration": 1,
        "microscopy": 9,
        "prostate": 9,
        "quanti": 3,
        "introduction": 1,
        "detection": 1,
        "everitygrading": 1,
        "examination": 1,
        "histopathological": 3,
        "practice": 1,
        "isprone": 1,
        "subjectivity": 2,
        "signi": 6,
        "ficant": 5,
        "experienced": 3,
        "pathologist": 9,
        "studies": 1,
        "show": 26,
        "inter": 2,
        "intraobserver": 1,
        "prostat": 1,
        "grading": 2,
        "high": 8,
        "quantitative": 11,
        "auto": 1,
        "manuscript": 1,
        "receive": 1,
        "september": 1,
        "revise": 1,
        "december": 1,
        "ac": 1,
        "cepted": 1,
        "january": 2,
        "date": 2,
        "publication": 1,
        "currentversion": 1,
        "work": 4,
        "support": 3,
        "part": 1,
        "swedish": 5,
        "researchcouncil": 1,
        "grant": 1,
        "asterisk": 1,
        "indicate": 4,
        "correspond": 6,
        "author": 2,
        "centre": 4,
        "uppsala": 12,
        "uni": 1,
        "versity": 1,
        "university": 11,
        "agri": 1,
        "cultural": 1,
        "sciences": 3,
        "s75105": 4,
        "sweden": 6,
        "hotswap": 1,
        "engineering": 1,
        "consultants": 1,
        "s17263": 1,
        "stockholm": 1,
        "email": 1,
        "ieeeorg": 1,
        "di": 4,
        "ew": 2,
        "ht": 1,
        "ec": 2,
        "ef": 1,
        "ri": 1,
        "agricultural": 3,
        "scie": 1,
        "nces": 1,
        "faculty": 1,
        "technical": 1,
        "novi": 1,
        "sad": 2,
        "21000novi": 1,
        "serbia": 1,
        "ciences": 1,
        "also": 14,
        "broad": 1,
        "institute": 1,
        "harvard": 1,
        "mit": 1,
        "cambridge": 1,
        "usa": 1,
        "department": 1,
        "immunology": 1,
        "genetics": 1,
        "pathology": 1,
        "s75185": 1,
        "digital": 1,
        "object": 1,
        "fier": 3,
        "101109/tmi20132239655mated": 1,
        "potential": 2,
        "reduce": 2,
        "elimin": 1,
        "ate": 1,
        "diagno": 1,
        "si": 5,
        "yield": 9,
        "objec": 1,
        "tive": 1,
        "basis": 1,
        "course": 1,
        "treatment": 1,
        "analysi": 1,
        "sa": 2,
        "oh": 1,
        "large": 4,
        "role": 1,
        "earch": 1,
        "allow": 4,
        "rapid": 1,
        "throughput": 1,
        "amount": 3,
        "data": 32,
        "req": 1,
        "db": 2,
        "yf": 1,
        "example": 5,
        "human": 1,
        "protein": 1,
        "atlas": 1,
        "project": 4,
        "pathologists": 1,
        "multiple": 3,
        "contrast": 4,
        "st": 1,
        "ains": 1,
        "hematoxylin": 9,
        "sta": 1,
        "cell": 9,
        "nuclei": 3,
        "blue": 2,
        "usually": 1,
        "combine": 3,
        "counters": 1,
        "tain": 1,
        "eosin": 14,
        "cytoplasm": 2,
        "pink": 1,
        "stromal": 1,
        "compon": 1,
        "ents": 1,
        "various": 1,
        "grade": 2,
        "red/pink": 1,
        "provide": 2,
        "local": 1,
        "whereas": 4,
        "effectively": 1,
        "col": 1,
        "tex": 1,
        "ture": 1,
        "morphologi": 1,
        "cal": 1,
        "fraught": 1,
        "first": 6,
        "intraspecimen": 1,
        "fact": 2,
        "concentrati": 1,
        "duration": 1,
        "thick": 1,
        "ness": 1,
        "fixation": 1,
        "tabesh": 1,
        "et": 9,
        "al": 8,
        "argue": 1,
        "contain": 7,
        "much": 4,
        "informatio": 1,
        "regard": 2,
        "severity": 2,
        "since": 4,
        "int": 1,
        "ragrade": 1,
        "often": 5,
        "great": 4,
        "intergrade": 1,
        "olor": 1,
        "order": 2,
        "essential": 1,
        "solely": 3,
        "ti": 3,
        "sue": 1,
        "speci": 1,
        "fic": 1,
        "without": 3,
        "fluence": 1,
        "introduce": 2,
        "sp": 1,
        "ecimen": 1,
        "second": 3,
        "set": 11,
        "process": 4,
        "domain": 1,
        "different": 5,
        "spectrum": 6,
        "quiring": 1,
        "decomposi": 2,
        "tion": 8,
        "ssue": 1,
        "class": 2,
        "instead": 1,
        "classify": 1,
        "two": 8,
        "mor": 1,
        "binary": 4,
        "soft": 2,
        "separate": 3,
        "relative": 8,
        "contribution": 3,
        "ification": 1,
        "similarly": 1,
        "limited": 1,
        "resolution": 1,
        "thickness": 1,
        "com": 1,
        "ponents": 1,
        "eg": 3,
        "nucleus": 6,
        "collocate": 1,
        "within": 2,
        "ep": 1,
        "need": 3,
        "separat": 1,
        "pix": 1,
        "el": 1,
        "dp": 1,
        "blem": 1,
        "standard": 9,
        "hreechannel": 1,
        "ccd": 6,
        "eal": 1,
        "ear": 1,
        "response": 2,
        "number": 13,
        "incident": 2,
        "photon": 10,
        "domin": 1,
        "ant": 1,
        "poissondistri": 1,
        "buted": 1,
        "introdu": 1,
        "ction": 1,
        "modeling": 3,
        "increase": 4,
        "acc": 1,
        "uracy": 1,
        "another": 1,
        "vari": 1,
        "ations": 1,
        "ie": 9,
        "sampl": 1,
        "optical": 10,
        "exhi": 1,
        "bit": 1,
        "prop": 1,
        "erties": 1,
        "fluorescence": 3,
        "sometimes": 2,
        "refer": 8,
        "biochemical": 3,
        "02780062/": 1,
        "ieee984": 1,
        "technique": 10,
        "develop": 2,
        "fluores": 1,
        "cence": 1,
        "idea": 1,
        "remote": 2,
        "sense": 2,
        "keshavaand": 1,
        "mustard": 1,
        "describe": 7,
        "unmixing": 1,
        "procedurerequiring": 1,
        "determination": 6,
        "ref": 4,
        "erence": 3,
        "extraction": 2,
        "graylevel": 1,
        "imagesshowing": 1,
        "individual": 3,
        "contributi": 1,
        "ons": 1,
        "band": 1,
        "multispectral": 4,
        "solution": 6,
        "offer": 2,
        "advantage": 1,
        "fil": 1,
        "ters": 2,
        "match": 1,
        "several": 2,
        "costly": 1,
        "time": 2,
        "consume": 1,
        "thanthree": 1,
        "channel": 7,
        "redgreenblue": 6,
        "rgb": 6,
        "thestandard": 1,
        "bright": 3,
        "field": 4,
        "reference": 38,
        "give": 15,
        "statistically": 1,
        "performance": 1,
        "hist": 1,
        "opathological": 1,
        "therefore": 4,
        "focus": 1,
        "imag": 1,
        "extension": 1,
        "mul": 1,
        "tiple": 1,
        "straightforward": 1,
        "paper": 2,
        "new": 1,
        "bcd": 25,
        "tissueseparation": 1,
        "transmission": 2,
        "light": 17,
        "ideathat": 1,
        "intensity": 14,
        "decouple": 1,
        "unlike": 1,
        "many": 1,
        "exist": 3,
        "thod": 1,
        "unsupervised": 1,
        "require": 8,
        "input": 9,
        "theuser": 1,
        "form": 4,
        "train": 1,
        "special": 1,
        "specimen": 8,
        "extractinformation": 1,
        "prior": 6,
        "statistical": 4,
        "fornoise": 1,
        "array": 2,
        "devise": 1,
        "measure": 8,
        "forbiochemical": 1,
        "assume": 2,
        "absorb": 7,
        "generally": 2,
        "case": 11,
        "model": 14,
        "relationship": 2,
        "thestain": 1,
        "beerlambert": 13,
        "law": 12,
        "maxwelliancolor": 1,
        "space": 10,
        "pattern": 2,
        "estimate": 8,
        "know": 3,
        "existing": 1,
        "depend": 2,
        "version": 1,
        "mixing": 11,
        "matrix": 22,
        "linearly": 2,
        "indepe": 1,
        "ndent": 1,
        "cluster": 27,
        "around": 4,
        "chromaticity": 14,
        "fully": 8,
        "separable": 20,
        "pairwise": 2,
        "oneagainstall": 2,
        "inversion": 3,
        "mix": 11,
        "good": 5,
        "however": 5,
        "chromaticityclusters": 1,
        "notseparable": 1,
        "others": 3,
        "call": 1,
        "partially": 11,
        "trichrome": 7,
        "gomoritrichrome": 2,
        "smooth": 5,
        "muscleand": 1,
        "collagen": 4,
        "methodsto": 1,
        "divide": 1,
        "invertingone": 1,
        "piecewiselinear": 1,
        "linearize": 3,
        "beerlambertlaw": 2,
        "apply": 6,
        "lightabsorbing": 1,
        "stainsif": 1,
        "ratherscatter": 1,
        "diaminobenzidine": 1,
        "dab": 5,
        "suggest": 2,
        "removal": 2,
        "dabstained": 2,
        "area": 7,
        "theimage": 1,
        "presentation": 1,
        "proceeds": 1,
        "fol": 1,
        "low": 5,
        "derive": 8,
        "theoretical": 1,
        "underpinnings": 1,
        "linearmixture": 2,
        "follow": 9,
        "algorithm": 2,
        "remove": 3,
        "maxwellianchromaticity": 2,
        "plane": 18,
        "formulate": 1,
        "rule": 3,
        "discus": 1,
        "im": 1,
        "prove": 1,
        "dataand": 1,
        "practical": 1,
        "patternclassi": 1,
        "maxwellian": 14,
        "comparisons": 4,
        "literature": 3,
        "largedata": 1,
        "hematoxylinandeosinstained": 1,
        "bladder": 5,
        "neckand": 1,
        "stomach": 10,
        "hematoxylinandherovici": 1,
        "giemsaandeosin": 1,
        "afirst": 1,
        "comparison": 14,
        "rootmean": 1,
        "square": 3,
        "error": 5,
        "rrmse": 10,
        "mi": 1,
        "xing": 1,
        "produce": 4,
        "dependent": 1,
        "ica": 7,
        "nmf": 15,
        "ground": 20,
        "truth": 20,
        "asdefined": 1,
        "reveals": 2,
        "outperforms": 2,
        "greatermargins": 1,
        "pearson": 4,
        "correlation": 12,
        "coef": 3,
        "ficient": 2,
        "average": 3,
        "median": 10,
        "withground": 1,
        "weak": 5,
        "compare": 8,
        "toother": 1,
        "publish": 3,
        "less": 4,
        "common": 1,
        "groundtruth": 1,
        "comp": 1,
        "ared": 1,
        "whenthe": 1,
        "ly": 1,
        "piece": 1,
        "wise": 1,
        "mediancorrelation": 1,
        "decompositionqualitative": 1,
        "clearlyillustrating": 1,
        "superior": 1,
        "end": 3,
        "observation": 1,
        "stainquality": 1,
        "limitation": 1,
        "ii": 3,
        "ackground": 1,
        "related": 1,
        "differ": 1,
        "term": 1,
        "employ": 1,
        "whether": 5,
        "tissuelight": 1,
        "determine": 3,
        "parameter": 8,
        "estimation": 11,
        "resultis": 1,
        "pixelor": 1,
        "proportion": 3,
        "tissuein": 1,
        "probability": 4,
        "indicatesthe": 1,
        "presence": 2,
        "versusother": 1,
        "methodsmay": 1,
        "user": 2,
        "completely": 1,
        "automated": 1,
        "finally": 1,
        "handle": 1,
        "separablereference": 1,
        "application": 1,
        "tech": 1,
        "niques": 1,
        "implement": 3,
        "directly": 1,
        "consider": 1,
        "ation": 1,
        "staintissue": 1,
        "interac": 1,
        "property": 2,
        "su": 2,
        "ch": 2,
        "lead": 1,
        "loss": 1,
        "deconvolution": 2,
        "similar": 3,
        "castleman": 1,
        "compensation": 2,
        "ingavrilovic": 1,
        "table": 5,
        "overview": 2,
        "methods": 1,
        "relativ": 1,
        "three": 15,
        "chan": 1,
        "nels": 1,
        "slide": 2,
        "single": 1,
        "followedby": 2,
        "transformation": 9,
        "andthe": 2,
        "computation": 1,
        "normali": 1,
        "zed": 1,
        "value": 13,
        "select": 8,
        "normalized": 1,
        "vector": 17,
        "tobuild": 1,
        "imageinto": 1,
        "borrow": 1,
        "fro": 3,
        "deter": 1,
        "mining": 1,
        "principal": 1,
        "pca": 5,
        "last": 2,
        "us": 4,
        "analyze": 1,
        "datareference": 1,
        "excellent": 1,
        "sparse": 1,
        "hyperspectraldata": 1,
        "dimensionality": 1,
        "reduction": 1,
        "therelative": 1,
        "newton": 1,
        "blin": 1,
        "wavelength": 5,
        "exceed": 1,
        "byat": 1,
        "least": 1,
        "henceit": 1,
        "applicable": 2,
        "threechannel": 3,
        "histopathology": 2,
        "onlynmf": 1,
        "test": 1,
        "threecolorimage": 1,
        "following": 6,
        "multiplication": 1,
        "pseudo": 2,
        "inverseof": 1,
        "note": 4,
        "deal": 1,
        "spectra": 1,
        "fied": 1,
        "independent": 1,
        "gi": 1,
        "angle": 4,
        "mapping": 3,
        "fluoresce": 1,
        "stable": 1,
        "even": 1,
        "clustersaround": 1,
        "onl": 1,
        "tissu": 1,
        "output": 1,
        "butrather": 1,
        "near": 2,
        "neighbor": 1,
        "major": 1,
        "erenced": 1,
        "summarize": 1,
        "summary": 1,
        "manually": 1,
        "tissuetypes": 2,
        "and3": 2,
        "separab": 1,
        "le": 1,
        "far": 2,
        "wellknown": 1,
        "greylevel": 2,
        "analy": 1,
        "extract": 1,
        "fea": 1,
        "tures": 1,
        "texture": 2,
        "shape": 3,
        "iii": 3,
        "ethods": 1,
        "notation": 1,
        "sample": 8,
        "denote": 4,
        "coordinate": 4,
        "unit": 3,
        "add": 1,
        "estimated": 4,
        "stainedtissue": 1,
        "imaged": 1,
        "derivation": 1,
        "wide": 1,
        "bandwidth": 1,
        "asin": 1,
        "camera": 2,
        "ote": 1,
        "logarithmic": 1,
        "exponential": 1,
        "function": 4,
        "elementwise": 1,
        "formation": 1,
        "linearization": 1,
        "illuminate": 1,
        "continuous": 1,
        "func": 2,
        "transfer": 4,
        "indi": 1,
        "vidual": 1,
        "respectively": 9,
        "distribution": 9,
        "measured": 2,
        "represent": 4,
        "range": 1,
        "de": 3,
        "fined": 2,
        "fig": 29,
        "visualize": 1,
        "3d": 4,
        "scatter": 6,
        "plot": 6,
        "gomori": 5,
        "illustrationpurposes": 1,
        "late": 1,
        "ourmethod": 2,
        "gomoritrichromestained": 1,
        "concentration": 1,
        "that986": 1,
        "typesa": 1,
        "erythrocytes": 1,
        "appear": 2,
        "red": 3,
        "fibroblasts": 3,
        "lymphocytes": 1,
        "purple": 3,
        "muscle": 2,
        "grayish": 1,
        "turquoise": 2,
        "scatterplots": 1,
        "colorcube": 1,
        "figure": 2,
        "scatterplot": 1,
        "lightab": 1,
        "sorbing": 1,
        "total": 3,
        "acquire": 3,
        "individualcolor": 1,
        "threedimensional": 1,
        "beerlamberttransformed": 1,
        "highlight": 1,
        "rewrite": 1,
        "along": 1,
        "arc": 1,
        "start": 1,
        "achromatic": 2,
        "axis": 3,
        "whereno": 1,
        "illumination": 1,
        "bend": 1,
        "attenuate": 1,
        "gt": 2,
        "ot": 4,
        "mean": 9,
        "theorem": 1,
        "transform": 4,
        "hb": 1,
        "yu": 1,
        "applying": 1,
        "logarithm": 1,
        "th": 4,
        "left": 2,
        "hand": 3,
        "side": 1,
        "oc": 1,
        "ev": 1,
        "center": 4,
        "define": 1,
        "catter": 1,
        "see": 3,
        "3gavrilovic": 1,
        "initial": 1,
        "sb": 1,
        "nt": 1,
        "perspective": 2,
        "projection": 3,
        "vertex": 2,
        "associate": 1,
        "pure": 4,
        "green": 1,
        "res": 2,
        "pectively": 2,
        "cyan": 1,
        "magenta": 1,
        "yellow": 1,
        "iginal": 1,
        "next": 5,
        "representation": 1,
        "called": 1,
        "maxwell": 2,
        "tri": 1,
        "distance": 4,
        "point": 14,
        "inthe": 2,
        "difference": 7,
        "thecorresponding": 1,
        "furthermore": 1,
        "ourcase": 1,
        "onto": 1,
        "equilateral": 1,
        "riangle": 1,
        "achro": 1,
        "matic": 1,
        "triangle": 2,
        "circum": 1,
        "equal": 1,
        "rgbs": 1,
        "pace": 1,
        "max": 1,
        "wellian": 1,
        "chro": 3,
        "maticity": 3,
        "express": 1,
        "origin": 2,
        "projec": 1,
        "onestained": 1,
        "knowledge": 2,
        "exact": 1,
        "datadistribution": 1,
        "gaussiandistribution": 1,
        "variance": 2,
        "gaussians": 1,
        "corresponding": 1,
        "projectedcolor": 1,
        "histogram": 4,
        "height": 1,
        "thebeerlambert": 1,
        "maxwellianplane": 2,
        "ence": 3,
        "eh": 1,
        "en": 1,
        "ap": 1,
        "size": 3,
        "must": 3,
        "simple": 1,
        "askmeans": 1,
        "meanshi": 1,
        "ft": 1,
        "gaussian": 5,
        "assumption": 2,
        "empl": 1,
        "oy": 1,
        "expectation": 2,
        "maximization": 2,
        "tofind": 1,
        "distri": 2,
        "butions": 1,
        "calculate": 1,
        "inv": 1,
        "erse": 1,
        "pose": 1,
        "original": 2,
        "blindly": 1,
        "constant": 1,
        "thus": 3,
        "refor": 1,
        "mulate": 1,
        "wefind": 1,
        "solve": 1,
        "leastsquares": 1,
        "multiply": 2,
        "pseudoinverseof": 1,
        "resulting": 3,
        "element": 2,
        "zero": 3,
        "assumes": 1,
        "thechromaticity": 1,
        "poor": 4,
        "one988": 1,
        "againstall": 1,
        "clus": 1,
        "piecewise": 11,
        "pseudoinverse": 1,
        "submatrices": 1,
        "comprise": 1,
        "subm": 1,
        "atrices": 1,
        "thedensity": 1,
        "minimum": 1,
        "third": 1,
        "equation": 1,
        "motivate": 1,
        "choose": 3,
        "pair": 1,
        "best": 1,
        "align": 1,
        "observed": 1,
        "corresponds": 2,
        "thedecomposition": 1,
        "maximal": 1,
        "minimal": 2,
        "deco": 2,
        "mposition": 2,
        "iv": 1,
        "mplementation": 1,
        "supervise": 1,
        "expert": 4,
        "training": 1,
        "region": 3,
        "appr": 1,
        "oach": 1,
        "automatically": 2,
        "knowledgeabout": 1,
        "absorbingstained": 1,
        "stored": 1,
        "blank": 4,
        "blankimage": 1,
        "available": 2,
        "estimatedfrom": 1,
        "pipeline": 1,
        "neck": 5,
        "datawe": 1,
        "olympus": 2,
        "acqui": 1,
        "sition": 1,
        "accompany": 1,
        "objective": 2,
        "filters": 1,
        "aperio": 1,
        "scanscope": 1,
        "xt": 1,
        "planapochromatic": 1,
        "step": 1,
        "affect": 3,
        "uncertainty": 1,
        "tothe": 1,
        "find": 1,
        "thereafter": 1,
        "gaussianlike": 1,
        "generate": 2,
        "make": 3,
        "column": 4,
        "andapply": 1,
        "whichassumes": 1,
        "lightsource": 1,
        "polymer": 1,
        "commonly": 1,
        "flowchart": 1,
        "obey": 2,
        "lawas": 1,
        "rather": 3,
        "suggestremoval": 1,
        "colordecomposition": 1,
        "sogavrilovic": 1,
        "absorbing": 2,
        "dominant": 3,
        "ispoissondistributed": 1,
        "create": 2,
        "distinct": 1,
        "peak": 2,
        "signaltonoise": 2,
        "ratio": 1,
        "densityareas": 1,
        "tend": 1,
        "spurious": 1,
        "level": 6,
        "noisehas": 1,
        "effect": 2,
        "white": 4,
        "usedto": 1,
        "aid": 2,
        "distinctpeaks": 1,
        "calibrate": 1,
        "ab": 1,
        "ki": 1,
        "ea": 1,
        "dad": 1,
        "kf": 1,
        "ampli": 2,
        "gain": 2,
        "perceive": 1,
        "usethese": 1,
        "colorsample": 1,
        "deviation": 4,
        "dark": 4,
        "frame": 3,
        "measurements": 2,
        "quantization": 2,
        "ei": 1,
        "root": 2,
        "quantiza": 1,
        "precise": 1,
        "important": 2,
        "highsignaltonoise": 1,
        "ofthe": 1,
        "become": 1,
        "gen": 1,
        "erate": 1,
        "cloud": 4,
        "approximate": 1,
        "poisson": 2,
        "previous": 1,
        "via": 1,
        "numberof": 1,
        "factor": 1,
        "weight": 1,
        "assign": 1,
        "scoreu": 1,
        "gah": 1,
        "cs": 1,
        "rt": 1,
        "tu": 1,
        "random": 1,
        "variable": 1,
        "drawn": 1,
        "uniform": 1,
        "bution": 1,
        "back": 1,
        "originalmeasurements": 1,
        "retain": 1,
        "score": 2,
        "randomization": 1,
        "whenweighting": 1,
        "otherwise": 1,
        "selection": 2,
        "would": 3,
        "equivalent": 1,
        "thresholding": 1,
        "omitweaker": 1,
        "sec": 1,
        "increasing": 1,
        "reach": 2,
        "five": 2,
        "seven": 2,
        "exper": 1,
        "iments": 1,
        "discuss": 2,
        "earlier": 2,
        "fit": 1,
        "planethe": 1,
        "thereference": 1,
        "lineardecomposition": 1,
        "rice": 1,
        "required": 1,
        "separability": 2,
        "orpiecewise": 1,
        "oneagainstone": 1,
        "suchas": 1,
        "fisher": 3,
        "criterion": 5,
        "well": 3,
        "lowerfisher": 1,
        "bad": 1,
        "cluste": 1,
        "oneagainstoneseparable": 1,
        "thereis": 1,
        "oneag": 1,
        "ainstall": 1,
        "simplelinear": 1,
        "xperimental": 1,
        "results": 1,
        "qualitative": 5,
        "compar": 1,
        "isons": 1,
        "four": 2,
        "importance": 1,
        "begin": 1,
        "howwe": 1,
        "validation": 2,
        "staining": 1,
        "ed": 1,
        "em": 1,
        "sm": 1,
        "xa": 1,
        "da": 2,
        "ob": 1,
        "dt": 3,
        "es": 1,
        "nents": 1,
        "degree": 1,
        "word": 1,
        "viceversa": 1,
        "adjoin": 1,
        "prostatetissue": 4,
        "alone": 5,
        "pick": 4,
        "of990": 1,
        "vectors": 1,
        "hema": 1,
        "toxylin": 1,
        "stroma": 2,
        "colorvectors": 1,
        "sections": 1,
        "thatthe": 1,
        "parti": 1,
        "cularly": 1,
        "dif": 1,
        "ferent": 1,
        "thisdemonstrates": 1,
        "necessity": 1,
        "usingthe": 1,
        "onlymanually": 1,
        "tissuetype": 1,
        "series": 1,
        "fields": 7,
        "view": 11,
        "please": 1,
        "asa": 1,
        "guide": 1,
        "knownto": 1,
        "primarily": 1,
        "inwhat": 1,
        "ineach": 1,
        "fie": 2,
        "fv": 2,
        "vg": 1,
        "fov": 2,
        "truthreference": 1,
        "particular": 2,
        "makeup": 1,
        "using": 2,
        "ourfirst": 1,
        "mixingmatrices": 1,
        "thetotal": 2,
        "matri": 2,
        "calculation": 1,
        "compute": 1,
        "illustrate": 2,
        "experiment": 2,
        "thfield": 1,
        "trace": 1,
        "randomly": 2,
        "icawith": 1,
        "margin": 1,
        "stainedwith": 1,
        "rowlabeled": 1,
        "isle": 1,
        "stainscan": 1,
        "attribute": 1,
        "quality": 3,
        "thesections": 1,
        "minor": 1,
        "experttable": 1,
        "ofmixing": 1,
        "robustness": 1,
        "respect": 1,
        "fferent": 1,
        "tell": 2,
        "whole": 3,
        "story": 2,
        "othercolor": 1,
        "stability": 1,
        "tests": 1,
        "eachstained": 1,
        "modelthe": 1,
        "zation": 1,
        "rootmeansquare": 1,
        "wo": 1,
        "fa": 1,
        "thevisual": 1,
        "appearance": 1,
        "bleed": 1,
        "notice": 2,
        "bleedthrough": 1,
        "direction": 1,
        "delineate": 1,
        "ga": 1,
        "segmentation": 1,
        "gland": 1,
        "easier": 1,
        "densitymap": 1,
        "mention": 1,
        "early": 1,
        "sincegavrilovic": 1,
        "trans": 1,
        "ferred": 1,
        "qualitativeexample": 1,
        "identical": 3,
        "ns": 1,
        "nv": 1,
        "ba": 1,
        "box": 3,
        "preprocessing": 1,
        "manual": 1,
        "extracted": 1,
        "complete": 1,
        "bo": 1,
        "pa": 1,
        "rameter": 1,
        "ficance": 1,
        "inverse": 1,
        "clinical": 1,
        "initialize": 1,
        "imple": 1,
        "mented": 1,
        "convergence": 1,
        "residual": 1,
        "change": 1,
        "byless": 1,
        "iteration": 1,
        "replicates": 1,
        "assumed": 1,
        "hyperbolic": 1,
        "tangent": 1,
        "nongaussian": 1,
        "shows992": 1,
        "bind": 1,
        "challenge": 1,
        "fo": 1,
        "algorithms": 1,
        "becomes": 1,
        "accurately": 1,
        "detect": 1,
        "strong": 1,
        "giemsa": 1,
        "bcdgive": 1,
        "satisfactory": 1,
        "herovici": 2,
        "stomachtissue": 1,
        "experimental": 1,
        "performs": 1,
        "boththe": 1,
        "evaluation": 1,
        "suitable": 1,
        "correlate": 1,
        "itsprobability": 1,
        "forthe": 2,
        "bl": 1,
        "adder": 1,
        "conclude": 1,
        "isoutperformed": 1,
        "strat": 1,
        "egies": 1,
        "approach": 1,
        "comparisonas": 1,
        "eference": 1,
        "manner": 1,
        "mixingmatrix": 1,
        "perform": 2,
        "accord": 1,
        "right": 1,
        "easy": 1,
        "decompositiongives": 1,
        "ofcollagen": 1,
        "connective": 1,
        "answer": 1,
        "collagenthe": 1,
        "act": 1,
        "quantitati": 1,
        "erythrocyte": 2,
        "andspatially": 1,
        "ficients": 1,
        "correla": 1,
        "co": 1,
        "mparisons": 1,
        "gpiecewise": 1,
        "lymphocyte": 1,
        "ld": 1,
        "pwld": 1,
        "16fields": 1,
        "vi": 1,
        "iscussion": 1,
        "conclusion": 1,
        "physicalmodel": 1,
        "quantitativelygavrilovic": 1,
        "sults": 1,
        "observe": 1,
        "particularly": 1,
        "oncentrations": 1,
        "concentra": 1,
        "towards": 1,
        "biochem": 1,
        "ical": 1,
        "originate": 1,
        "signaturesof": 1,
        "perfect": 1,
        "colortheory": 1,
        "referenc": 1,
        "compact": 1,
        "oversaturation": 1,
        "addition": 1,
        "enable": 1,
        "fica": 1,
        "measur": 1,
        "ing": 1,
        "romaticity": 1,
        "detected": 1,
        "shortcoming": 1,
        "fail": 1,
        "orthe": 1,
        "andimaging": 1,
        "artifact": 1,
        "obscure": 1,
        "polymers": 1,
        "lightand": 1,
        "hence": 1,
        "beerl": 1,
        "ambert": 1,
        "darkly": 1,
        "lightly": 1,
        "bylight": 1,
        "mo": 1,
        "rphological": 1,
        "highly": 1,
        "lend": 1,
        "processing": 1,
        "usingwellknown": 1,
        "extracting": 1,
        "distinguish": 1,
        "normal": 1,
        "cknowledgment": 1,
        "like": 1,
        "thank": 1,
        "larsson": 1,
        "hospital": 1,
        "prepare": 1,
        "authors": 1,
        "grateful": 1,
        "curi": 1,
        "anal": 1,
        "ysis": 1,
        "valuable": 1,
        "discussion": 1,
        "marzetta": 1,
        "bell": 1,
        "laboratories": 1,
        "nj": 1,
        "forhis": 1,
        "help": 1
    },
    "objective": [
        "we present a blind method forcolor decomposition of histological image ."
    ],
    "references": [
        "",
        "R EFERENCES [1] J. I. Epstein, W. C. Allsbrook, Jr., M. B. Amin, and L. Egevad, “Update on the Gleason grading system for prostate cancer: Results of an in-ternational consensus conference of urologic pathologists,” Adv. Anat. Pathol. , vol. 13, no. 1, pp. 57–59, Jan. 2006. [2] M. Uhlen, P. Oksvold, L. Fagerberg, E. Lundberg, K. Jonasson, M. Forsberg, M. Zwahlen, C. Kampf, K. Wester, H. Wernerus, L. Björling,and F. Ponten, “Towards a knowledge-based Human Protein Atlas,”Nature Biotech. , vol. 28, pp. 1248–1250, 2010. [3] A. Tabesh, M. Teverovskiy, H. Pang, V. P. Kumar, D. Verbel, A. Kotsianti, and O. Saidi, “Multifeature prostate cancer diagnosis andGleason grading of histological images,” IEEE Trans. Med. Imag. , vol. 26, no. 10, pp. 1366–1378, Oct. 2007.[ 4 ] Y .G a r i n i ,I .T .Y o u n g ,a n dG .M c N amara, “Spectral imaging: Princi- ples and applications,” Cytometry Part A. , vol. 69A, pp. 735–747, Aug. 2006. [5] J. C. Mullikin, L. J. van Vliet, H. Netten, F. R. Boddeke, G. van der Feltz, and I. T. Young, “Methods fo r CCD camera characterization,” Proc. SPIE Image Acquis. Sci. Imag. Syst. , vol. 2173, pp. 73–84, 1994. [6] G. Polder and G. W. van der Heijden, “Calibration and characteriza- tion of spectral imaging systems,” Proc. SPIE Multisp. Hypersp. Image Acquis. , vol. 4548, pp. 10–17, 2001. [7] K. R. Castleman, R. Eils, L. Morrison, J. Piper, K. Saracoglu, M. A. Schulze, and M. R. Speicher, “Classi ﬁcation accuracy in multiple color ﬂuorescence imaging microscopy,” Cytometry , vol. 41, no. 2, pp. 139–147, Sept. 2000. [ 8 ]N .K e s h a v aa n dJ .F .M u s t a r d ,“ S p e c t r a lu n m i x i n g , ” IEEE Signal Process. Mag , vol. 19, no. 1, pp. 44–57, Jan. 2002. [9] R. M. Levenson, “Spectral imaging perspective on cytomics,” Cytom- etry Part A , vol. 69A, pp. 592–600, Jul. 2006. [10] L. E. Boucheron, Z. Bi1, N. R. Harvey, B. Manjunath, and D. L. Rimm, “Utility of multispectral imaging for nuclear classi ﬁcation of routine clinical histopathology imagery,” BMC Cell Biol. , vol. 8, no. S8, Jul. 2007. [11] W. W. Parson , Modern Optical Spectroscopy , 2nd ed. Berlin-Heidel- berg, Germany: Springer, 2009, pp. 3–26. [12] C. M. van der Loos, “Multiple immunoenzyme staining: Methods and visualizations for the observation with spectral imaging,” J. Histochem. Cytochem. , vol. 56, no. 4, pp. 313–328, Apr. 2008. [13] Q. Wu, F. Merchant, and K. Castleman , Microscope Image Processing , 1st ed. New York: Academic, 2008, pp. 299–323. [14] A. Webb , Statistical Pattern Recognition , 2nd ed. Chichester, U.K.: Wiley, 2002, pp. 124–158, 362–370. [15] G. Gömöri, “A rapid one-step trichrome stain,” Am. J. Clin. Pathol. , vol. 20, no. 7, pp. 661–664, July 1950. [16] M. Gamble, “The Hematoxylins and Eosin,” in Theory and Practice of Histological Techniques , J. D. Bancroft and M. Gamble, Eds., 6th ed. Philadelphia, PA: Churchill Livingston Elsevier, 2008, pp. 121–134. [17] C. Herovici, “A polychrome stain for differentiating precollagen from collagen,” Biotechnic Histochemistry , vol. 38, no. 3, pp. 204–206, 1963. [18] G. Giemsa, “ Eine Vereinfachung und Vervollkommnung meiner Methylenazur-Methylenblau-Eosin-Färbemethode zur Erzielung derRomanowsky-Nocht’schen Chromatinfärbung,” Centralblatt für Bakteriologie , vol. 37, pp. 308–311, 1904. [19] K. Nguyen, A. K. Jain, and R. L. Allen, “Automated gland segmenta- tion and classi ﬁcation for Gleason grading of prostate tissue images,” inProc. 20th Int. Conf Pattern Recognit. , 2010, pp. 1497–1500. [20] A. Janowczyk, S. Chandran, R. Singh, D. Sasaroli, G. Coukos, M. D. Feldman, and A. Madabhushi, “Hierarchical normalized cuts: Un- supervised segmentation of vascula r biomarkers from ovarian cancer tissue microarrays,” Med. Image Comput. Comput. Assist. Interv. , vol. 12, no. 1, pp. 230–238, 2009. [21] A. C. Ruifrok and D. A. Johnston, “Quanti ﬁcation of histochemical staining by color deconvolution,” Anal Quant. Cytol. Histol. , vol. 23, no. 4, pp. 291–299, Aug. 2001. [22] K. R. Castleman, “Concepts in imaging and microscopy: Color image processing for microscopy,” Biol. Bull. , vol. 194, pp. 100–107, Apr. 1998. [23] A. Rabinovich, S. Agarwal, C. Laris, J. H. Price, and S. Belongie, “Un- supervised color decomposition of histologically stained tissue sam-ples,” Proc. Adv. Neur. Info. Process. Syst. , pp. 667–674, 2003. [24] G. Begelman, M. Zibulevsky, E. Rivlin, and T. Kolatt, “Blind decom- position of transmission light microscopic hyperspectral cube usingsparse representation,” IEEE Trans. Med. Imag. , vol. 28, no. 8, pp. 1317–1324, Aug. 2009. [25] J. Newberg and R. F. Murphy, “A framework for the automated anal- ysis of subcellular patterns in Human Protein Atlas images,” J. Pro- teome Res. , vol. 7, no. 6, pp. 2300–2308, Jun. 2008. [26] A. Tabesh and M. Teverovskiy, “Tumor classi ﬁcation in histological images of prostate using color texture,” in Proc. 40th Asilomar Conf. Signals, Syst. Comput. , 2006, pp. 841–845. [27] H. Choi, K. R. Castleman, and A. Bovik, “Color compensation of mul- ticolor FISH images,” IEEE Trans. Med. Imag. , vol. 28, no. 1, pp. 129–136, Jan. 2009. [28] F. A. Kruse, A. B. Lefkoff, J. W. Boardman, K. B. Heidebrecht, A. T .S h a p i r o ,P .J .B a r l o o n ,a n dA .F .H .G o e t z ,“ T h es p e c t r a li m a g eprocessing system (SIPS)—Interac tive visualization and analysis of imaging spectrometer data,” Remote Sens. Environ. ,v o l .4 4 ,n o .2 – 3 , pp. 145–163, Aug. 1993.994 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 32, NO. 6, JUNE 2013 [29] M. Gavrilovic and C. Wählby, “Quanti ﬁcation of colocalization and cross-talk based on spectral angles,” J. Microscopy , vol. 234, no. 3, pp. 311–324, June 2009. [30] B. Nielsen, F. Albregtsen, and H. E. Danielsen, “Statistical nuclear texture analysis in cancer research: A review of methods and appli-cations,” Crit. Rev. Oncog. , vol. 14, no. 2–3, pp. 89–164, 2008. [31] I. T. Young, P. W. Verbeek, and B. H. Mayall, “Characterization of chromatin distribution in cell nuclei,” J. Cytometry , vol. 7, no. 5, pp. 467–474, Sept. 1986. [32] N. Sladoje and J. Lindblad, “High-precision boundary length estima- tion by utilizing gray-level information,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 2, pp. 357–363, Feb. 2009. [33] A. Koschan and M. Abidi , Digital Color Image Processing ,1 s te d . Hoboken, NJ: Wiley, 2008, pp. 71–96. [34] J. C. Maxwell, “On the theory of compound colours, and the relations of the colours of the spectrum,” Phil. Trans. R. Soc. Lond. , vol. 150, pp. 57–84, Jan. 1860.[35] D. E. Judd, “A Maxwell triangle yielding uniform chromaticity scales,” J. Opt. Soc. Am. , vol. 25, no. 1, pp. 24–35, 1935. [36] J. Foley, A. van Dam, S. Feiner, and J. Hughes , Computer Graphics: Principles and Practice , 2nd ed. Reading, MA: Addison-Wesley, 1996, pp. 213–281, in C. [37] P. Stoica and P. Babu, “The Gaussian data assumption leads to the largest Cramér-Rao bound,” IEEE Signal Process. Mag. , vol. 28, no. 3, pp. 132–133, May 2011. [ 3 8 ] A .G e r s h oa n dR .M .G r a y , Vector Quantization and Signal Compres- sion, 1st ed. Norwell, MA: Kluwer, 1992, pp. 133–171. [39] P. Soille , Morphological Image Analysis, Principles and Applications , 2nd ed. Berlin, Germany: Springer, 2004. [40] M. B. Amin, D. J. Grignon, P. A. Humphrey, and J. R. Srigley , Gleason Grading of Prostate Cancer , 1st ed. Philadelphia, PA: Lippincott Williams Wilkins, 2004."
    ]
}{
    "name": "Combining Collective and Artificial Intelligence for Global Health Diseases Diagnosis Using Crowdsourced Annotated Medical Images",
    "paragraphs": [
        "combining collective and artiﬁcial intelligence for global health disease diagnosis use crowdsourced annotated medical image lin liny ; 1 ; 2 , david bermejo-peláezy ; 1 , daniel capellán-martín1 , daniel cuadrado1 cristina rodríguez1 , lydia garcía1 , nuria díez1 , rocío tomé1 mar´ıa postigo1 , maría jesús ledesma-carbayo2 , miguel luengo-oroz1 abstract — visual inspection of microscopic sample be still the gold standard diagnostic methodology for many global health disease .",
        "soil-transmitted helminth infection affect 1.5 billion people worldwide , and be the most prevalent disease among the neglected tropical diseases .",
        "it be diagnose by manual examination of stool sample by microscopy , which be a time-consuming task and require trained personnel and high specialization .",
        "artiﬁcial intelligence could automate this task make the diagnosis more accessible .",
        "still , it need a large amount of annotated training data come from expert .",
        "in this work , we propose the use of crowdsourced annotate medical image to train ai model ( neural network ) for the detection of soil-transmitted helminthiasis in microscopy image from stool sample leverage non-expert knowledge collect through play a video game .",
        "we collect annotation make by both school-age child and adult , and we show that , although the quality of crowdsourced annotation make by school-age child be sightly inferior than the one make by adult , ai model train on these crowdsourced annotation perform similarly ( auc of 0.928 and 0.939 respectively ) , and reach similar performance to the ai model train on expert annotation ( auc of 0.932 ) .",
        "we also show the impact of the training sample size and continuous training on the performance of the ai model .",
        "in conclusion , the workﬂow propose in this work combine collective and artiﬁcial intelligence for detect soil-transmitted helminthiasis .",
        "embedded within a digital health platform can be apply to any other medical image analysis task and contribute to reduce the burden of disease .",
        "i .",
        "introduction achieving universal health coverage by 2030 be one of the sustainable development goals and world health orga- nization priority ( who ) [ 1 ] .",
        "half the world ’ s population lack access to essential health service and diagnosis be a key step to achieve universal healthcare .",
        "many of those disease be diagnose by visual inspection , which require expert in front of the microscope and other medical device at a certain time , a resource that be not always available .",
        "artiﬁcial intelligence ( ai ) present an opportunity to sup- port these diagnostic process .",
        "the number of ai-based medical device for diagnosis be increase .",
        "from 2015 to 2020 , 222 ai device be approve in usa and 240 in europe [ 2 ] .",
        "most of them be develop for radiology and cardiovascular disease , and none of them be for microscopy 1spotlab sl , madrid , spain 2biomedical image technologies , etsi telecomunicación , universidad politécnica de madrid & ciber-bbn , madrid , spain yll and dbp contribute equally to this work and be consider co-ﬁrst authors.applied to microbiology .",
        "recently a few algorithm be train to detect malaria ’ s parasites [ 3 ] , [ 4 ] and helminth ’ s egg in fecal sample [ 5 ] – [ 7 ] , show the potential of ai algorithm for microscopic image .",
        "notwithstanding the above , more study be need to create algorithm approve by regulatory institution .",
        "soil-transmitted helminthiasis ( sth ) be a neglected trop- ical disease ( ntd ) that affect the poor and most de- prived community .",
        "according to who ’ s report , there be 1.5 billion people affect by helminths worldwide .",
        "who establish a roadmap to eliminate sth to reduce the global health burden .",
        "to accelerate the elimination , innovation and new technology like ai be need [ 8 ] .",
        "the recommended diagnosis method for sth be kato katz , which be a laboratory method for prepare stool sample for the late detection and quantiﬁcation of sth egg under a microscope [ 9 ] .",
        "image annotation to train ai model be a time-consuming labour that pose an important burden into expert .",
        "however , in recent year , the use of crowdsourcing have be propose to overcome this problem by delegate this task on a large group of untrained annotator .",
        "several study have already demonstrate the validity of the use of crowdsourcing for annotate medical image .",
        "in 2012 , luengo-oroz et .",
        "al demonstrate that the combination of the annotation collect use a video game of 22 player achieve a malaria parasite count accuracy high than 99 % in thick malaria smear [ 10 ] .",
        "in 2019 , linares et .",
        "al demonstrate that combined annotation form 25 player be able to distinguish most malaria specie with an accuracy of 99 % [ 11 ] .",
        "furthermore , keshavan et .",
        "al combine crowdsourcing and deep learning ( dl ) to predict the quality of magnetic resonance imaging [ 12 ] .",
        "within this context , this work propose a methodology to train dl algorithm for quantify parasitic infection in microscopy image with the follow objective : 1 ) to assess the feasibility of train dl algorithm for the differentiation of helminth egg base on microscopy im- age with annotation obtain from crowdsourcing use a custom video game , 2 ) to identify the relationship between the amount of training data and the deep learning model performance use incremental training and 3 ) to compare the performance of ai model train with data annotate by both untrained school-age child and adult ( general population ) .2021 43rd annual international conference of the ieee engineering in medicine & biology society ( embc ) oct 31 - nov 4 , 2021 .",
        "virtual conference this work be license under a creative commons attribution 3.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/3.0/3344ii .",
        "methodology a. crowdsourcing image annotation we develop spotwarriors ( sw ) , a publicly available1 set of mini-games that contribute to the diagnosis of dis- eas while play , by generate crowdsourced annotated medical image .",
        "for the purpose of this project , we focus on a mini-game for the classiﬁcation of small image patch from digitized stool sample for the identiﬁcation of differ- ent helminth egg , include ascaris spp.",
        ", trichuris spp.",
        ", hookworms , and image without egg .",
        "figure 1 show a screenshot of the game use .",
        "all data use in this study for training , validation and testing of the ai algorithm come from 41 digitized stool sample from 6 different infect patient who be part of a follow-up study .",
        "digitization of sample be make at 10x magniﬁcation .",
        "ethical approval be obtain from the kenya medical research institute ( kemri ) ethics review committee ( seru 3873 ) .",
        "from all digitize sample , we generate a total of 10319 cropped image patch ( 256x256 pixel ) without overlap .",
        "our interpretation be that all image patch can be consider as independent although they come from a limited number of subject .",
        "we introduce 700 randomly select image patch in the video game which be annotate by at least 20 adult and 20 school-age child ( from 11 to 18 year old ) player .",
        "these annotated image be use for train dl algorithm .",
        "for comparative purpose , and to assess the quality of crowdsourced annotation , these training image be also analyze by expert microscopist .",
        "annotations from school-age child be obtain by organize workshop in different school .",
        "the workshop , present in collaboration with the teacher , include an explanation of the project and concept relate to global health , artiﬁcial intelligence and collective intelligence in addition to play the game .",
        "data from adult be collect anonymously from online player .",
        "additionally , the remain image be annotate by expert and be use as validation and test set ( 2932 and 6678 image respectively , randomly separate ) .",
        "for crowdsourced annotated image , the ground truth ( gt ) be generate use the majority voting rule , where the most common response among player be choose .",
        "the ﬁnal distribution for the training set ( those image introduce in the game ) , validation set , and test set be present in table i .",
        "b. ai architecture : deep learn model in the present work , we use a convolutional neural net- work ( cnn ) -based algorithm to solve the classiﬁcation task for differentiate helminth egg along with non infect sample image .",
        "the algorithm , give an image , return an output probability distribution along the different class under study , and the ﬁnal predict label be then compute as the one that have the high probability .",
        "particularly , we use 1https : //spotwarriors.org/en/ , also available at google play store and apple app store .",
        "fig .",
        "1 : screenshot of the mini-game use to collect data with ascaris spp .",
        "( leave ) and trichuris spp .",
        "( right ) train validation test e sac a e e ascaris spp .",
        "179 182 176 1258 2819 trichuris spp .",
        "212 198 211 241 570 healthy 309 320 313 1433 3298 total 700 700 700 2932 6687 table i : distribution of the training , validation and test set .",
        "training image be annotate by three group : expert ( e ) , school-age child ( sac ) and adult ( a ) .",
        "the mobilenet v2 model [ 13 ] , a light-weighted architecture design to run on mobile phone in an efﬁcient manner .",
        "this particular architecture have three main component include depthwise convolution that signiﬁcantly reduce the number of parameter , invert residual connection block which modify residual block for efﬁciency purpose , and linear bottleneck layer without any non-linear activation function in order to preserve information in the low dimensional space .",
        "mobilenet v2 architecture be compose by 157 layer and involve only 3.5 million of parameter , compare to the 138,4 million of parameter that be involve in the well know vgg-16 architecture along its 23 layer [ 14 ] .",
        "to overcome the limitation of have a small training dataset , we use a transfer learning technique by pretraining the mobilenet v2 model on a large dataset ( imagenet [ 15 ] ) and ﬁne-tuning it in our dataset for the classiﬁcation of helminth egg .",
        "fine-tuning be perform by freeze the early layer which learn generic feature , and retrain late layer , responsible for extract speciﬁc feature of the problem under study .",
        "using this technique we can reduce the computational cost and result in good performance than train from scratch , specially when little training data be available .",
        "because crowd-sourced annotation usually contain some incorrect label , we use soft bootstrapping cross entropy loss function , which minimize the damage of incorrect label by dynamically update the target of the prediction base on the actual state of the model [ 16 ] .",
        "the loss function be deﬁned as equation 1 , where qis the prediction , tis the target , be the scale factor between prediction and targets3345andlis the number of class under study .",
        "lsoft ( q ; t ) =lx k=1 [ tk+ ( 1\u0000 ) qk ] log ( qk ) ( 1 ) furthermore , we use data augmentation include rota- tion , shift , ﬂip , zoom , and shear transformation to generate more training data to further improve the model performance .",
        "additionally , we also use early stopping technique during the training process with a patience of 10 iteration to avoid overﬁtting on the training set .",
        "dl model be design and train use keras with tensorﬂow , and use a gpu nvidia tesla t4 16gb .",
        "iii .",
        "e xperiments and results in this section , we ﬁrst evaluate the quality of crowd- sourced annotation use a majority voting mechanism .",
        "we continue with the study of the effect of the training sample size on the performance of the model .",
        "and ﬁnally we compare the dl model train with school-age child and adult annotation .",
        "to evaluate the quality of crowdsourced annotation , we use the accuracy metric , which be deﬁned as acc =tp+ tn=n where tp , tn and n stand for true positive , true negative and total number of sample respectively .",
        "we use the area under the receiver operate charac- teristic curve ( auc ) for evaluate the performance of dl algorithm .",
        "auc measure the performance of the model across all possible probability threshold .",
        "macro-average auc along class be compute in order to avoid bias due to imbalanced class distribution .",
        "in order to obtain a robust metric not affect by train instability , we repeat the training process 5 time , and calculate the mean and standard deviation of the perfor- mance metric .",
        "the training of the model be carry out use the training set while the validation set be use for hyperparameter tuning .",
        "the incremental training experiment and the ﬁnal performance evaluation be assess on the test set .",
        "it should be note that we do not include hookworm class in the analysis due to the lack of representativity in our database .",
        "no preprocessing be make on the image .",
        "a .",
        "quality of crowdsourced annotation in order to select the optimal size of the quorum that best performs in comparison with the expert annotation , we use a bootstrap sample method .",
        "for each image , we generate the ﬁnal annotation use the majority voting rule consider only n randomly select annotation .",
        "to measure the stability of each quorum size ( n ) we repeat this process 10 time .",
        "table ii show the difference on the quality of crowdsourced annotation use different quorum size , by compare the generate annotation by player and annotation make by expert .",
        "as derive from the table , we can observe that annotation base on 20 different player response obtain the best performance .",
        "even though adult annotation obtain well accuracy with respect to expert annotation , annotation from 20school-age child be find to be of enough quality ( accuracy > 94 % ) .",
        "quorum size ( n ) school-age child adults 5 0.842 ( 0.007 ) 0.966 ( 0.004 ) 10 0.910 ( 0.006 ) 0.988 ( 0.002 ) 15 0.931 ( 0.005 ) 0.989 ( 0.003 ) 20 0.946 ( 0.004 ) 0.991 ( 0.002 ) table ii : mean accuracy and the standard deviation of crowdsourced annotation use different quorum size com- par to the one make by expert .",
        "b. dl model : hyperparameter tune mobilenet v2 be build on different block .",
        "to determine the optimal number of layer to be ﬁne-tuned during transfer process , we freeze a determined number of block and ﬁne- tune the rest .",
        "for this experiment , model be train with expert annotation .",
        "furthermore , with the aim of evaluate the effectiveness of soft bootstrapping loss for noisy label , and to select the best loss function for this particular case study , we train the dl model use both conventional cross entropy and soft bootstrapping cross entropy ( = 0:95 ) loss function .",
        "models be train with school-age child and adult annotation ( expert annotation do not contain noisy label ) .",
        "as derive from table iii , the best performance be obtain when the ﬁrst 46 layer be not ﬁne-tuned and when bootstrap categorical cross entropy be use as the loss function .",
        "hyperparameter auc number of frozen layer 19 ( block 2 ) 0.873 ( 0.033 ) 46 ( block 5 ) 0.919 ( 0.019 ) 73 ( block 8 ) 0.914 ( 0.014 ) 99 ( block 11 ) 0.917 ( 0.011 ) loss function childrencross entropy 0.927 ( 0.007 ) bootstrapping cross entropy 0.932 ( 0.006 ) adultscross entropy 0.911 ( 0.014 ) bootstrapping cross entropy 0.925 ( 0.016 ) table iii : hyperparameter selection .",
        "mean auc and stan- dard deviation be show .",
        "c. incremental training to study the effect of train sample size on the model performance we train the model incrementally use dif- ferent sample size .",
        "we perform this incremental training by step of 100 training image from 100 to 700 .",
        "figure 2 show the result of the incremental training ex- periment , reveal the importance of the number of sample use for training and its impact on the model performance .",
        "d. differences between annotator group we compare the performance of the ai model train with school-age child , adult and expert annotation .",
        "table iv summarize the result of the three model use all available training sample ( n=700 ) .",
        "the result show that all3346fig .",
        "2 : evolution of the model performance ( auc ) as the training sample size increase .",
        "results from data annotate by child , adult and expert be present independently .",
        "model perform similarly , highlight the power of the use of crowdsourced annotation which obtain similar result when compare to the one obtain by the model train on expert-based annotation .",
        "it should be note that although the quality of school-age child annotation be low than the one collect by adult ( difference of 4.5 % in the accuracy , see table ii ) , the ai algorithm be robust to noisy label and decrease the difference in term of the model performance ( 0.9 % ) .",
        "auc experts adults children ascaris spp .",
        "0.960 ( 0.003 ) 0.958 ( 0.007 ) 0.948 ( 0.002 ) trichuris spp .",
        "0.912 ( 0.002 ) 0.926 ( 0.015 ) 0.912 ( 0.026 ) healthy 0.924 ( 0.019 ) 0.932 ( 0.010 ) 0.923 ( 0.008 ) mean 0.932 ( 0.015 ) 0.939 ( 0.01 ) 0.928 ( 0.012 ) table iv : detailed performance of the dl algorithm train with different annotation .",
        "mean auc and standard deviation be report .",
        "figure 3 show the prediction result of the model on different image from the test set , include the three class under study ( ascaris spp.",
        ", trichuris spp .",
        "and healthy ) .",
        "in addition , we compute the gradient-weighted class activation mapping ( grad-cam ) to visualize the the region in the image that be important for the model to make the decision [ 17 ] .",
        "iv .",
        "conclusions this work show promise result on the use of crowd- source annotation for the development of ai-based diagno- si system , and validate its use in the medical image ﬁeld , where manual annotation from expert be a time-consuming labour , and require high specialization .",
        "in this work , we collect crowdsourced annotation by use a customized video game to classify different specie of helminths egg , and use these annotation to train a cnn architecture ( mobilenet v2 ) .",
        "particularly , we obtain crowdsourced annotation from both untrained school-age child and adult , and the result show that dl model train on those annotation perform in a similar manner fig .",
        "3 : examples of image sample represent all class under study ( upper row ) along whit its activation map generate by the dl algorithm ( bottom row ) .",
        "correct label ( gt ) as well as prediction ( pred ) appear above each image .",
        "activation map for healthy sample ( hea ) focus on the entire image with no signiﬁcant activation , while activation map for ascaris spp .",
        "( asc ) and trichuris spp .",
        "( tri ) focus exactly on the egg location .",
        "compare to the one train with expert annotation ( auc of 0.928 , 0.939 and 0.932 for child , adult and expert annotation respectively ) .",
        "no signiﬁcant difference in the model performance be find when used child , adult or expert annotation .",
        "on the other hand , we show the impact of the training sample size on the performance of the ai model .",
        "we show that we obtain good performance as the training sample size increase .",
        "in particular , model performance increase approximately by a factor of 20 % when train on all available sample ( 700 ) compare to the result obtain when only 100 image be use for training .",
        "as derive from this experiment , we can conclude that we could train our dl model in an iterative manner as we obtain more image annotate by player , and thus obtain a more robust algorithm with a well predictive capacity .",
        "additionally , this work lay the foundation for the use of video game as data enrichment platform to automate and scale the medical image label process use human collective intelligence , enhance human relevance in the process of develop ai algorithm .",
        "environmental impact in this study a cumulative of 43 hour of computation be perform on gpu ( tesla t4 ) , which 20 hour contribute to obtain the ﬁnal result .",
        "the total emission , estimate by machinelearning impact calculator present in [ 18 ] , be 0.9 kg of co 2 .",
        "virtual machine that host our spotwarriors game be estimate to emit 0.39 kg co2eq per month .",
        "acknowledgments this project be grant by nesta ( innovation foundation ) and support by red.es and feder ( 2018/c003/00010900 ” impulso al sector del videojuego ” ) to develop spotwarrios .",
        "ll and upm member be support by the industrial doc- torate program of the community of madrid ( ind2019/tic- 17167 ) .",
        "we thank all school that allow us to organize workshop to collect annotation by use spotwarriors game.3347"
    ],
    "processed_text": "combining collective artificial intelligence global health disease diagnosis use crowdsourced annotated medical image lin liny 1 2 david bermejopelaezy 1 daniel capellanmartin1 daniel cuadrado1 cristina rodriguez1 lydia garcia1 nuria diez1 rocio tome1 mar postigo1 maria jesus ledesmacarbayo2 miguel luengooroz1 abstract visual inspection microscopic sample still gold standard diagnostic methodology many global health disease soiltransmitted helminth infection affect 15 billion people worldwide prevalent disease among neglected tropical diseases diagnose manual examination stool sample microscopy timeconsuming task require trained personnel high specialization artificial intelligence could automate task make diagnosis accessible still need large amount annotated training data come expert work propose use crowdsourced annotate medical image train ai model neural network detection soiltransmitted helminthiasis microscopy image stool sample leverage nonexpert knowledge collect play video game collect annotation make schoolage child adult show although quality crowdsourced annotation make schoolage child sightly inferior one make adult ai model train crowdsourced annotation perform similarly auc 0928 0939 respectively reach similar performance ai model train expert annotation auc 0932 also show impact training sample size continuous training performance ai model conclusion workflow propose work combine collective artificial intelligence detect soiltransmitted helminthiasis embedded within digital health platform apply medical image analysis task contribute reduce burden disease introduction achieving universal health coverage 2030 one sustainable development goals world health orga nization priority 1 half world population lack access essential health service diagnosis key step achieve universal healthcare many disease diagnose visual inspection require expert front microscope medical device certain time resource always available artificial intelligence ai present opportunity sup port diagnostic process number aibased medical device diagnosis increase 2015 2020 222 ai device approve usa 240 europe 2 develop radiology cardiovascular disease none microscopy 1spotlab sl madrid spain 2biomedical image technologies etsi telecomunicacion universidad politecnica de madrid & ciberbbn madrid spain yll dbp contribute equally work consider cofirst authorsapplied microbiology recently algorithm train detect malaria parasites 3 4 helminth egg fecal sample 5 7 show potential ai algorithm microscopic image notwithstanding study need create algorithm approve regulatory institution soiltransmitted helminthiasis sth neglected trop ical disease ntd affect poor de prived community according report 15 billion people affect helminths worldwide establish roadmap eliminate sth reduce global health burden accelerate elimination innovation new technology like ai need 8 recommended diagnosis method sth kato katz laboratory method prepare stool sample late detection quantification sth egg microscope 9 image annotation train ai model timeconsuming labour pose important burden expert however recent year use crowdsourcing propose overcome problem delegate task large group untrained annotator several study already demonstrate validity use crowdsourcing annotate medical image 2012 luengooroz et al demonstrate combination annotation collect use video game 22 player achieve malaria parasite count accuracy high 99 thick malaria smear 10 2019 linares et al demonstrate combined annotation form 25 player able distinguish malaria specie accuracy 99 11 furthermore keshavan et al combine crowdsourcing deep learning dl predict quality magnetic resonance imaging 12 within context work propose methodology train dl algorithm quantify parasitic infection microscopy image follow objective 1 assess feasibility train dl algorithm differentiation helminth egg base microscopy im age annotation obtain crowdsourcing use custom video game 2 identify relationship amount training data deep learning model performance use incremental training 3 compare performance ai model train data annotate untrained schoolage child adult general population 2021 43rd annual international conference ieee engineering medicine & biology society embc oct 31 nov 4 2021 virtual conference work license creative commons attribution 30 license information see http //creativecommonsorg/licenses/by/30/3344ii methodology crowdsourcing image annotation develop spotwarriors sw publicly available1 set minigames contribute diagnosis dis eas play generate crowdsourced annotated medical image purpose project focus minigame classification small image patch digitized stool sample identification differ ent helminth egg include ascaris spp trichuris spp hookworms image without egg figure 1 show screenshot game use data use study training validation testing ai algorithm come 41 digitized stool sample 6 different infect patient part followup study digitization sample make 10x magnification ethical approval obtain kenya medical research institute kemri ethics review committee seru 3873 digitize sample generate total 10319 cropped image patch 256x256 pixel without overlap interpretation image patch consider independent although come limited number subject introduce 700 randomly select image patch video game annotate least 20 adult 20 schoolage child 11 18 year old player annotated image use train dl algorithm comparative purpose assess quality crowdsourced annotation training image also analyze expert microscopist annotations schoolage child obtain organize workshop different school workshop present collaboration teacher include explanation project concept relate global health artificial intelligence collective intelligence addition play game data adult collect anonymously online player additionally remain image annotate expert use validation test set 2932 6678 image respectively randomly separate crowdsourced annotated image ground truth gt generate use majority voting rule common response among player choose final distribution training set image introduce game validation set test set present table b ai architecture deep learn model present work use convolutional neural net work cnn based algorithm solve classification task differentiate helminth egg along non infect sample image algorithm give image return output probability distribution along different class study final predict label compute one high probability particularly use 1https //spotwarriorsorg/en/ also available google play store apple app store fig 1 screenshot minigame use collect data ascaris spp leave trichuris spp right train validation test e sac e e ascaris spp 179 182 176 1258 2819 trichuris spp 212 198 211 241 570 healthy 309 320 313 1433 3298 total 700 700 700 2932 6687 table distribution training validation test set training image annotate three group expert e schoolage child sac adult mobilenet v2 model 13 lightweighted architecture design run mobile phone efficient manner particular architecture three main component include depthwise convolution significantly reduce number parameter invert residual connection block modify residual block efficiency purpose linear bottleneck layer without nonlinear activation function order preserve information low dimensional space mobilenet v2 architecture compose 157 layer involve 35 million parameter compare 1384 million parameter involve well know vgg16 architecture along 23 layer 14 overcome limitation small training dataset use transfer learning technique pretraining mobilenet v2 model large dataset imagenet 15 finetuning dataset classification helminth egg finetuning perform freeze early layer learn generic feature retrain late layer responsible extract specific feature problem study using technique reduce computational cost result good performance train scratch specially little training data available crowdsourced annotation usually contain incorrect label use soft bootstrapping cross entropy loss function minimize damage incorrect label dynamically update target prediction base actual state model 16 loss function defined equation 1 qis prediction tis target scale factor prediction targets3345andlis number class study lsoft q =lx k=1 tk+ 1\u0000 qk log qk 1 furthermore use data augmentation include rota tion shift flip zoom shear transformation generate training data improve model performance additionally also use early stopping technique training process patience 10 iteration avoid overfitting training set dl model design train use keras tensorflow use gpu nvidia tesla t4 16gb iii e xperiments results section first evaluate quality crowd sourced annotation use majority voting mechanism continue study effect training sample size performance model finally compare dl model train schoolage child adult annotation evaluate quality crowdsourced annotation use accuracy metric defined acc =tp+ tn=n tp tn n stand true positive true negative total number sample respectively use area receiver operate charac teristic curve auc evaluate performance dl algorithm auc measure performance model across possible probability threshold macroaverage auc along class compute order avoid bias due imbalanced class distribution order obtain robust metric affect train instability repeat training process 5 time calculate mean standard deviation perfor mance metric training model carry use training set validation set use hyperparameter tuning incremental training experiment final performance evaluation assess test set note include hookworm class analysis due lack representativity database preprocessing make image quality crowdsourced annotation order select optimal size quorum best performs comparison expert annotation use bootstrap sample method image generate final annotation use majority voting rule consider n randomly select annotation measure stability quorum size n repeat process 10 time table ii show difference quality crowdsourced annotation use different quorum size compare generate annotation player annotation make expert derive table observe annotation base 20 different player response obtain best performance even though adult annotation obtain well accuracy respect expert annotation annotation 20schoolage child find enough quality accuracy > 94 quorum size n schoolage child adults 5 0842 0007 0966 0004 10 0910 0006 0988 0002 15 0931 0005 0989 0003 20 0946 0004 0991 0002 table ii mean accuracy standard deviation crowdsourced annotation use different quorum size com par one make expert b dl model hyperparameter tune mobilenet v2 build different block determine optimal number layer finetuned transfer process freeze determined number block fine tune rest experiment model train expert annotation furthermore aim evaluate effectiveness soft bootstrapping loss noisy label select best loss function particular case study train dl model use conventional cross entropy soft bootstrapping cross entropy = 095 loss function models train schoolage child adult annotation expert annotation contain noisy label derive table iii best performance obtain first 46 layer finetuned bootstrap categorical cross entropy use loss function hyperparameter auc number frozen layer 19 block 2 0873 0033 46 block 5 0919 0019 73 block 8 0914 0014 99 block 11 0917 0011 loss function childrencross entropy 0927 0007 bootstrapping cross entropy 0932 0006 adultscross entropy 0911 0014 bootstrapping cross entropy 0925 0016 table iii hyperparameter selection mean auc stan dard deviation show c incremental training study effect train sample size model performance train model incrementally use dif ferent sample size perform incremental training step 100 training image 100 700 figure 2 show result incremental training ex periment reveal importance number sample use training impact model performance differences annotator group compare performance ai model train schoolage child adult expert annotation table iv summarize result three model use available training sample n=700 result show all3346fig 2 evolution model performance auc training sample size increase results data annotate child adult expert present independently model perform similarly highlight power use crowdsourced annotation obtain similar result compare one obtain model train expertbased annotation note although quality schoolage child annotation low one collect adult difference 45 accuracy see table ii ai algorithm robust noisy label decrease difference term model performance 09 auc experts adults children ascaris spp 0960 0003 0958 0007 0948 0002 trichuris spp 0912 0002 0926 0015 0912 0026 healthy 0924 0019 0932 0010 0923 0008 mean 0932 0015 0939 001 0928 0012 table iv detailed performance dl algorithm train different annotation mean auc standard deviation report figure 3 show prediction result model different image test set include three class study ascaris spp trichuris spp healthy addition compute gradientweighted class activation mapping gradcam visualize region image important model make decision 17 iv conclusions work show promise result use crowd source annotation development aibased diagno si system validate use medical image field manual annotation expert timeconsuming labour require high specialization work collect crowdsourced annotation use customized video game classify different specie helminths egg use annotation train cnn architecture mobilenet v2 particularly obtain crowdsourced annotation untrained schoolage child adult result show dl model train annotation perform similar manner fig 3 examples image sample represent class study upper row along whit activation map generate dl algorithm bottom row correct label gt well prediction pred appear image activation map healthy sample hea focus entire image significant activation activation map ascaris spp asc trichuris spp tri focus exactly egg location compare one train expert annotation auc 0928 0939 0932 child adult expert annotation respectively significant difference model performance find used child adult expert annotation hand show impact training sample size performance ai model show obtain good performance training sample size increase particular model performance increase approximately factor 20 train available sample 700 compare result obtain 100 image use training derive experiment conclude could train dl model iterative manner obtain image annotate player thus obtain robust algorithm well predictive capacity additionally work lay foundation use video game data enrichment platform automate scale medical image label process use human collective intelligence enhance human relevance process develop ai algorithm environmental impact study cumulative 43 hour computation perform gpu tesla t4 20 hour contribute obtain final result total emission estimate machinelearning impact calculator present 18 09 kg co 2 virtual machine host spotwarriors game estimate emit 039 kg co2eq per month acknowledgments project grant nesta innovation foundation support redes feder 2018/c003/00010900 impulso al sector del videojuego develop spotwarrios upm member support industrial doc torate program community madrid ind2019/tic 17167 thank school allow us organize workshop collect annotation use spotwarriors game3347",
    "bag_of_words": {
        "combining": 1,
        "collective": 4,
        "artificial": 5,
        "intelligence": 7,
        "global": 4,
        "health": 8,
        "disease": 7,
        "diagnosis": 6,
        "use": 44,
        "crowdsourced": 15,
        "annotated": 5,
        "medical": 10,
        "image": 37,
        "lin": 1,
        "liny": 1,
        "david": 1,
        "bermejopelaezy": 1,
        "daniel": 2,
        "capellanmartin1": 1,
        "cuadrado1": 1,
        "cristina": 1,
        "rodriguez1": 1,
        "lydia": 1,
        "garcia1": 1,
        "nuria": 1,
        "diez1": 1,
        "rocio": 1,
        "tome1": 1,
        "mar": 1,
        "postigo1": 1,
        "maria": 1,
        "jesus": 1,
        "ledesmacarbayo2": 1,
        "miguel": 1,
        "luengooroz1": 1,
        "abstract": 1,
        "visual": 2,
        "inspection": 2,
        "microscopic": 2,
        "sample": 24,
        "still": 2,
        "gold": 1,
        "standard": 4,
        "diagnostic": 2,
        "methodology": 3,
        "many": 2,
        "soiltransmitted": 4,
        "helminth": 6,
        "infection": 2,
        "affect": 4,
        "billion": 2,
        "people": 2,
        "worldwide": 2,
        "prevalent": 1,
        "among": 2,
        "neglected": 2,
        "tropical": 1,
        "diseases": 1,
        "diagnose": 2,
        "manual": 2,
        "examination": 1,
        "stool": 5,
        "microscopy": 5,
        "timeconsuming": 3,
        "task": 5,
        "require": 3,
        "trained": 1,
        "personnel": 1,
        "high": 4,
        "specialization": 2,
        "could": 2,
        "automate": 2,
        "make": 9,
        "accessible": 1,
        "need": 3,
        "large": 3,
        "amount": 2,
        "training": 30,
        "data": 11,
        "come": 3,
        "expert": 19,
        "work": 10,
        "propose": 4,
        "annotate": 8,
        "train": 27,
        "ai": 16,
        "model": 36,
        "neural": 2,
        "network": 1,
        "detection": 2,
        "helminthiasis": 3,
        "leverage": 1,
        "nonexpert": 1,
        "knowledge": 1,
        "collect": 8,
        "play": 4,
        "video": 6,
        "game": 10,
        "annotation": 44,
        "schoolage": 12,
        "child": 16,
        "adult": 15,
        "show": 13,
        "although": 3,
        "quality": 9,
        "sightly": 1,
        "inferior": 1,
        "one": 7,
        "perform": 6,
        "similarly": 2,
        "auc": 11,
        "respectively": 4,
        "reach": 1,
        "similar": 3,
        "performance": 22,
        "also": 4,
        "impact": 5,
        "size": 12,
        "continuous": 1,
        "conclusion": 1,
        "workflow": 1,
        "combine": 2,
        "detect": 2,
        "embedded": 1,
        "within": 2,
        "digital": 1,
        "platform": 2,
        "apply": 1,
        "analysis": 2,
        "contribute": 4,
        "reduce": 4,
        "burden": 3,
        "introduction": 1,
        "achieving": 1,
        "universal": 2,
        "coverage": 1,
        "sustainable": 1,
        "development": 2,
        "goals": 1,
        "world": 2,
        "orga": 1,
        "nization": 1,
        "priority": 1,
        "half": 1,
        "population": 2,
        "lack": 2,
        "access": 1,
        "essential": 1,
        "service": 1,
        "key": 1,
        "step": 2,
        "achieve": 2,
        "healthcare": 1,
        "front": 1,
        "microscope": 2,
        "device": 3,
        "certain": 1,
        "time": 3,
        "resource": 1,
        "always": 1,
        "available": 5,
        "present": 6,
        "opportunity": 1,
        "sup": 1,
        "port": 1,
        "process": 7,
        "number": 9,
        "aibased": 2,
        "increase": 4,
        "approve": 2,
        "usa": 1,
        "europe": 1,
        "develop": 4,
        "radiology": 1,
        "cardiovascular": 1,
        "none": 1,
        "1spotlab": 1,
        "sl": 1,
        "madrid": 4,
        "spain": 2,
        "2biomedical": 1,
        "technologies": 1,
        "etsi": 1,
        "telecomunicacion": 1,
        "universidad": 1,
        "politecnica": 1,
        "de": 2,
        "ciberbbn": 1,
        "yll": 1,
        "dbp": 1,
        "equally": 1,
        "consider": 3,
        "cofirst": 1,
        "authorsapplied": 1,
        "microbiology": 1,
        "recently": 1,
        "algorithm": 15,
        "malaria": 4,
        "parasites": 1,
        "egg": 9,
        "fecal": 1,
        "potential": 1,
        "notwithstanding": 1,
        "study": 13,
        "create": 1,
        "regulatory": 1,
        "institution": 1,
        "sth": 4,
        "trop": 1,
        "ical": 1,
        "ntd": 1,
        "poor": 1,
        "prived": 1,
        "community": 2,
        "according": 1,
        "report": 2,
        "helminths": 2,
        "establish": 1,
        "roadmap": 1,
        "eliminate": 1,
        "accelerate": 1,
        "elimination": 1,
        "innovation": 2,
        "new": 1,
        "technology": 1,
        "like": 1,
        "recommended": 1,
        "method": 3,
        "kato": 1,
        "katz": 1,
        "laboratory": 1,
        "prepare": 1,
        "late": 2,
        "quantification": 1,
        "labour": 2,
        "pose": 1,
        "important": 2,
        "however": 1,
        "recent": 1,
        "year": 2,
        "crowdsourcing": 5,
        "overcome": 2,
        "problem": 2,
        "delegate": 1,
        "group": 3,
        "untrained": 3,
        "annotator": 2,
        "several": 1,
        "already": 1,
        "demonstrate": 3,
        "validity": 1,
        "luengooroz": 1,
        "et": 3,
        "al": 4,
        "combination": 1,
        "player": 8,
        "parasite": 1,
        "count": 1,
        "accuracy": 7,
        "thick": 1,
        "smear": 1,
        "linares": 1,
        "combined": 1,
        "form": 1,
        "able": 1,
        "distinguish": 1,
        "specie": 2,
        "furthermore": 3,
        "keshavan": 1,
        "deep": 3,
        "learning": 3,
        "dl": 13,
        "predict": 2,
        "magnetic": 1,
        "resonance": 1,
        "imaging": 1,
        "context": 1,
        "quantify": 1,
        "parasitic": 1,
        "follow": 1,
        "objective": 1,
        "assess": 3,
        "feasibility": 1,
        "differentiation": 1,
        "base": 3,
        "im": 1,
        "age": 1,
        "obtain": 15,
        "custom": 1,
        "identify": 1,
        "relationship": 1,
        "incremental": 5,
        "compare": 8,
        "general": 1,
        "43rd": 1,
        "annual": 1,
        "international": 1,
        "conference": 2,
        "ieee": 1,
        "engineering": 1,
        "medicine": 1,
        "biology": 1,
        "society": 1,
        "embc": 1,
        "oct": 1,
        "nov": 1,
        "virtual": 2,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "information": 2,
        "see": 2,
        "http": 1,
        "//creativecommonsorg/licenses/by/30/3344ii": 1,
        "spotwarriors": 3,
        "sw": 1,
        "publicly": 1,
        "available1": 1,
        "set": 11,
        "minigames": 1,
        "dis": 1,
        "eas": 1,
        "generate": 7,
        "purpose": 3,
        "project": 3,
        "focus": 3,
        "minigame": 2,
        "classification": 3,
        "small": 2,
        "patch": 4,
        "digitized": 2,
        "identification": 1,
        "differ": 1,
        "ent": 1,
        "include": 6,
        "ascaris": 6,
        "spp": 12,
        "trichuris": 6,
        "hookworms": 1,
        "without": 3,
        "figure": 3,
        "screenshot": 2,
        "validation": 6,
        "testing": 1,
        "different": 10,
        "infect": 2,
        "patient": 1,
        "part": 1,
        "followup": 1,
        "digitization": 1,
        "10x": 1,
        "magnification": 1,
        "ethical": 1,
        "approval": 1,
        "kenya": 1,
        "research": 1,
        "institute": 1,
        "kemri": 1,
        "ethics": 1,
        "review": 1,
        "committee": 1,
        "seru": 1,
        "digitize": 1,
        "total": 4,
        "cropped": 1,
        "256x256": 1,
        "pixel": 1,
        "overlap": 1,
        "interpretation": 1,
        "independent": 1,
        "limited": 1,
        "subject": 1,
        "introduce": 2,
        "randomly": 3,
        "select": 4,
        "least": 1,
        "old": 1,
        "comparative": 1,
        "analyze": 1,
        "microscopist": 1,
        "annotations": 1,
        "organize": 2,
        "workshop": 3,
        "school": 2,
        "collaboration": 1,
        "teacher": 1,
        "explanation": 1,
        "concept": 1,
        "relate": 1,
        "addition": 2,
        "anonymously": 1,
        "online": 1,
        "additionally": 3,
        "remain": 1,
        "test": 6,
        "separate": 1,
        "ground": 1,
        "truth": 1,
        "gt": 2,
        "majority": 3,
        "voting": 3,
        "rule": 2,
        "common": 1,
        "response": 2,
        "choose": 1,
        "final": 5,
        "distribution": 4,
        "table": 10,
        "architecture": 6,
        "learn": 2,
        "convolutional": 1,
        "net": 1,
        "cnn": 2,
        "based": 1,
        "solve": 1,
        "differentiate": 1,
        "along": 5,
        "non": 1,
        "give": 1,
        "return": 1,
        "output": 1,
        "probability": 3,
        "class": 8,
        "label": 8,
        "compute": 3,
        "particularly": 2,
        "1https": 1,
        "//spotwarriorsorg/en/": 1,
        "google": 1,
        "store": 2,
        "apple": 1,
        "app": 1,
        "fig": 2,
        "leave": 1,
        "right": 1,
        "sac": 2,
        "healthy": 4,
        "three": 4,
        "mobilenet": 5,
        "v2": 5,
        "lightweighted": 1,
        "design": 2,
        "run": 1,
        "mobile": 1,
        "phone": 1,
        "efficient": 1,
        "manner": 3,
        "particular": 3,
        "main": 1,
        "component": 1,
        "depthwise": 1,
        "convolution": 1,
        "significantly": 1,
        "parameter": 3,
        "invert": 1,
        "residual": 2,
        "connection": 1,
        "block": 8,
        "modify": 1,
        "efficiency": 1,
        "linear": 1,
        "bottleneck": 1,
        "layer": 8,
        "nonlinear": 1,
        "activation": 6,
        "function": 7,
        "order": 4,
        "preserve": 1,
        "low": 2,
        "dimensional": 1,
        "space": 1,
        "compose": 1,
        "involve": 2,
        "million": 2,
        "well": 4,
        "know": 1,
        "vgg16": 1,
        "limitation": 1,
        "dataset": 3,
        "transfer": 2,
        "technique": 3,
        "pretraining": 1,
        "imagenet": 1,
        "finetuning": 2,
        "freeze": 2,
        "early": 2,
        "generic": 1,
        "feature": 2,
        "retrain": 1,
        "responsible": 1,
        "extract": 1,
        "specific": 1,
        "using": 1,
        "computational": 1,
        "cost": 1,
        "result": 10,
        "good": 2,
        "scratch": 1,
        "specially": 1,
        "little": 1,
        "usually": 1,
        "contain": 2,
        "incorrect": 2,
        "soft": 3,
        "bootstrapping": 5,
        "cross": 6,
        "entropy": 8,
        "loss": 7,
        "minimize": 1,
        "damage": 1,
        "dynamically": 1,
        "update": 1,
        "target": 2,
        "prediction": 5,
        "actual": 1,
        "state": 1,
        "defined": 2,
        "equation": 1,
        "qis": 1,
        "tis": 1,
        "scale": 2,
        "factor": 2,
        "targets3345andlis": 1,
        "lsoft": 1,
        "=lx": 1,
        "k=1": 1,
        "tk+": 1,
        "1\u0000": 1,
        "qk": 2,
        "log": 1,
        "augmentation": 1,
        "rota": 1,
        "tion": 1,
        "shift": 1,
        "flip": 1,
        "zoom": 1,
        "shear": 1,
        "transformation": 1,
        "improve": 1,
        "stopping": 1,
        "patience": 1,
        "iteration": 1,
        "avoid": 2,
        "overfitting": 1,
        "keras": 1,
        "tensorflow": 1,
        "gpu": 2,
        "nvidia": 1,
        "tesla": 2,
        "t4": 2,
        "16gb": 1,
        "iii": 3,
        "xperiments": 1,
        "results": 2,
        "section": 1,
        "first": 2,
        "evaluate": 4,
        "crowd": 2,
        "sourced": 1,
        "mechanism": 1,
        "continue": 1,
        "effect": 2,
        "finally": 1,
        "metric": 3,
        "acc": 1,
        "=tp+": 1,
        "tn=n": 1,
        "tp": 1,
        "tn": 1,
        "stand": 1,
        "true": 2,
        "positive": 1,
        "negative": 1,
        "area": 1,
        "receiver": 1,
        "operate": 1,
        "charac": 1,
        "teristic": 1,
        "curve": 1,
        "measure": 2,
        "across": 1,
        "possible": 1,
        "threshold": 1,
        "macroaverage": 1,
        "bias": 1,
        "due": 2,
        "imbalanced": 1,
        "robust": 3,
        "instability": 1,
        "repeat": 2,
        "calculate": 1,
        "mean": 5,
        "deviation": 4,
        "perfor": 1,
        "mance": 1,
        "carry": 1,
        "hyperparameter": 4,
        "tuning": 1,
        "experiment": 3,
        "evaluation": 1,
        "note": 2,
        "hookworm": 1,
        "representativity": 1,
        "database": 1,
        "preprocessing": 1,
        "optimal": 2,
        "quorum": 5,
        "best": 4,
        "performs": 1,
        "comparison": 1,
        "bootstrap": 2,
        "stability": 1,
        "ii": 3,
        "difference": 4,
        "derive": 3,
        "observe": 1,
        "even": 1,
        "though": 1,
        "respect": 1,
        "20schoolage": 1,
        "find": 2,
        "enough": 1,
        "adults": 2,
        "com": 1,
        "par": 1,
        "tune": 2,
        "build": 1,
        "determine": 1,
        "finetuned": 2,
        "determined": 1,
        "fine": 1,
        "rest": 1,
        "aim": 1,
        "effectiveness": 1,
        "noisy": 3,
        "case": 1,
        "conventional": 1,
        "models": 1,
        "categorical": 1,
        "frozen": 1,
        "childrencross": 1,
        "adultscross": 1,
        "selection": 1,
        "stan": 1,
        "dard": 1,
        "incrementally": 1,
        "dif": 1,
        "ferent": 1,
        "ex": 1,
        "periment": 1,
        "reveal": 1,
        "importance": 1,
        "differences": 1,
        "iv": 3,
        "summarize": 1,
        "n=700": 1,
        "all3346fig": 1,
        "evolution": 1,
        "independently": 1,
        "highlight": 1,
        "power": 1,
        "expertbased": 1,
        "decrease": 1,
        "term": 1,
        "experts": 1,
        "children": 1,
        "detailed": 1,
        "gradientweighted": 1,
        "mapping": 1,
        "gradcam": 1,
        "visualize": 1,
        "region": 1,
        "decision": 1,
        "conclusions": 1,
        "promise": 1,
        "source": 1,
        "diagno": 1,
        "si": 1,
        "system": 1,
        "validate": 1,
        "field": 1,
        "customized": 1,
        "classify": 1,
        "examples": 1,
        "represent": 1,
        "upper": 1,
        "row": 2,
        "whit": 1,
        "map": 3,
        "bottom": 1,
        "correct": 1,
        "pred": 1,
        "appear": 1,
        "hea": 1,
        "entire": 1,
        "significant": 2,
        "asc": 1,
        "tri": 1,
        "exactly": 1,
        "location": 1,
        "used": 1,
        "hand": 1,
        "approximately": 1,
        "conclude": 1,
        "iterative": 1,
        "thus": 1,
        "predictive": 1,
        "capacity": 1,
        "lay": 1,
        "foundation": 2,
        "enrichment": 1,
        "human": 2,
        "enhance": 1,
        "relevance": 1,
        "environmental": 1,
        "cumulative": 1,
        "hour": 2,
        "computation": 1,
        "emission": 1,
        "estimate": 2,
        "machinelearning": 1,
        "calculator": 1,
        "kg": 2,
        "co": 1,
        "machine": 1,
        "host": 1,
        "emit": 1,
        "co2eq": 1,
        "per": 1,
        "month": 1,
        "acknowledgments": 1,
        "grant": 1,
        "nesta": 1,
        "support": 2,
        "redes": 1,
        "feder": 1,
        "2018/c003/00010900": 1,
        "impulso": 1,
        "sector": 1,
        "del": 1,
        "videojuego": 1,
        "spotwarrios": 1,
        "upm": 1,
        "member": 1,
        "industrial": 1,
        "doc": 1,
        "torate": 1,
        "program": 1,
        "ind2019/tic": 1,
        "thank": 1,
        "allow": 1,
        "us": 1,
        "game3347": 1
    },
    "objective": [
        "within this context , this work propose a methodology to train dl algorithm for quantify parasitic infection in microscopy image with the follow objective : 1 ) to assess the feasibility of train dl algorithm for the differentiation of helminth egg base on microscopy im- age with annotation obtain from crowdsourcing use a custom video game , 2 ) to identify the relationship between the amount of training data and the deep learning model performance use incremental training and 3 ) to compare the performance of ai model train with data annotate by both untrained school-age child and adult ( general population ) .2021 43rd annual international conference of the ieee engineering in medicine & biology society ( embc ) oct 31 - nov 4 , 2021 ."
    ],
    "references": [
        "",
        "REFERENCES [1] United Nations. Transforming our world: the 2030 Agenda for Sustainable Development — Department of Economic and Social Affairs, 2015. [2] U. J. Muehlematter et al. Approval of artiﬁcial intelligence and machine learning-based medical devices in the USA and Europe (2015–20): a comparative analysis. The Lancet Digital Health , 0(0), jan 2021. [3] F. Yang et al. Deep Learning for Smartphone-Based Malaria Parasite Detection in Thick Blood Smears. IEEE Journal of Biomedical and Health Informatics , 24(5):1427–1438, may 2020. [4] Vijayalakshmi A and Rajesh Kanna B. Deep learning approach to detect malaria from microscopic images. Multimedia Tools and Applications , 79(21-22):15297–15317, jun 2020. [5] O. Holmstr ¨om et al. Point-of-care mobile digital microscopy and deep learning for the detection of soil-transmitted helminths and Schistosoma haematobium. Global Health Action , 10(3), 2017. [6] A. Yang et al. KankaNet: An artiﬁcial neural network-based object detection smartphone application and mobile microscope as a point-of- care diagnostic aid for soil-transmitted helminthiases. PLoS Neglected Tropical Diseases , 13(8):e0007577, 2019. [7] B. A. Mathison et al. Detection of intestinal protozoa in trichrome- stained stool specimens by use of a deep convolutional neural network. Journal of Clinical Microbiology , 58(6):1–13, 2020. [8] WHO. Ending the neglect to attain the Sustainable Development Goals – A road map for neglected tropical diseases 2021–2030 (Geneva: World Health Organization), pp. 55. Accessed on 7th July 2020. Technical report, 2020. [9] N. Katz et al. A simple device for quantitative stool thick-smear tech- nique in Schistosomiasis mansoni. Revista do Instituto de Medicina Tropical de Sao Paulo , 14(6):397–400, nov 1972. [10] M. A. Luengo-Oroz et al. Crowdsourcing malaria parasite quantiﬁ- cation: An online game for analyzing images of infected thick blood smears. Journal of Medical Internet Research , 14(6):1–14, nov 2012. [11] M. Linares et al. Collaborative intelligence and gamiﬁcation for on- line malaria species differentiation. Malaria Journal , 18(1):21, dec 2019. [12] A. Keshavan et al. Combining citizen science and deep learning to amplify expertise in neuroimaging. Frontiers in Neuroinformatics , 13:29, may 2019. [13] M. Sandler et al. MobileNetV2: Inverted Residuals and Linear Bottlenecks. Technical report, 2018. [14] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. Technical report, 2015. [15] O. Russakovsky et al. Best of both worlds: Human-machine collabo- ration for object annotation. Technical report, 2015. [16] S. E. Reed et al. Training deep neural networks on noisy labels with bootstrapping. 3rd International Conference on Learning Representa- tions, ICLR 2015 - Workshop Track Proceedings , pp. 1–11, 2015. [17] R. R. Selvaraju et al. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. International Journal of Computer Vision , 128(2):336–359, oct 2016. [18] A. Lacoste et al. Quantifying the carbon emissions of machine learning. arXiv preprint arXiv:1910.09700 , 2019.3348"
    ]
}{
    "name": "Dual Autoencoder Network for Retinex-Based Low-Light Image Enhancement",
    "paragraphs": [
        "received january 9 , 2018 , accept february 23 , 2018 , date of publication march 6 , 2018 , date of current version may 9 , 2018 .",
        "digital object identifier 10.1 109/access.2018.2812809 dual autoencoder network for retinex-based low-light image enhancement seonhee park , ( student member , ieee ) , soohwan yu , ( student member , ieee ) , minseo kim , kwanwoo park , and joonki paik , ( senior member , ieee ) department of image graduate school of advanced imaging science , multimedia and film , chung-ang university , seoul 06974 , south korea corresponding author : joonki paik ( paikj @ cau.ac.kr ) this work be support in part by the institute for information & communications technology promotion grant through the korea government under grant 2017-0-00250 and in part by the intelligent defense boundary surveillance technology using collaborative reinforced learning of embedded edge camera and image analysis .",
        "abstract this paper present a dual autoencoder network model base on the retinex theory to perform the low-light enhancement and noise reduction by combine the stacked and convolutional autoencoders .",
        "the propose method rst estimate the spatially smooth illumination component which be bright than an input low-light image use a stacked autoencoder with a small number of hidden unit .",
        "next , we use a convolutional autoencoder which deal with 2-d image information to reduce the ampli ed noise in the brightness enhancement process .",
        "we analyze and compare role of the stacked and convolutional autoencoders with the constraint term of the variational retinex model .",
        "in the experiment , we demonstrate the performance of the propose algorithm by compare with the state-of-the-art exist low-light and contrast enhancement method .",
        "index terms autoencoder , image processing , image enhancement , neural network , variational retinex model , unsupervised learning .",
        "i .",
        "introduction digital cameras play a role in sense information from external world in various application such as arti cial intel- ligence , remote sense , surveillance system , and advance driver assistance system .",
        "however , when the amount of incoming light to the sensor be insuf cient under poor illumi- nation condition , the dynamic range of the acquire image be reduce .",
        "in addition , the low-light image be corrupt by additive noise because of the limited number of photon receive by each pixel .",
        "as a result , it be dif cult to obtain a high-quality image under the low-light condition and the low-light artifact may reduce the performance of computer vision application such as object recognition , detection , and track .",
        "a theoretically sound approach to solve this prob- lem be image enhancement base on the retinex theory with the understanding of the human visual system ( hvs ) .",
        "more speci cally , land et al .",
        "rst propose the retinex theory to demonstrate the process of the hvs to perceive color from the retina to visual cortex [ 1 ] , [ 2 ] .",
        "they demonstrate that the hvs perceive the color by the re ected ratio of the light rather than the lightness .",
        "the retinex theory-based image enhancement method have be far develop to improve the dynamic rangeof the dark region .",
        "these method enhance the visibility by subtract the local and global illumination component , but the separation of the illumination and re ectance compo- nents be an ill-posed problem .",
        "jobson et al .",
        "[ 3 ] de ned the re ectance component as a ratio of the intensity value at the center to the average of the intensity value .",
        "they propose single-scale retinex ( ssr ) to enhance the dynamic range by eliminate the illumination component , which be esti- mat by gaussian low-pass ltering .",
        "however , the result image show halo effect near edge because of the conti- nuity of the illumination component .",
        "to solve this problem , rahman et al .",
        "[ 4 ] present multi-scale retinex ( msr ) use multiple gaussian kernel with different standard deviation .",
        "although the msr algorithm can suppress the halo effect use the weighted summation of multiple illumination com- ponents , the result image can not avoid color distortion .",
        "jobson et al .",
        "extend their previous work to compensate the color component by apply the color restoration function use the ratio of each color channel [ 5 ] .",
        "as an alternative approach to enhance the low-light image , variational retinex model be propose base on pri- or of illumination and re ectance component [ 6 ] \u0015 [ 12 ] .",
        "kimmel et al .",
        "[ 6 ] estimate the illumination component by 220842169-3536 2018 ieee .",
        "translations and content mining be permit for academic research only .",
        "personal use be also permit , but republication/redistribution require ieee permission .",
        "see http : //www.ieee.org/publications_standards/publications/rights/index.html for more information.volume 6 , 2018s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement minimize the gradient of illumination component use l2regularization .",
        "ma et al .",
        "[ 7 ] estimate the re ectance component which contain high-frequency component use anisotropic total variation ( tv ) -prior instead of the gaus- sian smoothness prior to reduce the ampli ed noise while preserve the edge .",
        "fu et al .",
        "[ 8 ] demonstrate the relation- ship between the bright channel and illumination component use the bright channel prior , and present a variational retinex model which can suppress halo-effect .",
        "park et al .",
        "[ 9 ] penalize the brightness of illumination use quadratic delity prior of the illumination component with respect to its enhanced version to suppress over-enhancement of the re ectance component .",
        "recently , deep learning-based image process meth- od have be propose in the image enhancement eld .",
        "lore et al .",
        "[ 13 ] adopt stacked-sparse denoising autoen- coder to a low-light image enhancement framework to simul- taneously perform the brightness enhancement and noise removal .",
        "shen et al .",
        "[ 14 ] analyze the property of msr algo- rithm in the sense of convolutional neural network ( cnn ) , and propose msr-net to enhance the low-light image use the cnn architecture .",
        "in this paper , we present a novel low-light image enhance- ment framework combine the stacked and convolutional autoencoders base on the retinex theory .",
        "in addition , we ana- lyze the relationship between the variational retinex model and the propose autoencoder-based enhancement meth- od .",
        "major contribution of the propose method be twofold : i ) since the stacked autoencoder decompose the low-light input patch into compact feature , it can reconstruct the opti- mal illumination component with enhanced brightness , and ii ) the convolutional autoencoder play a role in suppress noise ampli cation in the re ectance component without degrade sharp edge .",
        "in addition , the stacked autoencoder can be regard as the smoothness term or brightness con- straint on the illumination component .",
        "in the same manner , the convolutional autoencoder enforce the penalty on the re ectance component to reduce the ampli ed noise .",
        "the paper be organize as follow .",
        "section ii describe the variational retinex model and low-light net as a theo- retical background .",
        "section iii present the propose low- light image enhancement framework use dual autoencoder .",
        "experimental result be show in section iv and section v conclude the paper .",
        "ii .",
        "related works a. variational retinex model to enhance the contrast of a low-light image , kimmel et al .",
        "[ 6 ] estimate the illumination component by minimize the energy functional in the iterative manner .",
        "however , since the illumination and re ectance component be inversely proportional , the low illumination component result in the over-enhancement of the re ectance compo- nent .",
        "to overcome this problem , they adjust the amount of gamma correction to enhance the brightness of the estimatedillumination component .",
        "the resulting image be obtain by multiply the re ectance and adjust illumination component .",
        "to prevent the over-enhancement of the re ectance com- ponent , park et al .",
        "[ 9 ] present a modi ed variational retinex model use an additional data- delity term which penalize the brightness of the illumination component as arg min fr ; fl\u00151kfrfl\u0000gk2 2c\u00152krflk2 2 c\u00153krfrk1c\u00154kfl\u0000oflk2 2 ; ( 1 ) wherekfrfl\u0000gk2 2represents the data- delity term , krflk2 2andkrfrk1the smoothness term on illumination and re ectance component , respectively , kfl\u0000oflk2 2the data- delity term between illumination component and its enhanced version by the gamma correction .",
        "\u00151 ; \u00152 , \u00153 , and \u00154represent regularization parameter .",
        "in park 's method , the smoothness term on the illumination component , krflk2 2 , penalize the gradient of illumination component use an isotropic tv-prior which be equivalent to the gaussian smoothness prior .",
        "in addition , since the bright- ness of illumination component be iteratively increase use the fourth quadratic data- delity term in ( 1 ) , this method can estimate the natural re ectance component without gamma correction on the illumination component .",
        "moreover , this method can reduce noise by minimize the loss of edge information use an anisotropic tv-prior on the re ectance component .",
        "b. learning-based image enhancement methods an autoencoder be a feed-forward neural network which aim to extract meaningful feature by compress the input data in an unsupervised manner [ 15 ] \u0015 [ 19 ] .",
        "vincent et al .",
        "[ 17 ] per- form noise removal use stack denoising autoencoder and pair of original and noise corrupted vector .",
        "this method train the autoencoder to reconstruct the output vector as close to as the original vector in a self-supervised manner from a compressed representation of noise vector .",
        "motivated by the denoising autoencoder , lore et al .",
        "[ 13 ] present low-light net ( llnet ) to enhance the low-light image use the stacked denoising autoencoder with the sparsity prior because the low-dimensional representation provide more compact and meaningful feature .",
        "to simul- taneously perform contrast enhancement and noise removal , lore et al .",
        "generate a pair of ground-truth and cor- rupted image as the training data .",
        "the corrupted image be produce by degrade the brightness of ground-truth image use gamma correction and add white gaussian noise .",
        "the weight and bias of the autoencoder be update in the back-propagation step to minimize the error between ground-truth and reconstruct image .",
        "moreover , they learn each denoising and contrast enhancement net- work separately , and present stag llnet to indepen- dently control the performance of each image enhancement module .",
        "volume 6 , 2018 22085s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement figure 1 .",
        "the propose low-light image enhancement framework .",
        "iii .",
        "dual autoencoder network this section describe the propose low-light image enhancement framework use stack and convolutional autoencoders .",
        "the propose dual autoencoder model esti- mat the enhanced image in three step : i ) estimation of illumination component use a stacked autoencoder , ii ) initial estimation of re ectance component , and iii ) re ne- ment of re ectance component use a convolutional autoen- coder .",
        "in the following subsection , we describe the role of stacked and convolutional autoencoders .",
        "in addition , we analyze the relationship between the propose network architecture and each constraint term of modi ed variational retinex model in [ 12 ] .",
        "fig .",
        "1 show a block-diagram of the propose low-light image enhancement framework .",
        "a. illumination estimation using stacked autoencoder based on the retinex decomposition model , the illumina- tion component have a low-frequency characteristic since it smoothly change in the image space .",
        "for that reason , a gaussian low-pass lter be the most popular in exist- ing illumination estimation method .",
        "on the other hand , the propose method estimate the enhanced illumination component use the stack autoencoder which reduce the dimensionality of the input data .",
        "a conventional denoising autoencoder play a role in esti- mat the original data give its corrupted version .",
        "in the training step of the neural network , if we use a very small number of hidden unit , the encoder layer provide more compressed representation of the input data .",
        "it imply that the reconstruction of original data can not be successful .",
        "fig .",
        "2 show the comparative result of the reconstruction of brightness enhance illumination give the input low-light image .",
        "as show in fig .",
        "2 , the neural network with small num- ber of hidden unit can not successfully preserve the image structure such as edge and texture .",
        "the poor performance in preserve edge implies that the resulting image can not be consistent with the original image in term of noise reduction .",
        "however , the blurred result of the autoencoder can be use as the illumination component because it have the low-frequency figure 2 .",
        "comparative result of the reconstruction of brightness enhance illumination patch : ( a ) corrupt input patch , ( b ) reconstruct patch use 256 , 128 , and 32 hidden unit in each hidden layer , ( c ) reconstruct patch use 256 , 128 , and 64 hidden unit in each hidden layer , and ( d ) reconstruct patch use 256 , 128 , and 96 hidden unit in each hidden layer .",
        "property over the entire image as show in fig .",
        "2 .",
        "in addition , since the propose method train the neural network use a pair of low- and high-contrast image patch , the brightness enhance illumination component can be obtain .",
        "in the third , fth , and seventh column of fig .",
        "2 , row ( d ) have well reconstruct edge and detail because of more hidden unit in the bottleneck layer than row ( b ) and ( c ) .",
        "b. reflectance estimation using convolutional autoencoder we can estimate the re ectance component use the ratio of the input image to the illumination component estimate in the previous subsection .",
        "given the estimate illumination component in the previous step , the initial re ectance com- ponent be estimate as rdg l ; ( 2 ) where rrepresents an initially estimate re ectance com- ponent , gthe input low-light image , and lthe estimate illumination component .",
        "however , since the noise component be ampli ed dur- ing the contrast enhancement process , the noise removal of re ectance component be need to provide a high-quality image .",
        "although the stacked denoising autoencoder can perform noise removal to a certain degree , it ignore the 22086 volume 6 , 2018s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement figure 3 .",
        "the propose convolutional autoencoder model .",
        "two-dimensional structural information of image since the input low-light patch be transform into one-dimensional vector .",
        "on the contrary , the convolutional autoencoder can use the two-dimensional structural information for train- ing .",
        "so it result in reduce the loss of detail [ 18 ] , [ 19 ] .",
        "for that reason , the propose method can estimate improve re ectance component use convolutional autoencoder to reduce noise ampli cation while preserve the edge .",
        "fig .",
        "3 show the propose fully convolutional autoencoder network model .",
        "the encode part consist of one convolution layer and one pooling layer , all of which have one activation function .",
        "the rst convolution layer be represent as f1 ( x ) dmax ( 0 ; w1\u0003xcb1 ) ; ( 3 ) where xrepresents the input image and \u0003the convolution operation .",
        "wkandbkrepresent the weight and bias of the k-th convolution layer , respectively .",
        "the extracted feature be compress by down-sampling the output of convolution layer use the max-pooling as f2 ( x ) dp ( f1 ( x ) ) ; ( 4 ) where p ( \u0001 ) represent the max-pooling operation , which decrease the dimensionality of input data and extract effec- tive feature by take the maximum activation .",
        "the decode part consist of one up-sampling and two convolution layer .",
        "the second convolution layer be repre- sented as f3 ( x ) dmax ( 0 ; w2\u0003f2 ( x ) cb2 ) : ( 5 ) this layer take compact and cod feature to reconstruct the input image .",
        "the up-sampling process can be represent as f4 ( x ) du ( f3 ( x ) ) ; ( 6 ) where u ( \u0001 ) represent the up-sampling operation .",
        "the up- sampling layer play a role in enlarge the spatial resolution off3 ( x ) to have the same dimension of the input image x .",
        "finally , the reconstruction of result image be perform in the third convolution layer as f5 ( x ) d\u001b ( w3\u0003f4 ( x ) cb3 ) ; ( 7 ) where\u001b ( \u0001 ) represent the sigmoid function .",
        "since the last convolution layer provide the reconstructed result image in [ 0,1 ] , we use the sigmoid function as activation function than rectus ed linear unit ( relu ) .",
        "the weight and bias of each convolution layer be update to minimize the difference between the reconstruct and its ground-truth image .",
        "mean square error ( mse ) be use to de ne the loss function as l ( \u0012 ) d1 nnx id1kf ( xii\u0012 ) \u0000yik2 ; ( 8 ) where\u0012dfw 1 ; w2 ; w3 ; b1 ; b2 ; b3g ; nrepresents the number of train data , and yithei-th ground-truth image of xi .",
        "c. motivation from the variational retinex model in low-light condition , since the reduced amount of incoming light result in the low illumination component , it be highly probable to obtain the over-enhanced re ectance component because the estimated re ectance be inversely proportional to the illumination component .",
        "in this subsection , we compare the propose dual autoencoder network model with the con- straint term of variational retinex model to prevent the over- enhancement of re ectance component [ 12 ] .",
        "the propose method estimate the illumination compo- nent from the extremely compressed representation of the input low-light image explain in subsection 3.a .",
        "since the propose stacked autoencoder be train to provide the volume 6 , 2018 22087s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement blur illumination component use the small number of hidden unit , it can be regard as the smoothness prior , krflk2 2 , of the illumination component in the variational retinex model in ( 1 ) .",
        "in addition , the propose stack autoen- coder learn the mapping between the low- and high-contrast patch to obtain the illumination component of bright- ness enhance image .",
        "it imply that the propose stacked autoencoder enforce the data- delity between the illumina- tion component of an input low-light image and that of its enhanced version as the fourth term in ( 1 ) .",
        "in term of noise reduction , the propose method reduce the ampli ed noise in the enhanced re ectance compo- nent by use the convolutional autoencoder .",
        "the conven- tional denoising autoencoder perform the training in the form of the randomly corrupt input and original vector to reduce the dimensionality .",
        "on the other hand , the con- volutional autoencoder train the neural network use the two-dimensional image data .",
        "for that reason , the convolu- tional autoencoder can better preserve the image structure since the weight be share at all input data .",
        "in the pro- pose method , the convolutional autoencoder can be regard as the constraint term on the re ectance component use l1-norm minimization in ( 1 ) .",
        "in addition , the propose dual autoencoder be train to provide the output which be equal to input in self-supervised learning manner , the stacked and convolutional autoencoders be regard as the data- delity termkfl\u0000oflk2 2in the retinex model .",
        "iv .",
        "experimental results this section demonstrate the performance of propose dual autoencoder model by compare with exist low-light image enhancement method include kim 's method [ 20 ] , jiang 's method [ 21 ] , jobson 's method ( msrcr ) [ 5 ] , fu 's method [ 8 ] , guo 's method [ 22 ] , and park 's method [ 12 ] .",
        "the objective assessment be evaluate use the peak signal-to-noise ratio ( psnr ) and structural similarity index measure ( ssim ) [ 23 ] .",
        "in addition , we describe the training condition , to generate proper training data , and analyze the performance of pro- pose dual autoencoder model .",
        "adam , which be propose by kingma and ba [ 24 ] , be use for optimization with a learn- ing rate of 0.001 .",
        "the mini batch size of each autoencoder be respectively set to 512 and 128 .",
        "the experiment be perform on a personal computer with a cpu of 3.9 ghz , ram of 24 gbyte , and nvidia gpu titan xp .",
        "the training of stacked and convolutional autoencoder network respectively take about 254 and 1,501 second use gpu .",
        "given the input image of size 512\u0002512 , the propose method provide the enhanced result in 13.3 second use cpu .",
        "a .",
        "training data generation the propose method respectively estimate the illumina- tion and re ectance component in the stacked and convo- lutional autoencoders as show in fig .",
        "1 .",
        "since the stacked autoencoder estimate the brightness enhance illumination component from the input low-light image , we generate a figure 4 .",
        "set of ideal image collect from the internet to synthesize the training dataset .",
        "set of train data use a pair of low- and high-contrast patch because it be dif cult to naturally obtain low- and high-contrast image pair [ 13 ] .",
        "for that reason , we synthesize the low-contrast image patch use about 80,000 patch of size 33 \u000233 , which be sample from a set of ideal ( high-contrast ) image collect from the internet and the dataset use in [ 25 ] as show in fig .",
        "4 .",
        "the low-contrast patch be generate use the gamma correct luminance channel in the hsv color space of ideal image patch as fpdg p ; ( 9 ) where gpandfprepresent the low- and high-contrast patch and the adjusting parameter which be randomly set to in [ 1.6 , 3.3 ] for each patch .",
        "in the propose dual autoencoder model , the convolutional autoencoder perform the noise reduction in the initially estimate re ectance component .",
        "to train the convolutional denoising autoencoder , we generate about 190,000 pair of noisy and noise-free patch size 28 \u000228 use the luminance channel in the hsv color space of the ideal image .",
        "the noisy patch be synthesize by add gaussian noise with zero mean and randomly select standard deviation \u001b2 [ 10 ; 18 ] .",
        "fig .",
        "5 show a part of synthesized noisy low-contrast patch and their ground-truth .",
        "b .",
        "performance of proposed autoencoder models in this subsection , we compare the performance of the stacked autoencoder to estimate the illumination component .",
        "since the autoencoder reconstruct the original data from the com- pressed representation of the input data , the performance depend on the number of hidden unit .",
        "for that reason , we compare the result image with different number of hidden unit in the bottleneck layer as show in fig .",
        "6 .",
        "22088 volume 6 , 2018s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement figure 5 .",
        "a part of synthesized training dataset for the propose dual autoencoder network : ( a ) high- and low-contrast patch for the stacked autoencoder and ( b ) noise-free and noisy patch for the convolutional autoencoder .",
        "figure 6 .",
        "comparative result use different number hide unit in the bottleneck layer : ( a ) input image , ( b ) 32 hidden unit ( ae : 7.5489 ) , ( c ) 64 hidden unit ( ae : 7.5208 ) , and ( d ) 96 hidden unit ( ae : 7.5205 ) .",
        "the first row show the enhanced resulting image , and the second row show the estimated illumination component .",
        "since the input patch of size 33 \u000233 be transform to a vector in r332 , the number of bottleneck layer should be low than 332to compress the input data .",
        "fig .",
        "6 show the result image use the estimate illumination component by three different stack autoen- coder have 32 , 64 , and 96 hidden unit in the bottle- neck layer .",
        "speci cally , the result image use 32 hidden unit provide the best contrast because of more com- pressed representation of the input low-light image .",
        "it imply that the stacked autoencoder can better represent the low- frequency property of the illumination component with the small number of hidden unit .",
        "moreover , the high aver- age entropy ( ae ) value imply that the result image have more image information such as visible edge [ 26 ] .",
        "based on the observation , we use 32 hidden unit in the bottleneck layer .",
        "in the convolutional autoencoder , we compare the perfor- mance of noise reduction use the mse at different number of convolution lters and different size of receptive eld oftable 1 .",
        "comparison of the performance of convolution layer with three different filter size and receptive field of the max-pooling layer use the mse value ( 10\u00002 ) .",
        "table 2 .",
        "the output size of each layer in the convolutional autoencoder .",
        "figure 7 .",
        "the test image use in the objective assessment .",
        "max-pooling layer as summarize in table 1 .",
        "as show in the table 1 , n1 ; n2 , and n3represent the number of lters use in each convolution layer , and p1is the size of receptive eld in max-pooling layer .",
        "u1is a factor of magni cation in the decode part as show in fig .",
        "3 .",
        "as summarize in table 1 , the small size of the receptive eld in max- pooling layer and more convolution lters provide well denoising performance with the small mse value in the training and validation .",
        "therefore , the propose method take the maximum value in the local window of size 2 \u00022 .",
        "the output size of convolution and max-pooling layer be summarize in table 2 .",
        "volume 6 , 2018 22089s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement figure 8 .",
        "the performance comparison of propose and exist method use the synthesized low-light image : ( a ) input image , ( b ) synthesize low-light image , ( c ) kim 's method [ 20 ] , ( d ) jiang 's method [ 21 ] , ( e ) jobson 's method [ 5 ] , ( f ) fu 's method [ 8 ] , ( g ) guo 's method [ 22 ] , ( h ) park 's method [ 12 ] , and ( i ) the propose method .",
        "figure 9 .",
        "the performance comparison of propose and exist method use the synthesized low-light image : ( a ) input image , ( b ) synthesize low-light image , ( c ) kim 's method [ 20 ] , ( d ) jiang 's method [ 21 ] , ( e ) jobson 's method [ 5 ] , ( f ) fu 's method [ 8 ] , ( g ) guo 's method [ 22 ] , ( h ) park 's method [ 12 ] , and ( i ) the propose method .",
        "c. objective assessments to perform the objective assessment of the propose method , we synthesize the low-light image by degrade the brightness of the ideal image with an additive gaussian noise with zero mean and \u001bd3 only in the dark region .",
        "fig .",
        "7 show a set of ideal image , and the corresponding psnr and ssim value be summarize in table 3 .",
        "figs .",
        "8 ( a ) and 9 ( a ) show the ideal image and figs .",
        "8 ( b ) and 9 ( b ) show the synthesized low-light images.the histogram-based method can not provide a success- fully enhance result in both dark and bright region with an artifact of brightness saturation [ 20 ] .",
        "as show in figs .",
        "8 ( d ) and 9 ( d ) , although the transmission map-based method provide the enhanced result use the degradation model of hazy image , it can not avoid the noise ampli - cation and color distortion [ 21 ] .",
        "likewise , although job- son 's method provide the enhanced result use multi-scale retinex with the color correction function to suppress the color 22090 volume 6 , 2018s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement table 3 .",
        "objective evaluation of the performance use psnr and ssim [ 23 ] .",
        "the red and blue color represent the first and second best score , respectively .",
        "figure 10 .",
        "the performance comparison of propose and exist method use the real low-light image : ( a ) original image , ( b ) kim 's method [ 20 ] , ( c ) jiang 's method [ 21 ] , ( d ) jobson 's method [ 5 ] , ( e ) fu 's method [ 8 ] , ( f ) guo 's method [ 22 ] , ( g ) park 's method [ 12 ] , and ( h ) the propose method .",
        "figure 11 .",
        "the performance comparison of propose and exist method use the real low-light image : ( a ) original image , ( b ) kim 's method [ 20 ] , ( c ) jiang 's method [ 21 ] , ( d ) jobson 's method [ 5 ] , ( e ) fu 's method [ 8 ] , ( f ) guo 's method [ 22 ] , ( g ) park 's method [ 12 ] , and ( h ) the propose method .",
        "distortion , it also show the noise ampli cation , which can be easily recognize in the cropped , enlarge image [ 5 ] .",
        "as show in figs .",
        "8 ( f ) and 9 ( f ) , the variational retinex model-based method provide well enhance result use the bright channel prior [ 8 ] .",
        "however , it lose the edge and texture while suppress the noise since it esti- mat the re ectance component use l2-norm minimiza- tion .",
        "although guo 's method provide high-contrast image by re ning the illumination map at the low-computational cost , it can not control the ampli ed noise as show in figs .",
        "8 ( g ) and 9 ( g ) [ 22 ] .",
        "park 's method provide well per- formance than fu 's method in preserve the edge by the l1-norm minimization while suppress the noise , but the resulting image show a certain amount of brightness satura- tion [ 12 ] .",
        "on the other hand , the propose method provide well enhanced result in the sense of brightness enhancement and noise reduction without undesired artifact use retinex- base dual autoencoder network.d .",
        "qualitative assessments in this subsection , the performance of the propose dual autoencoder be evaluate use real low-light image as show in figs .",
        "10 and 11 .",
        "the histogram-based method can provide contrast enhanced image by redistribute the his- togram bin in each sub-histogram , but it can not successfully improve the quality of the dark region of the background [ 20 ] .",
        "although jiang 's method provide the signi cantly enhance result by use the transmission map estimate from the inverted input low-light image , it can not avoid the color distortion and noise ampli cation [ 21 ] .on the other hand , jobson 's method provide enhanced result by estimate the re ectance component use multiple gaussian kernel .",
        "however , it provide unnaturally enhance result with a narrow dynamic range [ 5 ] .",
        "the variational retinex approach provide well enhanced image , but it show the over-enhancement with ampli ed noise and black halo near edge [ 8 ] .",
        "although guo 's method volume 6 , 2018 22091s .",
        "park et al .",
        ": dual autoencoder network for retinex-based low-light image enhancement provide the high-contrast resulting image use re ned illu- mination map , it need additional post-processing to reduce the noise ampli cation [ 22 ] .",
        "in term of noise removal , park 's method provide well result image by use l1-norm minimization to the re ectance component , but this method can not avoid the brightness saturation in the bright region [ 12 ] .",
        "on the other hand , the propose method can provide signi cantly enhance result without saturation and noise ampli cation use the retinex-based dual autoencoder model than exist image enhancement method .",
        "v. conclusion in this paper , we propose the novel low-light image enhance- ment framework use the dual autoencoder network model base on the retinex theory .",
        "the propose dual autoencoder model consist of the stacked and convolutional autoencoders to perform both brightness enhancement and noise reduction .",
        "in the propose algorithm , the stacked autoencoder be use to estimate the brightness enhance and blur illumination component since the very small number of hidden unit gen- erates the very compact feature of an input data .",
        "the convo- lutional autoencoder be use to prevent the noise ampli cation of the estimate re ectance component while preserve the edge .",
        "in addition , we observe that the stacked and convo- lutional autoencoders play a role of the smoothness term on the illumination and re ectance component in the variational retinex model .",
        "finally , the propose method can provide the high-quality image in various image processing application such as robot vision and visual surveillance system in low- light condition ."
    ],
    "processed_text": "received january 9 2018 accept february 23 2018 date publication march 6 2018 date current version may 9 2018 digital object identifier 101 109/access20182812809 dual autoencoder network retinexbased lowlight image enhancement seonhee park student member ieee soohwan yu student member ieee minseo kim kwanwoo park joonki paik senior member ieee department image graduate school advanced imaging science multimedia film chungang university seoul 06974 south korea corresponding author joonki paik paikj @ cauackr work support part institute information & communications technology promotion grant korea government grant 2017000250 part intelligent defense boundary surveillance technology using collaborative reinforced learning embedded edge camera image analysis abstract paper present dual autoencoder network model base retinex theory perform lowlight enhancement noise reduction combine stacked convolutional autoencoders propose method rst estimate spatially smooth illumination component bright input lowlight image use stacked autoencoder small number hidden unit next use convolutional autoencoder deal 2d image information reduce ampli ed noise brightness enhancement process analyze compare role stacked convolutional autoencoders constraint term variational retinex model experiment demonstrate performance propose algorithm compare stateoftheart exist lowlight contrast enhancement method index terms autoencoder image processing image enhancement neural network variational retinex model unsupervised learning introduction digital cameras play role sense information external world various application arti cial intel ligence remote sense surveillance system advance driver assistance system however amount incoming light sensor insuf cient poor illumi nation condition dynamic range acquire image reduce addition lowlight image corrupt additive noise limited number photon receive pixel result dif cult obtain highquality image lowlight condition lowlight artifact may reduce performance computer vision application object recognition detection track theoretically sound approach solve prob lem image enhancement base retinex theory understanding human visual system hvs speci cally land et al rst propose retinex theory demonstrate process hvs perceive color retina visual cortex 1 2 demonstrate hvs perceive color ected ratio light rather lightness retinex theorybased image enhancement method far develop improve dynamic rangeof dark region method enhance visibility subtract local global illumination component separation illumination ectance compo nents illposed problem jobson et al 3 de ned ectance component ratio intensity value center average intensity value propose singlescale retinex ssr enhance dynamic range eliminate illumination component esti mat gaussian lowpass ltering however result image show halo effect near edge conti nuity illumination component solve problem rahman et al 4 present multiscale retinex msr use multiple gaussian kernel different standard deviation although msr algorithm suppress halo effect use weighted summation multiple illumination com ponents result image avoid color distortion jobson et al extend previous work compensate color component apply color restoration function use ratio color channel 5 alternative approach enhance lowlight image variational retinex model propose base pri illumination ectance component 6 \u0015 12 kimmel et al 6 estimate illumination component 2208421693536 2018 ieee translations content mining permit academic research personal use also permit republication/redistribution require ieee permission see http //wwwieeeorg/publications_standards/publications/rights/indexhtml informationvolume 6 2018s park et al dual autoencoder network retinexbased lowlight image enhancement minimize gradient illumination component use l2regularization et al 7 estimate ectance component contain highfrequency component use anisotropic total variation tv prior instead gaus sian smoothness prior reduce ampli ed noise preserve edge fu et al 8 demonstrate relation ship bright channel illumination component use bright channel prior present variational retinex model suppress haloeffect park et al 9 penalize brightness illumination use quadratic delity prior illumination component respect enhanced version suppress overenhancement ectance component recently deep learningbased image process meth od propose image enhancement eld lore et al 13 adopt stackedsparse denoising autoen coder lowlight image enhancement framework simul taneously perform brightness enhancement noise removal shen et al 14 analyze property msr algo rithm sense convolutional neural network cnn propose msrnet enhance lowlight image use cnn architecture paper present novel lowlight image enhance ment framework combine stacked convolutional autoencoders base retinex theory addition ana lyze relationship variational retinex model propose autoencoderbased enhancement meth od major contribution propose method twofold since stacked autoencoder decompose lowlight input patch compact feature reconstruct opti mal illumination component enhanced brightness ii convolutional autoencoder play role suppress noise ampli cation ectance component without degrade sharp edge addition stacked autoencoder regard smoothness term brightness con straint illumination component manner convolutional autoencoder enforce penalty ectance component reduce ampli ed noise paper organize follow section ii describe variational retinex model lowlight net theo retical background section iii present propose low light image enhancement framework use dual autoencoder experimental result show section iv section v conclude paper ii related works variational retinex model enhance contrast lowlight image kimmel et al 6 estimate illumination component minimize energy functional iterative manner however since illumination ectance component inversely proportional low illumination component result overenhancement ectance compo nent overcome problem adjust amount gamma correction enhance brightness estimatedillumination component resulting image obtain multiply ectance adjust illumination component prevent overenhancement ectance com ponent park et al 9 present modi ed variational retinex model use additional data delity term penalize brightness illumination component arg min fr fl\u00151kfrfl\u0000gk2 2c\u00152krflk2 2 c\u00153krfrk1c\u00154kfl\u0000oflk2 2 1 wherekfrfl\u0000gk2 2represents data delity term krflk2 2andkrfrk1the smoothness term illumination ectance component respectively kfl\u0000oflk2 2the data delity term illumination component enhanced version gamma correction \u00151 \u00152 \u00153 \u00154represent regularization parameter park 's method smoothness term illumination component krflk2 2 penalize gradient illumination component use isotropic tvprior equivalent gaussian smoothness prior addition since bright ness illumination component iteratively increase use fourth quadratic data delity term 1 method estimate natural ectance component without gamma correction illumination component moreover method reduce noise minimize loss edge information use anisotropic tvprior ectance component b learningbased image enhancement methods autoencoder feedforward neural network aim extract meaningful feature compress input data unsupervised manner 15 \u0015 19 vincent et al 17 per form noise removal use stack denoising autoencoder pair original noise corrupted vector method train autoencoder reconstruct output vector close original vector selfsupervised manner compressed representation noise vector motivated denoising autoencoder lore et al 13 present lowlight net llnet enhance lowlight image use stacked denoising autoencoder sparsity prior lowdimensional representation provide compact meaningful feature simul taneously perform contrast enhancement noise removal lore et al generate pair groundtruth cor rupted image training data corrupted image produce degrade brightness groundtruth image use gamma correction add white gaussian noise weight bias autoencoder update backpropagation step minimize error groundtruth reconstruct image moreover learn denoising contrast enhancement net work separately present stag llnet indepen dently control performance image enhancement module volume 6 2018 22085s park et al dual autoencoder network retinexbased lowlight image enhancement figure 1 propose lowlight image enhancement framework iii dual autoencoder network section describe propose lowlight image enhancement framework use stack convolutional autoencoders propose dual autoencoder model esti mat enhanced image three step estimation illumination component use stacked autoencoder ii initial estimation ectance component iii ne ment ectance component use convolutional autoen coder following subsection describe role stacked convolutional autoencoders addition analyze relationship propose network architecture constraint term modi ed variational retinex model 12 fig 1 show blockdiagram propose lowlight image enhancement framework illumination estimation using stacked autoencoder based retinex decomposition model illumina tion component lowfrequency characteristic since smoothly change image space reason gaussian lowpass lter popular exist ing illumination estimation method hand propose method estimate enhanced illumination component use stack autoencoder reduce dimensionality input data conventional denoising autoencoder play role esti mat original data give corrupted version training step neural network use small number hidden unit encoder layer provide compressed representation input data imply reconstruction original data successful fig 2 show comparative result reconstruction brightness enhance illumination give input lowlight image show fig 2 neural network small num ber hidden unit successfully preserve image structure edge texture poor performance preserve edge implies resulting image consistent original image term noise reduction however blurred result autoencoder use illumination component lowfrequency figure 2 comparative result reconstruction brightness enhance illumination patch corrupt input patch b reconstruct patch use 256 128 32 hidden unit hidden layer c reconstruct patch use 256 128 64 hidden unit hidden layer reconstruct patch use 256 128 96 hidden unit hidden layer property entire image show fig 2 addition since propose method train neural network use pair low highcontrast image patch brightness enhance illumination component obtain third fth seventh column fig 2 row well reconstruct edge detail hidden unit bottleneck layer row b c b reflectance estimation using convolutional autoencoder estimate ectance component use ratio input image illumination component estimate previous subsection given estimate illumination component previous step initial ectance com ponent estimate rdg l 2 rrepresents initially estimate ectance com ponent gthe input lowlight image lthe estimate illumination component however since noise component ampli ed dur ing contrast enhancement process noise removal ectance component need provide highquality image although stacked denoising autoencoder perform noise removal certain degree ignore 22086 volume 6 2018s park et al dual autoencoder network retinexbased lowlight image enhancement figure 3 propose convolutional autoencoder model twodimensional structural information image since input lowlight patch transform onedimensional vector contrary convolutional autoencoder use twodimensional structural information train ing result reduce loss detail 18 19 reason propose method estimate improve ectance component use convolutional autoencoder reduce noise ampli cation preserve edge fig 3 show propose fully convolutional autoencoder network model encode part consist one convolution layer one pooling layer one activation function rst convolution layer represent f1 x dmax 0 w1\u0003xcb1 3 xrepresents input image \u0003the convolution operation wkandbkrepresent weight bias kth convolution layer respectively extracted feature compress downsampling output convolution layer use maxpooling f2 x dp f1 x 4 p \u0001 represent maxpooling operation decrease dimensionality input data extract effec tive feature take maximum activation decode part consist one upsampling two convolution layer second convolution layer repre sented f3 x dmax 0 w2\u0003f2 x cb2 5 layer take compact cod feature reconstruct input image upsampling process represent f4 x du f3 x 6 u \u0001 represent upsampling operation sampling layer play role enlarge spatial resolution off3 x dimension input image x finally reconstruction result image perform third convolution layer f5 x d\u001b w3\u0003f4 x cb3 7 where\u001b \u0001 represent sigmoid function since last convolution layer provide reconstructed result image 01 use sigmoid function activation function rectus ed linear unit relu weight bias convolution layer update minimize difference reconstruct groundtruth image mean square error mse use de ne loss function l \u0012 d1 nnx id1kf xii\u0012 \u0000yik2 8 where\u0012dfw 1 w2 w3 b1 b2 b3g nrepresents number train data yitheith groundtruth image xi c motivation variational retinex model lowlight condition since reduced amount incoming light result low illumination component highly probable obtain overenhanced ectance component estimated ectance inversely proportional illumination component subsection compare propose dual autoencoder network model con straint term variational retinex model prevent enhancement ectance component 12 propose method estimate illumination compo nent extremely compressed representation input lowlight image explain subsection 3a since propose stacked autoencoder train provide volume 6 2018 22087s park et al dual autoencoder network retinexbased lowlight image enhancement blur illumination component use small number hidden unit regard smoothness prior krflk2 2 illumination component variational retinex model 1 addition propose stack autoen coder learn mapping low highcontrast patch obtain illumination component bright ness enhance image imply propose stacked autoencoder enforce data delity illumina tion component input lowlight image enhanced version fourth term 1 term noise reduction propose method reduce ampli ed noise enhanced ectance compo nent use convolutional autoencoder conven tional denoising autoencoder perform training form randomly corrupt input original vector reduce dimensionality hand con volutional autoencoder train neural network use twodimensional image data reason convolu tional autoencoder better preserve image structure since weight share input data pro pose method convolutional autoencoder regard constraint term ectance component use l1norm minimization 1 addition propose dual autoencoder train provide output equal input selfsupervised learning manner stacked convolutional autoencoders regard data delity termkfl\u0000oflk2 2in retinex model iv experimental results section demonstrate performance propose dual autoencoder model compare exist lowlight image enhancement method include kim 's method 20 jiang 's method 21 jobson 's method msrcr 5 fu 's method 8 guo 's method 22 park 's method 12 objective assessment evaluate use peak signaltonoise ratio psnr structural similarity index measure ssim 23 addition describe training condition generate proper training data analyze performance pro pose dual autoencoder model adam propose kingma ba 24 use optimization learn ing rate 0001 mini batch size autoencoder respectively set 512 128 experiment perform personal computer cpu 39 ghz ram 24 gbyte nvidia gpu titan xp training stacked convolutional autoencoder network respectively take 254 1501 second use gpu given input image size 512\u0002512 propose method provide enhanced result 133 second use cpu training data generation propose method respectively estimate illumina tion ectance component stacked convo lutional autoencoders show fig 1 since stacked autoencoder estimate brightness enhance illumination component input lowlight image generate figure 4 set ideal image collect internet synthesize training dataset set train data use pair low highcontrast patch dif cult naturally obtain low highcontrast image pair 13 reason synthesize lowcontrast image patch use 80000 patch size 33 \u000233 sample set ideal highcontrast image collect internet dataset use 25 show fig 4 lowcontrast patch generate use gamma correct luminance channel hsv color space ideal image patch fpdg p 9 gpandfprepresent low highcontrast patch adjusting parameter randomly set 16 33 patch propose dual autoencoder model convolutional autoencoder perform noise reduction initially estimate ectance component train convolutional denoising autoencoder generate 190000 pair noisy noisefree patch size 28 \u000228 use luminance channel hsv color space ideal image noisy patch synthesize add gaussian noise zero mean randomly select standard deviation \u001b2 10 18 fig 5 show part synthesized noisy lowcontrast patch groundtruth b performance proposed autoencoder models subsection compare performance stacked autoencoder estimate illumination component since autoencoder reconstruct original data com pressed representation input data performance depend number hidden unit reason compare result image different number hidden unit bottleneck layer show fig 6 22088 volume 6 2018s park et al dual autoencoder network retinexbased lowlight image enhancement figure 5 part synthesized training dataset propose dual autoencoder network high lowcontrast patch stacked autoencoder b noisefree noisy patch convolutional autoencoder figure 6 comparative result use different number hide unit bottleneck layer input image b 32 hidden unit ae 75489 c 64 hidden unit ae 75208 96 hidden unit ae 75205 first row show enhanced resulting image second row show estimated illumination component since input patch size 33 \u000233 transform vector r332 number bottleneck layer low 332to compress input data fig 6 show result image use estimate illumination component three different stack autoen coder 32 64 96 hidden unit bottle neck layer speci cally result image use 32 hidden unit provide best contrast com pressed representation input lowlight image imply stacked autoencoder better represent low frequency property illumination component small number hidden unit moreover high aver age entropy ae value imply result image image information visible edge 26 based observation use 32 hidden unit bottleneck layer convolutional autoencoder compare perfor mance noise reduction use mse different number convolution lters different size receptive eld oftable 1 comparison performance convolution layer three different filter size receptive field maxpooling layer use mse value 10\u00002 table 2 output size layer convolutional autoencoder figure 7 test image use objective assessment maxpooling layer summarize table 1 show table 1 n1 n2 n3represent number lters use convolution layer p1is size receptive eld maxpooling layer u1is factor magni cation decode part show fig 3 summarize table 1 small size receptive eld max pooling layer convolution lters provide well denoising performance small mse value training validation therefore propose method take maximum value local window size 2 \u00022 output size convolution maxpooling layer summarize table 2 volume 6 2018 22089s park et al dual autoencoder network retinexbased lowlight image enhancement figure 8 performance comparison propose exist method use synthesized lowlight image input image b synthesize lowlight image c kim 's method 20 jiang 's method 21 e jobson 's method 5 f fu 's method 8 g guo 's method 22 h park 's method 12 propose method figure 9 performance comparison propose exist method use synthesized lowlight image input image b synthesize lowlight image c kim 's method 20 jiang 's method 21 e jobson 's method 5 f fu 's method 8 g guo 's method 22 h park 's method 12 propose method c objective assessments perform objective assessment propose method synthesize lowlight image degrade brightness ideal image additive gaussian noise zero mean \u001bd3 dark region fig 7 show set ideal image corresponding psnr ssim value summarize table 3 figs 8 9 show ideal image figs 8 b 9 b show synthesized lowlight imagesthe histogrambased method provide success fully enhance result dark bright region artifact brightness saturation 20 show figs 8 9 although transmission mapbased method provide enhanced result use degradation model hazy image avoid noise ampli cation color distortion 21 likewise although job son 's method provide enhanced result use multiscale retinex color correction function suppress color 22090 volume 6 2018s park et al dual autoencoder network retinexbased lowlight image enhancement table 3 objective evaluation performance use psnr ssim 23 red blue color represent first second best score respectively figure 10 performance comparison propose exist method use real lowlight image original image b kim 's method 20 c jiang 's method 21 jobson 's method 5 e fu 's method 8 f guo 's method 22 g park 's method 12 h propose method figure 11 performance comparison propose exist method use real lowlight image original image b kim 's method 20 c jiang 's method 21 jobson 's method 5 e fu 's method 8 f guo 's method 22 g park 's method 12 h propose method distortion also show noise ampli cation easily recognize cropped enlarge image 5 show figs 8 f 9 f variational retinex modelbased method provide well enhance result use bright channel prior 8 however lose edge texture suppress noise since esti mat ectance component use l2norm minimiza tion although guo 's method provide highcontrast image ning illumination map lowcomputational cost control ampli ed noise show figs 8 g 9 g 22 park 's method provide well per formance fu 's method preserve edge l1norm minimization suppress noise resulting image show certain amount brightness satura tion 12 hand propose method provide well enhanced result sense brightness enhancement noise reduction without undesired artifact use retinex base dual autoencoder networkd qualitative assessments subsection performance propose dual autoencoder evaluate use real lowlight image show figs 10 11 histogrambased method provide contrast enhanced image redistribute togram bin subhistogram successfully improve quality dark region background 20 although jiang 's method provide signi cantly enhance result use transmission map estimate inverted input lowlight image avoid color distortion noise ampli cation 21 hand jobson 's method provide enhanced result estimate ectance component use multiple gaussian kernel however provide unnaturally enhance result narrow dynamic range 5 variational retinex approach provide well enhanced image show overenhancement ampli ed noise black halo near edge 8 although guo 's method volume 6 2018 22091s park et al dual autoencoder network retinexbased lowlight image enhancement provide highcontrast resulting image use ned illu mination map need additional postprocessing reduce noise ampli cation 22 term noise removal park 's method provide well result image use l1norm minimization ectance component method avoid brightness saturation bright region 12 hand propose method provide signi cantly enhance result without saturation noise ampli cation use retinexbased dual autoencoder model exist image enhancement method v conclusion paper propose novel lowlight image enhance ment framework use dual autoencoder network model base retinex theory propose dual autoencoder model consist stacked convolutional autoencoders perform brightness enhancement noise reduction propose algorithm stacked autoencoder use estimate brightness enhance blur illumination component since small number hidden unit gen erates compact feature input data convo lutional autoencoder use prevent noise ampli cation estimate ectance component preserve edge addition observe stacked convo lutional autoencoders play role smoothness term illumination ectance component variational retinex model finally propose method provide highquality image various image processing application robot vision visual surveillance system low light condition",
    "bag_of_words": {
        "received": 1,
        "january": 1,
        "accept": 1,
        "february": 1,
        "date": 2,
        "publication": 1,
        "march": 1,
        "current": 1,
        "version": 5,
        "may": 2,
        "digital": 2,
        "object": 2,
        "identifier": 1,
        "109/access20182812809": 1,
        "dual": 24,
        "autoencoder": 70,
        "network": 24,
        "retinexbased": 10,
        "lowlight": 47,
        "image": 111,
        "enhancement": 33,
        "seonhee": 1,
        "park": 20,
        "student": 2,
        "member": 3,
        "ieee": 5,
        "soohwan": 1,
        "yu": 1,
        "minseo": 1,
        "kim": 6,
        "kwanwoo": 1,
        "joonki": 2,
        "paik": 2,
        "senior": 1,
        "department": 1,
        "graduate": 1,
        "school": 1,
        "advanced": 1,
        "imaging": 1,
        "science": 1,
        "multimedia": 1,
        "film": 1,
        "chungang": 1,
        "university": 1,
        "seoul": 1,
        "south": 1,
        "korea": 2,
        "corresponding": 2,
        "author": 1,
        "paikj": 1,
        "cauackr": 1,
        "work": 3,
        "support": 1,
        "part": 7,
        "institute": 1,
        "information": 7,
        "communications": 1,
        "technology": 2,
        "promotion": 1,
        "grant": 2,
        "government": 1,
        "intelligent": 1,
        "defense": 1,
        "boundary": 1,
        "surveillance": 3,
        "using": 3,
        "collaborative": 1,
        "reinforced": 1,
        "learning": 3,
        "embedded": 1,
        "edge": 14,
        "camera": 1,
        "analysis": 1,
        "abstract": 1,
        "paper": 5,
        "present": 8,
        "model": 27,
        "base": 6,
        "retinex": 27,
        "theory": 5,
        "perform": 10,
        "noise": 37,
        "reduction": 7,
        "combine": 2,
        "stacked": 23,
        "convolutional": 25,
        "autoencoders": 9,
        "propose": 50,
        "method": 76,
        "rst": 3,
        "estimate": 23,
        "spatially": 1,
        "smooth": 1,
        "illumination": 50,
        "component": 68,
        "bright": 8,
        "input": 30,
        "use": 75,
        "small": 8,
        "number": 13,
        "hidden": 21,
        "unit": 20,
        "next": 1,
        "deal": 1,
        "2d": 1,
        "reduce": 12,
        "ampli": 15,
        "ed": 10,
        "brightness": 19,
        "process": 5,
        "analyze": 4,
        "compare": 7,
        "role": 7,
        "constraint": 3,
        "term": 16,
        "variational": 15,
        "experiment": 2,
        "demonstrate": 5,
        "performance": 17,
        "algorithm": 3,
        "stateoftheart": 1,
        "exist": 8,
        "contrast": 7,
        "index": 2,
        "terms": 1,
        "processing": 2,
        "neural": 7,
        "unsupervised": 2,
        "introduction": 1,
        "cameras": 1,
        "play": 5,
        "sense": 4,
        "external": 1,
        "world": 1,
        "various": 2,
        "application": 3,
        "arti": 1,
        "cial": 1,
        "intel": 1,
        "ligence": 1,
        "remote": 1,
        "system": 4,
        "advance": 1,
        "driver": 1,
        "assistance": 1,
        "however": 7,
        "amount": 4,
        "incoming": 2,
        "light": 5,
        "sensor": 1,
        "insuf": 1,
        "cient": 1,
        "poor": 2,
        "illumi": 1,
        "nation": 1,
        "condition": 5,
        "dynamic": 4,
        "range": 3,
        "acquire": 1,
        "addition": 10,
        "corrupt": 3,
        "additive": 2,
        "limited": 1,
        "photon": 1,
        "receive": 1,
        "pixel": 1,
        "result": 28,
        "dif": 2,
        "cult": 2,
        "obtain": 6,
        "highquality": 3,
        "artifact": 3,
        "computer": 2,
        "vision": 2,
        "recognition": 1,
        "detection": 1,
        "track": 1,
        "theoretically": 1,
        "sound": 1,
        "approach": 3,
        "solve": 2,
        "prob": 1,
        "lem": 1,
        "understanding": 1,
        "human": 1,
        "visual": 3,
        "hvs": 3,
        "speci": 2,
        "cally": 2,
        "land": 1,
        "et": 23,
        "al": 23,
        "perceive": 2,
        "color": 13,
        "retina": 1,
        "cortex": 1,
        "ected": 1,
        "ratio": 5,
        "rather": 1,
        "lightness": 1,
        "theorybased": 1,
        "far": 1,
        "develop": 1,
        "improve": 3,
        "rangeof": 1,
        "dark": 4,
        "region": 5,
        "enhance": 20,
        "visibility": 1,
        "subtract": 1,
        "local": 2,
        "global": 1,
        "separation": 1,
        "ectance": 33,
        "compo": 4,
        "nents": 1,
        "illposed": 1,
        "problem": 3,
        "jobson": 8,
        "de": 2,
        "ned": 2,
        "intensity": 2,
        "value": 7,
        "center": 1,
        "average": 1,
        "singlescale": 1,
        "ssr": 1,
        "eliminate": 1,
        "esti": 4,
        "mat": 4,
        "gaussian": 8,
        "lowpass": 2,
        "ltering": 1,
        "show": 26,
        "halo": 3,
        "effect": 2,
        "near": 2,
        "conti": 1,
        "nuity": 1,
        "rahman": 1,
        "multiscale": 2,
        "msr": 3,
        "multiple": 3,
        "kernel": 2,
        "different": 7,
        "standard": 2,
        "deviation": 2,
        "although": 7,
        "suppress": 7,
        "weighted": 1,
        "summation": 1,
        "com": 6,
        "ponents": 1,
        "avoid": 4,
        "distortion": 4,
        "extend": 1,
        "previous": 3,
        "compensate": 1,
        "apply": 1,
        "restoration": 1,
        "function": 7,
        "channel": 6,
        "alternative": 1,
        "pri": 1,
        "kimmel": 2,
        "translations": 1,
        "content": 1,
        "mining": 1,
        "permit": 2,
        "academic": 1,
        "research": 1,
        "personal": 2,
        "also": 2,
        "republication/redistribution": 1,
        "require": 1,
        "permission": 1,
        "see": 1,
        "http": 1,
        "//wwwieeeorg/publications_standards/publications/rights/indexhtml": 1,
        "informationvolume": 1,
        "2018s": 4,
        "minimize": 5,
        "gradient": 2,
        "l2regularization": 1,
        "contain": 1,
        "highfrequency": 1,
        "anisotropic": 2,
        "total": 1,
        "variation": 1,
        "tv": 1,
        "prior": 8,
        "instead": 1,
        "gaus": 1,
        "sian": 1,
        "smoothness": 7,
        "preserve": 7,
        "fu": 7,
        "relation": 1,
        "ship": 1,
        "haloeffect": 1,
        "penalize": 3,
        "quadratic": 2,
        "delity": 7,
        "respect": 1,
        "enhanced": 15,
        "overenhancement": 4,
        "recently": 1,
        "deep": 1,
        "learningbased": 2,
        "meth": 2,
        "od": 2,
        "eld": 4,
        "lore": 3,
        "adopt": 1,
        "stackedsparse": 1,
        "denoising": 10,
        "autoen": 4,
        "coder": 4,
        "framework": 7,
        "simul": 2,
        "taneously": 2,
        "removal": 6,
        "shen": 1,
        "property": 3,
        "algo": 1,
        "rithm": 1,
        "cnn": 2,
        "msrnet": 1,
        "architecture": 2,
        "novel": 2,
        "ment": 3,
        "ana": 1,
        "lyze": 1,
        "relationship": 2,
        "autoencoderbased": 1,
        "major": 1,
        "contribution": 1,
        "twofold": 1,
        "since": 16,
        "decompose": 1,
        "patch": 22,
        "compact": 4,
        "feature": 7,
        "reconstruct": 10,
        "opti": 1,
        "mal": 1,
        "ii": 4,
        "cation": 9,
        "without": 4,
        "degrade": 3,
        "sharp": 1,
        "regard": 4,
        "con": 3,
        "straint": 2,
        "manner": 5,
        "enforce": 2,
        "penalty": 1,
        "organize": 1,
        "follow": 1,
        "section": 6,
        "describe": 4,
        "net": 3,
        "theo": 1,
        "retical": 1,
        "background": 2,
        "iii": 3,
        "low": 11,
        "experimental": 2,
        "iv": 2,
        "conclude": 1,
        "related": 1,
        "works": 1,
        "energy": 1,
        "functional": 1,
        "iterative": 1,
        "inversely": 2,
        "proportional": 2,
        "nent": 3,
        "overcome": 1,
        "adjust": 2,
        "gamma": 5,
        "correction": 5,
        "estimatedillumination": 1,
        "resulting": 5,
        "multiply": 1,
        "prevent": 3,
        "ponent": 3,
        "modi": 2,
        "additional": 2,
        "data": 23,
        "arg": 1,
        "min": 1,
        "fr": 1,
        "fl\u00151kfrfl\u0000gk2": 1,
        "2c\u00152krflk2": 1,
        "c\u00153krfrk1c\u00154kfl\u0000oflk2": 1,
        "wherekfrfl\u0000gk2": 1,
        "2represents": 1,
        "krflk2": 3,
        "2andkrfrk1the": 1,
        "respectively": 6,
        "kfl\u0000oflk2": 1,
        "2the": 1,
        "\u00151": 1,
        "\u00152": 1,
        "\u00153": 1,
        "\u00154represent": 1,
        "regularization": 1,
        "parameter": 2,
        "isotropic": 1,
        "tvprior": 2,
        "equivalent": 1,
        "ness": 2,
        "iteratively": 1,
        "increase": 1,
        "fourth": 2,
        "natural": 1,
        "moreover": 3,
        "loss": 3,
        "methods": 1,
        "feedforward": 1,
        "aim": 1,
        "extract": 2,
        "meaningful": 2,
        "compress": 3,
        "vincent": 1,
        "per": 2,
        "form": 2,
        "stack": 5,
        "pair": 6,
        "original": 9,
        "corrupted": 3,
        "vector": 7,
        "train": 9,
        "output": 5,
        "close": 1,
        "selfsupervised": 2,
        "compressed": 3,
        "representation": 6,
        "motivated": 1,
        "llnet": 2,
        "sparsity": 1,
        "lowdimensional": 1,
        "provide": 25,
        "generate": 5,
        "groundtruth": 6,
        "cor": 1,
        "rupted": 1,
        "training": 10,
        "produce": 1,
        "add": 2,
        "white": 1,
        "weight": 4,
        "bias": 3,
        "update": 2,
        "backpropagation": 1,
        "step": 4,
        "error": 2,
        "learn": 3,
        "separately": 1,
        "stag": 1,
        "indepen": 1,
        "dently": 1,
        "control": 2,
        "module": 1,
        "volume": 7,
        "22085s": 1,
        "figure": 11,
        "three": 3,
        "estimation": 5,
        "initial": 2,
        "ne": 2,
        "following": 1,
        "subsection": 6,
        "fig": 13,
        "blockdiagram": 1,
        "based": 2,
        "decomposition": 1,
        "illumina": 3,
        "tion": 5,
        "lowfrequency": 2,
        "characteristic": 1,
        "smoothly": 1,
        "change": 1,
        "space": 3,
        "reason": 5,
        "lter": 1,
        "popular": 1,
        "ing": 4,
        "hand": 5,
        "dimensionality": 3,
        "conventional": 1,
        "give": 2,
        "encoder": 1,
        "layer": 30,
        "imply": 4,
        "reconstruction": 4,
        "successful": 1,
        "comparative": 3,
        "num": 1,
        "ber": 1,
        "successfully": 2,
        "structure": 2,
        "texture": 2,
        "implies": 1,
        "consistent": 1,
        "blurred": 1,
        "entire": 1,
        "highcontrast": 8,
        "third": 2,
        "fth": 1,
        "seventh": 1,
        "column": 1,
        "row": 4,
        "well": 7,
        "detail": 2,
        "bottleneck": 5,
        "reflectance": 1,
        "given": 2,
        "rdg": 1,
        "rrepresents": 1,
        "initially": 2,
        "gthe": 1,
        "lthe": 1,
        "dur": 1,
        "need": 2,
        "certain": 2,
        "degree": 1,
        "ignore": 1,
        "twodimensional": 3,
        "structural": 3,
        "transform": 2,
        "onedimensional": 1,
        "contrary": 1,
        "fully": 2,
        "encode": 1,
        "consist": 3,
        "one": 4,
        "convolution": 15,
        "pooling": 2,
        "activation": 3,
        "represent": 7,
        "f1": 2,
        "dmax": 2,
        "w1\u0003xcb1": 1,
        "xrepresents": 1,
        "\u0003the": 1,
        "operation": 3,
        "wkandbkrepresent": 1,
        "kth": 1,
        "extracted": 1,
        "downsampling": 1,
        "maxpooling": 6,
        "f2": 1,
        "dp": 1,
        "decrease": 1,
        "effec": 1,
        "tive": 1,
        "take": 4,
        "maximum": 2,
        "decode": 2,
        "upsampling": 3,
        "two": 1,
        "second": 5,
        "repre": 1,
        "sented": 1,
        "f3": 2,
        "w2\u0003f2": 1,
        "cb2": 1,
        "cod": 1,
        "f4": 1,
        "du": 1,
        "sampling": 1,
        "enlarge": 2,
        "spatial": 1,
        "resolution": 1,
        "off3": 1,
        "dimension": 1,
        "finally": 2,
        "f5": 1,
        "d\u001b": 1,
        "w3\u0003f4": 1,
        "cb3": 1,
        "where\u001b": 1,
        "sigmoid": 2,
        "last": 1,
        "reconstructed": 1,
        "rectus": 1,
        "linear": 1,
        "relu": 1,
        "difference": 1,
        "mean": 3,
        "square": 1,
        "mse": 4,
        "d1": 1,
        "nnx": 1,
        "id1kf": 1,
        "xii\u0012": 1,
        "\u0000yik2": 1,
        "where\u0012dfw": 1,
        "w2": 1,
        "w3": 1,
        "b1": 1,
        "b2": 1,
        "b3g": 1,
        "nrepresents": 1,
        "yitheith": 1,
        "xi": 1,
        "motivation": 1,
        "reduced": 1,
        "highly": 1,
        "probable": 1,
        "overenhanced": 1,
        "estimated": 2,
        "extremely": 1,
        "explain": 1,
        "3a": 1,
        "22087s": 1,
        "blur": 2,
        "mapping": 1,
        "conven": 1,
        "tional": 2,
        "randomly": 3,
        "volutional": 1,
        "convolu": 1,
        "better": 2,
        "share": 1,
        "pro": 2,
        "pose": 2,
        "l1norm": 3,
        "minimization": 3,
        "equal": 1,
        "termkfl\u0000oflk2": 1,
        "2in": 1,
        "results": 1,
        "include": 1,
        "jiang": 6,
        "msrcr": 1,
        "guo": 7,
        "objective": 5,
        "assessment": 3,
        "evaluate": 2,
        "peak": 1,
        "signaltonoise": 1,
        "psnr": 3,
        "similarity": 1,
        "measure": 1,
        "ssim": 3,
        "proper": 1,
        "adam": 1,
        "kingma": 1,
        "ba": 1,
        "optimization": 1,
        "rate": 1,
        "mini": 1,
        "batch": 1,
        "size": 12,
        "set": 6,
        "cpu": 2,
        "ghz": 1,
        "ram": 1,
        "gbyte": 1,
        "nvidia": 1,
        "gpu": 2,
        "titan": 1,
        "xp": 1,
        "512\u0002512": 1,
        "generation": 1,
        "convo": 3,
        "lutional": 3,
        "ideal": 7,
        "collect": 2,
        "internet": 2,
        "synthesize": 6,
        "dataset": 3,
        "naturally": 1,
        "lowcontrast": 4,
        "\u000233": 2,
        "sample": 1,
        "correct": 1,
        "luminance": 2,
        "hsv": 2,
        "fpdg": 1,
        "gpandfprepresent": 1,
        "adjusting": 1,
        "noisy": 4,
        "noisefree": 2,
        "\u000228": 1,
        "zero": 2,
        "select": 1,
        "\u001b2": 1,
        "synthesized": 5,
        "proposed": 1,
        "models": 1,
        "pressed": 2,
        "depend": 1,
        "high": 2,
        "hide": 1,
        "ae": 4,
        "first": 2,
        "r332": 1,
        "332to": 1,
        "bottle": 1,
        "neck": 1,
        "best": 2,
        "frequency": 1,
        "aver": 1,
        "age": 1,
        "entropy": 1,
        "visible": 1,
        "observation": 1,
        "perfor": 1,
        "mance": 1,
        "lters": 3,
        "receptive": 4,
        "oftable": 1,
        "comparison": 5,
        "filter": 1,
        "field": 1,
        "10\u00002": 1,
        "table": 7,
        "test": 1,
        "summarize": 4,
        "n1": 1,
        "n2": 1,
        "n3represent": 1,
        "p1is": 1,
        "u1is": 1,
        "factor": 1,
        "magni": 1,
        "max": 1,
        "validation": 1,
        "therefore": 1,
        "window": 1,
        "\u00022": 1,
        "22089s": 1,
        "assessments": 2,
        "\u001bd3": 1,
        "figs": 6,
        "imagesthe": 1,
        "histogrambased": 2,
        "success": 1,
        "saturation": 3,
        "transmission": 2,
        "mapbased": 1,
        "degradation": 1,
        "hazy": 1,
        "likewise": 1,
        "job": 1,
        "son": 1,
        "evaluation": 1,
        "red": 1,
        "blue": 1,
        "score": 1,
        "real": 3,
        "easily": 1,
        "recognize": 1,
        "cropped": 1,
        "modelbased": 1,
        "lose": 1,
        "l2norm": 1,
        "minimiza": 1,
        "ning": 1,
        "map": 3,
        "lowcomputational": 1,
        "cost": 1,
        "formance": 1,
        "satura": 1,
        "undesired": 1,
        "networkd": 1,
        "qualitative": 1,
        "redistribute": 1,
        "togram": 1,
        "bin": 1,
        "subhistogram": 1,
        "quality": 1,
        "signi": 2,
        "cantly": 2,
        "inverted": 1,
        "unnaturally": 1,
        "narrow": 1,
        "black": 1,
        "22091s": 1,
        "illu": 1,
        "mination": 1,
        "postprocessing": 1,
        "conclusion": 1,
        "gen": 1,
        "erates": 1,
        "observe": 1,
        "robot": 1
    },
    "objective": [
        "abstract this paper present a dual autoencoder network model base on the retinex theory to perform the low-light enhancement and noise reduction by combine the stacked and convolutional autoencoders .",
        "the propose method rst estimate the spatially smooth illumination component which be bright than an input low-light image use a stacked autoencoder with a small number of hidden unit .",
        "in the experiment , we demonstrate the performance of the propose algorithm by compare with the state-of-the-art exist low-light and contrast enhancement method .",
        "as an alternative approach to enhance the low-light image , variational retinex model be propose base on pri- or of illumination and re ectance component [ 6 ] \u0015 [ 12 ] .",
        "in this paper , we present a novel low-light image enhance- ment framework combine the stacked and convolutional autoencoders base on the retinex theory .",
        "on the other hand , the propose method estimate the enhanced illumination component use the stack autoencoder which reduce the dimensionality of the input data .",
        "in addition , since the propose method train the neural network use a pair of low- and high-contrast image patch , the brightness enhance illumination component can be obtain .",
        "for that reason , the propose method can estimate improve re ectance component use convolutional autoencoder to reduce noise ampli cation while preserve the edge .",
        "the propose method estimate the illumination compo- nent from the extremely compressed representation of the input low-light image explain in subsection 3.a .",
        "in term of noise reduction , the propose method reduce the ampli ed noise in the enhanced re ectance compo- nent by use the convolutional autoencoder .",
        "given the input image of size 512\u0002512 , the propose method provide the enhanced result in 13.3 second use cpu .",
        "training data generation the propose method respectively estimate the illumina- tion and re ectance component in the stacked and convo- lutional autoencoders as show in fig .",
        "therefore , the propose method take the maximum value in the local window of size 2 \u00022 .",
        "the performance comparison of propose and exist method use the synthesized low-light image : ( a ) input image , ( b ) synthesize low-light image , ( c ) kim 's method [ 20 ] , ( d ) jiang 's method [ 21 ] , ( e ) jobson 's method [ 5 ] , ( f ) fu 's method [ 8 ] , ( g ) guo 's method [ 22 ] , ( h ) park 's method [ 12 ] , and ( i ) the propose method .",
        "the performance comparison of propose and exist method use the synthesized low-light image : ( a ) input image , ( b ) synthesize low-light image , ( c ) kim 's method [ 20 ] , ( d ) jiang 's method [ 21 ] , ( e ) jobson 's method [ 5 ] , ( f ) fu 's method [ 8 ] , ( g ) guo 's method [ 22 ] , ( h ) park 's method [ 12 ] , and ( i ) the propose method .",
        "c. objective assessments to perform the objective assessment of the propose method , we synthesize the low-light image by degrade the brightness of the ideal image with an additive gaussian noise with zero mean and \u001bd3 only in the dark region .",
        "the performance comparison of propose and exist method use the real low-light image : ( a ) original image , ( b ) kim 's method [ 20 ] , ( c ) jiang 's method [ 21 ] , ( d ) jobson 's method [ 5 ] , ( e ) fu 's method [ 8 ] , ( f ) guo 's method [ 22 ] , ( g ) park 's method [ 12 ] , and ( h ) the propose method .",
        "the performance comparison of propose and exist method use the real low-light image : ( a ) original image , ( b ) kim 's method [ 20 ] , ( c ) jiang 's method [ 21 ] , ( d ) jobson 's method [ 5 ] , ( e ) fu 's method [ 8 ] , ( f ) guo 's method [ 22 ] , ( g ) park 's method [ 12 ] , and ( h ) the propose method .",
        "on the other hand , the propose method provide well enhanced result in the sense of brightness enhancement and noise reduction without undesired artifact use retinex- base dual autoencoder network.d .",
        "on the other hand , the propose method can provide signi cantly enhance result without saturation and noise ampli cation use the retinex-based dual autoencoder model than exist image enhancement method .",
        "v. conclusion in this paper , we propose the novel low-light image enhance- ment framework use the dual autoencoder network model base on the retinex theory .",
        "finally , the propose method can provide the high-quality image in various image processing application such as robot vision and visual surveillance system in low- light condition ."
    ],
    "references": [
        "",
        "REFERENCES [1] E. H. Land, ``The Retinex,'' Amer. Sci., vol. 52, no. 2, pp. 247\u0015264, 1964. [2] E. H. Land and J. J. McCann, ``Lightness and Retinex theory,'' J. Opt. Soc. Amer., vol. 61, no. 1, pp. 1\u001511, 1971. [3] D. J. Jobson, Z.-U. Rahman, and G. A. Woodell, ``Properties and perfor- mance of a center/surround Retinex,'' IEEE Trans. Image Process., vol. 6, no. 3, pp. 451\u0015462, Mar. 1997. [4] Z. Rahman, D. J. Jobson, and G. A. Woodell, ``Multi-scale Retinex for color image enhancement,'' in Proc. IEEE Int. Conf. Image Process., vol. 3. Sep. 1996, pp. 1003\u00151006. [5] D. J. Jobson, Z.-U. Rahman, and G. A. Woodell, ``A multiscale Retinex for bridging the gap between color images and the human observation of scenes,'' IEEE Trans. Image Process., vol. 6, no. 7, pp. 965\u0015976, Jul. 1997. [6] R. Kimmel, M. Elad, D. Shaked, R. Keshet, and I. Sobel, ``A variational framework for Retinex,'' Int. J. Comput. Vis., vol. 52, no. 1, pp. 7\u001523, 2003. [7] W. Ma, J.-M. Morel, S. Osher, and A. Chien, ``An L 1-based variational model for Retinex theory and its application to medical images,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2011, pp. 153\u0015160. [8] X. Fu, D. Zeng, Y. Huang, X. Ding, and X.-P. Zhang, ``A variational framework for single low light image enhancement using bright chan- nel prior,'' in Proc. IEEE Global Conf. Signal Inf. Process. , Dec. 2013, pp. 1085\u00151088. [9] S. Park, B. Moon, S. Ko, S. Yu, and J. Paik, ``Low-light image enhancement using variational optimization-based Retinex model,'' in Proc. IEEE Int. Conf. Consum. Electron., Jan. 2017, pp. 70\u001571. [10] D. Zosso, G. Tran, and S. Osher, ``A unifying Retinex model based on non-local differential operators,'' Proc. SPIE, vol. 8657, p. 865702, Feb. 2013. [11] X. Fu, Y. Liao, D. Zeng, Y. Huang, X. Zhang, and X. Ding, ``A prob- abilistic method for image enhancement with simultaneous illumination and re\u001dectance estimation,'' IEEE Trans. Image Process. , vol. 24, no. 12, pp. 4965\u00154977, Dec. 2015.[12] S. Park, S. Yu, B. Moon, S. Ko, and J. Paik, ``Low-light image enhance- ment using variational optimization-based Retinex model,'' IEEE Trans. Consum. Electron., vol. 63, no. 2, pp. 178\u0015184, May 2017. [13] K. G. Lore, A. Akintayo, and S. Sarkar, ``LLNet: A deep autoencoder approach to natural low-light image enhancement,'' Pattern Recognit., vol. 61, pp. 650\u0015662, Jan. 2017. [14] L. Shen, Z. Yue, F. Feng, Q. Chen, S. Liu, and J. Ma. (Nov. 2017). ``MSR- net:Low-light image enhancement using deep convolutional network.'' [Online]. Available: https://arxiv.org/abs/1711.02488 [15] C. Xing, L. Ma, and X. Yang, ``Stacked denoise autoencoder based fea- ture extraction and classi\u001ccation for hyperspectral images,'' J. Sensors, vol. 2016, Jun. 2016, Art. no. 3632943. [16] L. Gondara, ``Medical image denoising using convolutional denois- ing autoencoders,'' in Proc. IEEE 16th Int. Conf. Data Mining Work- shops (ICDMW), Barcelona, Spain, Dec. 2016, pp. 241\u0015246. [17] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, ``Extracting and composing robust features with denoising autoencoders,'' in Proc. 25th Int. Conf. Mach. Learn., 2008, pp. 1096\u00151103. [18] J. Masci, U. Meier, D. Cire³an, and J. Schmidhuber, ``Stacked convolu- tional auto-encoders for hierarchical feature extraction,'' in Arti\u001ccial Neu- ral Networks and Machine Learning. Springer, vol. 6791. 2011, pp. 52\u001559. [19] B. Du, W. Xiong, J. Wu, L. Zhang, L. Zhang, and D. Tao, ``Stacked convolutional denoising auto-encoders for feature representation,'' IEEE Trans. Cybern., vol. 47, no. 4, pp. 1017\u00151027, Apr. 2017. [20] Y.-T. Kim, ``Contrast enhancement using brightness preserving bi- histogram equalization,'' IEEE Trans. Consum. Electron., vol. 43, no. 1, pp. 1\u00158, Feb. 1997. [21] X. Jiang, H. Yao, S. Zhang, X. Lu, and W. Zeng, ``Night video enhancement using improved dark channel prior,'' in Proc. IEEE Int. Conf. Image Process., Sep. 2013, pp. 553\u0015557. [22] X. Guo, Y. Li, and H. Ling, ``LIME: Low-light image enhancement via illumination map estimation,'' IEEE Trans. Image Process., vol. 26, no. 2, pp. 982\u0015993, Feb. 2017. [23] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, ``Image quality assessment: From error visibility to structural similarity,'' IEEE Trans. Image Process., vol. 13, no. 4, pp. 600\u0015612, Apr. 2004. [24] D. P. Kingma and J. Ba. (2014). ``Adam: A method for stochastic optimiza- tion.'' [Online]. Available: https://arxiv.org/abs/1412.6980 [25] C. Dong, C. C. Loy, K. He, and X. Tang, ``Image super-resolution using deep convolutional networks,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. 38, no. 2, pp. 295\u0015307, Feb. 2016. [26] H. Hase, M. Yoneda, M. Sakai, and J. Yoshida, ``Evaluation of handprinting variation of characters using variation entropy,'' IEICE Trans. D, vol. 71, no. 6, pp. 1048\u00151056, 1988. SEONHEE PARK (S'16) was born in Busan, South Korea, in 1993. She received the B.S. degree in integrative engineering from Chung-Ang Uni- versity, South Korea, in 2016, where she is cur- rently pursuing the M.S. degree in digital imaging engineering. Her research interests include super- resolution, remote sensing images, denoising, and image enhancement and restoration for display processing. SOOHWAN YU (S'15) was born in Incheon, South Korea, in 1988. He received the B.S. degree in information and communication engineering from Suwon University, South Korea, in 2013, and the M.S degree in image engineering from Chung-Ang University, South Korea, in 2016, where he is currently pursuing the Ph.D. degree in image engineering. His research interests include image enhancement, super-resolution, and image restoration. 22092 VOLUME 6, 2018S. Park et al.: Dual Autoencoder Network for Retinex-Based Low-Light Image Enhancement MINSEO KIM was born in Seoul, South Korea, in 1992. She received the B.S. degree in integrative engineering from Chung-Ang University, South Korea, in 2016, where she is currently pursuing the M.S. degree in digital imaging engineering. Her research interests include dehazing, machine learning, and image enhancement and restoration for display processing. KWANWOO PARK was born in Ulsan, South Korea, in 1994. He received the B.S. degree in inte- grative engineering from Chung-Ang University, South Korea, in 2017, where he is currently pursu- ing the M.S. degree in digital imaging engineering. His research interests include denoising, machine learning, and image enhancement and restoration for display processing. JOONKI PAIK (M'89\u0015SM'12) was born in Seoul, South Korea, in 1960. He received the B.Sc. degree in control and instrumentation engineering from Seoul National University, in 1984, and the M.Sc. and Ph.D. degrees in electrical engineering and computer science from Northwestern University, in 1987 and 1990, respectively. From 1990 to 1993, he joined Samsung Electronics, where he designed the image stabilization chip sets for con- sumer camcorders. Since 1993, he has been the faculty with Chung-Ang University, Seoul, South Korea, where he is cur- rently a Professor with the Graduate School of Advanced Imaging Science, Multimedia, and Film. From 1999 to 2002, he was a Visiting Professor with the Department of Electrical and Computer Engineering, The University of Tennessee, Knoxville. He has served the Consumer Electronics Society of the IEEE as a member of the Editorial Board. Since 2005, he has been the Head of the National Research Laboratory in the \u001celd of image processing and intelligent systems. From 2005 to 2007, he served as the Dean of the Graduate School of Advanced Imaging Science, Multimedia, and Film. From 2005 to 2007, he was the Director of the Seoul Future Contents Convergence Cluster established by the Seoul Research and Business Devel- opment Program. In 2008, he was a full-time Technical Consultant for the System LSI Division of Samsung Electronics, where he developed various computational photographic techniques, including an extended depth of \u001celd system. He is currently serving as a member of the Presidential Advisory Board for Scienti\u001cc/Technical Policy with the Korean Government and also a Technical Consultant for the Korean Supreme Prosecutor's Of\u001cce for computational forensics. He was a recipient of the Chester-Sall Award from the IEEE Consumer Electronics Society, Academic Award from the Institute of Electronic Engineers of Korea, and a Best Research Professor Award from Chung-Ang University. VOLUME 6, 2018 22093"
    ]
}{
    "name": "Dynamic MR Image Reconstruction&#x2013;Separation From Undersampled (<formula formulatype=\"inline\"><tex Notation=\"TeX\">${\\bf k},t$</tex></formula>)-Space via Low-Rank Plus Sparse Prior",
    "paragraphs": [
        "ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 1689 dynamic mr image reconstruction–separation from undersampled ( ) -space via low-rank plus sparse prior benjamin trémoulhéac * , nikolaos dikaios , david atkinson , and simon r. arridge abstract— dynamic magnetic resonance imaging ( mri ) be use in multiple clinical application , but can stil lb e n e ﬁtf r o mh i g h e r spatial or temporal resolution .",
        "a dynamic mr image reconstruc-tion method from partial ( ) -space measurement be introduce that recovers and inherently separate the in f o r m a t i o ni nt h ed y - namic scene .",
        "the reconstruction model be base on a low-rank plus sparse decomposition prior , whi ch be relate to robust principal component analysis .",
        "an algorithm be propos ed to solve the convex optimization problem base on an alternating direction method ofmultipliers .",
        "the method be validate with numerical phantom sim-ulations and cardiac mri data agains t state of the art dynamic mri reconstruction method .",
        "results suggest that use the pro-posed approach as a mean of regularize the inverse problem re-mains competitive with state of th e art reconstruction technique .",
        "additionally , the decomposition induce by the reconstruction isshown to help in the context of motion estimation in dynamic con-trast enhance mri .",
        "index terms— compressive sen sing ( cs ) , dynamic magnetic res- onance ( mr ) imaging , low-rank , ro bust principal component anal- ysis , sparsity .",
        "i .",
        "introduction magnetic resonance imaging ( mri ) be a medical imaging technique that prod uces image of internal structure of the body .",
        "dynamic mri , a magnetic resonancesignal with both spatial and temporal information , be use inmultiple clinical application such as cardiovascular imaging or dynamic contrast enhance mri .",
        "however , mri be inherentlya slow process due to a combination of different constraint in-cluding nuclear relaxation time , peripheral nerve stimulation , power absorption and signal to noise .",
        "this can limit spatialand temporal mr resolution , ye t they be critical to monitor dynamic process where event change on relatively small manuscript receive february 08 , 2014 ; revise april 04 , 2014 ; accept april 27 , 2014 .",
        "date of publication april 30 , 2014 ; date of current versionjuly 30 , 2014 .",
        "this work be support by engineering and physical sciencesresearch council ( epsrc ) under grant ep/h046410/1 and the national in-stitute for health research ( nihr ) fund comprehensive biomedical re-search centre ( cbrc ) at university college london .",
        "asterisk indicate cor- respond author .",
        "* b. trémoulhéac be with the centre for medical image computing , univer- sity college london , wc1e 6bt london , u.k. ( e-mail : b.tremoulheac @ cs.ucl.ac.uk ) .",
        "n. dikaios and s. r. arridge be with the centre for medical image com- puting , university college london , wc1e 6bt london , u.k. d. atkinson be with the centre for medical imaging , university college london , wc1e 6jf london , u.k. digital object identi ﬁer 10.1109/tmi.2014.2321190scales ( few millimetre and sub-second ) .",
        "additionally , long scan duration can affect patient comfort and for that reasonincrease chance of motion artefact .",
        "hence , many approach have be propose to reduce ac- quisition time since the development of mri .",
        "popular tech-niques include for example echo planar image [ 1 ] , fast low-angle shot image [ 2 ] , and parallel mr image [ 3 ] which usesmultiple receiver coil .",
        "in addition , complementary accel eration approach that ex- ploit information redundancy in the signal have be developed.in general , part of the -space measurement that would nor- mally be acquire be skip .",
        "doing so result in an ill-posedinverse problem that need to be r egularized by incorporate prior information about the si gnal to provide physiologically representative and accurate image , i.e.",
        ", without artefact intro- duced by the ill-posedness .",
        "the prior information may be anyvaluable assumption about the signal .",
        "although this approachhas be use previously , it have recently receive interest dueto compress sensing ( cs ) [ 4 ] , [ 5 ] .",
        "cs refers to the topic ofsignal acquisition and reconstruc tion from incomplete measure- ments yield acceptable or perfect recovery use the factthat the signal of interest be spa rse ( either in its direct repre- sentation or after a transform to another domain ) .",
        "intuitively , a signal be say to be sparse if only a small fraction of coef ﬁ- cients be signi ﬁcant .",
        "cs have be successfully apply in mri and dynamic mri [ 6 ] – [ 8 ] .",
        "more r ecently , researcher have also look at exploit the low-rank property of matrix , insteadof simply sparsity of vector .",
        "th ese technique have start to gain interest in dynamic mri [ 9 ] , [ 10 ] and have be com-bined with a sparsity prior [ 11 ] , [ 12 ] .",
        "in addition , there hasbeen interest in the low-rank plus sparse decomposition model , also refer to as robust principal component analysis ( rpca ) [ 13 ] , [ 14 ] .",
        "many result in the literature have report that itis possible under some assumption to recover both low-rankand sparse component from only a fraction of observation [ 13 ] , [ 15 ] – [ 17 ] .",
        "the propose approach in this paper be basedon previous investigation use the low-rank plus sparse de-composition model as both a regularization prior and a separa-tion method in dynamic mri from partial measurement [ 18 ] , which be itself inspire by the work of gao et al .",
        "[ 19 ] in dy- namic compute tomography .",
        "gao et al .",
        "have apply their ap- proach in cardiac cine mri [ 20 ] – [ 22 ] and diffusion mri [ 23 ] , and recent work by otazo et al .",
        "[ 24 ] have also highlight the role of the low-rank plus sparse decomposition as a backgroundand contrast separation .",
        "this work be license under a creative commons attribution 3.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/3.0/1690 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 the work present in this paper be particularly develop for dynamic magnetic resonance imaging .",
        "image reconstruc-tion be formulate as an inverse problem regularize by a low-rank plus sparse prior , with a fourier transform as the sparsi-fying transform in the temporal direction .",
        "the alternate direc-tion method of multiplier ( admm ) framework be propose tosolve the minimization problem and derive an algorithm call -rpca .",
        "random sample scheme for dynamic undersam- plead mri be test and compare .",
        "experiments use com-plex-valued noise , numerical phantom and in vivo mri data along with comparison against state of the art dynamic mrreconstruction method be presen ted .",
        "additionally , the useful- ness of the decomposition provide by the reconstruction modelis show in the context of motion estimation in dynamic contrastenhanced mri .",
        "the rest of the article be organize as follow .",
        "section ii brieﬂy review reconstruction method for undersampled dynamic mri and the robust principal component analysistechnique .",
        "section iii present the propose -rpca ap- proach .",
        "numerical simulation be show in section iv.sections v and vi , respectively , present discussion and con-clusion of this study .",
        "ii .",
        "b ackground a .",
        "dynamic mri from partial measurements the imaging equation in dynamic mri can be write as ( 1 ) where represent the measured ( ) -space signal , be the desired image function and represent the noise .",
        "considering complex-valued raw mr data , the noisecan reasonably be model by an additive white gaussian distribution on both real and imaginary component ( with i.i.d.random variable ) [ 25 ] .",
        "finding the close representation of the true object from a limited number of measurement be the inverse problem of interest in this paper .",
        "here , limited refers to under- sample data or sub-nyquist sampling in accordance with theshannon–nyquist sample theory .",
        "b .",
        "fast imaging methods previously proposed many technique to tackle this inverse problem in dynamic mri rely on the assumption that a fourier transform along thetemporal dimension return an approximately sparse signal , because the original 2-d image in time exhibit signi ﬁcant correlation and/or periodici ty .",
        "this prior knowledge have be use in technique such as unfold [ 26 ] and -blast [ 27 ] ; the latter additionally exploit the compactness of thesignal distribution .",
        "compressed sensing ( cs ) [ 4 ] , [ 5 ] suggest that if the signal of interest be sparse , it be possible under certain assumption toreconstruct the signal exactly wi th high probability with few sample than the standard shannon–nyquist theory demands.in other word , cs propose to directly acquire compressivemeasurements and reconstruct the signal from this reduce setof sample .",
        "cs have be apply to mri [ 28 ] and in particular technique have be develop speci ﬁcally for dynamic mri , such as -sparse [ 6 ] and -focuss [ 7 ] .",
        "-focuss ﬁrst estimate a low-resolution version of the ( ) -space , prior to a cs reconstruction use the focuss algorithm [ 29 ] , a generalestimation method to ﬁnd localized energy solution from limit data .",
        "c. low-rank and sparsity methods consider image of dimension .",
        "approaches base on low-rank matrix completion be usually base on a ma-trix which be form so that each column represent a vectorizedmr image of the sequence , [ 30 ] , [ 10 ] .",
        "this matrix , refer to as a casorati matrix , be very likely to be approximately low -rank , where only a few singular value be signi ﬁcant , because of the high correlation between image .",
        "generally , a ﬁnite-dimensional spatio-temporal mri model equivalent to ( 1 ) be adopt ( 2 ) where represent the stacked ( ) -space measure- ments vector , be the mri encode oper- ator model both the sub-nyquist sampling and fourier trans-form with represent the matrix to recover , and be the noise vector .",
        "a common approach to recover low-rank matrix be base on rank minimization subject to adataﬁdelity term .",
        "however , similar to the norm in cs recon- struction , the rank operator make the minimization computa-tionally intractable as the dimension of the problem increases.the rank penalty be often replace by the nuclear norm , and theequality constraint relaxed .",
        "t he nuclear norm ( also know as trace norm or schatten -norm with ) be know to be the convex envelope of the rank operator [ 31 ] , [ 32 ] and be de ﬁned as the sum of singular value , i.e.",
        ", , w h e r e denote the th singular value of .",
        "in its lagrangian form , this lead to a nuclear norm regulari zed linear least square problem which can be solve ef ﬁciently use accelerate proximal gra- dient method [ 33 ] , [ 34 ] , but it be also possible to solve variantsof the rank minimization problem without the use of the nuclearnorm , for example base on powerfactorization [ 9 ] , [ 35 ] .",
        "finally , there have be recent i nterest to explore the combi- nation of both low-rank and sparsity penalty [ 11 ] , [ 12 ] .",
        "thesemethods formulate the problem as ( 3 ) where be relate to prior information about the rank and about the sparsity .",
        "in -slr [ 11 ] , the regularization penal- tie be the nonconvex schatten -norm with , a n d represent the spatio-temporal total variation norm , i.e.",
        ", the norm of the gradient in direction , a n d approximate by ﬁnite difference ; and be the associated regularization param eters .",
        "the author in [ 12 ] have also propose to exploit both rank and sparsity ap r i o r i infor- mation use respectively the partial separability model and atemporal fourier transform .",
        "a notable feature of this work liestrémoulhéac et al .",
        ": dynamic mr image reconstruction–separation from under-sampled ( ) -space 1 691 in a single formulation of both c onstraints use a sparsity con- straint to regularize the partial separability model .",
        "d. robust principal component analysis robust pca ( rpca ) [ 13 ] , [ 14 ] be a mathematical method that decompose a give matrix into a low-rank and sparse component .",
        "considering a casorati matrix of dimension , rpca describe the convex minimization problem ( 4 ) rpca be solve ef ﬁciently via alternat ing direction method of multiplier ( admm ) that rely on the augmented la-grangian function ( 5 ) where denote the trace inner product , be the lagrange multiplier of the linear constraint and be the penalty param- eter ( a positive scalar ) .",
        "admm be an iterative scheme that min-imizes over and separately , then update lagrange mul- tipliers .",
        "there exist closed-form expression for and , respectively the singular va lue thresholding operator ( where represent the singular value decomposition ) and the shrinkage operator de-ﬁned element-wise as .t h e penalty parameter can be ﬁxed as in [ 13 ] , [ 14 ] although an- other strategy be to update it dynamically [ 36 ] .",
        "the iterative pro-cedure be describe in algorithm 1 where denote the iteration number ( and the last iteration ) .",
        "rpca can be stop when the quantity be small or when a maximum number of iterat ion be reach .",
        "parameter can be see as a trade-off between how much the low-rank compo-nent get “ low-rank ” and how much the sparse component get “ sparse ” .",
        "the author of [ 13 ] suggest the theoretically sup-ported value ( 6 ) where .",
        "in general , this choice offer a reasonable sep- aration , although by vary it can be tailor to a give application .",
        "note that the low-rank plus sparse decomposition be not unique if the give matrix be both low-rank and sparse , sinceboth component can then be s een interchangeably as either low-rank or sparse ( for example , a matrix that have only one fig .",
        "1 .",
        "schematic rpca decomposition .",
        "given a matrix that be neither low- rank nor sparse , rpca estimate low-rank and sparse matrix such that .",
        "fig .",
        "2 .",
        "rpca on a breath-hold cardiac mri sequence with .",
        "algorithm 1 with w a su s e dt og e n e r a t e ﬁgures in this example .",
        "decomposition result in a rank-1 matrix for the low-rank part as show bythe only nonzero singular value , while the sparse component do not have alow rank because most of its singular value be not close to zero .",
        "it can beseen on the corresponding image and h istograms that the sparse component be much more sparse than the low-rank one .",
        "physiologically , the low-rank partappears as a static component while the sparse component capture motion , in this particular case mostly heartbeats .",
        "nonzero element ) .",
        "in a dynamic mr imaging scenario , it be unlikely that the data to reconstruct would be both low-rankand sparse at the same time .",
        "generally it will be approximatelylow-rank ( because 2-d image exhibit signi ﬁcant correlation and/or periodicity in time ) but not sparse in the image domainbecause either 2-d image repre sent anatomical section that be rarely sparse or the presence of noise make image notsparse .",
        "a graphic representa t i o no fr p c ai s h o w ni nf i g .1 , and rpca apply to mr image be present in fig .",
        "2 .",
        "iii .",
        "m ethod a. low-rank plus sparse prior a dynamic mr image reconstruction method from sub-nyquist measurement base on an intrinsic separa-tion between low-rank plus sparse component be introduced.the method have strong connection with robust principal com-ponents analysis from partial entry [ 13 ] , [ 15 ] and low-rank matrix recovery framework in accelerated dynamic mri [ 9 ] ,1692 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 [ 10 ] .",
        "the propose approach assume that the casorati matrix can be express as a linear combination of a low-rank plussparse component , and at the sam e time assume that this prior information be strong enough to be able to reconstruct imagesfrom partial sample .",
        "at this point , it be important to distinguishbetween method that consider the signal to reconstruct asbeing simultaneously low-rank and sparse ( as present insection ii-c ) and the approach present in this paper that consider the signal to reconstruct as be the sum of low-rankplus sparse component .",
        "image reconstruction be formulate as a minimization problem with the convex objective function deﬁned as ( 7 ) where represent the mri encoding operator model both the sub-nyquist sampling and fourier transform as described insection ii-c , denote the fourier transform operator along the temporal dimension , be a regularization parameter and be the decomposition parameter1as de ﬁn e di n ( 6 ) .t h ei n c l u - sion of those prior in the recons truction problem make the as- sumption that the dynamic imag ing data have the property of be separable into an approx imately low-rank and approxi- mately sparse component .",
        "the additional operator can be justiﬁed by the fact that the propose method deal with the re- construction of undersampled dynamic image data : a fourier transform along the temporal dimension as a sparsifying trans-form have be show to improve sparsity in many dynamic re-construction method ( e.g.",
        ", [ 6 ] , [ 7 ] ) .",
        "this be bene ﬁcial since it be assume in such study that the more the signal be sparse , thehigher the undersampling ratio can be .",
        "an illustration be pro-vided in fig .",
        "3 .",
        "the method be name -rpca , since the ﬁrst term in the objective function represent a data ﬁtting criterion enforce consistency between reconstruc ted data and partial acquire ( ) -space sample , and the second term enclose a low-rank plus sparse decomposition .",
        "b. complex-valued data although rpca have be study f or real-valued matrix , it can be show empirically that complex-valued matrix can alsobe separate into the sum of low-rank plus sparse components.the rpca algorithm can readil y handle a complex-valued ma- trix since it be base on operator that be easily extensible tocomplex-valued data .",
        "indeed , the singular value thresholdingoperator ( svt ) be a shrinkage on s ingular value that be always nonnegative real number ( even for a complex-valued matrix ) .hence , svt can be simply generalized and de ﬁned as , w h e r e denote the hermitian transpose of .",
        "the shrinkage operator can also be easily extend to com- plex-valued number .",
        "the reason for interest in complex-valued 1the decomposition parameter can be see as either orinterchangeably .",
        "in the following , we will mainly refer to it as because it be easy to interpret since it can be see as a scaling parameter that do not depend on the matrixdimensions .",
        "fig .",
        "3 .",
        "justi ﬁcation of the additional fourier transform operator along the time dimension use different decomposition parameter .t h e norm of the sparse component transform use the fourier operator along the time dimension ( gray ) be generally low than the norm of the sparse component on its own ( black ) .",
        "this ﬁgure have be generate use algorithm 1 and breath-hold car- diac mri dataset of fig .",
        "2. decomposition be that mr data be inherently complex-valued , although usually only magn itude image be display .",
        "c. image reconstruction to minimize ( 7 ) , an algorithm be derive base on admm , which can be interpret as a variable splitting scheme com-bined with the augmented lagrangi an [ 37 ] , [ 38 ] .",
        "variable split- ting be introduce ( 8 ) and the associate augmented lagrangian function ( 9 ) where be lagrangian multiplier and denote the real part .",
        "ignoring constant irrelevant t o optimization , ( 9 ) can also be write as ( 10 ) admm minimize over and separately lead to sub-problems that have closed-form solution .",
        "the nuclearnorm minimization problem be so lved analytically via singular value thresholding [ 39 ] ; the solution of the norm problem istrémoulhéac et al .",
        ": dynamic mr image reconstruction–separation from under-sampled ( ) -space 1 693 find by soft thresholding [ 13 ] , [ 14 ] , and the other sub-prob- lem be quadratic result in a linear system of equation ( 11 ) ( 12 ) ( 13 ) ( 14 ) based on these analytical solution , an image reconstruction procedure be derive ( algorith m 2 ) , which can be see as rpca for undersampled ( ) -space mri data .",
        "penalty parameter and be both set and ﬁxed to 1 , although as in standard rpca they could be update dynamically .",
        "to ensure convergence , the -rpca algorithm be stop when a maximum number of 200 iteration be reach , or when .",
        "d. sampling strategies low-rank matrix completion and compress sense have strong parallel [ 31 ] .",
        "hence , the sample strategy adoptedin this paper be similar to compressed sense mri methods.one of the requirement for a su ccessful cs reconstruction in mri be the incoherence of unde rsampling artefact .",
        "this can be achieve by undersampling randomly in -space .",
        "however , sample strategy must also satisfy hardware and physiolog-ical constraint , which general ly mean that trajectory must follow relatively smooth line and curve [ 8 ] .",
        "since a conventional strategy to acquire fourier sample in mri be along parallel equispaced -space line onto a cartesiangrid , a convenient way to achieve incoherent undersampling be to randomly select few line .",
        "however , since the energy dis-tribution of mr image in -space be know to be concentrate close to the center , a common strategy consist of densely sam-pling central -space line and randomly select line else- where .",
        "although selection of random line can be draw froma simple uniform probability di stribution , a good approach be to give low probability to the selection of line nearer to the -space edge in order to take into account the energy distri- bution and also because it may o vercome coherence problem at low spatial frequency for so me sparsifying transforms [ 40 ] .",
        "this be often refer to as polynomial variable density sam-pling [ 28 ] .",
        "in this paper , a similar sampling strategy be adaptedto dynamic imaging , where for each acquisition time frame thesampling density of -space line be one near -space center and decrease towards the edge of -space .",
        "note that it have be report in the literature that radial sam- pling provide good reconstruction result from a cs point ofview since result artefact m ore closely resemble noise com- par to cartesian undersampling [ 8 ] .",
        "hence , a radial schemeis also test with acquisition be make by 2-d projectionsat different angle .",
        "equi-angul ar spacing projection be use and incoherency in time be achie ved by apply a random ro- tation between on the whole pattern across each acquisition frame as do in [ 11 ] .",
        "note the radial sampling ishere directly approximate to th e close cartesian trajectory , hence it be refer to as “ pseudo-radial ” since it do not in-clude important step that would have to be include in a realradial-based mri acquisition ( i .e.",
        ", a density compensation func- tion and a gridding procedure ) .",
        "an illustration of the sampling pattern use in this study be show in fig .",
        "4 .",
        "these undersampling strategy can beachieved by omit readout fr om conventional cartesian or radial acquisition .",
        "this make th em particularly suitable and inexpensive from an mr acquis ition point of view , since only minor pulse sequence modi ﬁcations be require .",
        "iv .",
        "e xperiments and results a .",
        "framework 1 ) preliminaries : experiments be run in matlab on a linux platform .",
        "intensity of data be normalize betweenvalues 0 and 255 prior to any processing .",
        "simulated datawere create directly in the image domain and in vivo data w e r eb a s e do nm a g n i t u d e - r e c o n s t r u c t e di m a g e sf r o ma nm rscanner .",
        "datasets be then un dersampled retrospectively use a polynomial variable density or pseudo-radial samplingschemes as show in fig .",
        "4 .",
        "in all experiment , white gaussiannoise be add explicitly on each real and imaginary channel of the undersampled data with a standard deviation to obtain more realistic simulation .",
        "performance of reconstruction method be quanti ﬁed with the follow metric : ( 15 ) where ( resp .",
        "represent the ground truth fully-sampled noiseless matrix ( resp .",
        "estim ated matrix ) .",
        "this quantity is1694 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 fig .",
        "4 .",
        "( a ) one time frame acquisition pattern for polynomial variable density sampling and ( b ) the ( ) -space sample pattern function of time ( leave ) with its associate probability density function ( right ) .",
        "( c ) one time frame acquisitionpattern for pseudo-radial sampling and ( d ) the angle of rotation function of time ( leave ) with the associated uniform probability density function ( right ) .",
        "express in decibel for conve nience .",
        "since ( 15 ) provide a global measure , the normalized mean square error ( nmse ) ateach time frame will be show for some experiment ( 16 ) where ( resp .",
        "represent the ground truth fully-sampled noiseless image ( resp .",
        "estimate image ) at time frame .",
        "2 ) comparisons with other reconstruction algorithms : a zero-ﬁlled inverse fourier transform and a sliding window re- construction use a zeroth-order hold technique [ 41 ] be in-cluded , mainly to illustrate the level of undersampling .",
        "compar-isons with dynamic mr reconstruction method -focuss [ 7 ] and -slr [ 11 ] be provide .",
        "lit erature review suggest that they be arguably very ef ﬁcient state of the art techniques respectively in cs , and low-rank and sparsity method for dy-namic mri reconstruction .",
        "-focuss be implement with 40 inner iteration ( con- jugate gradient step ) , two outer iteration ( focuss step ) , andweighting matrix power factor of 0.5 .",
        "the low-resolution initial estimate be important to guarantee a good performance of - focuss and be obtain by use a zero- ﬁlled inverse fourier transform use the low-frequency sample .",
        "in -slr , the nonconvex schatten -norm with be use .",
        "there be parameter to tune relate to the continuation strategy of the op-timization algorithm that be use to improve the convergencerate .",
        "these parameter be set at suggested value provide inthe -slr package ( penalty parameter for schatten and tv norm ; penalty parameter incrementationboth set to 25 in the outer loop ; maximum number of 50 innerand nine outer iteration ) .",
        "fig .",
        "5 .",
        "modelling local intensity change ( show here pixel intensity value in time ) as the uptake and washout of a contrast agent use the modi ﬁed tofts model [ 42 ] .",
        "3 ) regularization parameters : in-focuss , one regu- larization parameter can be tune t hat control the stability of the solution under noisy condition .",
        "here , reconstruction witha different regularization par ameter select from a range of value be compute and the best one be select in accordancewith ( 15 ) .",
        "in -slr , different regular ization parameter and for respectively the schatt en norm and spatio-temporal tv norm be test , and the best r econstruction be select ac- cording to ( 15 ) .",
        "a similar strategy for -rpca be employ by vary both the regularization and decomposition pa- rameters .",
        "note that if one be look for a speci ﬁc type of de- composition , can be ﬁxed accordingly , al though it should be note that it may also affect the reconstruction result , which isd i s c u s s e di ns e c t i o nv - a .",
        "b. reconstruction results this section present reconstruction result where the separa- tion be not of particular interest , but prove to be a strong enoughap r i o r i information to remain competitive against state of the art method .",
        "in these experiment , in-rpca be automati- cally select to return the best reconstruction .",
        "1 ) phantom simulations : first experiment be conduct on a numerical phantom of dimension , as show in figs .",
        "6 and 7 .",
        "this phantom be create to model typical dynamic mri sequence with different type oftime-varying component .",
        "speci ﬁcally , it can include periodic local and global motion , and lo calized change of intensity .",
        "local motion simulates movin g organ ( such as the beat heart ) while global motion simulate respiratory-like move-ment imitate free-breathing imaging .",
        "motion be modelledusing trigonometric function with vary frequency andamplitudes .",
        "local intensity change mimic a contrast enhance ( ce ) signal , i.e.",
        ", the uptake and washout of a contrast agentusing the modi ﬁed tofts model [ 42 ] as show in fig .",
        "5 .",
        "this be typical in dynamic contrast enhance mri study .",
        "while sim-plistic , the major advantage of this phantom be the full controland availability of ground truth .",
        "fine adjustment can be madesuch as add speci ﬁc level of noise , create motion-free or ce-free dynamic sequence .",
        "to evaluate the performanceof the different reconstruction algorithm , the same phantomwith different time-varying element be use .",
        "in particular , reconstruction method be test when the phantom have onlyintensity change ( no motion ) , p eriodic motion ( no intensity change ) and with a combination of the two .",
        "table i providessome characteristic of the thr ee phantom in the noiselesstrémoulhéac et al .",
        ": dynamic mr image reconstruction–separation from under-sampled ( ) -space 1 695 fig .",
        "6 .",
        "qualitative result for phantom with a combination of intensity and motion ( cartesian sampling ) .",
        "( a ) magnitude image .",
        "( b ) zoom-in magnitud ei m a g e s ( correspond to the red square on the ground truth image ) .",
        "( c ) phase image .",
        "( d ) -temporal pro ﬁles .",
        "( e ) -temporal pro ﬁles ( accord to the dot line on the ground truth image ) .",
        "time frame show in the ﬁrst three row correspond to the frame select on the dotted line on the temporal pro ﬁles .",
        "left colormaps refer to magnitude image .",
        "right colormap refers to phase image .",
        "case , i.e.",
        ", the rank , norm of the fourier transform along the time dimension and norm of the gradient in direction approximate by ﬁnite difference .",
        "note that noiseless ( ground truth ) matrix be of dimension with various rank depend on whether intensity/motion be present .",
        "however , noisy matrix be full-rank ( 80 ) because of the presence ofnoise , although they remain approximately low-rank with anumber of signi ﬁcant singular value about equivalent to their noiseless counterpart .",
        "in these experiment , the acceler ation factor be approximately 10 ( about 10 % of acquire sample ) .",
        "quantitative result arereported for cartesian sampling and pseudo-radial sampling intables ii and iii .",
        "reconstruction error be show in decibelsand have be compute as in ( 15 ) with associate regulariza- tion parameter ( s ) for the different method in bracket .",
        "for - slr , they refer to and for -rpca to .",
        "visual eval- uations be provide in figs .",
        "6 and 7 .",
        "fig .",
        "6 show magnitudeimages , phase image and temporal pro ﬁles for the phantom with a combination of intensity and motion .",
        "fig .",
        "7 present timeproﬁles of reconstruction for the phantom with only intensity and with only motion .",
        "different type of dynamic imaging be test , but from these result there be no indication in which -rpca might have a preference for a certain one .",
        "in fact , it can be observe that - rpca have a similar behavior as -slr , although -slr con- sistently provide good reconstruction than -rpca itself .",
        "both -slr and -rpca outperform -focuss when motion be present , and when a combination of intensity and mo-tion be present .",
        "when only intensity be present however , -fo- cuss seem to have a slight advantage over both -slr and -rpca .",
        "the general good performance of -slr over other method can possibly be attribute to the fact that the phantomis a piecewise constant signal .",
        "a spa tio-temporal tot al variation1696 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 fig .",
        "7 .",
        "( a , c ) -temporal pro ﬁles and ( b , d ) -temporal pro ﬁles of various reconstruction method for ( a , b ) intensity only phantom and ( c , d ) motion onlyphantom ( cartesian sampling ) .",
        "prior be particularly ef ﬁcient for this type of signal , since the total variation model penalize highly oscillatory solutionswhile allow jump in the regularized solution .",
        "in otherwords , this mean that the solution obtain by -slr be rather due to the sparsity prior than the low-rank one .",
        "for ex-ample , it can be see that no prior information about the rank ofthe matrix be use in the reconstruction of the phantom withonly intensity for cartesian sample [ fig .",
        "7 ( a ) and ( b ) ] , as be select equal to zero ( table i i , “ intensity only ” column ) .",
        "tables ii and iii show that all reconstruction method bene ﬁt from the pseudo-radial sampling , whether they be base onlyon sparsity or both low-rank and sparsity prior .",
        "this can be ex-pected because it can be see that a direct inversion ( zero- ﬁlled inverse fourier transform , zf-i dft ) already give an improved reconstruction performance whe n a pseudo-radial sampling pat- tern be employ over the car tesian sampling pattern .",
        "2 ) cardiac mri : the second experiment be conduct on cardiac in vivo mri data , speci ﬁcally a free-breathing cardio- vascular dataset of dimension from a 3t mri scanner .",
        "apart from motion such as heartbeat andlarge breathe movement , this dataset have complex anatom-ical feature that make it more challenging to reconstruct thanthe numerical phantom .",
        "an acceler ation factor of approximately 8 be choose which correspond to about 12.5 % of acquire sam-ples .",
        "it be necessary to add noise to in vivo data because the orig-table i characteristics of the different noiseless phantoms table ii reconstruction results using metric ( 15 ) ( e xpressed in decibels ) fornumerical phantoms withcartesian sampling .numbers in brackets refer to regularization parameters table iii reconstruction results using metric ( 15 ) ( e xpressed in decibels ) fornumerical phantoms withpseudo -radial sampling .numbers in brackets refer to regularization parameters inal noise in the magnitude imag e become part of the apparent signal when retrospectively undersampled .",
        "time frames extract from the different reconstruction method be show in fig .",
        "8 , although it be visually dif ﬁcult to claim objectively which method be the best .",
        "quantitative result be give in table iv for the different sampling strategies.additionally , nmse at each time frame be show in fig .",
        "9 forboth cartesian and pseudo-radial sampling .",
        "based on these result , all method perform similarly use the polynomial variable den ity sampling , and a slight advan- tage can be see for both -slr and -rpca when pseudo- radial sampling be use .",
        "in -rpca , the select reconstruc- tions be choose with , which mean that the select reconstruction have favour the low-rank part rather than thesparse part in this context .",
        "-slr do not successfully manage to obtain much good reconstruction result over other existingmethods as it previously do on the ﬁrst experiment .",
        "one of the possible reason can be attribute to the fact that the cardiacmri dataset do not have a particu larly sparse gradient in space and time compare to the numerical phantom .",
        "this last experiment demonstrate -rpca as a competi- tive and distinct dynamic mri r econstruction method from par- tial measurement .",
        "c. exploiting the separation in the following section , the utility of the intrinsic separation of the reconstruct data into low-rank and sparse componentsis demonstrate in the context of motion estimation in dynamiccontrast enhance ( dce ) mri .",
        "in dce mri , acquisition of multiple 2-d mr image be take before , during , and after the adm inistration of a contrast agent ( ca ) .",
        "the uptake and washout of the ca concentration overtrémoulhéac et al .",
        ": dynamic mr image reconstruction–separation from under-sampled ( ) -space 1 697 fig .",
        "8 .",
        "visual comparison of reconstruction method for cardiac mri data show one time frame magnitude image ( frame number ) .",
        "first row corre- sponds to cartesian sampling , second row to pseudo-radial sampling .",
        "table iv reconstruction results using metric ( 15 ) ( e xpressed in decibels ) forcardiac mri d atawithcartesian and pseudo -radial sampling fig .",
        "9 .",
        "nmse at each time frame for cardiac mri data with cartesian sampling ( top ) and pseudo-radial sampling ( bottom ) .",
        "time in the body correspond to local change of intensity in the mr image .",
        "pharmacokinetic analysis can then be use to relateto tissue characteristic [ 42 ] .",
        "however , patient motion duringacquisition ( such as heartbeat , breathing , or involuntary move- ments ) produce inter-frame misalignment and complicate the fig .",
        "10 .",
        "different type of separation into low-rank and sparse component use -rpca with different decomposition parameter .",
        "it can be observe that this parameter act as a trade-off b etween the two component .",
        "undersam- pling rate be 0.25 .",
        "( a ) low-rank time frame .",
        "( b ) sparse time frame .",
        "( c ) - temporal pro ﬁles of low-rank component .",
        "( d ) -temporal pro ﬁles of sparse component .",
        "estimation of the rate of the uptake by the tissue .",
        "image regis- tration can be use to solve this problem , but the presence of thecontrast enhance ( ce ) image in terferes with the registration procedure because conventional algorithm can interpret local intensity change as motion .",
        "due to the embedded separation , the propose -rpca ap- proach be expect to separate slow time-varying element frommore abrupt change .",
        "hence , it be possible to separate to somedegree the local change of intensity in the sparse componentwhen use an appropriate parameter .",
        "fig .",
        "10 demonstrate the different decomposition obtain with different .r e g i s - tering low-rank image that include most of the motion and lesslocal intensity change provoke by the ca be likely to provide a1698 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 fig .",
        "11 .",
        "-temporal pro ﬁles use in the registration procedure .",
        "for the registration of -rpca , only the low-rank part be use which mostly contain image without contrast enhancement thanks to the separation process .",
        "fig .",
        "12 .",
        "displacement ﬁelds ( zoom-in ) over source image use for registration .",
        "table v provide the associated quantitative result .",
        "( a ) ground truth noiseless phantom .",
        "( b ) noisy phantom with local intensity change .",
        "( c ) -focuss .",
        "( d ) -slr .",
        "( e ) -rpca , low-rank part .",
        "it can be see that the displacement ﬁeld be well estimate in the region with local change of intensity in -rpca .",
        "displacement ﬁeld that be close to the ground truth image ( i.e.",
        ", the same signal without ce im age ) .",
        "this displacement ﬁeld can then be employ for more accu rate motion correction [ 43 ] .",
        "as a proof of concept , the numer ical phantom of the previous section with a combination of int ensity and motion be employ for the purpose of demonstration with an acceleration factor of4 use the pseudo-radial sampling .",
        "-focuss and -slr be reconstruct as previously , use the best regularization pa-rameters .",
        "however , -rpca reconstruction be now explicitly select with to end up with mostly the local intensity change in the sparse part , and motion in the low-rank part .",
        "re-construction error for -focuss , -slr , and -rpca be , respectively , 25.3 db , 31.1 db , and 26.3 db .",
        "a sequential registration of each frame of -focuss , - slr and the low-rank part of -rpca be perform with niftyreg2 [ 44 ] , an ef ﬁcient c++ implementation of a parallel formulation of the free-form deformation ( ffd ) algorithm [ 45 ] base on cubic b-splines .",
        "the time pro ﬁles of the different reconstruction method along with the ground truth be shownin fig .",
        "11 .",
        "note the ground truth be obtain with the noise-less phantom create without int ensity change but include motion .",
        "the reference image take n for registration be the last time frame image in the respective dynamic reconstructedsequences .",
        "displacement ﬁelds ( zoom-in with source image use for registration ) be show in fig .",
        "12 .",
        "to quantify these result , as i m i l a rm e t r i ct o ( 1 5 ) i su s e dw ith the jacobian of the 2-d dis- placement ﬁelds take in the region of interest with local in- 2local normalize cross correlation be use as measure of similarity ( standard deviation of the gaussian kernel set to ﬁve pixel for all time point ) and a control point spacing of two pixel in all directions.table v displacement fields errors using the jacobian ( taken in the region of interest withlocal intensity changes ) in the metric ( 15 ) ( e xpressed in decibels ) tensity chang e .",
        "results be report in table v which show a slight impro vement for -rpca over other method .",
        "v. d iscussion a .",
        "prior assumptions and regularization parameters experiments suggest that from a reconstruction point of view , the prior assumption make in -rpca be strong enough to re- main competitive with state of the art method .",
        "the prior as-sumption in -focuss be that the -space be a sparse signal , which be appropriate with dynamic datasets that exhibit periodicity in time .",
        "-slr perform well over other method for phantom simulation , but be not so successful for freebreathing cardiac mri data .",
        "generally , regularization par ameters affect directly the reconstruction result , and se lecting the right one be always challenge in the general topic of inverse problem .",
        "in - focuss and -slr , the best reconstr uctions be select by test a range of different regularization parameter .",
        "twostrategies for the choice of in-rpca have be adopt .",
        "if interested in obtain the best reconstruction , the choice of should be select such that the b est reconstruction be return .",
        "however , can also be force to a speci ﬁc value to obtain atrémoulhéac et al .",
        ": dynamic mr image reconstruction–separation from under-sampled ( ) -space 1 699 fig .",
        "13 .",
        "in ﬂuence of regularization parameter on the reconstruction error ( in db ) for -slr and -rpca .",
        "numerical phantom simulation with 10-fold acceleration and cartesian sampling .",
        "for -slr , and refers to ( 3 ) and for -rpca , and refers to ( 7 ) .",
        "desirable decomposition .",
        "fig .",
        "13 present reconstruction error ( in db ) use different regularization parameter for -slr and -rpca .",
        "this ﬁgure and previous experiment use the phantom suggest that the low-rank ap r i o r i information in - slr be not play an important role in this case .",
        "when , it be observe that a good reconstruction can be obtain usingonly the sparsity ap r i o r i information .",
        "this can be attribute to the fact that piecewise constant signal such as the phantom isvery sparse when the norm of the gradient be compute .",
        "for -rpca , the regularization parameter be a trade-off between data consistency and the low-rank plus sparse decomposition.as show in fig .",
        "13 , the solution be not regularize when and an appropriate value must be select to obtain a goodregularized solution .",
        "the decomposition parameter can be vary , although it also affect s the reconstruction result .",
        "in this paper , the selection of regularization parameter be optimize but this be an unrealistic strategy since the groundtruth be not available in a practi cal scenario .",
        "however , method can be adapt to ﬁnd ideal regularization parameter such as the discrepancy principle if noi se property be know , and for example l-curve or generalize cross-validation method if not [ 46 ] .",
        "b. decomposition while a separation into low-r ank and sparse component be easy to see mathematically , it may be dif ﬁcult to interpret phys- iologically what it represent in a dynamic mri context .",
        "oneof the reason be that the decomposition depend on the typeof dynamic data .",
        "further work in this direction should be ad-dressed to understand more deep ly how it can be interpret physiologically .",
        "generally , the decomposition provide a separation into two component that have different c haracteristics .",
        "the low-rank component will tend to have slow time-varying element whilethe sparse component will capture more abrupt change , but can be modi ﬁed to balance between the two part .",
        "in the simulation , a speci ﬁc example have be show where partial isolation of local change of intensity in the sparse com-ponent from the general motio n lead to a good estimation of the displacement ﬁeld .",
        "departing from this example , it islikely that this combined reconstr uction-separation approach of- fers far application that could be investigate .",
        "for example , motion-related application where sparse and localized motionelements interfere with the general background signal , or arte-facts removal where the outli er component would cause unde- sired alteration of data .",
        "in the la tter case , an artefact correction algorithm for rf spike noise have be propose base on rpcaas a postprocessing technique [ 47 ] .",
        "c. noise this study have include complex-valued noise to simulate more realistic experiment .",
        "however , this study have not evalu-ated the reconstruction ( and separation ) performance of the pro-posed approach as a function of added noise .",
        "generally in - rpca , increase noise be incline to interfere with the sparsecomponent .",
        "both -focuss and -slr may be relatively more robust to noise regard reconstruct data , since in - focuss the noise in -space will generally not be rep- resent by highly sparse coef ﬁcients , and the spatio-temporal total variation norm will tend to smooth a noisy solution in - slr .",
        "d. acquisition and sampling two strategy to undersample the ( ) -space , a cartesian and pseudo-radial sampling pattern , have be use in thispaper .",
        "there be respectivel y base on polynomial variable density and random rotation acr oss each acquisition frame to produce incoherent sample a rtefacts .",
        "from the experiment section , in particular tables ii , i i i , a n di v , i ti ss u g g e s t e dt h a t the pseudo-radial undersampling strategy provide good recon-struction result for all method either base on only sparsity as -focuss , or base on low-rank and sparse prior informa- tion ( -slr , -rpca ) .",
        "however , these sample strategy w e r eb a s e do nr e t r o s p e c t i v ely undersampling the ( ) -space and they would ideally need to be va lidated use prospectively undersampled data from an mri scanner .",
        "e. computational times the purpose of this paper be not to focus on computational aspect of the different reconstruction method .",
        "the different1700 ieee transactions on medical imaging , vol .",
        "33 , no .",
        "8 , august 2014 algorithm use be implement in matlab and not opti- mized .",
        "however , it should be note that during our simulation , -focuss reconstruction could be obtain in less than a minute , whereas -slr and -rpca could require several minute of computation in contrast ( min ) .",
        "vi .",
        "c onclusion dynamic mr imaging be a widely use technique in medicine .",
        "numerous method have be develop to reduceacquisition time , but it can still bene ﬁt from high acceleration rate and ef ﬁcient reconstruction algorithm .",
        "this paper have present a method term -rpca that jointly reconstructs and separ ate dynamic mr data from par- tial measurement by employ a low-rank plus sparse regu-larization prior .",
        "while provide a competitive reconstructionmethod for accelerated dynamic mr i as comparison with state of the art method have show , this technique also provide aseparation into two component have different characteristicsthat can have potential when tailor ed to the right application .",
        "in this paper , the decomposition be use to partially separate the contrast enhanced region in a simulated dce sequence and helpin motion estimation .",
        "overall , this study support the use of low-rank and sparsity prior information in dynamic mr image reconstruction tech-niques from highly undersampled data .",
        "interestingly , the pro- pose reconstruction—separat ion approach suggest a method that be not only about ﬁnding the close representation of the true object , but be also a step towards method that would di-rectly infer relevant characteris tic from limited measurement ."
    ],
    "processed_text": "ieee transactions medical imaging vol 33 8 august 2014 1689 dynamic mr image reconstructionseparation undersampled space via lowrank plus sparse prior benjamin tremoulheac nikolaos dikaios david atkinson simon r arridge abstract dynamic magnetic resonance imaging mri use multiple clinical application stil lb e n e fitf r mh g h e r spatial temporal resolution dynamic mr image reconstruction method partial space measurement introduce recovers inherently separate f r ni nt h ed namic scene reconstruction model base lowrank plus sparse decomposition prior whi ch relate robust principal component analysis algorithm propos ed solve convex optimization problem base alternating direction method ofmultipliers method validate numerical phantom simulations cardiac mri data agains state art dynamic mri reconstruction method results suggest use proposed approach mean regularize inverse problem remains competitive state th e art reconstruction technique additionally decomposition induce reconstruction isshown help context motion estimation dynamic contrast enhance mri index terms compressive sen sing cs dynamic magnetic res onance mr imaging lowrank ro bust principal component anal ysis sparsity introduction magnetic resonance imaging mri medical imaging technique prod uces image internal structure body dynamic mri magnetic resonancesignal spatial temporal information use inmultiple clinical application cardiovascular imaging dynamic contrast enhance mri however mri inherentlya slow process due combination different constraint including nuclear relaxation time peripheral nerve stimulation power absorption signal noise limit spatialand temporal mr resolution ye critical monitor dynamic process event change relatively small manuscript receive february 08 2014 revise april 04 2014 accept april 27 2014 date publication april 30 2014 date current versionjuly 30 2014 work support engineering physical sciencesresearch council epsrc grant ep/h046410/1 national institute health research nihr fund comprehensive biomedical research centre cbrc university college london asterisk indicate cor respond author b tremoulheac centre medical image computing univer sity college london wc1e 6bt london uk email btremoulheac @ csuclacuk n dikaios r arridge centre medical image com puting university college london wc1e 6bt london uk atkinson centre medical imaging university college london wc1e 6jf london uk digital object identi fier 101109/tmi20142321190scales millimetre subsecond additionally long scan duration affect patient comfort reasonincrease chance motion artefact hence many approach propose reduce ac quisition time since development mri popular techniques include example echo planar image 1 fast lowangle shot image 2 parallel mr image 3 usesmultiple receiver coil addition complementary accel eration approach ex ploit information redundancy signal developedin general part space measurement would mally acquire skip result illposedinverse problem need r egularized incorporate prior information si gnal provide physiologically representative accurate image ie without artefact intro duced illposedness prior information may anyvaluable assumption signal although approachhas use previously recently receive interest dueto compress sensing cs 4 5 cs refers topic ofsignal acquisition reconstruc tion incomplete measure ments yield acceptable perfect recovery use factthat signal interest spa rse either direct repre sentation transform another domain intuitively signal say sparse small fraction coef fi cients signi ficant cs successfully apply mri dynamic mri 6 8 r ecently researcher also look exploit lowrank property matrix insteadof simply sparsity vector th ese technique start gain interest dynamic mri 9 10 combined sparsity prior 11 12 addition hasbeen interest lowrank plus sparse decomposition model also refer robust principal component analysis rpca 13 14 many result literature report itis possible assumption recover lowrankand sparse component fraction observation 13 15 17 propose approach paper basedon previous investigation use lowrank plus sparse decomposition model regularization prior separation method dynamic mri partial measurement 18 inspire work gao et al 19 dy namic compute tomography gao et al apply ap proach cardiac cine mri 20 22 diffusion mri 23 recent work otazo et al 24 also highlight role lowrank plus sparse decomposition backgroundand contrast separation work license creative commons attribution 30 license information see http //creativecommonsorg/licenses/by/30/1690 ieee transactions medical imaging vol 33 8 august 2014 work present paper particularly develop dynamic magnetic resonance imaging image reconstruction formulate inverse problem regularize lowrank plus sparse prior fourier transform sparsifying transform temporal direction alternate direction method multiplier admm framework propose tosolve minimization problem derive algorithm call rpca random sample scheme dynamic undersam plead mri test compare experiments use complexvalued noise numerical phantom vivo mri data along comparison state art dynamic mrreconstruction method presen ted additionally useful ness decomposition provide reconstruction modelis show context motion estimation dynamic contrastenhanced mri rest article organize follow section ii briefly review reconstruction method undersampled dynamic mri robust principal component analysistechnique section iii present propose rpca ap proach numerical simulation show section ivsections v vi respectively present discussion conclusion study ii b ackground dynamic mri partial measurements imaging equation dynamic mri write 1 represent measured space signal desired image function represent noise considering complexvalued raw mr data noisecan reasonably model additive white gaussian distribution real imaginary component iidrandom variable 25 finding close representation true object limited number measurement inverse problem interest paper limited refers sample data subnyquist sampling accordance theshannonnyquist sample theory b fast imaging methods previously proposed many technique tackle inverse problem dynamic mri rely assumption fourier transform along thetemporal dimension return approximately sparse signal original 2d image time exhibit signi ficant correlation and/or periodici ty prior knowledge use technique unfold 26 blast 27 latter additionally exploit compactness thesignal distribution compressed sensing cs 4 5 suggest signal interest sparse possible certain assumption toreconstruct signal exactly wi th high probability sample standard shannonnyquist theory demandsin word cs propose directly acquire compressivemeasurements reconstruct signal reduce setof sample cs apply mri 28 particular technique develop speci fically dynamic mri sparse 6 focuss 7 focuss first estimate lowresolution version space prior cs reconstruction use focuss algorithm 29 generalestimation method find localized energy solution limit data c lowrank sparsity methods consider image dimension approaches base lowrank matrix completion usually base matrix form column represent vectorizedmr image sequence 30 10 matrix refer casorati matrix likely approximately low rank singular value signi ficant high correlation image generally finitedimensional spatiotemporal mri model equivalent 1 adopt 2 represent stacked space measure ments vector mri encode oper ator model subnyquist sampling fourier transform represent matrix recover noise vector common approach recover lowrank matrix base rank minimization subject adatafidelity term however similar norm cs recon struction rank operator make minimization computationally intractable dimension problem increasesthe rank penalty often replace nuclear norm theequality constraint relaxed nuclear norm also know trace norm schatten norm know convex envelope rank operator 31 32 de fined sum singular value ie w h e r e denote th singular value lagrangian form lead nuclear norm regulari zed linear least square problem solve ef ficiently use accelerate proximal gra dient method 33 34 also possible solve variantsof rank minimization problem without use nuclearnorm example base powerfactorization 9 35 finally recent nterest explore combi nation lowrank sparsity penalty 11 12 thesemethods formulate problem 3 relate prior information rank sparsity slr 11 regularization penal tie nonconvex schatten norm n represent spatiotemporal total variation norm ie norm gradient direction n approximate finite difference associated regularization param eters author 12 also propose exploit rank sparsity ap r r infor mation use respectively partial separability model atemporal fourier transform notable feature work liestremoulheac et al dynamic mr image reconstructionseparation undersampled space 1 691 single formulation c onstraints use sparsity con straint regularize partial separability model robust principal component analysis robust pca rpca 13 14 mathematical method decompose give matrix lowrank sparse component considering casorati matrix dimension rpca describe convex minimization problem 4 rpca solve ef ficiently via alternat ing direction method multiplier admm rely augmented lagrangian function 5 denote trace inner product lagrange multiplier linear constraint penalty param eter positive scalar admm iterative scheme minimizes separately update lagrange mul tipliers exist closedform expression respectively singular va lue thresholding operator represent singular value decomposition shrinkage operator defined elementwise h e penalty parameter fixed 13 14 although strategy update dynamically 36 iterative procedure describe algorithm 1 denote iteration number last iteration rpca stop quantity small maximum number iterat ion reach parameter see tradeoff much lowrank component get lowrank much sparse component get sparse author 13 suggest theoretically supported value 6 general choice offer reasonable sep aration although vary tailor give application note lowrank plus sparse decomposition unique give matrix lowrank sparse sinceboth component een interchangeably either lowrank sparse example matrix one fig 1 schematic rpca decomposition given matrix neither low rank sparse rpca estimate lowrank sparse matrix fig 2 rpca breathhold cardiac mri sequence algorithm 1 w su e dt og e n e r e figures example decomposition result rank1 matrix lowrank part show bythe nonzero singular value sparse component alow rank singular value close zero beseen corresponding image h istograms sparse component much sparse lowrank one physiologically lowrank partappears static component sparse component capture motion particular case mostly heartbeats nonzero element dynamic mr imaging scenario unlikely data reconstruct would lowrankand sparse time generally approximatelylowrank 2d image exhibit signi ficant correlation and/or periodicity time sparse image domainbecause either 2d image repre sent anatomical section rarely sparse presence noise make image notsparse graphic representa fr p c ai h w ni nf g 1 rpca apply mr image present fig 2 iii ethod lowrank plus sparse prior dynamic mr image reconstruction method subnyquist measurement base intrinsic separation lowrank plus sparse component introducedthe method strong connection robust principal components analysis partial entry 13 15 lowrank matrix recovery framework accelerated dynamic mri 9 1692 ieee transactions medical imaging vol 33 8 august 2014 10 propose approach assume casorati matrix express linear combination lowrank plussparse component sam e time assume prior information strong enough able reconstruct imagesfrom partial sample point important distinguishbetween method consider signal reconstruct asbeing simultaneously lowrank sparse present insection iic approach present paper consider signal reconstruct sum lowrankplus sparse component image reconstruction formulate minimization problem convex objective function defined 7 represent mri encoding operator model subnyquist sampling fourier transform described insection iic denote fourier transform operator along temporal dimension regularization parameter decomposition parameter1as de fin e di n 6 h ei n c l u sion prior recons truction problem make sumption dynamic imag ing data property separable approx imately lowrank approxi mately sparse component additional operator justified fact propose method deal construction undersampled dynamic image data fourier transform along temporal dimension sparsifying transform show improve sparsity many dynamic reconstruction method eg 6 7 bene ficial since assume study signal sparse thehigher undersampling ratio illustration provided fig 3 method name rpca since first term objective function represent data fitting criterion enforce consistency reconstruc ted data partial acquire space sample second term enclose lowrank plus sparse decomposition b complexvalued data although rpca study f realvalued matrix show empirically complexvalued matrix alsobe separate sum lowrank plus sparse componentsthe rpca algorithm readil handle complexvalued trix since base operator easily extensible tocomplexvalued data indeed singular value thresholdingoperator svt shrinkage ingular value always nonnegative real number even complexvalued matrix hence svt simply generalized de fined w h e r e denote hermitian transpose shrinkage operator also easily extend com plexvalued number reason interest complexvalued 1the decomposition parameter see either orinterchangeably following mainly refer easy interpret since see scaling parameter depend matrixdimensions fig 3 justi fication additional fourier transform operator along time dimension use different decomposition parameter h e norm sparse component transform use fourier operator along time dimension gray generally low norm sparse component black figure generate use algorithm 1 breathhold car diac mri dataset fig 2 decomposition mr data inherently complexvalued although usually magn itude image display c image reconstruction minimize 7 algorithm derive base admm interpret variable splitting scheme combined augmented lagrangi 37 38 variable split ting introduce 8 associate augmented lagrangian function 9 lagrangian multiplier denote real part ignoring constant irrelevant optimization 9 also write 10 admm minimize separately lead subproblems closedform solution nuclearnorm minimization problem lved analytically via singular value thresholding 39 solution norm problem istremoulheac et al dynamic mr image reconstructionseparation undersampled space 1 693 find soft thresholding 13 14 subprob lem quadratic result linear system equation 11 12 13 14 based analytical solution image reconstruction procedure derive algorith 2 see rpca undersampled space mri data penalty parameter set fixed 1 although standard rpca could update dynamically ensure convergence rpca algorithm stop maximum number 200 iteration reach sampling strategies lowrank matrix completion compress sense strong parallel 31 hence sample strategy adoptedin paper similar compressed sense mri methodsone requirement su ccessful cs reconstruction mri incoherence unde rsampling artefact achieve undersampling randomly space however sample strategy must also satisfy hardware physiological constraint general ly mean trajectory must follow relatively smooth line curve 8 since conventional strategy acquire fourier sample mri along parallel equispaced space line onto cartesiangrid convenient way achieve incoherent undersampling randomly select line however since energy distribution mr image space know concentrate close center common strategy consist densely sampling central space line randomly select line else although selection random line draw froma simple uniform probability di stribution good approach give low probability selection line nearer space edge order take account energy distri bution also may vercome coherence problem low spatial frequency sparsifying transforms 40 often refer polynomial variable density sampling 28 paper similar sampling strategy adaptedto dynamic imaging acquisition time frame thesampling density space line one near space center decrease towards edge space note report literature radial sam pling provide good reconstruction result cs point ofview since result artefact ore closely resemble noise com par cartesian undersampling 8 hence radial schemeis also test acquisition make 2d projectionsat different angle equiangul ar spacing projection use incoherency time achie ved apply random ro tation whole pattern across acquisition frame 11 note radial sampling ishere directly approximate th e close cartesian trajectory hence refer pseudoradial since include important step would include realradialbased mri acquisition e density compensation func tion gridding procedure illustration sampling pattern use study show fig 4 undersampling strategy beachieved omit readout fr om conventional cartesian radial acquisition make th em particularly suitable inexpensive mr acquis ition point view since minor pulse sequence modi fications require iv e xperiments results framework 1 preliminaries experiments run matlab linux platform intensity data normalize betweenvalues 0 255 prior processing simulated datawere create directly image domain vivo data w e r eb e nm g n u e r e c n r u c e di g e sf r nm rscanner datasets un dersampled retrospectively use polynomial variable density pseudoradial samplingschemes show fig 4 experiment white gaussiannoise add explicitly real imaginary channel undersampled data standard deviation obtain realistic simulation performance reconstruction method quanti fied follow metric 15 resp represent ground truth fullysampled noiseless matrix resp estim ated matrix quantity is1694 ieee transactions medical imaging vol 33 8 august 2014 fig 4 one time frame acquisition pattern polynomial variable density sampling b space sample pattern function time leave associate probability density function right c one time frame acquisitionpattern pseudoradial sampling angle rotation function time leave associated uniform probability density function right express decibel conve nience since 15 provide global measure normalized mean square error nmse ateach time frame show experiment 16 resp represent ground truth fullysampled noiseless image resp estimate image time frame 2 comparisons reconstruction algorithms zerofilled inverse fourier transform sliding window construction use zerothorder hold technique 41 included mainly illustrate level undersampling comparisons dynamic mr reconstruction method focuss 7 slr 11 provide lit erature review suggest arguably ef ficient state art techniques respectively cs lowrank sparsity method dynamic mri reconstruction focuss implement 40 inner iteration con jugate gradient step two outer iteration focuss step andweighting matrix power factor 05 lowresolution initial estimate important guarantee good performance focuss obtain use zero filled inverse fourier transform use lowfrequency sample slr nonconvex schatten norm use parameter tune relate continuation strategy optimization algorithm use improve convergencerate parameter set suggested value provide inthe slr package penalty parameter schatten tv norm penalty parameter incrementationboth set 25 outer loop maximum number 50 innerand nine outer iteration fig 5 modelling local intensity change show pixel intensity value time uptake washout contrast agent use modi fied tofts model 42 3 regularization parameters infocuss one regu larization parameter tune hat control stability solution noisy condition reconstruction witha different regularization par ameter select range value compute best one select accordancewith 15 slr different regular ization parameter respectively schatt en norm spatiotemporal tv norm test best r econstruction select ac cording 15 similar strategy rpca employ vary regularization decomposition pa rameters note one look speci fic type de composition fixed accordingly al though note may also affect reconstruction result isd c u e di ns e c nv b reconstruction results section present reconstruction result separa tion particular interest prove strong enoughap r r information remain competitive state art method experiment inrpca automati cally select return best reconstruction 1 phantom simulations first experiment conduct numerical phantom dimension show figs 6 7 phantom create model typical dynamic mri sequence different type oftimevarying component speci fically include periodic local global motion lo calized change intensity local motion simulates movin g organ beat heart global motion simulate respiratorylike movement imitate freebreathing imaging motion modelledusing trigonometric function vary frequency andamplitudes local intensity change mimic contrast enhance ce signal ie uptake washout contrast agentusing modi fied tofts model 42 show fig 5 typical dynamic contrast enhance mri study simplistic major advantage phantom full controland availability ground truth fine adjustment madesuch add speci fic level noise create motionfree cefree dynamic sequence evaluate performanceof different reconstruction algorithm phantomwith different timevarying element use particular reconstruction method test phantom onlyintensity change motion p eriodic motion intensity change combination two table providessome characteristic thr ee phantom noiselesstremoulheac et al dynamic mr image reconstructionseparation undersampled space 1 695 fig 6 qualitative result phantom combination intensity motion cartesian sampling magnitude image b zoomin magnitud ei g e correspond red square ground truth image c phase image temporal pro files e temporal pro files accord dot line ground truth image time frame show first three row correspond frame select dotted line temporal pro files left colormaps refer magnitude image right colormap refers phase image case ie rank norm fourier transform along time dimension norm gradient direction approximate finite difference note noiseless ground truth matrix dimension various rank depend whether intensity/motion present however noisy matrix fullrank 80 presence ofnoise although remain approximately lowrank anumber signi ficant singular value equivalent noiseless counterpart experiment acceler ation factor approximately 10 10 acquire sample quantitative result arereported cartesian sampling pseudoradial sampling intables ii iii reconstruction error show decibelsand compute 15 associate regulariza tion parameter different method bracket slr refer rpca visual eval uations provide figs 6 7 fig 6 show magnitudeimages phase image temporal pro files phantom combination intensity motion fig 7 present timeprofiles reconstruction phantom intensity motion different type dynamic imaging test result indication rpca might preference certain one fact observe rpca similar behavior slr although slr con sistently provide good reconstruction rpca slr rpca outperform focuss motion present combination intensity motion present intensity present however fo cuss seem slight advantage slr rpca general good performance slr method possibly attribute fact phantomis piecewise constant signal spa tiotemporal tot al variation1696 ieee transactions medical imaging vol 33 8 august 2014 fig 7 c temporal pro files b temporal pro files various reconstruction method b intensity phantom c motion onlyphantom cartesian sampling prior particularly ef ficient type signal since total variation model penalize highly oscillatory solutionswhile allow jump regularized solution otherwords mean solution obtain slr rather due sparsity prior lowrank one example see prior information rank ofthe matrix use reconstruction phantom withonly intensity cartesian sample fig 7 b select equal zero table intensity column tables ii iii show reconstruction method bene fit pseudoradial sampling whether base onlyon sparsity lowrank sparsity prior expected see direct inversion zero filled inverse fourier transform zfi dft already give improved reconstruction performance whe n pseudoradial sampling pat tern employ car tesian sampling pattern 2 cardiac mri second experiment conduct cardiac vivo mri data speci fically freebreathing cardio vascular dataset dimension 3t mri scanner apart motion heartbeat andlarge breathe movement dataset complex anatomical feature make challenging reconstruct thanthe numerical phantom acceler ation factor approximately 8 choose correspond 125 acquire samples necessary add noise vivo data origtable characteristics different noiseless phantoms table ii reconstruction results using metric 15 e xpressed decibels fornumerical phantoms withcartesian sampling numbers brackets refer regularization parameters table iii reconstruction results using metric 15 e xpressed decibels fornumerical phantoms withpseudo radial sampling numbers brackets refer regularization parameters inal noise magnitude imag e become part apparent signal retrospectively undersampled time frames extract different reconstruction method show fig 8 although visually dif ficult claim objectively method best quantitative result give table iv different sampling strategiesadditionally nmse time frame show fig 9 forboth cartesian pseudoradial sampling based result method perform similarly use polynomial variable den ity sampling slight advan tage see slr rpca pseudo radial sampling use rpca select reconstruc tions choose mean select reconstruction favour lowrank part rather thesparse part context slr successfully manage obtain much good reconstruction result existingmethods previously first experiment one possible reason attribute fact cardiacmri dataset particu larly sparse gradient space time compare numerical phantom last experiment demonstrate rpca competi tive distinct dynamic mri r econstruction method par tial measurement c exploiting separation following section utility intrinsic separation reconstruct data lowrank sparse componentsis demonstrate context motion estimation dynamiccontrast enhance dce mri dce mri acquisition multiple 2d mr image take adm inistration contrast agent ca uptake washout ca concentration overtremoulheac et al dynamic mr image reconstructionseparation undersampled space 1 697 fig 8 visual comparison reconstruction method cardiac mri data show one time frame magnitude image frame number first row corre sponds cartesian sampling second row pseudoradial sampling table iv reconstruction results using metric 15 e xpressed decibels forcardiac mri atawithcartesian pseudo radial sampling fig 9 nmse time frame cardiac mri data cartesian sampling top pseudoradial sampling bottom time body correspond local change intensity mr image pharmacokinetic analysis use relateto tissue characteristic 42 however patient motion duringacquisition heartbeat breathing involuntary move ments produce interframe misalignment complicate fig 10 different type separation lowrank sparse component use rpca different decomposition parameter observe parameter act tradeoff b etween two component undersam pling rate 025 lowrank time frame b sparse time frame c temporal pro files lowrank component temporal pro files sparse component estimation rate uptake tissue image regis tration use solve problem presence thecontrast enhance ce image terferes registration procedure conventional algorithm interpret local intensity change motion due embedded separation propose rpca ap proach expect separate slow timevarying element frommore abrupt change hence possible separate somedegree local change intensity sparse componentwhen use appropriate parameter fig 10 demonstrate different decomposition obtain different r e g tering lowrank image include motion lesslocal intensity change provoke ca likely provide a1698 ieee transactions medical imaging vol 33 8 august 2014 fig 11 temporal pro files use registration procedure registration rpca lowrank part use mostly contain image without contrast enhancement thanks separation process fig 12 displacement fields zoomin source image use registration table v provide associated quantitative result ground truth noiseless phantom b noisy phantom local intensity change c focuss slr e rpca lowrank part see displacement field well estimate region local change intensity rpca displacement field close ground truth image ie signal without ce im age displacement field employ accu rate motion correction 43 proof concept numer ical phantom previous section combination int ensity motion employ purpose demonstration acceleration factor of4 use pseudoradial sampling focuss slr reconstruct previously use best regularization parameters however rpca reconstruction explicitly select end mostly local intensity change sparse part motion lowrank part reconstruction error focuss slr rpca respectively 253 db 311 db 263 db sequential registration frame focuss slr lowrank part rpca perform niftyreg2 44 ef ficient c++ implementation parallel formulation freeform deformation ffd algorithm 45 base cubic bsplines time pro files different reconstruction method along ground truth shownin fig 11 note ground truth obtain noiseless phantom create without int ensity change include motion reference image take n registration last time frame image respective dynamic reconstructedsequences displacement fields zoomin source image use registration show fig 12 quantify result l rm e r ct 1 5 su e dw ith jacobian 2d dis placement fields take region interest local 2local normalize cross correlation use measure similarity standard deviation gaussian kernel set five pixel time point control point spacing two pixel directionstable v displacement fields errors using jacobian taken region interest withlocal intensity changes metric 15 e xpressed decibels tensity chang e results report table v show slight impro vement rpca method v iscussion prior assumptions regularization parameters experiments suggest reconstruction point view prior assumption make rpca strong enough main competitive state art method prior assumption focuss space sparse signal appropriate dynamic datasets exhibit periodicity time slr perform well method phantom simulation successful freebreathing cardiac mri data generally regularization par ameters affect directly reconstruction result se lecting right one always challenge general topic inverse problem focuss slr best reconstr uctions select test range different regularization parameter twostrategies choice inrpca adopt interested obtain best reconstruction choice select b est reconstruction return however also force speci fic value obtain atremoulheac et al dynamic mr image reconstructionseparation undersampled space 1 699 fig 13 fluence regularization parameter reconstruction error db slr rpca numerical phantom simulation 10fold acceleration cartesian sampling slr refers 3 rpca refers 7 desirable decomposition fig 13 present reconstruction error db use different regularization parameter slr rpca figure previous experiment use phantom suggest lowrank ap r r information slr play important role case observe good reconstruction obtain usingonly sparsity ap r r information attribute fact piecewise constant signal phantom isvery sparse norm gradient compute rpca regularization parameter tradeoff data consistency lowrank plus sparse decompositionas show fig 13 solution regularize appropriate value must select obtain goodregularized solution decomposition parameter vary although also affect reconstruction result paper selection regularization parameter optimize unrealistic strategy since groundtruth available practi cal scenario however method adapt find ideal regularization parameter discrepancy principle noi se property know example lcurve generalize crossvalidation method 46 b decomposition separation lowr ank sparse component easy see mathematically may dif ficult interpret phys iologically represent dynamic mri context oneof reason decomposition depend typeof dynamic data work direction addressed understand deep ly interpret physiologically generally decomposition provide separation two component different c haracteristics lowrank component tend slow timevarying element whilethe sparse component capture abrupt change modi fied balance two part simulation speci fic example show partial isolation local change intensity sparse component general motio n lead good estimation displacement field departing example islikely combined reconstr uctionseparation approach fers far application could investigate example motionrelated application sparse localized motionelements interfere general background signal artefacts removal outli er component would cause unde sired alteration data la tter case artefact correction algorithm rf spike noise propose base rpcaas postprocessing technique 47 c noise study include complexvalued noise simulate realistic experiment however study evaluated reconstruction separation performance proposed approach function added noise generally rpca increase noise incline interfere sparsecomponent focuss slr may relatively robust noise regard reconstruct data since focuss noise space generally rep resent highly sparse coef ficients spatiotemporal total variation norm tend smooth noisy solution slr acquisition sampling two strategy undersample space cartesian pseudoradial sampling pattern use thispaper respectivel base polynomial variable density random rotation acr oss acquisition frame produce incoherent sample rtefacts experiment section particular tables ii n di v ti ss u g g e e dt h pseudoradial undersampling strategy provide good reconstruction result method either base sparsity focuss base lowrank sparse prior informa tion slr rpca however sample strategy w e r eb e nr e r p e c v ely undersampling space would ideally need va lidated use prospectively undersampled data mri scanner e computational times purpose paper focus computational aspect different reconstruction method different1700 ieee transactions medical imaging vol 33 8 august 2014 algorithm use implement matlab opti mized however note simulation focuss reconstruction could obtain less minute whereas slr rpca could require several minute computation contrast min vi c onclusion dynamic mr imaging widely use technique medicine numerous method develop reduceacquisition time still bene fit high acceleration rate ef ficient reconstruction algorithm paper present method term rpca jointly reconstructs separ ate dynamic mr data par tial measurement employ lowrank plus sparse regularization prior provide competitive reconstructionmethod accelerated dynamic mr comparison state art method show technique also provide aseparation two component different characteristicsthat potential tailor ed right application paper decomposition use partially separate contrast enhanced region simulated dce sequence helpin motion estimation overall study support use lowrank sparsity prior information dynamic mr image reconstruction techniques highly undersampled data interestingly pro pose reconstructionseparat ion approach suggest method finding close representation true object also step towards method would directly infer relevant characteris tic limited measurement",
    "bag_of_words": {
        "ieee": 7,
        "transactions": 7,
        "medical": 11,
        "imaging": 21,
        "vol": 7,
        "august": 7,
        "dynamic": 48,
        "mr": 24,
        "image": 56,
        "reconstructionseparation": 6,
        "undersampled": 13,
        "space": 27,
        "via": 3,
        "lowrank": 51,
        "plus": 13,
        "sparse": 53,
        "prior": 24,
        "benjamin": 1,
        "tremoulheac": 2,
        "nikolaos": 1,
        "dikaios": 2,
        "david": 1,
        "atkinson": 2,
        "simon": 1,
        "arridge": 2,
        "abstract": 1,
        "magnetic": 5,
        "resonance": 3,
        "mri": 50,
        "use": 48,
        "multiple": 2,
        "clinical": 2,
        "application": 6,
        "stil": 1,
        "lb": 1,
        "fitf": 1,
        "mh": 1,
        "spatial": 3,
        "temporal": 15,
        "resolution": 2,
        "reconstruction": 58,
        "method": 45,
        "partial": 9,
        "measurement": 8,
        "introduce": 2,
        "recovers": 1,
        "inherently": 2,
        "separate": 5,
        "ni": 2,
        "nt": 1,
        "ed": 3,
        "namic": 2,
        "scene": 1,
        "model": 13,
        "base": 15,
        "decomposition": 24,
        "whi": 1,
        "ch": 1,
        "relate": 3,
        "robust": 7,
        "principal": 6,
        "component": 33,
        "analysis": 5,
        "algorithm": 16,
        "propos": 1,
        "solve": 5,
        "convex": 4,
        "optimization": 3,
        "problem": 19,
        "alternating": 1,
        "direction": 7,
        "ofmultipliers": 1,
        "validate": 1,
        "numerical": 7,
        "phantom": 23,
        "simulations": 2,
        "cardiac": 8,
        "data": 30,
        "agains": 1,
        "state": 7,
        "art": 7,
        "results": 7,
        "suggest": 7,
        "proposed": 3,
        "approach": 11,
        "mean": 5,
        "regularize": 4,
        "inverse": 8,
        "remains": 1,
        "competitive": 4,
        "th": 6,
        "technique": 10,
        "additionally": 4,
        "induce": 1,
        "isshown": 1,
        "help": 1,
        "context": 5,
        "motion": 26,
        "estimation": 6,
        "contrast": 11,
        "enhance": 6,
        "index": 1,
        "terms": 1,
        "compressive": 1,
        "sen": 1,
        "sing": 1,
        "cs": 12,
        "res": 1,
        "onance": 1,
        "ro": 2,
        "bust": 1,
        "anal": 1,
        "ysis": 1,
        "sparsity": 16,
        "introduction": 1,
        "prod": 1,
        "uces": 1,
        "internal": 1,
        "structure": 1,
        "body": 2,
        "resonancesignal": 1,
        "information": 12,
        "inmultiple": 1,
        "cardiovascular": 1,
        "however": 13,
        "inherentlya": 1,
        "slow": 3,
        "process": 3,
        "due": 3,
        "combination": 7,
        "different": 23,
        "constraint": 4,
        "including": 1,
        "nuclear": 4,
        "relaxation": 1,
        "time": 32,
        "peripheral": 1,
        "nerve": 1,
        "stimulation": 1,
        "power": 2,
        "absorption": 1,
        "signal": 21,
        "noise": 16,
        "limit": 2,
        "spatialand": 1,
        "ye": 1,
        "critical": 1,
        "monitor": 1,
        "event": 1,
        "change": 17,
        "relatively": 3,
        "small": 3,
        "manuscript": 1,
        "receive": 2,
        "february": 1,
        "revise": 1,
        "april": 3,
        "accept": 1,
        "date": 2,
        "publication": 1,
        "current": 1,
        "versionjuly": 1,
        "work": 7,
        "support": 2,
        "engineering": 1,
        "physical": 1,
        "sciencesresearch": 1,
        "council": 1,
        "epsrc": 1,
        "grant": 1,
        "ep/h046410/1": 1,
        "national": 1,
        "institute": 1,
        "health": 1,
        "research": 2,
        "nihr": 1,
        "fund": 1,
        "comprehensive": 1,
        "biomedical": 1,
        "centre": 4,
        "cbrc": 1,
        "university": 3,
        "college": 4,
        "london": 7,
        "asterisk": 1,
        "indicate": 1,
        "cor": 1,
        "respond": 1,
        "author": 3,
        "computing": 1,
        "univer": 1,
        "sity": 1,
        "wc1e": 3,
        "6bt": 2,
        "uk": 3,
        "email": 1,
        "btremoulheac": 1,
        "csuclacuk": 1,
        "com": 3,
        "puting": 1,
        "6jf": 1,
        "digital": 1,
        "object": 3,
        "identi": 1,
        "fier": 1,
        "101109/tmi20142321190scales": 1,
        "millimetre": 1,
        "subsecond": 1,
        "long": 1,
        "scan": 1,
        "duration": 1,
        "affect": 4,
        "patient": 2,
        "comfort": 1,
        "reasonincrease": 1,
        "chance": 1,
        "artefact": 5,
        "hence": 6,
        "many": 4,
        "propose": 10,
        "reduce": 2,
        "ac": 2,
        "quisition": 1,
        "since": 14,
        "development": 1,
        "popular": 1,
        "techniques": 3,
        "include": 7,
        "example": 9,
        "echo": 1,
        "planar": 1,
        "fast": 2,
        "lowangle": 1,
        "shot": 1,
        "parallel": 4,
        "usesmultiple": 1,
        "receiver": 1,
        "coil": 1,
        "addition": 2,
        "complementary": 1,
        "accel": 1,
        "eration": 1,
        "ex": 1,
        "ploit": 1,
        "redundancy": 1,
        "developedin": 1,
        "general": 7,
        "part": 12,
        "would": 6,
        "mally": 1,
        "acquire": 6,
        "skip": 1,
        "result": 19,
        "illposedinverse": 1,
        "need": 2,
        "egularized": 1,
        "incorporate": 1,
        "si": 1,
        "gnal": 1,
        "provide": 14,
        "physiologically": 3,
        "representative": 1,
        "accurate": 1,
        "ie": 6,
        "without": 5,
        "intro": 1,
        "duced": 1,
        "illposedness": 1,
        "may": 5,
        "anyvaluable": 1,
        "assumption": 6,
        "although": 11,
        "approachhas": 1,
        "previously": 4,
        "recently": 1,
        "interest": 10,
        "dueto": 1,
        "compress": 2,
        "sensing": 2,
        "refers": 5,
        "topic": 2,
        "ofsignal": 1,
        "acquisition": 10,
        "reconstruc": 3,
        "tion": 5,
        "incomplete": 1,
        "measure": 4,
        "ments": 3,
        "yield": 1,
        "acceptable": 1,
        "perfect": 1,
        "recovery": 2,
        "factthat": 1,
        "spa": 2,
        "rse": 1,
        "either": 5,
        "direct": 2,
        "repre": 2,
        "sentation": 1,
        "transform": 16,
        "another": 1,
        "domain": 2,
        "intuitively": 1,
        "say": 1,
        "fraction": 2,
        "coef": 2,
        "fi": 1,
        "cients": 1,
        "signi": 5,
        "ficant": 5,
        "successfully": 2,
        "apply": 5,
        "ecently": 1,
        "researcher": 1,
        "also": 16,
        "look": 2,
        "exploit": 3,
        "property": 3,
        "matrix": 26,
        "insteadof": 1,
        "simply": 2,
        "vector": 3,
        "ese": 1,
        "start": 1,
        "gain": 1,
        "combined": 3,
        "hasbeen": 1,
        "refer": 9,
        "rpca": 45,
        "literature": 2,
        "report": 3,
        "itis": 1,
        "possible": 5,
        "recover": 3,
        "lowrankand": 2,
        "observation": 1,
        "paper": 10,
        "basedon": 1,
        "previous": 3,
        "investigation": 1,
        "regularization": 19,
        "separation": 11,
        "inspire": 1,
        "gao": 2,
        "et": 8,
        "al": 10,
        "dy": 1,
        "compute": 4,
        "tomography": 1,
        "ap": 6,
        "proach": 3,
        "cine": 1,
        "diffusion": 1,
        "recent": 2,
        "otazo": 1,
        "highlight": 1,
        "role": 2,
        "backgroundand": 1,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "see": 10,
        "http": 1,
        "//creativecommonsorg/licenses/by/30/1690": 1,
        "present": 14,
        "particularly": 3,
        "develop": 3,
        "formulate": 3,
        "fourier": 14,
        "sparsifying": 3,
        "alternate": 1,
        "multiplier": 4,
        "admm": 5,
        "framework": 3,
        "tosolve": 1,
        "minimization": 7,
        "derive": 3,
        "call": 1,
        "random": 4,
        "sample": 16,
        "scheme": 3,
        "undersam": 2,
        "plead": 1,
        "test": 6,
        "compare": 2,
        "experiments": 3,
        "complexvalued": 9,
        "vivo": 4,
        "along": 9,
        "comparison": 3,
        "mrreconstruction": 1,
        "presen": 1,
        "ted": 2,
        "useful": 1,
        "ness": 1,
        "modelis": 1,
        "show": 23,
        "contrastenhanced": 1,
        "rest": 1,
        "article": 1,
        "organize": 1,
        "follow": 3,
        "section": 8,
        "ii": 6,
        "briefly": 1,
        "review": 2,
        "analysistechnique": 1,
        "iii": 5,
        "simulation": 6,
        "ivsections": 1,
        "vi": 2,
        "respectively": 6,
        "discussion": 1,
        "conclusion": 1,
        "study": 8,
        "ackground": 1,
        "measurements": 1,
        "equation": 2,
        "write": 2,
        "represent": 12,
        "measured": 1,
        "desired": 1,
        "function": 11,
        "considering": 2,
        "raw": 1,
        "noisecan": 1,
        "reasonably": 1,
        "additive": 1,
        "white": 2,
        "gaussian": 2,
        "distribution": 3,
        "real": 4,
        "imaginary": 2,
        "iidrandom": 1,
        "variable": 8,
        "finding": 2,
        "close": 6,
        "representation": 2,
        "true": 2,
        "limited": 3,
        "number": 8,
        "subnyquist": 4,
        "sampling": 33,
        "accordance": 1,
        "theshannonnyquist": 1,
        "theory": 2,
        "methods": 2,
        "tackle": 1,
        "rely": 2,
        "thetemporal": 1,
        "dimension": 12,
        "return": 3,
        "approximately": 5,
        "original": 1,
        "2d": 6,
        "exhibit": 3,
        "correlation": 4,
        "and/or": 2,
        "periodici": 1,
        "ty": 1,
        "knowledge": 1,
        "unfold": 1,
        "blast": 1,
        "latter": 1,
        "compactness": 1,
        "thesignal": 1,
        "compressed": 2,
        "certain": 2,
        "toreconstruct": 1,
        "exactly": 1,
        "wi": 1,
        "high": 3,
        "probability": 5,
        "standard": 4,
        "shannonnyquist": 1,
        "demandsin": 1,
        "word": 1,
        "directly": 5,
        "compressivemeasurements": 1,
        "reconstruct": 9,
        "setof": 1,
        "particular": 5,
        "speci": 7,
        "fically": 3,
        "focuss": 18,
        "first": 6,
        "estimate": 5,
        "lowresolution": 2,
        "version": 1,
        "generalestimation": 1,
        "find": 3,
        "localized": 2,
        "energy": 3,
        "solution": 10,
        "consider": 3,
        "approaches": 1,
        "completion": 2,
        "usually": 2,
        "form": 2,
        "column": 2,
        "vectorizedmr": 1,
        "sequence": 6,
        "casorati": 3,
        "likely": 2,
        "low": 5,
        "rank": 13,
        "singular": 10,
        "value": 16,
        "generally": 7,
        "finitedimensional": 1,
        "spatiotemporal": 4,
        "equivalent": 2,
        "adopt": 2,
        "stacked": 1,
        "encode": 1,
        "oper": 1,
        "ator": 1,
        "common": 2,
        "subject": 1,
        "adatafidelity": 1,
        "term": 4,
        "similar": 5,
        "norm": 20,
        "recon": 1,
        "struction": 1,
        "operator": 11,
        "make": 7,
        "computationally": 1,
        "intractable": 1,
        "increasesthe": 1,
        "penalty": 7,
        "often": 2,
        "replace": 1,
        "theequality": 1,
        "relaxed": 1,
        "know": 4,
        "trace": 2,
        "schatten": 4,
        "envelope": 1,
        "de": 4,
        "fined": 2,
        "sum": 3,
        "denote": 6,
        "lagrangian": 4,
        "lead": 3,
        "regulari": 1,
        "zed": 1,
        "linear": 4,
        "least": 1,
        "square": 3,
        "ef": 6,
        "ficiently": 2,
        "accelerate": 1,
        "proximal": 1,
        "gra": 1,
        "dient": 1,
        "variantsof": 1,
        "nuclearnorm": 2,
        "powerfactorization": 1,
        "finally": 1,
        "nterest": 1,
        "explore": 1,
        "combi": 1,
        "nation": 1,
        "thesemethods": 1,
        "slr": 28,
        "penal": 1,
        "tie": 1,
        "nonconvex": 2,
        "total": 3,
        "variation": 3,
        "gradient": 5,
        "approximate": 3,
        "finite": 2,
        "difference": 2,
        "associated": 3,
        "param": 2,
        "eters": 1,
        "infor": 1,
        "mation": 1,
        "separability": 2,
        "atemporal": 1,
        "notable": 1,
        "feature": 2,
        "liestremoulheac": 1,
        "single": 1,
        "formulation": 2,
        "onstraints": 1,
        "con": 3,
        "straint": 1,
        "pca": 1,
        "mathematical": 1,
        "decompose": 1,
        "give": 6,
        "describe": 2,
        "alternat": 1,
        "ing": 2,
        "augmented": 3,
        "inner": 2,
        "product": 1,
        "lagrange": 2,
        "eter": 1,
        "positive": 1,
        "scalar": 1,
        "iterative": 2,
        "minimizes": 1,
        "separately": 2,
        "update": 3,
        "mul": 1,
        "tipliers": 1,
        "exist": 1,
        "closedform": 2,
        "expression": 1,
        "va": 2,
        "lue": 1,
        "thresholding": 3,
        "shrinkage": 3,
        "defined": 2,
        "elementwise": 1,
        "parameter": 24,
        "fixed": 3,
        "strategy": 13,
        "dynamically": 2,
        "procedure": 5,
        "iteration": 6,
        "last": 3,
        "stop": 2,
        "quantity": 2,
        "maximum": 3,
        "iterat": 1,
        "ion": 2,
        "reach": 2,
        "tradeoff": 3,
        "much": 4,
        "get": 2,
        "theoretically": 1,
        "supported": 1,
        "choice": 3,
        "offer": 1,
        "reasonable": 1,
        "sep": 1,
        "aration": 1,
        "vary": 4,
        "tailor": 2,
        "note": 8,
        "unique": 1,
        "sinceboth": 1,
        "een": 1,
        "interchangeably": 1,
        "one": 13,
        "fig": 29,
        "schematic": 1,
        "given": 1,
        "neither": 1,
        "breathhold": 2,
        "su": 3,
        "dt": 2,
        "og": 1,
        "figures": 1,
        "rank1": 1,
        "bythe": 1,
        "nonzero": 2,
        "alow": 1,
        "zero": 4,
        "beseen": 1,
        "corresponding": 1,
        "istograms": 1,
        "partappears": 1,
        "static": 1,
        "capture": 2,
        "case": 4,
        "mostly": 3,
        "heartbeats": 1,
        "element": 4,
        "scenario": 2,
        "unlikely": 1,
        "approximatelylowrank": 1,
        "periodicity": 2,
        "domainbecause": 1,
        "sent": 1,
        "anatomical": 2,
        "rarely": 1,
        "presence": 3,
        "notsparse": 1,
        "graphic": 1,
        "representa": 1,
        "fr": 2,
        "ai": 1,
        "nf": 1,
        "ethod": 1,
        "intrinsic": 2,
        "introducedthe": 1,
        "strong": 5,
        "connection": 1,
        "components": 1,
        "entry": 1,
        "accelerated": 2,
        "assume": 3,
        "express": 2,
        "plussparse": 1,
        "sam": 2,
        "enough": 2,
        "able": 1,
        "imagesfrom": 1,
        "point": 6,
        "important": 4,
        "distinguishbetween": 1,
        "asbeing": 1,
        "simultaneously": 1,
        "insection": 2,
        "iic": 2,
        "lowrankplus": 1,
        "objective": 2,
        "encoding": 1,
        "described": 1,
        "parameter1as": 1,
        "fin": 1,
        "di": 5,
        "ei": 2,
        "sion": 1,
        "recons": 1,
        "truction": 1,
        "sumption": 1,
        "imag": 2,
        "separable": 1,
        "approx": 1,
        "imately": 1,
        "approxi": 1,
        "mately": 1,
        "additional": 2,
        "justified": 1,
        "fact": 5,
        "deal": 1,
        "construction": 2,
        "improve": 2,
        "eg": 1,
        "bene": 3,
        "ficial": 1,
        "thehigher": 1,
        "undersampling": 8,
        "ratio": 1,
        "illustration": 2,
        "provided": 1,
        "name": 1,
        "fitting": 1,
        "criterion": 1,
        "enforce": 1,
        "consistency": 2,
        "second": 3,
        "enclose": 1,
        "realvalued": 1,
        "empirically": 1,
        "alsobe": 1,
        "componentsthe": 1,
        "readil": 1,
        "handle": 1,
        "trix": 1,
        "easily": 2,
        "extensible": 1,
        "tocomplexvalued": 1,
        "indeed": 1,
        "thresholdingoperator": 1,
        "svt": 2,
        "ingular": 1,
        "always": 2,
        "nonnegative": 1,
        "even": 1,
        "generalized": 1,
        "hermitian": 1,
        "transpose": 1,
        "extend": 1,
        "plexvalued": 1,
        "reason": 3,
        "1the": 1,
        "orinterchangeably": 1,
        "following": 2,
        "mainly": 2,
        "easy": 2,
        "interpret": 5,
        "scaling": 1,
        "depend": 3,
        "matrixdimensions": 1,
        "justi": 1,
        "fication": 1,
        "gray": 1,
        "black": 1,
        "figure": 2,
        "generate": 1,
        "car": 2,
        "diac": 1,
        "dataset": 4,
        "magn": 1,
        "itude": 1,
        "display": 1,
        "minimize": 2,
        "splitting": 1,
        "lagrangi": 1,
        "split": 1,
        "ting": 1,
        "associate": 3,
        "ignoring": 1,
        "constant": 3,
        "irrelevant": 1,
        "subproblems": 1,
        "lved": 1,
        "analytically": 1,
        "istremoulheac": 1,
        "soft": 1,
        "subprob": 1,
        "lem": 1,
        "quadratic": 1,
        "system": 1,
        "based": 2,
        "analytical": 1,
        "algorith": 1,
        "set": 4,
        "could": 4,
        "ensure": 1,
        "convergence": 1,
        "strategies": 1,
        "sense": 2,
        "adoptedin": 1,
        "methodsone": 1,
        "requirement": 1,
        "ccessful": 1,
        "incoherence": 1,
        "unde": 2,
        "rsampling": 1,
        "achieve": 2,
        "randomly": 3,
        "must": 3,
        "satisfy": 1,
        "hardware": 1,
        "physiological": 1,
        "ly": 2,
        "trajectory": 2,
        "smooth": 2,
        "line": 10,
        "curve": 1,
        "conventional": 3,
        "equispaced": 1,
        "onto": 1,
        "cartesiangrid": 1,
        "convenient": 1,
        "way": 1,
        "incoherent": 2,
        "select": 14,
        "concentrate": 1,
        "center": 2,
        "consist": 1,
        "densely": 1,
        "central": 1,
        "else": 1,
        "selection": 3,
        "draw": 1,
        "froma": 1,
        "simple": 1,
        "uniform": 2,
        "stribution": 1,
        "good": 9,
        "nearer": 1,
        "edge": 2,
        "order": 1,
        "take": 4,
        "account": 1,
        "distri": 1,
        "bution": 1,
        "vercome": 1,
        "coherence": 1,
        "frequency": 2,
        "transforms": 1,
        "polynomial": 5,
        "density": 8,
        "adaptedto": 1,
        "frame": 17,
        "thesampling": 1,
        "near": 1,
        "decrease": 1,
        "towards": 2,
        "radial": 7,
        "pling": 2,
        "ofview": 1,
        "ore": 1,
        "closely": 1,
        "resemble": 1,
        "par": 5,
        "cartesian": 12,
        "schemeis": 1,
        "projectionsat": 1,
        "angle": 2,
        "equiangul": 1,
        "ar": 1,
        "spacing": 2,
        "projection": 1,
        "incoherency": 1,
        "achie": 1,
        "ved": 1,
        "tation": 1,
        "whole": 1,
        "pattern": 6,
        "across": 1,
        "ishere": 1,
        "pseudoradial": 12,
        "step": 4,
        "realradialbased": 1,
        "compensation": 1,
        "func": 1,
        "gridding": 1,
        "beachieved": 1,
        "omit": 1,
        "readout": 1,
        "om": 1,
        "em": 1,
        "suitable": 1,
        "inexpensive": 1,
        "acquis": 1,
        "ition": 1,
        "view": 2,
        "minor": 1,
        "pulse": 1,
        "modi": 4,
        "fications": 1,
        "require": 2,
        "iv": 3,
        "xperiments": 1,
        "preliminaries": 1,
        "run": 1,
        "matlab": 2,
        "linux": 1,
        "platform": 1,
        "intensity": 23,
        "normalize": 2,
        "betweenvalues": 1,
        "processing": 1,
        "simulated": 2,
        "datawere": 1,
        "create": 4,
        "eb": 2,
        "nm": 2,
        "sf": 1,
        "rscanner": 1,
        "datasets": 2,
        "un": 1,
        "dersampled": 1,
        "retrospectively": 2,
        "samplingschemes": 1,
        "experiment": 11,
        "gaussiannoise": 1,
        "add": 3,
        "explicitly": 2,
        "channel": 1,
        "deviation": 2,
        "obtain": 11,
        "realistic": 2,
        "performance": 5,
        "quanti": 1,
        "fied": 4,
        "metric": 5,
        "resp": 4,
        "ground": 10,
        "truth": 10,
        "fullysampled": 2,
        "noiseless": 7,
        "estim": 1,
        "ated": 1,
        "is1694": 1,
        "leave": 2,
        "right": 5,
        "acquisitionpattern": 1,
        "rotation": 2,
        "decibel": 1,
        "conve": 1,
        "nience": 1,
        "global": 3,
        "normalized": 1,
        "error": 5,
        "nmse": 3,
        "ateach": 1,
        "comparisons": 2,
        "algorithms": 1,
        "zerofilled": 1,
        "sliding": 1,
        "window": 1,
        "zerothorder": 1,
        "hold": 1,
        "included": 1,
        "illustrate": 1,
        "level": 2,
        "lit": 1,
        "erature": 1,
        "arguably": 1,
        "ficient": 4,
        "implement": 2,
        "jugate": 1,
        "two": 8,
        "outer": 3,
        "andweighting": 1,
        "factor": 4,
        "initial": 1,
        "guarantee": 1,
        "filled": 2,
        "lowfrequency": 1,
        "tune": 2,
        "continuation": 1,
        "convergencerate": 1,
        "suggested": 1,
        "inthe": 1,
        "package": 1,
        "tv": 2,
        "incrementationboth": 1,
        "loop": 1,
        "innerand": 1,
        "nine": 1,
        "modelling": 1,
        "local": 12,
        "pixel": 3,
        "uptake": 4,
        "washout": 3,
        "agent": 2,
        "tofts": 2,
        "parameters": 5,
        "infocuss": 1,
        "regu": 1,
        "larization": 1,
        "hat": 1,
        "control": 2,
        "stability": 1,
        "noisy": 4,
        "condition": 1,
        "witha": 1,
        "ameter": 1,
        "range": 2,
        "best": 7,
        "accordancewith": 1,
        "regular": 1,
        "ization": 1,
        "schatt": 1,
        "en": 1,
        "econstruction": 2,
        "cording": 1,
        "employ": 5,
        "pa": 1,
        "rameters": 1,
        "fic": 4,
        "type": 5,
        "composition": 1,
        "accordingly": 1,
        "though": 1,
        "isd": 1,
        "ns": 1,
        "nv": 1,
        "separa": 1,
        "prove": 1,
        "enoughap": 1,
        "remain": 2,
        "inrpca": 2,
        "automati": 1,
        "cally": 1,
        "conduct": 2,
        "figs": 2,
        "typical": 2,
        "oftimevarying": 1,
        "periodic": 1,
        "lo": 1,
        "calized": 1,
        "simulates": 1,
        "movin": 1,
        "organ": 1,
        "beat": 1,
        "heart": 1,
        "simulate": 2,
        "respiratorylike": 1,
        "movement": 2,
        "imitate": 1,
        "freebreathing": 3,
        "modelledusing": 1,
        "trigonometric": 1,
        "andamplitudes": 1,
        "mimic": 1,
        "ce": 3,
        "agentusing": 1,
        "simplistic": 1,
        "major": 1,
        "advantage": 2,
        "full": 1,
        "controland": 1,
        "availability": 1,
        "fine": 1,
        "adjustment": 1,
        "madesuch": 1,
        "motionfree": 1,
        "cefree": 1,
        "evaluate": 1,
        "performanceof": 1,
        "phantomwith": 1,
        "timevarying": 3,
        "onlyintensity": 1,
        "eriodic": 1,
        "table": 8,
        "providessome": 1,
        "characteristic": 2,
        "thr": 1,
        "ee": 1,
        "noiselesstremoulheac": 1,
        "qualitative": 1,
        "magnitude": 4,
        "zoomin": 3,
        "magnitud": 1,
        "correspond": 4,
        "red": 1,
        "phase": 3,
        "pro": 11,
        "files": 10,
        "accord": 1,
        "dot": 1,
        "three": 1,
        "row": 3,
        "dotted": 1,
        "left": 1,
        "colormaps": 1,
        "colormap": 1,
        "various": 2,
        "whether": 2,
        "intensity/motion": 1,
        "fullrank": 1,
        "ofnoise": 1,
        "anumber": 1,
        "counterpart": 1,
        "acceler": 2,
        "ation": 2,
        "quantitative": 3,
        "arereported": 1,
        "intables": 1,
        "decibelsand": 1,
        "regulariza": 1,
        "bracket": 1,
        "visual": 2,
        "eval": 1,
        "uations": 1,
        "magnitudeimages": 1,
        "timeprofiles": 1,
        "indication": 1,
        "might": 1,
        "preference": 1,
        "observe": 3,
        "behavior": 1,
        "sistently": 1,
        "outperform": 1,
        "fo": 1,
        "cuss": 1,
        "seem": 1,
        "slight": 3,
        "possibly": 1,
        "attribute": 3,
        "phantomis": 1,
        "piecewise": 2,
        "tiotemporal": 1,
        "tot": 1,
        "variation1696": 1,
        "onlyphantom": 1,
        "penalize": 1,
        "highly": 3,
        "oscillatory": 1,
        "solutionswhile": 1,
        "allow": 1,
        "jump": 1,
        "regularized": 1,
        "otherwords": 1,
        "rather": 2,
        "ofthe": 1,
        "withonly": 1,
        "equal": 1,
        "tables": 2,
        "fit": 2,
        "onlyon": 1,
        "expected": 1,
        "inversion": 1,
        "zfi": 1,
        "dft": 1,
        "already": 1,
        "improved": 1,
        "whe": 1,
        "pat": 1,
        "tern": 1,
        "tesian": 1,
        "cardio": 1,
        "vascular": 1,
        "3t": 1,
        "scanner": 2,
        "apart": 1,
        "heartbeat": 2,
        "andlarge": 1,
        "breathe": 1,
        "complex": 1,
        "challenging": 1,
        "thanthe": 1,
        "choose": 2,
        "samples": 1,
        "necessary": 1,
        "origtable": 1,
        "characteristics": 1,
        "phantoms": 3,
        "using": 4,
        "xpressed": 4,
        "decibels": 4,
        "fornumerical": 2,
        "withcartesian": 1,
        "numbers": 2,
        "brackets": 2,
        "withpseudo": 1,
        "inal": 1,
        "become": 1,
        "apparent": 1,
        "frames": 1,
        "extract": 1,
        "visually": 1,
        "dif": 2,
        "ficult": 2,
        "claim": 1,
        "objectively": 1,
        "strategiesadditionally": 1,
        "forboth": 1,
        "perform": 3,
        "similarly": 1,
        "den": 1,
        "ity": 1,
        "advan": 1,
        "tage": 1,
        "pseudo": 2,
        "tions": 1,
        "favour": 1,
        "thesparse": 1,
        "manage": 1,
        "existingmethods": 1,
        "cardiacmri": 1,
        "particu": 1,
        "larly": 1,
        "demonstrate": 3,
        "competi": 1,
        "tive": 1,
        "distinct": 1,
        "tial": 2,
        "exploiting": 1,
        "utility": 1,
        "componentsis": 1,
        "dynamiccontrast": 1,
        "dce": 3,
        "adm": 1,
        "inistration": 1,
        "ca": 3,
        "concentration": 1,
        "overtremoulheac": 1,
        "corre": 1,
        "sponds": 1,
        "forcardiac": 1,
        "atawithcartesian": 1,
        "top": 1,
        "bottom": 1,
        "pharmacokinetic": 1,
        "relateto": 1,
        "tissue": 2,
        "duringacquisition": 1,
        "breathing": 1,
        "involuntary": 1,
        "move": 1,
        "produce": 2,
        "interframe": 1,
        "misalignment": 1,
        "complicate": 1,
        "act": 1,
        "etween": 1,
        "rate": 4,
        "regis": 1,
        "tration": 1,
        "thecontrast": 1,
        "terferes": 1,
        "registration": 7,
        "embedded": 1,
        "expect": 1,
        "frommore": 1,
        "abrupt": 2,
        "somedegree": 1,
        "componentwhen": 1,
        "appropriate": 3,
        "tering": 1,
        "lesslocal": 1,
        "provoke": 1,
        "a1698": 1,
        "contain": 1,
        "enhancement": 1,
        "thanks": 1,
        "displacement": 7,
        "fields": 4,
        "source": 2,
        "field": 4,
        "well": 2,
        "region": 4,
        "im": 1,
        "age": 1,
        "accu": 1,
        "correction": 2,
        "proof": 1,
        "concept": 1,
        "numer": 1,
        "ical": 1,
        "int": 2,
        "ensity": 2,
        "purpose": 2,
        "demonstration": 1,
        "acceleration": 3,
        "of4": 1,
        "end": 1,
        "db": 5,
        "sequential": 1,
        "niftyreg2": 1,
        "c++": 1,
        "implementation": 1,
        "freeform": 1,
        "deformation": 1,
        "ffd": 1,
        "cubic": 1,
        "bsplines": 1,
        "shownin": 1,
        "reference": 1,
        "respective": 1,
        "reconstructedsequences": 1,
        "quantify": 1,
        "rm": 1,
        "ct": 1,
        "dw": 1,
        "ith": 1,
        "jacobian": 2,
        "dis": 1,
        "placement": 1,
        "2local": 1,
        "cross": 1,
        "similarity": 1,
        "kernel": 1,
        "five": 1,
        "directionstable": 1,
        "errors": 1,
        "taken": 1,
        "withlocal": 1,
        "changes": 1,
        "tensity": 1,
        "chang": 1,
        "impro": 1,
        "vement": 1,
        "iscussion": 1,
        "assumptions": 1,
        "main": 1,
        "successful": 1,
        "ameters": 1,
        "se": 2,
        "lecting": 1,
        "challenge": 1,
        "reconstr": 2,
        "uctions": 1,
        "twostrategies": 1,
        "interested": 1,
        "est": 1,
        "force": 1,
        "atremoulheac": 1,
        "fluence": 1,
        "10fold": 1,
        "desirable": 1,
        "play": 1,
        "usingonly": 1,
        "isvery": 1,
        "decompositionas": 1,
        "goodregularized": 1,
        "optimize": 1,
        "unrealistic": 1,
        "groundtruth": 1,
        "available": 1,
        "practi": 1,
        "cal": 1,
        "adapt": 1,
        "ideal": 1,
        "discrepancy": 1,
        "principle": 1,
        "noi": 1,
        "lcurve": 1,
        "generalize": 1,
        "crossvalidation": 1,
        "lowr": 1,
        "ank": 1,
        "mathematically": 1,
        "phys": 1,
        "iologically": 1,
        "oneof": 1,
        "typeof": 1,
        "addressed": 1,
        "understand": 1,
        "deep": 1,
        "haracteristics": 1,
        "tend": 2,
        "whilethe": 1,
        "balance": 1,
        "isolation": 1,
        "motio": 1,
        "departing": 1,
        "islikely": 1,
        "uctionseparation": 1,
        "fers": 1,
        "far": 1,
        "investigate": 1,
        "motionrelated": 1,
        "motionelements": 1,
        "interfere": 2,
        "background": 1,
        "artefacts": 1,
        "removal": 1,
        "outli": 1,
        "er": 1,
        "cause": 1,
        "sired": 1,
        "alteration": 1,
        "la": 1,
        "tter": 1,
        "rf": 1,
        "spike": 1,
        "rpcaas": 1,
        "postprocessing": 1,
        "evaluated": 1,
        "added": 1,
        "increase": 1,
        "incline": 1,
        "sparsecomponent": 1,
        "regard": 1,
        "rep": 1,
        "resent": 1,
        "ficients": 1,
        "undersample": 1,
        "thispaper": 1,
        "respectivel": 1,
        "acr": 1,
        "oss": 1,
        "rtefacts": 1,
        "ti": 1,
        "ss": 1,
        "informa": 1,
        "nr": 1,
        "ely": 1,
        "ideally": 1,
        "lidated": 1,
        "prospectively": 1,
        "computational": 2,
        "times": 1,
        "focus": 1,
        "aspect": 1,
        "different1700": 1,
        "opti": 1,
        "mized": 1,
        "less": 1,
        "minute": 2,
        "whereas": 1,
        "several": 1,
        "computation": 1,
        "min": 1,
        "onclusion": 1,
        "widely": 1,
        "medicine": 1,
        "numerous": 1,
        "reduceacquisition": 1,
        "still": 1,
        "jointly": 1,
        "reconstructs": 1,
        "separ": 1,
        "ate": 1,
        "reconstructionmethod": 1,
        "aseparation": 1,
        "characteristicsthat": 1,
        "potential": 1,
        "partially": 1,
        "enhanced": 1,
        "helpin": 1,
        "overall": 1,
        "interestingly": 1,
        "pose": 1,
        "reconstructionseparat": 1,
        "infer": 1,
        "relevant": 1,
        "characteris": 1,
        "tic": 1
    },
    "objective": [
        "hence , many approach have be propose to reduce ac- quisition time since the development of mri .",
        "the propose approach in this paper be basedon previous investigation use the low-rank plus sparse de-composition model as both a regularization prior and a separa-tion method in dynamic mri from partial measurement [ 18 ] , which be itself inspire by the work of gao et al .",
        "8 , august 2014 the work present in this paper be particularly develop for dynamic magnetic resonance imaging .",
        "the alternate direc-tion method of multiplier ( admm ) framework be propose tosolve the minimization problem and derive an algorithm call -rpca .",
        "numerical simulation be show in section iv.sections v and vi , respectively , present discussion and con-clusion of this study .",
        "finding the close representation of the true object from a limited number of measurement be the inverse problem of interest in this paper .",
        "the propose approach assume that the casorati matrix can be express as a linear combination of a low-rank plussparse component , and at the sam e time assume that this prior information be strong enough to be able to reconstruct imagesfrom partial sample .",
        "at this point , it be important to distinguishbetween method that consider the signal to reconstruct asbeing simultaneously low-rank and sparse ( as present insection ii-c ) and the approach present in this paper that consider the signal to reconstruct as be the sum of low-rankplus sparse component .",
        "the additional operator can be justiﬁed by the fact that the propose method deal with the re- construction of undersampled dynamic image data : a fourier transform along the temporal dimension as a sparsifying trans-form have be show to improve sparsity in many dynamic re-construction method ( e.g.",
        "e. computational times the purpose of this paper be not to focus on computational aspect of the different reconstruction method .",
        "this paper have present a method term -rpca that jointly reconstructs and separ ate dynamic mr data from par- tial measurement by employ a low-rank plus sparse regu-larization prior ."
    ],
    "references": [
        "",
        "R EFERENCES [1] P. Mans ﬁeld, “Multiplanar image formation using NMR spin echoes,” J. Phys. C Solid State Phys. , vol. 10, no. 3, pp. L55–L58, 1977. [2] A. Haase, J. Frahm, D. Matthaei, W . Hänicke, and K.-D. Merboldt, “FLASH imaging: Rapid NMR imaging using low ﬂip-angle pulses,” J. Magn. Reson. , vol. 67, pp. 258–266, Dec. 1986. [ 3 ]D .J .L a r k m a na n dR .G .N u n e s ,“ P a r a l l e lm a g n e t i cr e s o n a n c e imaging,” P h y s .M e d .B i o l . , vol. 52, no. 7, pp. R15–55, Apr. 2007. [4] E. J. Candès, J. Romberg, and T. Tao, “Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency infor-mation,” IEEE Trans. Inf. Theory , vol. 52, no. 2, pp. 489–509, Feb. 2006. [5] D. L. Donoho, “Compressed sensing,” IEEE Trans. Inf. Theory , vol. 52, no. 4, pp. 1289–1306, Apr. 2006. [ 6 ] M .L u s t i g ,J .M .S a n t o s ,D .L .D o n o h o ,a n dJ .M .P a u l y ,“ k - tS P A R S E : High frame rate dynamic MRI exploiting spatio-temporal sparsity,” inProc. Int. Soc. Magn. Reson. Med. , 2006, p. 2003. [7] H. Jung, J. C. Ye, and E. Y. Kim, “Improved k-t BLAST and k-t SENSE using FOCUSS,” Phys. Med. Biol. , vol. 52, no. 11, pp. 3201–3226, Jun. 2007. [ 8 ] M .L u s t i g ,D .L .D o n o h o ,J .M .S a n t o s ,a n dJ .M .P a u l y ,“ C o m p r e s s e d sensing MRI,” IEEE Signal Process. Mag. , vol. 25, no. 2, pp. 72–82, Mar. 2008. [9] B. Zhao, J. P. Haldar, C. Brinegar, and Z.-P. Liang, “Low rank matrix recovery for real-time cardiac MRI,” in Proc. IEEE Int. Symp. Biomed. Imag. , Rotterdam, The Netherlands, 2010, pp. 996–999. [10] J. P. Haldar and Z.-P. Liang, “Spatiotemporal imaging with partially separable functions: A matrix recovery approach,” in Proc. IEEE Int. Symp. Biomed. Imag. , Rotterdam, The Netherlands, 2010, pp. 716–719. [11] S. G. Lingala, Y. Hu, E. V. R. DiBella, and M. Jacob, “Accelerated dynamic MRI exploiting sparsity and low-rank structure: k-t SLR,”IEEE Trans. Med. Imag. , vol. 30, no. 5, pp. 1042–1054, May 2011.[12] B. Zhao, J. P. Haldar, A. G. Christodoulou, and Z.-P. Liang, “Image reconstruction from highly undersampled (k,t)-space data with jointpartial separability and sparsity constraints,” IEEE Trans. Med. Imag. , vol. 31, no. 9, pp. 1809–1820, Sep. 2012. [13] E. J. Candès, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?,” J. ACM , vol. 58, no. 3, 2011. [14] X. M. Yuan and J. F. Yang, “Sparse and low-rank matrix decomposition via alternating direction methods,” Paciﬁc J. Optim. , vol. 9, no. 1, pp. 167–180, 2013. [15] M. Tao and X. Yuan, “Recovering low-rank and sparse components of matrices from incomplete and noisy observations,” SIAM J. Optim. , vol. 21, no. 1, pp. 57–81, 2011. [16] A. E. Waters, A. C. Sankaranarayanan, and R. G. Baraniuk, “SpaRCS: Recovering low-rank and sparse mat rices from compressive measure- ments,” in Proc. Adv. Neural Inf. Process. Syst. , Granada, 2011, pp. 1089–1097. [17] J. Wright, A. Ganesh, K. Min, and Y. Ma, “Compressive principal com- ponent pursuit,” Inf. Inference , vol. 2, no. 1, pp. 32–68, Jun. 2013. [18] B. Trémoulhéac, D. Atkinson, and S. R. Arridge, “Motion and contrast enhancement separation model reco nstruction from partial measure- ments in dynamic MRI,” presented at the MICCAI Workshop SparsityTech. Med. Imag., Nice, France, 2012. [19] H. Gao, J.-F. Cai, Z. Shen, and H. Zhao, “Robust principal component analysis-based four-dimensional computed tomography,” Phys. Med. Biol., vol. 56, no. 11, pp. 3181–3198, Jun. 2011. [20] H. Gao, Y. Lin, C. B. Ahn, and O. Nalcioglu, PRISM: A divide-and- conquer low-rank and sparse decomposition model for dynamic MRIUniv. California, Los Angeles, Tech. Rep., 2011. [21] H. Gao, S. Rapacchi, D. Wang, J. Moriarty, C. Meehan, J. Sayre, G. Laub, P. Finn, and P. Hu, “Compressed sensing using prior rank, inten-sity and sparsity model (PRISM): Applications in cardiac cine MRI,”inProc. Int. Soc. Magn. Reson. Med. , 2012, p. 2242. [22] H. Gao, “Prior rank, intensity and sparsity model (PRISM): A divide-and-conquer matrix decomposition model with low-rank co- herence and sparse variation,” in Proc. SPIE 8506, Develop. X-Ray Tomogr. VIII , Oct. 2012, pp. 85060Y-1–85060Y-10. [23] H. Gao, L. Li, and X. Hu, “Compressive diffusion MRI—Part 1: Why low-rank?,” in Proc. Int. Soc. Magn. Reson. Med. , 2013, p. 0610. [24] R. Otazo, E. J. Candès, and D. K. Sodickson, “Low-rank and sparse matrix decomposition for acceler ated DCE-MRI with background and contrast separation,” presented at the Int. Soc. Magn. Reson. Med.Workshop Data Sampl. Image Reconstruct., Sedona, AZ, 2013. [25] H. Gudbjartsson and S. Patz, “The Rician distribution of noisy MRI data,” M a g n .R e s o n .M e d . , vol. 34, no. 6, pp. 910–914, 2005. [26] B. Madore, G. H. Glover, and N. J. Pelc, “Unaliasing by Fourier-en- coding the overlaps using the temporal dimension (UNFOLD), appliedto cardiac imaging and fMRI,” Magn. Reson. Med. , vol. 42, no. 5, pp. 813–828, Nov. 1999. [27] J. Tsao, P. Boesiger, and K. P. Pruessmann, “k-t BLAST and k-t SENSE: Dynamic MRI with high frame rate exploiting spatiotemporalcorrelations,” Magn. Reson. Med. , vol. 50, no. 5, pp. 1031–1042, Nov. 2003. [28] M. Lustig, D. L. Donoho, and J. M. Pauly, “Sparse MRI: The appli- cation of compressed sensing for rapid MR imaging,” Magn. Reson. Med. , vol. 58, no. 6, pp. 1182–1195, Dec. 2007. [29] I. F. Gorodnitsky and B. D. Rao, “Sparse signal reconstruction from limited data using FOCUSS: A re-weighted minimum norm algo-rithm,” IEEE Trans. Signal Process. , vol. 45, no. 3, pp. 600–616, Mar. 1997. [30] Z.-P. Liang, “Spatiotemporal imaging with partially separable func- tions,” in P r o c .I E E EI n t .S y m p .B i o m e d .I m a g . , 2007, pp. 988–991. [31] B. Recht, M. Fazel, and P. A. Parrilo , “Guaranteed minimum-rank solu- tions of linear matrix equations via nuclear norm minimization,” SIAM Rev., vol. 52, no. 3, pp. 471–501, 2010. [32] M. Fazel, “Matrix rank minimization with applications,” Ph.D. disser- tation, Stanford Univ., Stanford, CA, 2002. [33] K. C. Toh and S. Yun, “An acceler ated proximal gradient algorithm for nuclear norm regularized linear least squares problems,” PaciﬁcJ . Optim. , vol. 6, no. 3, pp. 615–640, 2010. [34] B. Trémoulhéac, D. Atkinson, and S. R. Arridge, “Fast dynamic MRI via nuclear norm minimization and accelerated proximal gradient,” inProc. IEEE Int. Symp. Biomed. Imag. , San Francisco, CA, 2013, pp. 322–325. [35] J. P. Haldar and D. Hernando, “Rank-constrained solutions to linear matrix equations using powerfactorization,” IEEE Signal Process. Lett., vol. 16, no. 7, pp. 584–587, Jul. 2009.TRÉMOULHÉAC et al. : DYNAMIC MR IMAGE RECONSTRUCTION–SEPARATION FROM UNDER-SAMPLED ( )-SPACE 1 701 [36] Z. Lin, M. Chen, and Y. Ma, The augmented Lagrange multiplier method for exact recovery of corr upted low-rank matrices Univ. Illinois, Urbana-Champaign, Tech. Rep., 2009. [ 3 7 ] M .V .A f o n s o ,J .M .B i o u c a s - D i a s ,a n dM .A .T .F i g u e i r e d o ,“ A na u g - mented Lagrangian approach to the constrained optimization formula-tion of imaging inverse problems,” IEEE Trans. Image Process. , vol. 20, no. 3, pp. 681–695, Mar. 2011. [38] S. Ramani and J. A. Fessler, “Parallel MR image reconstruction using augmented Lagrangian methods,” IEEE Trans. Med. Imag. , vol. 30, no. 3, pp. 694–706, Mar. 2011. [39] J.-F. Cai, E. J. Candès, and Z. Shen, “A singular value thresholding algorithm for matrix completion,” SIAM J. Optim. , vol. 20, pp. 1956–1982, 2010. [40] B. Adcock, A. Hansen, B. Roman, and G. Teschke, “Generalized sampling: Stable reconstructions, inverse problems and compressedsensing over the continuum,” arXiv, 2013. [41] J. Tsao and S. Kozerke, “MRI tem poral acceleration techniques,” J. Magn. Reson. Imag. , vol. 36, no. 3, pp. 543–560, Sep. 2012. [42] P. S. Tofts, “T1-weighted DCE imaging concepts: Modelling, acquisi- tion and analysis,” MAGNETOM Flash , no. 3, pp. 30–39, 2010.[ 4 3 ]V .H a m y ,N .D i k a i o s ,S .P u n w a n i ,A .M e l b o u r n e ,A .L a t i f o l t o j a r , J .M a k a n y a n g a ,M .C h o u h a n ,E .H e l b r e n ,A .M e n y s ,S .T a y l o r ,a n dD. Atkinson, “Respiratory motion correction in dynamic MRI usingrobust data decomposition registr ation—Application to DCE-MRI,” Med. Image Anal. , vol. 18, no. 2, pp. 301–313, 2014. [44] M. Modat, G. R. Ridgway, Z. A. Taylor, M. Lehmann, J. Barnes, D. J. H a w k e s ,N .C .F o x ,a n dS .O u r s e l i n ,“ F a s tf r e e - f o r md e f o r m a t i o nu s i n ggraphics processing units,” Comput. Methods Programs Biomed. , vol. 98, no. 3, pp. 278–284, Jun. 2010. [45] D. Rueckert, L. I. Sonoda, C. Hayes, D. L. G. Hill, M. O. Leach, and D. J. Hawkes, “Nonrigid registration using free-form deformations: Ap-plication to breast MR images,” IEEE Trans. Med. Imag. , vol. 18, no. 8, pp. 712–721, Aug. 1999. [46] W. C. Karl, “Regularization in image restoration and reconstruction,” inHandbook of Image and Video Processing ,A .C .B o v i k ,E d . N e w York: Elsevier, 2005, ch. 3.6, pp. 183–202. [47] A. E. Campbell-Washburn, D. Atkinson, O. Josephs, M. F. Lythgoe, R. J. Ordidge, and D. L. Thomas, “Correction of RF spike noise in MRimages using robust princip al component analysis,” in Proc. Int. Soc. Magn. Reson. Medi. , Salt Lake City, UT, 2013, p. 3780."
    ]
}{
    "name": "Dynamic PET Image Reconstruction Incorporating Multiscale Superpixel Clusters",
    "paragraphs": [
        "received january 20 , 2021 , accept february 6 , 2021 , date of publication february 11 , 2021 , date of current version february 24 , 2021 .",
        "digital object identifier 10.1 109/access.2021.3058807 dynamic pet image reconstruction incorporating multiscale superpixel clusters shuangliang cao , yuru he , hongyan zhang , wenbing lv , lijun lu , and wufan chen school of biomedical engineering , southern medical university , guangzhou 510515 , china guangdong provincial key laboratory of medical image processing , southern medical university , guangzhou 510515 , china corresponding author : lijun lu ( ljlubme @ gmail.com ) and wufan chen ( chenwf @ mmu.com ) this work be support in part by the national natural science foundation of china under grant 81871437 , and in part by the guangdong basic and applied basic research foundation under grant 2019a1515011104 .",
        "the work of lijun lu be support by the guangdong province universities and colleges pearl river scholar funded scheme , in 2018 .",
        "abstract dynamic positron emission tomography ( pet ) image reconstruction be challenge due to the low-count statistic of individual frame .",
        "this study propose a novel reconstruction framework aim to enhance the quantitative accuracy of individual dynamic frame via the introduction of prior base on multiscale superpixel cluster .",
        "the cluster be derive from pre-reconstruction composite image use superpixel cluster follow by fuzzy c-means ( fcm ) clustering .",
        "a multiscale aggregation be exploit during the superpixel cluster to generate multiscale superpixel cluster .",
        "then , maximum a posteriori ( map ) pet reconstruction with different-scale cluster be separately apply to individual frame and fuse to generate the nal result .",
        "using realistic simulate dynamic brain pet data , the quantitative performance of the propose method be investigate and compare with the maximum-likelihood expectation-maximization ( mlem ) , bowsher method , and kernelized expectation-maximization ( the kernel method ) .",
        "the propose method achieve substantial improvement in both visual and quantitative accuracy ( in term of the signal- to-noise ratio and contrast versus noise performance ) .",
        "the method be also test with a 60 min18f-fdg rat study perform with an inveon small animal pet scanner .",
        "the propose method be show to outperform the other method via improvement in visual and quantitative accuracy ( in term of noise versus the mean intensity of the region of interest ) .",
        "index terms image reconstruction , maximum a posteriori , positron emission tomography , superpixel clustering .",
        "i .",
        "introduction positron emission tomography ( pet ) , a functional imaging modality widely use in oncology , cardiology , and neurol- ogy , can measure radiotracer distribution in vivo [ 1 ] \u0015 [ 3 ] .",
        "dynamic pet scan generally result in multiple time frame range from second to minute in a series start from the moment of tracer injection .",
        "with the addition of tracer kinetic modeling , dynamic pet be capable of quantify physiologically or biochemically important parameter at the level of the voxel or region of interest ( roi ) [ 4 ] , [ 5 ] .",
        "however , accurate tracer kinetic modeling require very short time frame , which result in low statistic count and high noise in each frame [ 6 ] \u0015 [ 8 ] .",
        "the associate editor coordinate the review of this manuscript and approve it for publication be yunjie yang .the tomography image reconstruction be inherently an ill-posed problem , which be far accentuate with low- count projection data from short individual time frame .",
        "conventional analytical reconstruction , such as ltered back projection ( fbp ) [ 9 ] , [ 10 ] , often result in noisy image .",
        "statistical image reconstruction , such as the maximum-likelihood expectation-maximization ( mlem ) algorithm [ 11 ] , [ 12 ] , can exploit the statistical property of the detect data and produce improve reconstructed image compare with fbp .",
        "however , direct mlem estimate of pet image often exhibit high variance at low count with increase iteration .",
        "the maximum a posteriori ( map ) framework aim to tackle the ill-posedness inherent in pet image reconstruction through the incorporation of prior model [ 13 ] .",
        "conventional prior model focus on local neighborhood and subsequently volume 9 , 2021this work be license under a creative commons attribution 4.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/4.0/28965s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters penalize inter-voxel intensity difference through different penalty function such as the quadratic prior [ 14 ] .",
        "more sophisticated prior have be propose for improved pet image reconstruction [ 15 ] \u0015 [ 18 ] .",
        "an alternative approach seek to control the penalization of inter-voxel difference via the incorporation of information from segment or non- segmented anatomical image .",
        "the classic anatomical prior void need for segmented anatomical information be pro- pose by bowsher et al .",
        "[ 19 ] .",
        "this prior ( refer to as the bowsher prior ) encourage smooth over an anatomy- dependent neighborhood , de ned by select a set of the most similar neighbor in the anatomical image [ 20 ] .",
        "ehrhardt et al .",
        "derive a prior base on the structural similar- ity between pet and mr image measure by the alignment of pet and mr gradient [ 21 ] .",
        "inspired by the kernel method , a model of pet image intensity at each pixel can be express as a function of a set of feature and incorporate into the forward model of pet projection data .",
        "thus , the coef cients of the feature can be estimate by the maximum likelihood ( ml ) , and the corresponding pet image can be derive .",
        "this novel pet image reconstruction be name kernelized expectation- maximization ( kem ) .",
        "the feature can be derive from the composite image for dynamic pet image [ 22 ] , mr image for static pet image [ 23 ] , pet and mri informa- tion for the list-mode reconstruction of static image [ 24 ] , and the composite image and sinograms for high temporal- resolution dynamic pet reconstruction [ 25 ] .",
        "kem recon- struction have also be apply in direct parametric imaging by combine the spatial kernel with tracer kinetic mod- el such as the spectral model [ 26 ] or the patlak graphical model [ 27 ] .",
        "in the different context of post-reconstruction dynamic pet image analysis , a number of clustering-based technique have be propose to reduce noise in kinetic analysis .",
        "factor analysis seek to decompose dynamic cardiac pet image into different tissue type base on their unique temporal signature to improve quanti cation of physiological func- tion [ 28 ] \u0015 [ 30 ] .",
        "in oncologic whole-body imaging , the prin- cipal component analysis ( pca ) approach have be use to enhance the distinction of tumor in dynamic fdg image compare with conventional static standard uptake value ( suv ) image [ 31 ] .",
        "janssen et al .",
        "apply k-means cluster to the slope of time activity curve ( calculate base on the last few time frame of fdg uptake ) to differentiate between tumor and healthy tissue [ 32 ] .",
        "the k-means and gaussian mixture models cluster algorithm be apply prior to voxel-wise kinetic modeling , which improve the classi cation of time activity curve between active and non- active neurotransmitter state [ 33 ] .",
        "in contrast to the abovementioned post-reconstruction method , our group propose a `` 3.5d '' image reconstruction utilize cluster to enhance the image reconstruction via the generation of cluster of neighborhood [ 34 ] .",
        "as an exten- sion of the previous work , the present study utilizes two-step clustering , include superpixel clustering and fuzzy c-means ( fcm ) clustering .",
        "the advantage of two-step clustering be that on the one hand it can exploit the local spatial infor- mation by superpixel cluster while on the other hand the global feature information be utilize by fcm cluster .",
        "the cluster result be use as a prior for the reconstruction to encourage pet image smoothness within the same cluster .",
        "moreover , multiscale aggregation be perform to far reduce bias and noise .",
        "the propose method can combine the advantage of superpixel clustering , fcm clustering , and multiscale aggregation and thus can make good use of the image prior .",
        "the reconstruction performance of the propose method be compare with the mlem algorithm , the bowsher method and the kernel method [ 22 ] in simulated and real clinical data reconstruction .",
        "the main contribution of this work be as follow .",
        "\u000fthis study propose a novel reconstruction framework aim to enhance the quantitative accuracy of individ- ual dynamic frame via the introduction of prior base on multiscale superpixel cluster .",
        "\u000fthe cluster be derive from pre-reconstruction com- posite image use superpixel cluster follow by fcm cluster .",
        "a multiscale aggregation be exploit during the superpixel cluster to generate multiscale superpixel cluster .",
        "\u000fmap pet reconstruction with different-scale cluster be separately apply to individual frame and fuse to generate the nal result .",
        "the rest of this paper be organize as follow .",
        "we rst introduce the map reconstruction framework for pet imag- ing and describe how the propose reconstruction method be perform in section ii .",
        "then , we present a computer simu- lation study in section iii to validate the improvement of the propose method over exist method .",
        "section iv present the result of apply the new method to real clinical data .",
        "finally , a discussion be provide in section v , and conclusion be draw in section vi .",
        "ii .",
        "theory a. map image reconstruction pet projection data yare well model as independent pois- son random variable with the log-likelihood function : l ( yjx ) dmx id1yilognyi\u0000nyi\u0000logyiw ; ( 1 ) wherenyis the expectation of the projection data and relate to the unknown image xby nydaxcr ; ( 2 ) where a2rm\u0002nis the system matrix with element aij denote the probability of a positron emit from pixel j result in a coincidence at the ith detector pair , and r represent the expectation of random and scattered event .",
        "m andndenote the total number of detector pair and pixel , respectively .",
        "the ml estimate of image xi obtain by 28966 volume 9 , 2021s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters maximize the log-likelihood function above : oxdarg max x\u00150l ( yjx ) : ( 3 ) however , the ml estimate can be very noisy at convergence .",
        "this problem be commonly solve by incorporate an image prior into the map framework : oxdarg max x\u00150l ( yjx ) \u0000 u ( x ) ; ( 4 ) where be a regularization parameter that control the trade- off between resolution and noise , and u ( x ) be the energy function , commonly know as a prior .",
        "to derive the map estimate , the preconditioned gradient ascent algorithm [ 18 ] be use instead of the one-step-late ( osl ) approach [ 16 ] to avoid the numerical problem that the latter may cause .",
        "the result iterative update to the map estimate be as follow : xjdxold jc\u0012 @ l @ xj\u0000 @ u @ xj\u0013 , p iaij xold jc @ 2u @ x2 j !",
        "; ( 5 ) where all partial derivative be evaluate in the current recon- struction xold , and xjis the new activity estimate at pixel j .",
        "the performance of the map reconstruction strongly depend on u ( x ) and regularization parameter .",
        "b .",
        "generation of the prior model 1 ) proposed cluster-based prior to make use of more pixel to further encourage smooth without cause signi cant bias , we expand the use of local neighborhood to those contain all pixel with similar intensity value as cluster together .",
        "the prior be de ned as : u ( x ) dnx jd1x k2cfjgwjk ( xj\u0000xk ) ; ( 6 ) where c { j } stand for the cluster in which pixel ji group ( a detail description of which can be find in the next section ) .",
        "be the potential function and take the form of ( s ) ds2 , and wjkis the weight of a give pixel kin the neighborhood c { j } of pixel j .",
        "as in the previous study , wjk be inversely proportional to the euclidean distance between pixel jandk.we compute wjkin a particular neighborhood ( e.g.",
        ", 9\u00029 as in the following simulation experiment ) instead of the entire cluster .",
        "the weight of more distant pixel within the cluster be negligible , lead to a considerable increase in computational speed .",
        "2 ) clustering the construction of the prior strongly depend on the cluster c { j } , which determine how accurately the prior describe the nature of the image .",
        "in our previous work [ 34 ] , fcm clustering be perform base on time activity curve of each pixel .",
        "however , fcm be sensitive to noise because the local spatial information of pixel be not utilized .",
        "here , we propose a two-step clustering : superpixel cluster follow by fcm cluster .",
        "the advantage of the propose clustering schemeis that superpixel cluster can exploit local information , while fcm can exploit global feature information .",
        "first , superpixel clustering be perform base on the three composite image reconstruct from the summed sinograms of multiple time frame of a dynamic pet .",
        "in this study , superpixel clustering be perform use the simple linear iterative clustering ( slic ) method [ 35 ] for its computational and memory ef ciency and good adherence to the image boundary .",
        "we use the composite image as the input to slic , and thus the weighted distance measure dj ; lbetween pixel jandlis de ned by : dj ; lds d2 fc\u0012ds s\u00132 m2 ; ( 7 ) where dsis the spatial euclidean distance between pixel j andl , and dfdqph hd1 ( fh j\u0000fh l ) 2is the pixel intensity similarity measure between pixel jandl , where hstands for the number of image channel and fh ji the activity value of pixel jin the hth channel .",
        "in the present study , his set to three .",
        "sdp ( n=k ) be the mean superpixel width as a normalization factor , where nis the number of pixel and kis the number of superpixels .",
        "finally , mis the weight between the intensity similarity and spatial proximity .",
        "a small mresults in good boundary adherence with a less regular size and shape .",
        "then , fcm cluster [ 36 ] , [ 37 ] be carry out to classify superpixels accord to the mean image intensity of every superpixel region in the three composite image .",
        "the classi- cation number tof fcm can be set to the number of main tissue ; for example , tcan be three for the human brain data because three main cluster ( gray matter , white matter , and background ) would be find in the reconstructed image .",
        "for a give tvalue , the fcm clustering minimizes jdkx pd1tx qd1uv pq bp\u0000cq 2 ; ( 8 ) where bpis the vector comprise of the mean intensity of the pth superpixel region in all composite image , cqis the center of the qth cluster , upqis the degree of membership of bpin the qth cluster , and vis the fuzzy partition matrix exponent , use for control the degree of fuzzy overlap .",
        "after fcm clustering , a membership matrix be obtain and use to determine each superpixel 's classi cation .",
        "how- ever , it be not suitable to directly classify all superpixels intotclusters accord to the maximum membership value because some small-sized tissue , e.g.",
        ", tumor , do not belong to these tclusters .",
        "moreover , it be dif cult to make small- sized tumor tissue classi ed into a separate cluster only by select a large value of t. given that the superpixels in a tumor region have a relatively low maximum membership , we set a threshold to distinguish these superpixels from the tmain cluster .",
        "the value can range from 0 to 1 and should be the low value that can ensure distinguishing of the superpixels .",
        "each superpixel with a low maximum mem- bership than the threshold be treat as a cluster separate volume 9 , 2021 28967s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters from the tclusters .",
        "the other superpixels be then divide intotclusters accord to the maximum membership .",
        "3 ) multiscale aggregation when only single-scale superpixel cluster follow by fcm clustering be perform , the result map estimate have much bias from the true image .",
        "to reduce the bias , multiscale aggregation can be perform as an average of multiple estimate base on multiscale superpixel cluster [ 38 ] .",
        "for the slic method , these multiscale superpixels be generate by vary the number of superpixels that decide the mean superpixel size .",
        "each scale superpixel clustering be follow by fcm clustering , and the corresponding map estimate be derive .",
        "assuming nsscales be use , the average of all estimate be the nal reconstructed result x\u0003 : x\u0003d1 nsnsx nd1oxn ; ( 9 ) whereoxnis the image estimate base on the nth single-scale superpixel clustering .",
        "4 ) implementation of the proposed dynamic pet reconstruction the owchart of the propose reconstruction algorithm be show in fig .",
        "1 .",
        "it consist of ve step , elaborate as follow : step 1 : the dynamic pet sinogram data be rebinned into three composite frame with the same duration .",
        "mlem reconstruction be rst use to generate three composite imagesoxreb 1 , oxreb 2 , andoxreb 3 .",
        "then , each composite image be normalize by divide its activity by the standard deriva- tion of the activity .",
        "step 2 : using the composite image , slic superpixel clus- tering be perform accord to the number of superpixels k and the compactness factor m. step 3 : the ksuperpixels be cluster by fcm ( 8 ) .",
        "each superpixel be classi ed accord to the maximum member- ship and the threshold .",
        "step 4 : the nal clustering result from step 3 be use as the cluster prior ( 6 ) for the map reconstruction ( 5 ) , and a single-scale image estimate oxnis obtain .",
        "step 5 : varying kin the give range , step 2-4 be repeat .",
        "finally , all scale image estimate be derive , and their average be the reconstruction result x\u0003 ( 9 ) of the propose method .",
        "iii .",
        "validation using computer simulation a. simulation setup the geometry of a ge dst whole-body pet scanner be simulate for dynamic pet scan .",
        "a 2d simulated pet phan- tom ( image dimension 217 \u0002217 ) be construct base on an anatomical model from the brainweb database [ 39 ] .",
        "we aim to evaluate the reconstruction performance of all method for the lesion with different size and location .",
        "three different size tumor be add to the pet phantom , as show in fig .",
        "2 ( a ) .",
        "the large and small tumor werelocated in the white matter , whereas the medium-sized tumor be position across the white matter and gray matter .",
        "the scanning schedule be as follow : 4 \u000220 s , 4\u000240 s , 4\u0002 60 s , 4\u0002180 s , and 8\u0002300 s , which result in 24 time frame .",
        "the regional time activity curve show in fig .",
        "2 ( c ) be assign to different brain region .",
        "dynamic activity image be rst forward project to generate noise-free sinograms , and then poisson noise be introduce to generate the projection data .",
        "a 20 % uniform background be include to simulate random event .",
        "scatters be not simulate in this study .",
        "an attenuation image for 511 kev photon be create use the anatomical model by assign a value of 0 cm\u00001 to air , 0.146 cm\u00001to bone , and 0.096 cm\u00001to other tissue , as show in fig .",
        "2 ( b ) .",
        "attenuation and random correction be include into all the reconstruction method to obtain quantitative image .",
        "a total of 3 \u0002107events be acquire over 60 min , and ten noisy realization be simulate .",
        "the 24 frame be rebinned into three high-count com- posite frame , correspond to the rst 20 min , middle 20 min , and last 20 min .",
        "all composite frame be recon- structed use the mlem algorithm with 100 iteration .",
        "the three composite image provide the prior information use in the bowsher method , kernel method , and propose method .",
        "the neighborhood size be set to 9 \u00029 for all method use the prior image .",
        "the feature vector , com- pose of three intensity at the same pixel position of the three composite image , be use to search the 20 near- est neighbor for the bowsher method and the 50 near neighbor for the kernel method .",
        "for the propose approach , the number of superpixels kranged from 1000 to 2600 in step of 100 for multiscale slic , the compactness factor m be xed to 70 without vary with kvalue , the cluster number tof fcm be set to 3 , and the threshold be set to 0.7 .",
        "both the bowsher method and propose method use a quadratic potential function , and 300 iteration be use to ensure convergence .",
        "the mlem algorithm with post- reconstruction gaussian ltering be also include for per- formance comparison .",
        "both the mlem algorithm and the kernel method be em-based method .",
        "b .",
        "evaluation metrics in the quantitative comparison between the different recon- struction method , the overall image quality be assess by the signal-to-noise ratio ( snr ) : snrd10 log10 xtrue 2 xi\u0000xtrue 2 !",
        "; ( 10 ) where xtrueandxidenote the ground-truth and reconstruct image , respectively .",
        "the three tumor be choose as the region of interest ( rois ) , and the contrast recovery coef cient ( crc ) be cal- culated by : crcd1 nrnrx id1\u0012nri nbi\u00001\u0013 , \u0012nrtrue nbtrue\u00001\u0013 ; ( 11 ) 28968 volume 9 , 2021s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 1 .",
        "the flowchart of the propose pet reconstruction algorithm .",
        "figure 2 .",
        "digital brain phantom , attenuation map , and time activity curve .",
        "( a ) pet phantom compose of the gray matter , white matter and three tumor a , b , c. ( b ) the corresponding attenuation image .",
        "( c ) regional time activity curve .",
        "where nris the total number of noisy realization ( n r= 10 in this simulation ) , nriis mean intensity of the roi in the ith realization , nbiis the mean intensity of the background , nrtrueis the true roi mean , and nbtrueis the true background mean .",
        "the white matter region be erode by a 5 \u00025 square structure element and choose as the background to calculate the noise standard deviation ( sd ) .",
        "the sd be also average over all realization .",
        "the spatially average pixel-level normalized bias for each roi be de ned as : bias=100 % \u00021 nroix j2roi nxj\u0000xtrue j xtrue j ; ( 12 ) where nroiis the total number of pixel in the roi and nxjis the ensemble mean value of pixel j ( i.e.",
        ", nxjd1 nrpnr id1xi j ) .",
        "the spatially average pixel-level coef cient of variation ( cov ) for each roi be de ned as : cov=100 % \u00021 nroix j2roiq 1 nr\u00001pnr id1 ( xi j\u0000nxj ) 2 nxj : ( 13 ) c. simulation results we mainly compare the reconstruction performance of the different method for frame 12 and 24 , which have 406 k and 2752 k event , respectively.fig .",
        "3 show the true activity image and the image recon- structed by the four method for the 12th and 24th frame .",
        "for each method , a reconstructed image be show with the high snr by vary either the iteration number for the em-based method or the regularization parameter for the regularization-based method .",
        "frame 12 have a much low scan count than frame 24 , and thus its reconstruc- tion result show large difference .",
        "the image from the mlem algorithm have a high level of noise .",
        "by incorpo- rating a prior , the kernel method , bowsher method , and propose method have substantially reduce noise and good preserve edge and tumor than the mlem algorithm with post-reconstruction gaussian ltering for the two study frame .",
        "the propose method achieve the high snr and an optimal visual effect , include the sharp boundary between the gray matter and white matter and the least noise in the white matter .",
        "the corresponding bias image be show in fig .",
        "4 .",
        "the propose method have the least bias , especially in the white matter region .",
        "fig .",
        "5 show the contrast recovery coef cients ( crcs ) of the three tumor region versus background standard devi- ation ( sd ) trade-off achieve with the different method , obtain by vary either the iteration number or regu- larization parameter in each method for the 12th and 24th frame .",
        "as expect , the method that utilize a prior have low background noise than the mlem algorithm with gaussian post ltering at matched crc level .",
        "the propose approach achieve the high crc with the low back- volume 9 , 2021 28969s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 3 .",
        "true activity image and reconstruct image by different method for the 12th frame ( top row ) , and 24th frame ( bottom row ) .",
        "the reconstruction method include ( from leave to right ) the mlem with gaussian postfiltering , kernel method , bowsher method and propose approach .",
        "figure 4 .",
        "bias image for the 12th frame ( top row ) , and 24th frame ( bottom row ) .",
        "ground noise for all tumor .",
        "one of the key reason why the propose method can preserve a high tumor contrast than other method be that in each single-scale map recon- struction process , the smoothness of the tumor region activ- ities be limit in the superpixel region correspond to that tumor and do not occur across that tumor and other tissue .",
        "fig .",
        "6 show the spatially average pixel-level bias versus spatially average pixel-level cov trade-off of the three tumor region for the 12th and 24th frame .",
        "the method incorporate a prior achieve well bias-variance perfor- mance than the post-smoothed mlem algorithm for all tumor .",
        "the propose method have the optimal bias-variance trade-off for the most case and slightly poor trade-off than the bowsher method only for tumor b ( the large tumor ) of the 24th frame.fig .",
        "7 show the plot of the image snr of all time frame for the different method .",
        "the snr be the mean of the snrs over the ten noisy realization , and the error bar indicate the standard deviation of the snrs over the ten realization .",
        "all method utilize a prior outperform the post-smoothed mlem algorithm for all frame .",
        "the propose approach achieve high snrs than the bowsher method and kernel method , especially for the low-count frame .",
        "d. illustration about the effect of each component in our propose method , three component , i.e.",
        ", superpixel clustering , fcm clustering , and multiscale aggregation , be combine for pet image reconstruction .",
        "we use the recon- struction of the simulated 12th frame as an example to brie y illustrate the effect of these component .",
        "fig .",
        "8 show the true 28970 volume 9 , 2021s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 5 .",
        "crcs of three tumor region versus background sd trade-off achieve by different method for frame 12 ( top row ) , and 24 ( bottom row ) .",
        "( from leave to right ) : correspond to the tumor a , b , and c. figure 6 .",
        "pixel-level bias versus cov trade-off achieve by different method for frame 12 ( top row ) , and 24 ( bottom row ) .",
        "( from leave to right ) : correspond to the tumor a , b , and c. image and image reconstruct by ( a ) the mlem algorithm without any component utilized and the cluster prior-based map method with ( b ) only superpixel clustering ( k d1500 ) utilize , ( c ) both superpixel clustering ( k d1500 ) and fcm cluster utilized , and ( d ) all three component utilized ( i.e.",
        ", the propose method ) .",
        "all map method use the same component parameter , and the regularization parameter be tune for each reconstruction .",
        "fig .",
        "8 ( b ) present good edge than ( a ) by use a superpixel clustering-based prior .",
        "fig .",
        "8 ( c ) illustrate less noise and good tissue contrast than ( b ) by add fcm clustering .",
        "however , high bias persists in fig .",
        "8 ( c ) , such as the two region indicate by red arrow .",
        "the bias level be substantially decrease owe to the effect of multiscale aggregation , as show in fig .",
        "8 ( d ) .",
        "the snr of fig .",
        "8 ( a ) - ( d ) increase as more component be used.iv .",
        "application to real clinical data a .",
        "clinical data acquisition a rat with myocardial infarction be scan by a siemens inveon small animal pet scanner .",
        "the rat receive a bolus injection of 1.15 mci18f-fdg .",
        "the pet scan start right at the injection and last 60 min .",
        "the dynamic pet data be divide into 25 frame : 10 \u00023 s , 3\u000210 s , 4\u000260 s , 5\u0002300 s , and 3\u0002600 s. a ct scan be acquire to provide the attenuation map for attenuation correction .",
        "attenuation factor be extract use the vendor software and include in the forward model during reconstruction .",
        "as mention in the simulation study , three 20 min composite frame be reconstruct to provide the image prior .",
        "the rat data be reconstruct into an image matrix of 217\u0002217\u0002159 voxels with a voxel size of volume 9 , 2021 28971s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 7 .",
        "plots of image snr of all time frame reconstruct by different method .",
        "0:46\u00020:46\u00020:796 mm3using the mlem algorithm , kernel method , bowsher method , and propose method .",
        "for the propose method , the parameter mandtwere set to 50 and 5 , respectively .",
        "other parameter be keep the same as in the simulation study .",
        "since the true activity value be unknown , bias analy- si be not perform .",
        "to compare the different method , we plot the mean activity versus standard deviation ( sd ) curve of the roi ( the myocardium region indicate by the white arrow in fig .",
        "9 ) .",
        "b .",
        "results fig .",
        "9 show a transverse slice of reconstructed image of the 18th and 25th frame use the different method .",
        "for the mlem algorithm and kernel method , 100 iteration be use .",
        "for the bowsher method and propose method , the reg- ularization parameter be heuristically select and set to 0.01 and 0.005 for the 18th and 25th frame , respectively .",
        "the reconstructed image from the mlem algorithm suffer from considerable noise .",
        "by use the composite image prior , the kernel method suppress noise to a certain extent and preserve the tissue contrast .",
        "the bowsher method partly reduce the noise but over smooth the image structure .",
        "in comparison , the propose method present well noise suppression and preserved boundary and tissue contrast well than other method .",
        "fig .",
        "10 show the mean activity versus standard deviation trade-off of the roi use the different method by vary- ing the iteration number or regularization parameter in each method for the 18th and 25th frame .",
        "for the myocardium region , the propose method achieve less noise at the same activity value than other method .",
        "v. discussion a. parameters selection the performance of the propose method be affect by the number of superpixels kand the compactness factor muse for superpixel clustering , the cluster number tand thresh- old use for fcm clustering , and the scale selection for multiscale aggregation .",
        "the number of superpixels kshould be neither too large nor too small .",
        "a large kvalue resultsin meaningless , small-sized superpixels , while a small k value lead to large-sized superpixels with excessive loss of detail result from some superpixels contain more than one class of tissue .",
        "however , for a give image size , an appropriate set of kvalues could be determine , e.g.",
        ", an image of size 217 \u0002217 , it would be appropriate to setkbetween 1000 and 3000 .",
        "in other word , the suitable number of superpixels for the slic algorithm be proportional to the total number of image pixel .",
        "it be easy to select some scale from the range of appropriate kvalues because the propose method be not sensitive to multiscale selection .",
        "the cluster number tcould be equal to or slightly great than the number of main tissue in the image to be reconstruct ; e.g.",
        ", in our simulation study , tcan be 3 , 4 , 5 , or 6 without obvious improvement or degradation of image quality .",
        "this nding be consistent with our previous study [ 34 ] .",
        "both the compactness factor mand threshold be relate to the quality of the prior image .",
        "the mvalue and value should be small when the composite prior image have less noise , and vice versa .",
        "in practice , we prefer to use a small mvalue for good boundary adherence .",
        "thus , for image reconstruction with the propose method , we can easily select parameter kandtand multiple scale from experience and only need to carefully choose the parameter mand .",
        "b .",
        "implementation of multiscale aggregation as investigate in [ 38 ] , multiscale superpixels can be gener- ated by vary the number of superpixels kand the compact- ness factor min the slic algorithm .",
        "however , vary the kvalue be much more ef cient than vary the mvalue for eliminate the bias accord to our experiment .",
        "this may be because it be easy to capture the different-scale structural information by vary the kvalue [ 40 ] and because the reconstructed image quality be susceptible to the mvalue .",
        "thus , we implement multiscale over-segmentations only by vary the kvalue .",
        "in the simulation study , no few than ve scale range from 1000 to 3000 should be select for vary the kvalues .",
        "for each single-scale map estimate , we use the same compactness factor m , cluster number t , threshold , and regularization parameter to avoid add new tunable parameter .",
        "furthermore , the computational time of the propose method be proportional to the number of chosen scale and can be reduce by parallel compute .",
        "c. disadvantage of the proposed method according to the analysis of the bias image in fig .",
        "4 , the propose method can not reconstruct slender structure well .",
        "this be because the slic algorithm can not segment the slen- der structure well from the surroundings .",
        "d. deep image prior with the development of deep learning , some deep prior model [ 41 ] , [ 42 ] have be propose for pet reconstruc- tion .",
        "these method incorporate the deep image prior [ 43 ] into static pet image reconstruction [ 41 ] and dynamic pet image reconstruction use non-negative matrix factorization 28972 volume 9 , 2021s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 8 .",
        "true image of frame 12 and reconstruct image by different method base on different combination of three component .",
        "figure 9 .",
        "reconstructed image of the 18th ( top row ) and 25th ( bottom row ) frame use different method .",
        "the myocardium region be indicate by the white arrow .",
        "figure 10 .",
        "mean activity versus sd trade-off of myocardium roi achieve by different method for the ( a ) 18th and ( b ) 25th frame .",
        "the curve be plot by vary the iteration number from 20 to 100 for the mlem algorithm and kernel method and vary the regularization parameter for the bowsher method and propose method .",
        "[ 42 ] and show good performance visually and quantitatively than some traditional reconstruction algorithm .",
        "these deep prior-based method will be study and compare with our propose method in the future .",
        "vi .",
        "conclusion in this paper , we develop a novel cluster prior-based map reconstruction method .",
        "the cluster consists of superpixelclustering follow by fcm clustering , and multiscale aggre- gation be use to far improve the image quality .",
        "the simulation result show the propose approach achieve bet- ter visual effect and crc versus sd trade-off than the mlem algorithm , kernel method , and bowsher method .",
        "the propose approach can preserve edge and tumor well with the least background noise .",
        "the propose method be apply to reconstruct the dynamic pet image of a rat volume 9 , 2021 28973s .",
        "cao et al .",
        ": dynamic pet image reconstruction incorporating multiscale superpixel clusters with myocardial infarction and achieve visual and quanti- tative accuracy improvement over the other method .",
        "this reconstruction method can be easily extend to utilize a multimodal anatomical prior or a combination of anatomical and functional prior by change the input channel of the slic algorithm .",
        "applications to human clinical data and the corresponding parameter selection strategy will be study in the future ."
    ],
    "processed_text": "received january 20 2021 accept february 6 2021 date publication february 11 2021 date current version february 24 2021 digital object identifier 101 109/access20213058807 dynamic pet image reconstruction incorporating multiscale superpixel clusters shuangliang cao yuru hongyan zhang wenbing lv lijun lu wufan chen school biomedical engineering southern medical university guangzhou 510515 china guangdong provincial key laboratory medical image processing southern medical university guangzhou 510515 china corresponding author lijun lu ljlubme @ gmailcom wufan chen chenwf @ mmucom work support part national natural science foundation china grant 81871437 part guangdong basic applied basic research foundation grant 2019a1515011104 work lijun lu support guangdong province universities colleges pearl river scholar funded scheme 2018 abstract dynamic positron emission tomography pet image reconstruction challenge due lowcount statistic individual frame study propose novel reconstruction framework aim enhance quantitative accuracy individual dynamic frame via introduction prior base multiscale superpixel cluster cluster derive prereconstruction composite image use superpixel cluster follow fuzzy cmeans fcm clustering multiscale aggregation exploit superpixel cluster generate multiscale superpixel cluster maximum posteriori map pet reconstruction differentscale cluster separately apply individual frame fuse generate nal result using realistic simulate dynamic brain pet data quantitative performance propose method investigate compare maximumlikelihood expectationmaximization mlem bowsher method kernelized expectationmaximization kernel method propose method achieve substantial improvement visual quantitative accuracy term signal tonoise ratio contrast versus noise performance method also test 60 min18ffdg rat study perform inveon small animal pet scanner propose method show outperform method via improvement visual quantitative accuracy term noise versus mean intensity region interest index terms image reconstruction maximum posteriori positron emission tomography superpixel clustering introduction positron emission tomography pet functional imaging modality widely use oncology cardiology neurol ogy measure radiotracer distribution vivo 1 \u0015 3 dynamic pet scan generally result multiple time frame range second minute series start moment tracer injection addition tracer kinetic modeling dynamic pet capable quantify physiologically biochemically important parameter level voxel region interest roi 4 5 however accurate tracer kinetic modeling require short time frame result low statistic count high noise frame 6 \u0015 8 associate editor coordinate review manuscript approve publication yunjie yang tomography image reconstruction inherently illposed problem far accentuate low count projection data short individual time frame conventional analytical reconstruction ltered back projection fbp 9 10 often result noisy image statistical image reconstruction maximumlikelihood expectationmaximization mlem algorithm 11 12 exploit statistical property detect data produce improve reconstructed image compare fbp however direct mlem estimate pet image often exhibit high variance low count increase iteration maximum posteriori map framework aim tackle illposedness inherent pet image reconstruction incorporation prior model 13 conventional prior model focus local neighborhood subsequently volume 9 2021this work license creative commons attribution 40 license information see http //creativecommonsorg/licenses/by/40/28965s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters penalize intervoxel intensity difference different penalty function quadratic prior 14 sophisticated prior propose improved pet image reconstruction 15 \u0015 18 alternative approach seek control penalization intervoxel difference via incorporation information segment non segmented anatomical image classic anatomical prior void need segmented anatomical information pro pose bowsher et al 19 prior refer bowsher prior encourage smooth anatomy dependent neighborhood de ned select set similar neighbor anatomical image 20 ehrhardt et al derive prior base structural similar ity pet mr image measure alignment pet mr gradient 21 inspired kernel method model pet image intensity pixel express function set feature incorporate forward model pet projection data thus coef cients feature estimate maximum likelihood ml corresponding pet image derive novel pet image reconstruction name kernelized expectation maximization kem feature derive composite image dynamic pet image 22 mr image static pet image 23 pet mri informa tion listmode reconstruction static image 24 composite image sinograms high temporal resolution dynamic pet reconstruction 25 kem recon struction also apply direct parametric imaging combine spatial kernel tracer kinetic mod el spectral model 26 patlak graphical model 27 different context postreconstruction dynamic pet image analysis number clusteringbased technique propose reduce noise kinetic analysis factor analysis seek decompose dynamic cardiac pet image different tissue type base unique temporal signature improve quanti cation physiological func tion 28 \u0015 30 oncologic wholebody imaging prin cipal component analysis pca approach use enhance distinction tumor dynamic fdg image compare conventional static standard uptake value suv image 31 janssen et al apply kmeans cluster slope time activity curve calculate base last time frame fdg uptake differentiate tumor healthy tissue 32 kmeans gaussian mixture models cluster algorithm apply prior voxelwise kinetic modeling improve classi cation time activity curve active non active neurotransmitter state 33 contrast abovementioned postreconstruction method group propose 35d image reconstruction utilize cluster enhance image reconstruction via generation cluster neighborhood 34 exten sion previous work present study utilizes twostep clustering include superpixel clustering fuzzy cmeans fcm clustering advantage twostep clustering one hand exploit local spatial infor mation superpixel cluster hand global feature information utilize fcm cluster cluster result use prior reconstruction encourage pet image smoothness within cluster moreover multiscale aggregation perform far reduce bias noise propose method combine advantage superpixel clustering fcm clustering multiscale aggregation thus make good use image prior reconstruction performance propose method compare mlem algorithm bowsher method kernel method 22 simulated real clinical data reconstruction main contribution work follow \u000fthis study propose novel reconstruction framework aim enhance quantitative accuracy individ ual dynamic frame via introduction prior base multiscale superpixel cluster \u000fthe cluster derive prereconstruction com posite image use superpixel cluster follow fcm cluster multiscale aggregation exploit superpixel cluster generate multiscale superpixel cluster \u000fmap pet reconstruction differentscale cluster separately apply individual frame fuse generate nal result rest paper organize follow rst introduce map reconstruction framework pet imag ing describe propose reconstruction method perform section ii present computer simu lation study section iii validate improvement propose method exist method section iv present result apply new method real clinical data finally discussion provide section v conclusion draw section vi ii theory map image reconstruction pet projection data yare well model independent pois son random variable loglikelihood function l yjx dmx id1yilognyi\u0000nyi\u0000logyiw 1 wherenyis expectation projection data relate unknown image xby nydaxcr 2 a2rm\u0002nis system matrix element aij denote probability positron emit pixel j result coincidence ith detector pair r represent expectation random scattered event andndenote total number detector pair pixel respectively ml estimate image xi obtain 28966 volume 9 2021s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters maximize loglikelihood function oxdarg max x\u00150l yjx 3 however ml estimate noisy convergence problem commonly solve incorporate image prior map framework oxdarg max x\u00150l yjx \u0000 u x 4 regularization parameter control trade resolution noise u x energy function commonly know prior derive map estimate preconditioned gradient ascent algorithm 18 use instead onesteplate osl approach 16 avoid numerical problem latter may cause result iterative update map estimate follow xjdxold jc\u0012 @ l @ xj\u0000 @ u @ xj\u0013 p iaij xold jc @ 2u @ x2 j 5 partial derivative evaluate current recon struction xold xjis new activity estimate pixel j performance map reconstruction strongly depend u x regularization parameter b generation prior model 1 proposed clusterbased prior make use pixel encourage smooth without cause signi cant bias expand use local neighborhood contain pixel similar intensity value cluster together prior de ned u x dnx jd1x k2cfjgwjk xj\u0000xk 6 c { j } stand cluster pixel ji group detail description find next section potential function take form ds2 wjkis weight give pixel kin neighborhood c { j } pixel j previous study wjk inversely proportional euclidean distance pixel jandkwe compute wjkin particular neighborhood eg 9\u00029 following simulation experiment instead entire cluster weight distant pixel within cluster negligible lead considerable increase computational speed 2 clustering construction prior strongly depend cluster c { j } determine accurately prior describe nature image previous work 34 fcm clustering perform base time activity curve pixel however fcm sensitive noise local spatial information pixel utilized propose twostep clustering superpixel cluster follow fcm cluster advantage propose clustering schemeis superpixel cluster exploit local information fcm exploit global feature information first superpixel clustering perform base three composite image reconstruct summed sinograms multiple time frame dynamic pet study superpixel clustering perform use simple linear iterative clustering slic method 35 computational memory ef ciency good adherence image boundary use composite image input slic thus weighted distance measure dj lbetween pixel jandlis de ned dj lds d2 fc\u0012ds s\u00132 m2 7 dsis spatial euclidean distance pixel j andl dfdqph hd1 fh j\u0000fh l 2is pixel intensity similarity measure pixel jandl hstands number image channel fh ji activity value pixel jin hth channel present study set three sdp n=k mean superpixel width normalization factor nis number pixel kis number superpixels finally mis weight intensity similarity spatial proximity small mresults good boundary adherence less regular size shape fcm cluster 36 37 carry classify superpixels accord mean image intensity every superpixel region three composite image classi cation number tof fcm set number main tissue example tcan three human brain data three main cluster gray matter white matter background would find reconstructed image give tvalue fcm clustering minimizes jdkx pd1tx qd1uv pq bp\u0000cq 2 8 bpis vector comprise mean intensity pth superpixel region composite image cqis center qth cluster upqis degree membership bpin qth cluster vis fuzzy partition matrix exponent use control degree fuzzy overlap fcm clustering membership matrix obtain use determine superpixel 's classi cation ever suitable directly classify superpixels intotclusters accord maximum membership value smallsized tissue eg tumor belong tclusters moreover dif cult make small sized tumor tissue classi ed separate cluster select large value given superpixels tumor region relatively low maximum membership set threshold distinguish superpixels tmain cluster value range 0 1 low value ensure distinguishing superpixels superpixel low maximum mem bership threshold treat cluster separate volume 9 2021 28967s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters tclusters superpixels divide intotclusters accord maximum membership 3 multiscale aggregation singlescale superpixel cluster follow fcm clustering perform result map estimate much bias true image reduce bias multiscale aggregation perform average multiple estimate base multiscale superpixel cluster 38 slic method multiscale superpixels generate vary number superpixels decide mean superpixel size scale superpixel clustering follow fcm clustering corresponding map estimate derive assuming nsscales use average estimate nal reconstructed result x\u0003 x\u0003d1 nsnsx nd1oxn 9 whereoxnis image estimate base nth singlescale superpixel clustering 4 implementation proposed dynamic pet reconstruction owchart propose reconstruction algorithm show fig 1 consist step elaborate follow step 1 dynamic pet sinogram data rebinned three composite frame duration mlem reconstruction rst use generate three composite imagesoxreb 1 oxreb 2 andoxreb 3 composite image normalize divide activity standard deriva tion activity step 2 using composite image slic superpixel clus tering perform accord number superpixels k compactness factor step 3 ksuperpixels cluster fcm 8 superpixel classi ed accord maximum member ship threshold step 4 nal clustering result step 3 use cluster prior 6 map reconstruction 5 singlescale image estimate oxnis obtain step 5 varying kin give range step 24 repeat finally scale image estimate derive average reconstruction result x\u0003 9 propose method iii validation using computer simulation simulation setup geometry ge dst wholebody pet scanner simulate dynamic pet scan 2d simulated pet phan tom image dimension 217 \u0002217 construct base anatomical model brainweb database 39 aim evaluate reconstruction performance method lesion different size location three different size tumor add pet phantom show fig 2 large small tumor werelocated white matter whereas mediumsized tumor position across white matter gray matter scanning schedule follow 4 \u000220 4\u000240 4\u0002 60 4\u0002180 8\u0002300 result 24 time frame regional time activity curve show fig 2 c assign different brain region dynamic activity image rst forward project generate noisefree sinograms poisson noise introduce generate projection data 20 uniform background include simulate random event scatters simulate study attenuation image 511 kev photon create use anatomical model assign value 0 cm\u00001 air 0146 cm\u00001to bone 0096 cm\u00001to tissue show fig 2 b attenuation random correction include reconstruction method obtain quantitative image total 3 \u0002107events acquire 60 min ten noisy realization simulate 24 frame rebinned three highcount com posite frame correspond rst 20 min middle 20 min last 20 min composite frame recon structed use mlem algorithm 100 iteration three composite image provide prior information use bowsher method kernel method propose method neighborhood size set 9 \u00029 method use prior image feature vector com pose three intensity pixel position three composite image use search 20 near est neighbor bowsher method 50 near neighbor kernel method propose approach number superpixels kranged 1000 2600 step 100 multiscale slic compactness factor xed 70 without vary kvalue cluster number tof fcm set 3 threshold set 07 bowsher method propose method use quadratic potential function 300 iteration use ensure convergence mlem algorithm post reconstruction gaussian ltering also include per formance comparison mlem algorithm kernel method embased method b evaluation metrics quantitative comparison different recon struction method overall image quality assess signaltonoise ratio snr snrd10 log10 xtrue 2 xi\u0000xtrue 2 10 xtrueandxidenote groundtruth reconstruct image respectively three tumor choose region interest rois contrast recovery coef cient crc cal culated crcd1 nrnrx id1\u0012nri nbi\u00001\u0013 \u0012nrtrue nbtrue\u00001\u0013 11 28968 volume 9 2021s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 1 flowchart propose pet reconstruction algorithm figure 2 digital brain phantom attenuation map time activity curve pet phantom compose gray matter white matter three tumor b c b corresponding attenuation image c regional time activity curve nris total number noisy realization n r= 10 simulation nriis mean intensity roi ith realization nbiis mean intensity background nrtrueis true roi mean nbtrueis true background mean white matter region erode 5 \u00025 square structure element choose background calculate noise standard deviation sd sd also average realization spatially average pixellevel normalized bias roi de ned bias=100 \u00021 nroix j2roi nxj\u0000xtrue j xtrue j 12 nroiis total number pixel roi nxjis ensemble mean value pixel j ie nxjd1 nrpnr id1xi j spatially average pixellevel coef cient variation cov roi de ned cov=100 \u00021 nroix j2roiq 1 nr\u00001pnr id1 xi j\u0000nxj 2 nxj 13 c simulation results mainly compare reconstruction performance different method frame 12 24 406 k 2752 k event respectivelyfig 3 show true activity image image recon structed four method 12th 24th frame method reconstructed image show high snr vary either iteration number embased method regularization parameter regularizationbased method frame 12 much low scan count frame 24 thus reconstruc tion result show large difference image mlem algorithm high level noise incorpo rating prior kernel method bowsher method propose method substantially reduce noise good preserve edge tumor mlem algorithm postreconstruction gaussian ltering two study frame propose method achieve high snr optimal visual effect include sharp boundary gray matter white matter least noise white matter corresponding bias image show fig 4 propose method least bias especially white matter region fig 5 show contrast recovery coef cients crcs three tumor region versus background standard devi ation sd tradeoff achieve different method obtain vary either iteration number regu larization parameter method 12th 24th frame expect method utilize prior low background noise mlem algorithm gaussian post ltering matched crc level propose approach achieve high crc low back volume 9 2021 28969s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 3 true activity image reconstruct image different method 12th frame top row 24th frame bottom row reconstruction method include leave right mlem gaussian postfiltering kernel method bowsher method propose approach figure 4 bias image 12th frame top row 24th frame bottom row ground noise tumor one key reason propose method preserve high tumor contrast method singlescale map recon struction process smoothness tumor region activ ities limit superpixel region correspond tumor occur across tumor tissue fig 6 show spatially average pixellevel bias versus spatially average pixellevel cov tradeoff three tumor region 12th 24th frame method incorporate prior achieve well biasvariance perfor mance postsmoothed mlem algorithm tumor propose method optimal biasvariance tradeoff case slightly poor tradeoff bowsher method tumor b large tumor 24th framefig 7 show plot image snr time frame different method snr mean snrs ten noisy realization error bar indicate standard deviation snrs ten realization method utilize prior outperform postsmoothed mlem algorithm frame propose approach achieve high snrs bowsher method kernel method especially lowcount frame illustration effect component propose method three component ie superpixel clustering fcm clustering multiscale aggregation combine pet image reconstruction use recon struction simulated 12th frame example brie illustrate effect component fig 8 show true 28970 volume 9 2021s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 5 crcs three tumor region versus background sd tradeoff achieve different method frame 12 top row 24 bottom row leave right correspond tumor b c figure 6 pixellevel bias versus cov tradeoff achieve different method frame 12 top row 24 bottom row leave right correspond tumor b c image image reconstruct mlem algorithm without component utilized cluster priorbased map method b superpixel clustering k d1500 utilize c superpixel clustering k d1500 fcm cluster utilized three component utilized ie propose method map method use component parameter regularization parameter tune reconstruction fig 8 b present good edge use superpixel clusteringbased prior fig 8 c illustrate less noise good tissue contrast b add fcm clustering however high bias persists fig 8 c two region indicate red arrow bias level substantially decrease owe effect multiscale aggregation show fig 8 snr fig 8 increase component usediv application real clinical data clinical data acquisition rat myocardial infarction scan siemens inveon small animal pet scanner rat receive bolus injection 115 mci18ffdg pet scan start right injection last 60 min dynamic pet data divide 25 frame 10 \u00023 3\u000210 4\u000260 5\u0002300 3\u0002600 ct scan acquire provide attenuation map attenuation correction attenuation factor extract use vendor software include forward model reconstruction mention simulation study three 20 min composite frame reconstruct provide image prior rat data reconstruct image matrix 217\u0002217\u0002159 voxels voxel size volume 9 2021 28971s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 7 plots image snr time frame reconstruct different method 046\u0002046\u00020796 mm3using mlem algorithm kernel method bowsher method propose method propose method parameter mandtwere set 50 5 respectively parameter keep simulation study since true activity value unknown bias analy si perform compare different method plot mean activity versus standard deviation sd curve roi myocardium region indicate white arrow fig 9 b results fig 9 show transverse slice reconstructed image 18th 25th frame use different method mlem algorithm kernel method 100 iteration use bowsher method propose method reg ularization parameter heuristically select set 001 0005 18th 25th frame respectively reconstructed image mlem algorithm suffer considerable noise use composite image prior kernel method suppress noise certain extent preserve tissue contrast bowsher method partly reduce noise smooth image structure comparison propose method present well noise suppression preserved boundary tissue contrast well method fig 10 show mean activity versus standard deviation tradeoff roi use different method vary ing iteration number regularization parameter method 18th 25th frame myocardium region propose method achieve less noise activity value method v discussion parameters selection performance propose method affect number superpixels kand compactness factor muse superpixel clustering cluster number tand thresh old use fcm clustering scale selection multiscale aggregation number superpixels kshould neither large small large kvalue resultsin meaningless smallsized superpixels small k value lead largesized superpixels excessive loss detail result superpixels contain one class tissue however give image size appropriate set kvalues could determine eg image size 217 \u0002217 would appropriate setkbetween 1000 3000 word suitable number superpixels slic algorithm proportional total number image pixel easy select scale range appropriate kvalues propose method sensitive multiscale selection cluster number tcould equal slightly great number main tissue image reconstruct eg simulation study tcan 3 4 5 6 without obvious improvement degradation image quality nding consistent previous study 34 compactness factor mand threshold relate quality prior image mvalue value small composite prior image less noise vice versa practice prefer use small mvalue good boundary adherence thus image reconstruction propose method easily select parameter kandtand multiple scale experience need carefully choose parameter mand b implementation multiscale aggregation investigate 38 multiscale superpixels gener ated vary number superpixels kand compact ness factor min slic algorithm however vary kvalue much ef cient vary mvalue eliminate bias accord experiment may easy capture differentscale structural information vary kvalue 40 reconstructed image quality susceptible mvalue thus implement multiscale oversegmentations vary kvalue simulation study scale range 1000 3000 select vary kvalues singlescale map estimate use compactness factor cluster number threshold regularization parameter avoid add new tunable parameter furthermore computational time propose method proportional number chosen scale reduce parallel compute c disadvantage proposed method according analysis bias image fig 4 propose method reconstruct slender structure well slic algorithm segment slen der structure well surroundings deep image prior development deep learning deep prior model 41 42 propose pet reconstruc tion method incorporate deep image prior 43 static pet image reconstruction 41 dynamic pet image reconstruction use nonnegative matrix factorization 28972 volume 9 2021s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters figure 8 true image frame 12 reconstruct image different method base different combination three component figure 9 reconstructed image 18th top row 25th bottom row frame use different method myocardium region indicate white arrow figure 10 mean activity versus sd tradeoff myocardium roi achieve different method 18th b 25th frame curve plot vary iteration number 20 100 mlem algorithm kernel method vary regularization parameter bowsher method propose method 42 show good performance visually quantitatively traditional reconstruction algorithm deep priorbased method study compare propose method future vi conclusion paper develop novel cluster priorbased map reconstruction method cluster consists superpixelclustering follow fcm clustering multiscale aggre gation use far improve image quality simulation result show propose approach achieve bet ter visual effect crc versus sd tradeoff mlem algorithm kernel method bowsher method propose approach preserve edge tumor well least background noise propose method apply reconstruct dynamic pet image rat volume 9 2021 28973s cao et al dynamic pet image reconstruction incorporating multiscale superpixel clusters myocardial infarction achieve visual quanti tative accuracy improvement method reconstruction method easily extend utilize multimodal anatomical prior combination anatomical functional prior change input channel slic algorithm applications human clinical data corresponding parameter selection strategy study future",
    "bag_of_words": {
        "received": 1,
        "january": 1,
        "accept": 1,
        "february": 3,
        "date": 2,
        "publication": 2,
        "current": 2,
        "version": 1,
        "digital": 2,
        "object": 1,
        "identifier": 1,
        "109/access20213058807": 1,
        "dynamic": 29,
        "pet": 53,
        "image": 109,
        "reconstruction": 53,
        "incorporating": 10,
        "multiscale": 31,
        "superpixel": 44,
        "clusters": 10,
        "shuangliang": 1,
        "cao": 10,
        "yuru": 1,
        "hongyan": 1,
        "zhang": 1,
        "wenbing": 1,
        "lv": 1,
        "lijun": 3,
        "lu": 3,
        "wufan": 2,
        "chen": 2,
        "school": 1,
        "biomedical": 1,
        "engineering": 1,
        "southern": 2,
        "medical": 3,
        "university": 2,
        "guangzhou": 2,
        "china": 3,
        "guangdong": 3,
        "provincial": 1,
        "key": 2,
        "laboratory": 1,
        "processing": 1,
        "corresponding": 6,
        "author": 1,
        "ljlubme": 1,
        "gmailcom": 1,
        "chenwf": 1,
        "mmucom": 1,
        "work": 6,
        "support": 2,
        "part": 2,
        "national": 1,
        "natural": 1,
        "science": 1,
        "foundation": 2,
        "grant": 2,
        "basic": 2,
        "applied": 1,
        "research": 1,
        "2019a1515011104": 1,
        "province": 1,
        "universities": 1,
        "colleges": 1,
        "pearl": 1,
        "river": 1,
        "scholar": 1,
        "funded": 1,
        "scheme": 1,
        "abstract": 1,
        "positron": 4,
        "emission": 3,
        "tomography": 4,
        "challenge": 1,
        "due": 1,
        "lowcount": 2,
        "statistic": 2,
        "individual": 5,
        "frame": 42,
        "study": 17,
        "propose": 46,
        "novel": 4,
        "framework": 5,
        "aim": 4,
        "enhance": 4,
        "quantitative": 7,
        "accuracy": 5,
        "via": 5,
        "introduction": 3,
        "prior": 37,
        "base": 11,
        "cluster": 48,
        "derive": 8,
        "prereconstruction": 2,
        "composite": 17,
        "use": 37,
        "follow": 11,
        "fuzzy": 4,
        "cmeans": 2,
        "fcm": 22,
        "clustering": 30,
        "aggregation": 10,
        "exploit": 6,
        "generate": 8,
        "maximum": 9,
        "posteriori": 3,
        "map": 18,
        "differentscale": 3,
        "separately": 2,
        "apply": 7,
        "fuse": 2,
        "nal": 4,
        "result": 17,
        "using": 3,
        "realistic": 1,
        "simulate": 5,
        "brain": 4,
        "data": 16,
        "performance": 8,
        "method": 104,
        "investigate": 2,
        "compare": 7,
        "maximumlikelihood": 2,
        "expectationmaximization": 3,
        "mlem": 20,
        "bowsher": 16,
        "kernelized": 2,
        "kernel": 15,
        "achieve": 12,
        "substantial": 1,
        "improvement": 5,
        "visual": 5,
        "term": 2,
        "signal": 1,
        "tonoise": 1,
        "ratio": 2,
        "contrast": 8,
        "versus": 10,
        "noise": 22,
        "also": 4,
        "test": 1,
        "min18ffdg": 1,
        "rat": 5,
        "perform": 10,
        "inveon": 2,
        "small": 9,
        "animal": 2,
        "scanner": 3,
        "show": 18,
        "outperform": 2,
        "mean": 14,
        "intensity": 11,
        "region": 18,
        "interest": 3,
        "index": 1,
        "terms": 1,
        "functional": 2,
        "imaging": 3,
        "modality": 1,
        "widely": 1,
        "oncology": 1,
        "cardiology": 1,
        "neurol": 1,
        "ogy": 1,
        "measure": 4,
        "radiotracer": 1,
        "distribution": 1,
        "vivo": 1,
        "scan": 6,
        "generally": 1,
        "multiple": 4,
        "time": 15,
        "range": 5,
        "second": 1,
        "minute": 1,
        "series": 1,
        "start": 2,
        "moment": 1,
        "tracer": 4,
        "injection": 3,
        "addition": 1,
        "kinetic": 5,
        "modeling": 3,
        "capable": 1,
        "quantify": 1,
        "physiologically": 1,
        "biochemically": 1,
        "important": 1,
        "parameter": 17,
        "level": 4,
        "voxel": 2,
        "roi": 9,
        "however": 7,
        "accurate": 1,
        "require": 1,
        "short": 2,
        "low": 9,
        "count": 4,
        "high": 10,
        "associate": 1,
        "editor": 1,
        "coordinate": 1,
        "review": 1,
        "manuscript": 1,
        "approve": 1,
        "yunjie": 1,
        "yang": 1,
        "inherently": 1,
        "illposed": 1,
        "problem": 3,
        "far": 3,
        "accentuate": 1,
        "projection": 6,
        "conventional": 3,
        "analytical": 1,
        "ltered": 1,
        "back": 2,
        "fbp": 2,
        "often": 2,
        "noisy": 5,
        "statistical": 2,
        "algorithm": 25,
        "property": 1,
        "detect": 1,
        "produce": 1,
        "improve": 4,
        "reconstructed": 8,
        "direct": 2,
        "estimate": 15,
        "exhibit": 1,
        "variance": 1,
        "increase": 3,
        "iteration": 8,
        "tackle": 1,
        "illposedness": 1,
        "inherent": 1,
        "incorporation": 2,
        "model": 12,
        "focus": 1,
        "local": 5,
        "neighborhood": 7,
        "subsequently": 1,
        "volume": 9,
        "2021this": 1,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "information": 9,
        "see": 1,
        "http": 1,
        "//creativecommonsorg/licenses/by/40/28965s": 1,
        "et": 12,
        "al": 12,
        "penalize": 1,
        "intervoxel": 2,
        "difference": 3,
        "different": 21,
        "penalty": 1,
        "function": 7,
        "quadratic": 2,
        "sophisticated": 1,
        "improved": 1,
        "alternative": 1,
        "approach": 9,
        "seek": 2,
        "control": 3,
        "penalization": 1,
        "segment": 2,
        "non": 2,
        "segmented": 2,
        "anatomical": 8,
        "classic": 1,
        "void": 1,
        "need": 2,
        "pro": 1,
        "pose": 2,
        "refer": 1,
        "encourage": 3,
        "smooth": 3,
        "anatomy": 1,
        "dependent": 1,
        "de": 5,
        "ned": 5,
        "select": 6,
        "set": 11,
        "similar": 3,
        "neighbor": 3,
        "ehrhardt": 1,
        "structural": 2,
        "ity": 1,
        "mr": 3,
        "alignment": 1,
        "gradient": 2,
        "inspired": 1,
        "pixel": 23,
        "express": 1,
        "feature": 6,
        "incorporate": 4,
        "forward": 3,
        "thus": 6,
        "coef": 4,
        "cients": 2,
        "likelihood": 1,
        "ml": 3,
        "name": 1,
        "expectation": 3,
        "maximization": 1,
        "kem": 2,
        "static": 4,
        "mri": 1,
        "informa": 1,
        "tion": 5,
        "listmode": 1,
        "sinograms": 3,
        "temporal": 2,
        "resolution": 2,
        "recon": 7,
        "struction": 5,
        "parametric": 1,
        "combine": 3,
        "spatial": 5,
        "mod": 1,
        "el": 1,
        "spectral": 1,
        "patlak": 1,
        "graphical": 1,
        "context": 1,
        "postreconstruction": 3,
        "analysis": 5,
        "number": 27,
        "clusteringbased": 2,
        "technique": 1,
        "reduce": 6,
        "factor": 9,
        "decompose": 1,
        "cardiac": 1,
        "tissue": 12,
        "type": 1,
        "unique": 1,
        "signature": 1,
        "quanti": 2,
        "cation": 4,
        "physiological": 1,
        "func": 1,
        "oncologic": 1,
        "wholebody": 2,
        "prin": 1,
        "cipal": 1,
        "component": 9,
        "pca": 1,
        "distinction": 1,
        "tumor": 25,
        "fdg": 2,
        "standard": 7,
        "uptake": 2,
        "value": 13,
        "suv": 1,
        "janssen": 1,
        "kmeans": 2,
        "slope": 1,
        "activity": 18,
        "curve": 8,
        "calculate": 2,
        "last": 3,
        "differentiate": 1,
        "healthy": 1,
        "gaussian": 5,
        "mixture": 1,
        "models": 1,
        "voxelwise": 1,
        "classi": 5,
        "active": 2,
        "neurotransmitter": 1,
        "state": 1,
        "abovementioned": 1,
        "group": 2,
        "35d": 1,
        "utilize": 6,
        "generation": 2,
        "exten": 1,
        "sion": 1,
        "previous": 4,
        "present": 6,
        "utilizes": 1,
        "twostep": 3,
        "include": 7,
        "advantage": 3,
        "one": 3,
        "hand": 2,
        "infor": 1,
        "mation": 1,
        "global": 2,
        "smoothness": 2,
        "within": 2,
        "moreover": 2,
        "bias": 15,
        "make": 3,
        "good": 8,
        "simulated": 3,
        "real": 3,
        "clinical": 5,
        "main": 4,
        "contribution": 1,
        "\u000fthis": 1,
        "individ": 1,
        "ual": 1,
        "\u000fthe": 1,
        "com": 3,
        "posite": 2,
        "\u000fmap": 1,
        "rest": 1,
        "paper": 2,
        "organize": 1,
        "rst": 4,
        "introduce": 2,
        "imag": 1,
        "ing": 2,
        "describe": 2,
        "section": 6,
        "ii": 2,
        "computer": 2,
        "simu": 1,
        "lation": 1,
        "iii": 2,
        "validate": 1,
        "exist": 1,
        "iv": 1,
        "new": 3,
        "finally": 3,
        "discussion": 2,
        "provide": 4,
        "conclusion": 2,
        "draw": 1,
        "vi": 2,
        "theory": 1,
        "yare": 1,
        "well": 7,
        "independent": 1,
        "pois": 1,
        "son": 1,
        "random": 4,
        "variable": 1,
        "loglikelihood": 2,
        "yjx": 3,
        "dmx": 1,
        "id1yilognyi\u0000nyi\u0000logyiw": 1,
        "wherenyis": 1,
        "relate": 2,
        "unknown": 2,
        "xby": 1,
        "nydaxcr": 1,
        "a2rm\u0002nis": 1,
        "system": 1,
        "matrix": 5,
        "element": 2,
        "aij": 1,
        "denote": 1,
        "probability": 1,
        "emit": 1,
        "coincidence": 1,
        "ith": 2,
        "detector": 2,
        "pair": 2,
        "represent": 1,
        "scattered": 1,
        "event": 3,
        "andndenote": 1,
        "total": 5,
        "respectively": 4,
        "xi": 2,
        "obtain": 5,
        "2021s": 4,
        "maximize": 1,
        "oxdarg": 2,
        "max": 2,
        "x\u00150l": 2,
        "convergence": 2,
        "commonly": 2,
        "solve": 1,
        "regularization": 7,
        "trade": 1,
        "energy": 1,
        "know": 1,
        "preconditioned": 1,
        "ascent": 1,
        "instead": 2,
        "onesteplate": 1,
        "osl": 1,
        "avoid": 2,
        "numerical": 1,
        "latter": 1,
        "may": 2,
        "cause": 2,
        "iterative": 2,
        "update": 1,
        "xjdxold": 1,
        "jc\u0012": 1,
        "xj\u0000": 1,
        "xj\u0013": 1,
        "iaij": 1,
        "xold": 2,
        "jc": 1,
        "2u": 1,
        "x2": 1,
        "partial": 1,
        "derivative": 1,
        "evaluate": 2,
        "xjis": 1,
        "strongly": 2,
        "depend": 2,
        "proposed": 3,
        "clusterbased": 1,
        "without": 4,
        "signi": 1,
        "cant": 1,
        "expand": 1,
        "contain": 2,
        "together": 1,
        "dnx": 1,
        "jd1x": 1,
        "k2cfjgwjk": 1,
        "xj\u0000xk": 1,
        "stand": 1,
        "ji": 2,
        "detail": 2,
        "description": 1,
        "find": 2,
        "next": 1,
        "potential": 2,
        "take": 1,
        "form": 1,
        "ds2": 1,
        "wjkis": 1,
        "weight": 3,
        "give": 4,
        "kin": 2,
        "wjk": 1,
        "inversely": 1,
        "proportional": 3,
        "euclidean": 2,
        "distance": 3,
        "jandkwe": 1,
        "compute": 2,
        "wjkin": 1,
        "particular": 1,
        "eg": 4,
        "9\u00029": 1,
        "following": 1,
        "simulation": 10,
        "experiment": 2,
        "entire": 1,
        "distant": 1,
        "negligible": 1,
        "lead": 2,
        "considerable": 2,
        "computational": 3,
        "speed": 1,
        "construction": 1,
        "determine": 3,
        "accurately": 1,
        "nature": 1,
        "sensitive": 2,
        "utilized": 4,
        "schemeis": 1,
        "first": 1,
        "three": 21,
        "reconstruct": 11,
        "summed": 1,
        "simple": 1,
        "linear": 1,
        "slic": 9,
        "memory": 1,
        "ef": 2,
        "ciency": 1,
        "adherence": 3,
        "boundary": 5,
        "input": 2,
        "weighted": 1,
        "dj": 2,
        "lbetween": 1,
        "jandlis": 1,
        "lds": 1,
        "d2": 1,
        "fc\u0012ds": 1,
        "s\u00132": 1,
        "m2": 1,
        "dsis": 1,
        "andl": 1,
        "dfdqph": 1,
        "hd1": 1,
        "fh": 2,
        "j\u0000fh": 1,
        "2is": 1,
        "similarity": 2,
        "jandl": 1,
        "hstands": 1,
        "channel": 3,
        "jin": 1,
        "hth": 1,
        "sdp": 1,
        "n=k": 1,
        "width": 1,
        "normalization": 1,
        "nis": 1,
        "kis": 1,
        "superpixels": 19,
        "mis": 1,
        "proximity": 1,
        "mresults": 1,
        "less": 4,
        "regular": 1,
        "size": 8,
        "shape": 1,
        "carry": 1,
        "classify": 2,
        "accord": 6,
        "every": 1,
        "tof": 2,
        "example": 2,
        "tcan": 2,
        "human": 2,
        "gray": 4,
        "matter": 12,
        "white": 10,
        "background": 9,
        "would": 2,
        "tvalue": 1,
        "minimizes": 1,
        "jdkx": 1,
        "pd1tx": 1,
        "qd1uv": 1,
        "pq": 1,
        "bp\u0000cq": 1,
        "bpis": 1,
        "vector": 2,
        "comprise": 1,
        "pth": 1,
        "cqis": 1,
        "center": 1,
        "qth": 2,
        "upqis": 1,
        "degree": 2,
        "membership": 5,
        "bpin": 1,
        "vis": 1,
        "partition": 1,
        "exponent": 1,
        "overlap": 1,
        "ever": 1,
        "suitable": 2,
        "directly": 1,
        "intotclusters": 2,
        "smallsized": 2,
        "belong": 1,
        "tclusters": 2,
        "dif": 1,
        "cult": 1,
        "sized": 1,
        "ed": 2,
        "separate": 2,
        "large": 6,
        "given": 1,
        "relatively": 1,
        "threshold": 6,
        "distinguish": 1,
        "tmain": 1,
        "ensure": 2,
        "distinguishing": 1,
        "mem": 1,
        "bership": 1,
        "treat": 1,
        "28967s": 1,
        "divide": 3,
        "singlescale": 5,
        "much": 3,
        "true": 8,
        "average": 8,
        "vary": 13,
        "decide": 1,
        "scale": 7,
        "assuming": 1,
        "nsscales": 1,
        "x\u0003": 2,
        "x\u0003d1": 1,
        "nsnsx": 1,
        "nd1oxn": 1,
        "whereoxnis": 1,
        "nth": 1,
        "implementation": 2,
        "owchart": 1,
        "fig": 17,
        "consist": 1,
        "step": 9,
        "elaborate": 1,
        "sinogram": 1,
        "rebinned": 2,
        "duration": 1,
        "imagesoxreb": 1,
        "oxreb": 1,
        "andoxreb": 1,
        "normalize": 1,
        "deriva": 1,
        "clus": 1,
        "tering": 1,
        "compactness": 5,
        "ksuperpixels": 1,
        "member": 1,
        "ship": 1,
        "oxnis": 1,
        "varying": 1,
        "repeat": 1,
        "validation": 1,
        "setup": 1,
        "geometry": 1,
        "ge": 1,
        "dst": 1,
        "2d": 1,
        "phan": 1,
        "tom": 1,
        "dimension": 1,
        "\u0002217": 2,
        "construct": 1,
        "brainweb": 1,
        "database": 1,
        "lesion": 1,
        "location": 1,
        "add": 3,
        "phantom": 3,
        "werelocated": 1,
        "whereas": 1,
        "mediumsized": 1,
        "position": 2,
        "across": 2,
        "scanning": 1,
        "schedule": 1,
        "\u000220": 1,
        "4\u000240": 1,
        "4\u0002": 1,
        "4\u0002180": 1,
        "8\u0002300": 1,
        "regional": 2,
        "assign": 2,
        "project": 1,
        "noisefree": 1,
        "poisson": 1,
        "uniform": 1,
        "scatters": 1,
        "attenuation": 7,
        "kev": 1,
        "photon": 1,
        "create": 1,
        "cm\u00001": 1,
        "air": 1,
        "cm\u00001to": 2,
        "bone": 1,
        "correction": 2,
        "\u0002107events": 1,
        "acquire": 2,
        "min": 7,
        "ten": 3,
        "realization": 6,
        "highcount": 1,
        "correspond": 4,
        "middle": 1,
        "structed": 2,
        "\u00029": 1,
        "search": 1,
        "near": 2,
        "est": 1,
        "kranged": 1,
        "xed": 1,
        "kvalue": 5,
        "post": 2,
        "ltering": 3,
        "per": 1,
        "formance": 1,
        "comparison": 3,
        "embased": 2,
        "evaluation": 1,
        "metrics": 1,
        "overall": 1,
        "quality": 5,
        "assess": 1,
        "signaltonoise": 1,
        "snr": 7,
        "snrd10": 1,
        "log10": 1,
        "xtrue": 2,
        "xi\u0000xtrue": 1,
        "xtrueandxidenote": 1,
        "groundtruth": 1,
        "choose": 3,
        "rois": 1,
        "recovery": 2,
        "cient": 3,
        "crc": 4,
        "cal": 1,
        "culated": 1,
        "crcd1": 1,
        "nrnrx": 1,
        "id1\u0012nri": 1,
        "nbi\u00001\u0013": 1,
        "\u0012nrtrue": 1,
        "nbtrue\u00001\u0013": 1,
        "figure": 10,
        "flowchart": 1,
        "compose": 1,
        "nris": 1,
        "r=": 1,
        "nriis": 1,
        "nbiis": 1,
        "nrtrueis": 1,
        "nbtrueis": 1,
        "erode": 1,
        "\u00025": 1,
        "square": 1,
        "structure": 4,
        "deviation": 4,
        "sd": 7,
        "spatially": 4,
        "pixellevel": 5,
        "normalized": 1,
        "bias=100": 1,
        "\u00021": 2,
        "nroix": 2,
        "j2roi": 1,
        "nxj\u0000xtrue": 1,
        "nroiis": 1,
        "nxjis": 1,
        "ensemble": 1,
        "ie": 3,
        "nxjd1": 1,
        "nrpnr": 1,
        "id1xi": 1,
        "variation": 1,
        "cov": 3,
        "cov=100": 1,
        "j2roiq": 1,
        "nr\u00001pnr": 1,
        "id1": 1,
        "j\u0000nxj": 1,
        "nxj": 1,
        "results": 2,
        "mainly": 1,
        "respectivelyfig": 1,
        "four": 1,
        "12th": 6,
        "24th": 6,
        "either": 2,
        "regularizationbased": 1,
        "reconstruc": 2,
        "incorpo": 1,
        "rating": 1,
        "substantially": 2,
        "preserve": 4,
        "edge": 3,
        "two": 2,
        "optimal": 2,
        "effect": 5,
        "sharp": 1,
        "least": 3,
        "especially": 2,
        "crcs": 2,
        "devi": 1,
        "ation": 1,
        "tradeoff": 9,
        "regu": 1,
        "larization": 1,
        "expect": 1,
        "matched": 1,
        "28969s": 1,
        "top": 5,
        "row": 10,
        "bottom": 5,
        "leave": 3,
        "right": 4,
        "postfiltering": 1,
        "ground": 1,
        "reason": 1,
        "process": 1,
        "activ": 1,
        "ities": 1,
        "limit": 1,
        "occur": 1,
        "biasvariance": 2,
        "perfor": 1,
        "mance": 1,
        "postsmoothed": 2,
        "case": 1,
        "slightly": 2,
        "poor": 1,
        "framefig": 1,
        "plot": 3,
        "snrs": 3,
        "error": 1,
        "bar": 1,
        "indicate": 4,
        "illustration": 1,
        "brie": 1,
        "illustrate": 2,
        "priorbased": 3,
        "d1500": 2,
        "tune": 1,
        "persists": 1,
        "red": 1,
        "arrow": 3,
        "decrease": 1,
        "owe": 1,
        "usediv": 1,
        "application": 1,
        "acquisition": 1,
        "myocardial": 2,
        "infarction": 2,
        "siemens": 1,
        "receive": 1,
        "bolus": 1,
        "mci18ffdg": 1,
        "\u00023": 1,
        "3\u000210": 1,
        "4\u000260": 1,
        "5\u0002300": 1,
        "3\u0002600": 1,
        "ct": 1,
        "extract": 1,
        "vendor": 1,
        "software": 1,
        "mention": 1,
        "217\u0002217\u0002159": 1,
        "voxels": 1,
        "28971s": 1,
        "plots": 1,
        "046\u0002046\u00020796": 1,
        "mm3using": 1,
        "mandtwere": 1,
        "keep": 1,
        "since": 1,
        "analy": 1,
        "si": 1,
        "myocardium": 4,
        "transverse": 1,
        "slice": 1,
        "18th": 5,
        "25th": 5,
        "reg": 1,
        "ularization": 1,
        "heuristically": 1,
        "suffer": 1,
        "suppress": 1,
        "certain": 1,
        "extent": 1,
        "partly": 1,
        "suppression": 1,
        "preserved": 1,
        "parameters": 1,
        "selection": 4,
        "affect": 1,
        "kand": 2,
        "muse": 1,
        "tand": 1,
        "thresh": 1,
        "old": 1,
        "kshould": 1,
        "neither": 1,
        "resultsin": 1,
        "meaningless": 1,
        "largesized": 1,
        "excessive": 1,
        "loss": 1,
        "class": 1,
        "appropriate": 3,
        "kvalues": 3,
        "could": 1,
        "setkbetween": 1,
        "word": 1,
        "easy": 2,
        "tcould": 1,
        "equal": 1,
        "great": 1,
        "obvious": 1,
        "degradation": 1,
        "nding": 1,
        "consistent": 1,
        "mand": 2,
        "mvalue": 4,
        "vice": 1,
        "versa": 1,
        "practice": 1,
        "prefer": 1,
        "easily": 2,
        "kandtand": 1,
        "experience": 1,
        "carefully": 1,
        "gener": 1,
        "ated": 1,
        "compact": 1,
        "ness": 1,
        "eliminate": 1,
        "capture": 1,
        "susceptible": 1,
        "implement": 1,
        "oversegmentations": 1,
        "tunable": 1,
        "furthermore": 1,
        "chosen": 1,
        "parallel": 1,
        "disadvantage": 1,
        "according": 1,
        "slender": 1,
        "slen": 1,
        "der": 1,
        "surroundings": 1,
        "deep": 5,
        "development": 1,
        "learning": 1,
        "nonnegative": 1,
        "factorization": 1,
        "combination": 2,
        "visually": 1,
        "quantitatively": 1,
        "traditional": 1,
        "future": 2,
        "develop": 1,
        "consists": 1,
        "superpixelclustering": 1,
        "aggre": 1,
        "gation": 1,
        "bet": 1,
        "ter": 1,
        "28973s": 1,
        "tative": 1,
        "extend": 1,
        "multimodal": 1,
        "change": 1,
        "applications": 1,
        "strategy": 1
    },
    "objective": [
        "this study propose a novel reconstruction framework aim to enhance the quantitative accuracy of individual dynamic frame via the introduction of prior base on multiscale superpixel cluster .",
        "using realistic simulate dynamic brain pet data , the quantitative performance of the propose method be investigate and compare with the maximum-likelihood expectation-maximization ( mlem ) , bowsher method , and kernelized expectation-maximization ( the kernel method ) .",
        "the propose method achieve substantial improvement in both visual and quantitative accuracy ( in term of the signal- to-noise ratio and contrast versus noise performance ) .",
        "the propose method be show to outperform the other method via improvement in visual and quantitative accuracy ( in term of noise versus the mean intensity of the region of interest ) .",
        "the propose method can combine the advantage of superpixel clustering , fcm clustering , and multiscale aggregation and thus can make good use of the image prior .",
        "the reconstruction performance of the propose method be compare with the mlem algorithm , the bowsher method and the kernel method [ 22 ] in simulated and real clinical data reconstruction .",
        "\u000fthis study propose a novel reconstruction framework aim to enhance the quantitative accuracy of individ- ual dynamic frame via the introduction of prior base on multiscale superpixel cluster .",
        "we rst introduce the map reconstruction framework for pet imag- ing and describe how the propose reconstruction method be perform in section ii .",
        "then , we present a computer simu- lation study in section iii to validate the improvement of the propose method over exist method .",
        "finally , all scale image estimate be derive , and their average be the reconstruction result x\u0003 ( 9 ) of the propose method .",
        "for the propose approach , the number of superpixels kranged from 1000 to 2600 in step of 100 for multiscale slic , the compactness factor m be xed to 70 without vary with kvalue , the cluster number tof fcm be set to 3 , and the threshold be set to 0.7 .",
        "the propose method achieve the high snr and an optimal visual effect , include the sharp boundary between the gray matter and white matter and the least noise in the white matter .",
        "the propose method have the least bias , especially in the white matter region .",
        "the propose approach achieve the high crc with the low back- volume 9 , 2021 28969s .",
        "one of the key reason why the propose method can preserve a high tumor contrast than other method be that in each single-scale map recon- struction process , the smoothness of the tumor region activ- ities be limit in the superpixel region correspond to that tumor and do not occur across that tumor and other tissue .",
        "the propose method have the optimal bias-variance trade-off for the most case and slightly poor trade-off than the bowsher method only for tumor b ( the large tumor ) of the 24th frame.fig .",
        "the propose approach achieve high snrs than the bowsher method and kernel method , especially for the low-count frame .",
        ", the propose method ) .",
        "for the propose method , the parameter mandtwere set to 50 and 5 , respectively .",
        "in comparison , the propose method present well noise suppression and preserved boundary and tissue contrast well than other method .",
        "for the myocardium region , the propose method achieve less noise at the same activity value than other method .",
        "v. discussion a. parameters selection the performance of the propose method be affect by the number of superpixels kand the compactness factor muse for superpixel clustering , the cluster number tand thresh- old use for fcm clustering , and the scale selection for multiscale aggregation .",
        "it be easy to select some scale from the range of appropriate kvalues because the propose method be not sensitive to multiscale selection .",
        "thus , for image reconstruction with the propose method , we can easily select parameter kandtand multiple scale from experience and only need to carefully choose the parameter mand .",
        "furthermore , the computational time of the propose method be proportional to the number of chosen scale and can be reduce by parallel compute .",
        "c. disadvantage of the proposed method according to the analysis of the bias image in fig .",
        "4 , the propose method can not reconstruct slender structure well .",
        "the simulation result show the propose approach achieve bet- ter visual effect and crc versus sd trade-off than the mlem algorithm , kernel method , and bowsher method .",
        "the propose approach can preserve edge and tumor well with the least background noise .",
        "the propose method be apply to reconstruct the dynamic pet image of a rat volume 9 , 2021 28973s ."
    ],
    "references": [
        "",
        "REFERENCES [1] G. J. Kelloff, J. M. Hoffman, B. Johnson, H. I. Scher, B. A. Siegel, E. Y. Cheng, B. D. Cheson, J. O'Shaughnessy, K. Z. Guyton, D. A. Mankoff, L. Shankar, S. M. Larson, C. C. Sigman, R. L. Schilsky, and D. C. Sullivan, ``Progress and promise of FDG-PET imaging for cancer patient management and oncologic drug development,'' Clin. Cancer Res., vol. 11, no. 8, pp. 2785\u00152808, Apr. 2005. [2] T. S. Khan, A. Sundin, C. Juhlin, B. Långström, M. Bergström, and B. Eriksson, ``11 C-metomidate PET imaging of adrenocortical cancer,'' Eur. J. Nucl. Med. Mol., vol. 30, no. 3, pp. 403\u0015410, 2003. [3] P. Vakil, J. J. Lee, J. J. Mouannes-Srour, C. P. Derdeyn, and T. J. Carroll, ``Cerebrovascular occlusive disease: Quantitative cerebral blood \u001dow using dynamic susceptibility contrast MR imaging correlates with quantitative H2[15O] PET,'' Radiology, vol. 266, no. 3, pp. 879\u0015886, Mar. 2013. [4] H. Watabe, Y. Ikoma, Y. Kimura, M. Naganawa, and M. Shidahara, ``PET kinetic analysis\u0016Compartmental model,'' Ann. Nucl. Med., vol. 20, no. 9, pp. 583\u0015588, Nov. 2006. [5] M. Bentourkia and H. Zaidi, ``Tracer kinetic modeling in PET,'' PET Clinics, vol. 2, no. 2, pp. 267\u0015277, Apr. 2007. [6] A. Dimitrakopoulou-Strauss, L. Pan, and L. G. Strauss, ``Parametric imag- ing: A promising approach for the evaluation of dynamic PET-18 F- FDG studies-the DKFZ experience,'' Hell J. Nucl. Med., vol. 13, no. 1, pp. 18\u001522, 2010. [7] N. A. Karakatsanis, M. A. Lodge, A. K. Tahari, Y. Zhou, R. L. Wahl, and A. Rahmim, ``Dynamic whole-body PET parametric imaging: I. Concept, acquisition protocol optimization and clinical application,'' Phys. Med. Biol., vol. 58, no. 20, pp. 7391\u00157418, Oct. 2013. [8] N. A. Karakatsanis, M. A. Lodge, Y. Zhou, R. L. Wahl, and A. Rahmim, ``Dynamic whole-body PET parametric imaging: II. task- oriented statistical estimation,'' Phys. Med. Biol., vol. 58, no. 20, pp. 7419\u00157445, Oct. 2013. [9] L. A. Shepp and B. F. Logan, ``The Fourier reconstruction of a head section,'' IEEE Trans. Nucl. Sci., vol. 21, no. 3, pp. 21\u001543, Jun. 1974. [10] P. E. Kinahan and J. G. Rogers, ``Analytic 3D image reconstruction using all detected events,'' IEEE Trans. Nucl. Sci., vol. 36, no. 1, pp. 964\u0015968, 1989. [11] L. A. Shepp and Y. Vardi, ``Maximum likelihood reconstruction for emission tomography,'' IEEE Trans. Med. Imag., vol. 1, no. 2, pp. 113\u0015122, Jan. 1982. [12] K. Lange and R. Carson, ``EM reconstruction algorithms for emission and transmission tomography,'' J. Comput. Assist. Tomogr., vol. 8, no. 2, pp. 306\u0015316, Apr. 1984. [13] R. M. Leahy and J. Qi, ``Statistical approaches in quantitative positron emission tomography,'' Statist. Comput., vol. 10, no. 2, pp. 147\u0015165, 2000. [14] S. Geman and D. Geman, ``Stochastic relaxation, gibbs distributions, and the Bayesian restoration of images,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. PAMI-6, no. 6, pp. 721\u0015741, Nov. 1984. [15] S. Geman and D. E. McClure, ``Statistical methods for tomographic image reconstruction,'' Bull. Int. Stat. Inst., vol. 4, pp. 5\u001521, 1987. [16] P. J. Green, ``Bayesian reconstructions from emission tomography data using a modi\u001ced EM algorithm,'' IEEE Trans. Med. Imag., vol. 9, no. 1, pp. 84\u001593, Mar. 1990. [17] E. Ü. Mumcuoglu, R. M. Leahy, and S. R. Cherry, ``Bayesian reconstruc- tion of PET images: Methodology and performance analysis,'' Phys. Med. Biol., vol. 41, no. 9, pp. 1777\u00151807, Sep. 1996. [18] J. Nuyts, D. Beque, P. Dupont, and L. Mortelmans, ``A concave prior penalizing relative differences for maximum-a-posteriori reconstruction in emission tomography,'' IEEE Trans. Nucl. Sci. , vol. 49, no. 1, pp. 56\u001560, Feb. 2002.[19] J. E. Bowsher, H. Yuan, L. W. Hedlund, T. G. Turkington, G. Akabani, A. Badea, W. C. Kurylo, C. T. Wheeler, G. P. Cofer, M. W. Dewhirst, and G. A. Johnson, ``Utilizing MRI information to estimate F18-FDG distributions in rat \u001dank tumors,'' in Proc. IEEE Symp. Conf. Rec. Nucl. Sci., vol. 4, Oct. 2004, pp. 2488\u00152492. [20] K. Vunckx, A. Atre, K. Baete, A. Reilhac, C. M. Deroose, K. Van Laere, and J. Nuyts, ``Evaluation of three MRI-based anatomical priors for quan- titative PET brain imaging,'' IEEE Trans. Med. Imag., vol. 31, no. 3, pp. 599\u0015612, Mar. 2012. [21] M. J. Ehrhardt, P. Markiewicz, M. Liljeroth, A. Barnes, V. Kolehmainen, J. S. Duncan, L. Pizarro, D. Atkinson, B. F. Hutton, S. Ourselin, K. Thielemans, and S. R. Arridge, ``PET reconstruction with an anatomical MRI prior using parallel level sets,'' IEEE Trans. Med. Imag., vol. 35, no. 9, pp. 2189\u00152199, Sep. 2016. [22] G. Wang and J. Qi, ``PET image reconstruction using kernel method,'' IEEE Trans. Med. Imag., vol. 34, no. 1, pp. 61\u001571, Jan. 2015. [23] W. Hutchcroft, G. Wang, K. T. Chen, C. Catana, and J. Qi, ``Anatomically- aided PET reconstruction using the kernel method,'' Phys. Med. Biol., vol. 61, no. 18, pp. 6668\u00156683, Sep. 2016. [24] D. Deidda, N. A. Karakatsanis, P. M. Robson, Y.-J. Tsai, N. Efthimiou, K. Thielemans, Z. A. Fayad, R. G. Aykroyd, and C. Tsoumpas, ``Hybrid PET-MR list-mode kernelized expectation maximization reconstruction,'' Inverse Problems, vol. 35, no. 4, Apr. 2019, Art. no. 044001. [25] G. Wang, ``High temporal-resolution dynamic PET image reconstruction using a new spatiotemporal kernel method,'' IEEE Trans. Med. Imag., vol. 38, no. 3, pp. 664\u0015674, Mar. 2019. [26] P. Novosad and A. J. Reader, ``MR-guided dynamic PET reconstruction with the kernel method and spectral temporal basis functions,'' Phys. Med. Biol., vol. 61, no. 12, pp. 4624\u00154644, Jun. 2016. [27] K. Gong, J. Cheng-Liao, G. Wang, K. T. Chen, C. Catana, and J. Qi, ``Direct patlak reconstruction from dynamic PET data using the kernel method with MRI information based on structural similarity,'' IEEE Trans. Med. Imag., vol. 37, no. 4, pp. 955\u0015965, Apr. 2018. [28] G. E. Fakhri, A. Sitek, B. Guérin, M. F. Kijewski, M. F. D. Carli, and S. C. Moore, ``Quantitative dynamic cardiac 82Rb PET using general- ized factor and compartment analyses,'' J. Nucl. Med., vol. 46, no. 8, pp. 1264\u00151271, 2005. [29] R. Klein, R. S. Beanlands, R. W. Wassenaar, S. L. Thorn, M. Lamoureux, J. N. DaSilva, A. Adler, and R. A. deKemp, ``Kinetic model-based factor analysis of dynamic sequences for 82-rubidium cardiac positron emission tomography,'' Med. Phys., vol. 37, no. 8, pp. 3995\u00154010, Jul. 2010. [30] Y. C. Cavalcanti, T. Oberlin, N. Dobigeon, C. Fevotte, S. Stute, M.-J. Ribeiro, and C. Tauber, ``Factor analysis of dynamic PET images: Beyond Gaussian noise,'' IEEE Trans. Med. Imag., vol. 38, no. 9, pp. 2231\u00152241, Sep. 2019. [31] Y. Anzai, S. Minoshima, G. T. Wolf, and R. L. Wahl, ``Head and neck can- cer: Detection of recurrence with three-dimensional principal components analysis at dynamic FDG PET,'' Radiology, vol. 212, no. 1, pp. 285\u0015290, Jul. 1999. [32] M. H. M. Janssen, H. J. W. L. Aerts, M. C. Öllers, G. Bosmans, J. A. Lee, J. Buijsen, D. De Ruysscher, P. Lambin, G. Lammering, and A. L. A. J. Dekker, ``Tumor delineation based on time\u0015activity curve differences assessed with dynamic \u001duorodeoxyglucose positron emis- sion tomography\u0015computed tomography in rectal cancer patients,'' Int. J. Radiat. Oncol. Biol. Phys., vol. 73, no. 2, pp. 456\u0015465, Feb. 2009. [33] R. Misiunaite, G. I. Angelis, and S. R. Meikle, ``Clustering analysis for neurotransmitter response pro\u001cles of dynamic PET data,'' in Proc. IEEE Nucl. Sci. Symp. Med. Imag. Conf. (NSS/MIC), Oct. 2017, pp. 1\u00154. [34] L. Lu, N. A. Karakatsanis, J. Tang, W. Chen, and A. Rahmim, ``3.5D dynamic PET image reconstruction incorporating kinetics-based clusters,'' Phys. Med. Biol., vol. 57, no. 15, pp. 5035\u00155055, Aug. 2012. [35] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Süsstrunk, ``SLIC superpixels compared to state-of-the-art superpixel methods,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 11, pp. 2274\u00152282, Nov. 2012. [36] J. C. Bezdek, Pattern Recognition With Fuzzy Objective Function Algo- rithms. New York, NY, USA: Plenum Press, 1981. [37] C. L. Chowdhary, M. Mittal, P. A. Pattanaik, and Z. Marszalek, ``An ef\u001ccient segmentation and classi\u001ccation system in medical images using intuitionist possibilistic fuzzy C-mean clustering and fuzzy SVM algorithm,'' Sensors, vol. 20, no. 14, pp. 3903\u00153922, Jul. 2020. [38] J. Jiao, P. Markiewicz, N. Burgos, D. Atkinson, B. Hutton, S. Arridge, and S. Ourselin, ``Detail-preserving PET reconstruction with sparse image representation and anatomical priors,'' in Proc. Int. Conf. Inf. Process. Med. Imag. Cham, Switzerland: Springer, 2015, pp. 540\u0015551. 28974 VOLUME 9, 2021S. Cao et al.: Dynamic PET Image Reconstruction Incorporating Multiscale Superpixel Clusters [39] D. L. Collins, A. P. Zijdenbos, V. Kollokian, J. G. Sled, N. J. Kabani, C. J. Holmes, and A. C. Evans, ``Design and construction of a realistic dig- ital brain phantom,'' IEEE Trans. Med. Imag., vol. 17, no. 3, pp. 463\u0015468, Jun. 1998. [40] L. Bi, J. Kim, A. Kumar, L. Wen, D. Feng, and M. Fulham, ``Automatic detection and classi\u001ccation of regions of FDG uptake in whole-body PET-CT lymphoma studies,'' Computerized Med. Imag. Graph., vol. 60, pp. 3\u001510, Sep. 2017. [41] K. Gong, C. Catana, J. Qi, and Q. Li, ``PET image reconstruction using deep image prior,'' IEEE Trans. Med. Imag., vol. 38, no. 7, pp. 1655\u00151665, Jul. 2019. [42] T. Yokota, K. Kawai, M. Sakata, Y. Kimura, and H. Hontani, ``Dynamic PET image reconstruction using nonnegative matrix factorization incorpo- rated with deep image prior,'' in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 3126\u00153135. [43] V. Lempitsky, A. Vedaldi, and D. Ulyanov, ``Deep image prior,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 9446\u00159454. SHUANGLIANG CAO received the B.Eng. degree from the Hebei University of Science and Technol- ogy, in 2012. He is currently pursuing the Ph.D. degree with the Guangdong Provincial Key Lab- oratory of Medial Image Processing, School of Biomedical Engineering, Southern Medical Uni- versity. His research interests include dynamic PET imaging and parametric imaging. YURU HE received the B.Eng. degree from South- ern Medical University, in 2018, where she is cur- rently pursuing the master's degree in engineering with the School of Biomedical Engineering. Her research interest includes PET/MRI denoising. HONGYAN ZHANG received the B.Eng. degree from Southern Medical University, in 2018, where she is currently pursuing the master's degree with the Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomed- ical Engineering. Her research interest includes dynamic PET factor analysis. WENBING LV received the Ph.D. degree in biomedical engineering from Southern Medical University, China, in 2020. She is currently a Postdoctoral Research Fellow with the Guang- dong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University. Her research inter- ests include PET image analysis and radiomics. LIJUN LU received the Ph.D. degree in biomedi- cal engineering from Southern Medical University, in 2012. He is currently an Associate Professor with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomedi- cal Engineering, Southern Medical University. His research interests include PET imaging methods, medical image processing, and radiomics. WUFAN CHEN received the B.S. and M.Sc. degrees from Beihang University, in 1975 and 1981, respectively. He is currently a Full Professor with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomed- ical Engineering, Southern Medical University. His research interests include biomedical imaging principle and image processing. VOLUME 9, 2021 28975"
    ]
}{
    "name": "Edge-Guided Dual-Modality Image Reconstruction",
    "paragraphs": [
        "special section on emerging computed tomography technologies received october 27 , 2014 , accept november 3 , 2014 , date of publication november 20 , 2014 , date of current version november 26 , 2014 .",
        "digital object identifier 10.1 109/access.2014.2371994 edge-guided dual-modality image reconstruction yang lu1 , jun zhao2 , and ge wang3 , ( fellow , ieee ) 1molecular imaging business unit , shanghai united imaging healthcare company , ltd. , shanghai 201815 , china 2school of biomedical engineering , shanghai jiao tong university , shanghai 200240 , china 3biomedical imaging center , department of biomedical engineering , rensselaer polytechnic institute , troy , ny 12180 , usa corresponding author : j. zhao ( junzhao @ sjtu.edu.cn ) this work be support in part by the national institutes of health under grant u01-eb017140 , in part by the national basic research program ( 973 program ) of china under grant 2010cb834302 , in part by the national institutes of health/national institute of biomedical imaging and bioengineering under grant r01-eb016977 , in part by the national natural science foundation of china under grant 81371634 , in part by the scienti c innovation act through the science and technology commission of shanghai municipality under grant 13511504200 , and in part by the biomedical engineering cross fund through the shanghai jiao tong university , shanghai , china , under grant yg2013ms30 .",
        "abstract to utilize the synergy between compute tomography ( ct ) and magnetic resonance imaging ( mri ) data set from an object at the same time , an edge-guided dual-modality image reconstruction approach be propose .",
        "the key be to establish a knowledge-based connection between these two data set for the tight fusion of different image modality .",
        "our scheme consist of four inter-related element : 1 ) segmentation ; 2 ) initial guess generation ; 3 ) ct image reconstruction ; and 4 ) mri image reconstruction .",
        "our experiment show that , aid by the image obtain from one image modality , even with highly under- sample data , we can better reconstruct the image of the other modality .",
        "this approach can be potentially useful for a simultaneous ct-mri system .",
        "index terms l1-norm minimization , multi-modality imaging , ct-mri system , image reconstruction .",
        "i .",
        "introduction in general , the imaging modality be classi ed into various category , such as structural imaging ( ct/mri/us ) and functional imaging ( pet/spect ) .",
        "the main advantage of multi-modality imaging be that weakness of individual modality can be offset by the strength of the others .",
        "as a primary example , positron emission tomography ( pet ) and compute tomography ( ct ) now work together in the pet-ct scanner for functional and structural study .",
        "this have become the most common tomographic examination in oncological application .",
        "pet-ct not only avoid the inaccu- racy from image registration but also save time and cost for good healthcare .",
        "another multi-modality image example be pet-mr , which have be commercially available [ 1 ] .",
        "pet-mr integrates pet and magnetic resonance imaging ( mri ) .",
        "despite high system cost , pet-mr may outperform pet-ct in term of less ionize radiation dose and good soft tissue contrast .",
        "except for pet-ct and pet-mr , there exist other possibil- ities for multi-modality scanner .",
        "ct and mri be two mostpopular modality for structural and functional imaging .",
        "ct can provide anatomical structure especially high-contrast detail , whereas mri may depict soft tissue with clarity .",
        "both ct and mri generate important functional informa- tion , aid by classic and novel contrast agent .",
        "clinically speaking , ct and mri be complementary for evaluation of calci cation relate disease , e.g.",
        ", calci ed lesion in the brain [ 2 ] , [ 3 ] .",
        "mri image show the hypo-intense lesion , which be then con rmed by ct image .",
        "ct-mri may be an ideal multi-modality combination for imaging-guided cardio- vascular intervention such as heart valve replacement where both anatomical and functional evaluation must be perform in real-time .",
        "in this paper , we investigate the feasibility of uni ed ct-mri imaging .",
        "when both mri and ct scan be obtain from an object at the same time , the resultant datasets share inherent similarity ( i.e.",
        ", the boundary of organ ) .",
        "with an mri/ct image as the priori information , we could better recover its counterpart image .",
        "in the next section , we describe our uni ed ct-mri reconstruction method .",
        "in the volume 2 , 20142169-3536 2014 ieee .",
        "translations and content mining be permit for academic research only .",
        "personal use be also permit , but republication/redistribution require ieee permission .",
        "see http : //www.ieee.org/publications_standards/publications/rights/index.html for more information.1359y .",
        "lu et al .",
        ": edge-guided dual-modality image reconstruction third section , we report our numerical simulation result .",
        "finally , we discuss relevant issue and conclude the paper in the last section .",
        "ii .",
        "method a. l 1-regularized problems in image reconstruction in contrast to the shannon-nyquist theorem , candes and donaho 's great work [ 4 ] , [ 5 ] show that the technique of compressed sensing can accurately recover the signal even if it be sample at a rather low rate .",
        "the success of com- press sensing be base on the assumption that the signal be sparse ( or can be transform to be sparse ) , and the measure matrix satis es the rip rule .",
        "by minimize the l1-norm of the signal , the solution to the signal recovery problem be almost unique .",
        "in reality , most of the signal ful ll the requirement for compressed sensing , and many application of compressed sense theory have be demonstrate [ 6 ] .",
        "the key of compressed sensing be the l1-norm minimiza- tion .",
        "l1-norm , also know as the manhattan distance , calcu- lates the sum of absolute component value of a vector x .",
        "it be a special case of the lp-norm and express as : kxkpd ( jx1jpcjx2jpc\u0001\u0001\u0001cjxnjp ) 1 pwith pd1 ( 1 ) strictly speak , the l0-norm should be use to help nd the sparse solution from an underdetermined set of equation .",
        "however , the l0-norm minimization be an np-hard problem , and generally too complex to be computationally solve [ 7 ] .",
        "fortunately , candes and donoho 's work suggest clearly that thel1-norm be a good alternative of the l0-norm .",
        "in the eld of image reconstruction , the l1-norm mini- mization be equivalent to reconstruct an image ufrom few projection ( for a ct scan ) or partial k-space data ( for an mri scan ) .",
        "a general l1-regularized image reconstruction problem be arg minuk8uk1c\u0016 2kfu\u0000fk2 2 ( 2 ) where\u0016is the relaxation parameter , fis the measure data , fis a transform from the image space to either the sinogram or k-space ; that be , the radon transform for ct imaging or the fourier transform for mri imaging , and 8is a sparsifying operator upon an image .",
        "since the gradient of the ct/mri image usually contain many zero or nearly-zero value , formula ( 2 ) can be write as arg minukruk1c\u0016 2kfu\u0000fk2 2 ( 3 ) this be an unconstraint minimization problem .",
        "the l1-regularization termkruk1and the data delitykfu\u0000fk2 2 term be alternatively and iteratively process to reach a converged result .",
        "there be many paper discuss how to solve the l1-regularized problem .",
        "in this work , we use the split-bregman technique [ 8 ] for mri reconstruction and the sart-tv algorithm for ct reconstruction respectively.the sart-tv algorithm be very popular in ct image reconstruction ; see a detailed description in [ 9 ] .",
        "the split-bregman technique be widely use in recent year , for its high ef ciency and accuracy .",
        "let dd8 ( u ) , then formula ( 3 ) can be put in the `` split bregman '' format : min u ; dkdk1c\u0016 2kfu\u0000fk2ckd\u00008 ( u ) \u0000bk2 ( 4 ) where bi a bregman parameter .",
        "with kd0 ; u0d0 ; b0d0 , eq .",
        "( 4 ) be solve iteratively as follow : while uk\u0000uk\u00001 2 2 > '' do ukc1dmin u dk\u00008 ( u ) \u0000bk 2 2c\u0016 2kfu\u0000fk2 2 dkc1dmin d d\u00008 ( ukc1 ) \u0000bk 2 2ckdk1 bkc1dbkc8 ( ukc1 ) \u0000dkc1 kdkc1 end while clearly , there be two `` sub-problems '' in the above process .",
        "however , the procedure be not as complicate as it appear .",
        "the rst sub-problem be quadratic in u , and have a closed- form solution with a rather low complexity , while the second sub-problem can be solve use the so-called shrinkage operation [ 10 ] .",
        "b. inter-modality synergy in the literature , there have be no ideal solution that trans- form an mri image to a ct image .",
        "the ct raw data be collect in the sinogram space , while the mri raw data be measure in the fourier space ( or k-space equivalently ) .",
        "from the mathematical point of view , the fourier space and the sinogram space be fundamentally link , such as by the well-known central slice theorem .",
        "however , the physic behind mri and ct be rather different .",
        "mri rely on the nuclear magnetic resonance of the hydrogen nucleus , while ct target the attenuation ability of the tissue .",
        "hence , a direct one-to-one mapping be impossible , and an indirect method must be instead use .",
        "in the following , we explain in detail how to generate edge information from an mri image and how to use it for ct reconstruction , and vice versa .",
        "the basic assumption of the propose method be that the mri and the ct image be well register .",
        "1 ) segmentation a generalized l1-norm solver for image reconstruction be rst use .",
        "the near-zero value be smoothen to keep large value in the gradient image .",
        "in most case , large value correspond to the boundary of organ , which be connect .",
        "a noisy image may have many large value in its gradient image , but they be isolate .",
        "from a highly under-sampled dataset , the boundary information ( or edge information ) may not be fully recover , thus make the l1-norm 1360 volume 2 , 2014y .",
        "lu et al .",
        ": edge-guided dual-modality image reconstruction figure 1 .",
        "top row : register ct and mri image ; bottom row : the gradient of the image in the top row .",
        "solution converge incorrectly .",
        "on the other side , if the edge information be pre-de ned , the l1-norm solver will be unlikely trap at a local minimum , yield the true solution [ 11 ] .",
        "by inspect gradient image , it be find that the edge information can be classi ed into two category : public and private edge respectively .",
        "the public edge be those which can be present in both image modality , while the private edge be those which be only present in one imaging modality .",
        "examples of public and private edge be indicate by red and green arrow respectively in figure 1 .",
        "to use the edge information , a segmentation procedure be need .",
        "the gradient be a natural segmentation method .",
        "an improved method be the canny edge detector [ 12 ] .",
        "after image segmentation , the whole image be decompose into many sub-regions , each label a unique value .",
        "2 ) local mean the mean value of each segment sub-region be calcu- lated by the end of each iteration , and be write back to the image .",
        "the local-mean penalty be an extreme case ofthel1-regularization .",
        "it enforce a reconstructed image to be strictly piecewise constant thereby the l1-norm of the gradient be zero ( more generally , piecewise polynom- inal constraint could be use too ) .",
        "the rationale behind this operation be that during the reconstruction process , low frequency component ( region with slowly change value ) be quickly recover , and the high frequency component ( noise , edge ) be gradually recover .",
        "by do so , public edge be establish in the reconstructed image , and the gradient image be much closer to the truth .",
        "the next step be to recover private edge of the image .",
        "it be achieve by solve thel1-regularization problem de ned by eq .",
        "( 3 ) , base on the previous result .",
        "iii .",
        "simulation results numerical test be perform to validate our pro- pose method .",
        "the data be originally synthesize from the ncat phantom , with some modi cation .",
        "( http : //dmip1.rad.jhmi.edu/ \u0018wsegars/phantom_intro.htm ) .",
        "in the rst experiment , we use the ct image as priori information .",
        "it be segment into 9 part , each be iden- ti ed by a unique value ; see figure 2 .",
        "the segmented image be later use by the csmri algorithm [ 8 ] to generate an initial guess .",
        "only a small area ( 10 % and 15 % respectively ) of the k-space be sample in this pilot study .",
        "even for such a simple phantom , the reconstruction be quite chal- lenging since the data be sparsely sample at random .",
        "with the local mean penalty , the initial guess converge very fast , after 3\u00184 iteration .",
        "then , the local mean penalty be turn off ( or give a small relaxation coef cient ) , and the csmri algorithm be execute with the initial guess until the stop criterion be satis ed .",
        "the result be in figure 3 .",
        "a similar process be perform in the second experiment , in which the mri image be use to guide the ct recon- struction .",
        "fifteen projection be uniformly generate over a 2\u0019range in the fan-beam geometry .",
        "for comparison , we do reconstruction use the sart-tv algorithm with/without the propose initial guess ; see figure 4 .",
        "a parameter \u0015was choose to control the strength of the tv term .",
        "the small the parameter\u0015is , the strong the tv term will be .",
        "from highly insuf cient projection data , the sart-tv algorithm without figure 2 .",
        "from leave to right be the standard ct image , standard mri image , segment ct image and segment mri image , respectively .",
        "volume 2 , 2014 1361y .",
        "lu et al .",
        ": edge-guided dual-modality image reconstruction figure 3 .",
        "reconstructed mri image in the first experiment .",
        "top row : with 15 % of the k-space data ; bottom row : with 10 % of the k-space data .",
        "left : reconstructions use the direct inverse fourier transform , set miss sample to zero in the k-space ; middle : reconstructions use csmri ; right : reconstructions use the propose method .",
        "figure 4 .",
        "reconstructed ct image in the second experiment .",
        "left : reconstruction use sart-tv with \u0015d800 ; middle : reconstruction use sart-tv with \u0015d200 ; right : reconstruction use the propose method .",
        "the initial guess produce severely blocky artifact ( \u0015d800 ) ; see the left image in figure 4 .",
        "adjusting the parameter \u0015 would result in an over-smoothed image ( \u0015d200 ) ; see the middle image in figure 4 .",
        "in contrast , a rather large \u0015 ( \u0015d2000 ) be use for the reconstruction with the initial guess since the majority have be restore from the initial guess.iv .",
        "discussions and conclusion compared to ct , mri be soft tissue sensitive and non- ionizing .",
        "however , the scanning time for mri be much long than ct because an mri scanner use rf pulse to generate mri signal , and the rf energy deposition be limit by mri physic .",
        "this compromise the dynamic mri performance .",
        "in contrast , ct be very fast .",
        "modern ct acquire thousand 1362 volume 2 , 2014y .",
        "lu et al .",
        ": edge-guided dual-modality image reconstruction projection per second , and advance ct reconstruction algorithms allow an image to be reconstruct from an incom- plete dataset [ 9 ] .",
        "when mri be integrate with ct , we hope that the strength of ct and mri can be seamlessly inte- grate .",
        "in this study , we have present a methodology for ct-mri imaging .",
        "using an image from one image modality as priori information , we can estimate an image of the other modality subject to the local mean penalty .",
        "in brief , the miss information in one imaging modality can be effectively compensate for by the priori image from the other image modality , thus relax the requirement of individual modality-based measurement signi cantly for a give image quality .",
        "this direction be promise for radiation dose reduction and high-speed mri in particular .",
        "while we have only investigate the image reconstruction for a ct-mri combination , a more ambitious goal be towards omni-tomography [ 13 ] , which be a grand fusion of ct , mri , pet , spect , us , optical imaging and more .",
        "each individ- ual imaging modality be only one component of the entire system .",
        "in a uni ed framework , data be collect simultane- ously , share by all the involved modality , generate more synergistic information on functional , structural , cellular and molecular characteristic of a biological system .",
        "how to build close connection between the image obtain from differ- ent modality and how to fully utilize all prior information will be an interesting topic for our future research ."
    ],
    "processed_text": "special section emerging computed tomography technologies received october 27 2014 accept november 3 2014 date publication november 20 2014 date current version november 26 2014 digital object identifier 101 109/access20142371994 edgeguided dualmodality image reconstruction yang lu1 jun zhao2 ge wang3 fellow ieee 1molecular imaging business unit shanghai united imaging healthcare company ltd shanghai 201815 china 2school biomedical engineering shanghai jiao tong university shanghai 200240 china 3biomedical imaging center department biomedical engineering rensselaer polytechnic institute troy ny 12180 usa corresponding author j zhao junzhao @ sjtueducn work support part national institutes health grant u01eb017140 part national basic research program 973 program china grant 2010cb834302 part national institutes health/national institute biomedical imaging bioengineering grant r01eb016977 part national natural science foundation china grant 81371634 part scienti c innovation act science technology commission shanghai municipality grant 13511504200 part biomedical engineering cross fund shanghai jiao tong university shanghai china grant yg2013ms30 abstract utilize synergy compute tomography ct magnetic resonance imaging mri data set object time edgeguided dualmodality image reconstruction approach propose key establish knowledgebased connection two data set tight fusion different image modality scheme consist four interrelated element 1 segmentation 2 initial guess generation 3 ct image reconstruction 4 mri image reconstruction experiment show aid image obtain one image modality even highly sample data better reconstruct image modality approach potentially useful simultaneous ctmri system index terms l1norm minimization multimodality imaging ctmri system image reconstruction introduction general imaging modality classi ed various category structural imaging ct/mri/us functional imaging pet/spect main advantage multimodality imaging weakness individual modality offset strength others primary example positron emission tomography pet compute tomography ct work together petct scanner functional structural study become common tomographic examination oncological application petct avoid inaccu racy image registration also save time cost good healthcare another multimodality image example petmr commercially available 1 petmr integrates pet magnetic resonance imaging mri despite high system cost petmr may outperform petct term less ionize radiation dose good soft tissue contrast except petct petmr exist possibil ities multimodality scanner ct mri two mostpopular modality structural functional imaging ct provide anatomical structure especially highcontrast detail whereas mri may depict soft tissue clarity ct mri generate important functional informa tion aid classic novel contrast agent clinically speaking ct mri complementary evaluation calci cation relate disease eg calci ed lesion brain 2 3 mri image show hypointense lesion con rmed ct image ctmri may ideal multimodality combination imagingguided cardio vascular intervention heart valve replacement anatomical functional evaluation must perform realtime paper investigate feasibility uni ed ctmri imaging mri ct scan obtain object time resultant datasets share inherent similarity ie boundary organ mri/ct image priori information could better recover counterpart image next section describe uni ed ctmri reconstruction method volume 2 201421693536 2014 ieee translations content mining permit academic research personal use also permit republication/redistribution require ieee permission see http //wwwieeeorg/publications_standards/publications/rights/indexhtml information1359y lu et al edgeguided dualmodality image reconstruction third section report numerical simulation result finally discuss relevant issue conclude paper last section ii method l 1regularized problems image reconstruction contrast shannonnyquist theorem candes donaho 's great work 4 5 show technique compressed sensing accurately recover signal even sample rather low rate success com press sensing base assumption signal sparse transform sparse measure matrix satis es rip rule minimize l1norm signal solution signal recovery problem almost unique reality signal ful requirement compressed sensing many application compressed sense theory demonstrate 6 key compressed sensing l1norm minimiza tion l1norm also know manhattan distance calcu lates sum absolute component value vector x special case lpnorm express kxkpd jx1jpcjx2jpc\u0001\u0001\u0001cjxnjp 1 pwith pd1 1 strictly speak l0norm use help nd sparse solution underdetermined set equation however l0norm minimization nphard problem generally complex computationally solve 7 fortunately candes donoho 's work suggest clearly thel1norm good alternative l0norm eld image reconstruction l1norm mini mization equivalent reconstruct image ufrom projection ct scan partial kspace data mri scan general l1regularized image reconstruction problem arg minuk8uk1c\u0016 2kfu\u0000fk2 2 2 where\u0016is relaxation parameter fis measure data fis transform image space either sinogram kspace radon transform ct imaging fourier transform mri imaging 8is sparsifying operator upon image since gradient ct/mri image usually contain many zero nearlyzero value formula 2 write arg minukruk1c\u0016 2kfu\u0000fk2 2 3 unconstraint minimization problem l1regularization termkruk1and data delitykfu\u0000fk2 2 term alternatively iteratively process reach converged result many paper discuss solve l1regularized problem work use splitbregman technique 8 mri reconstruction sarttv algorithm ct reconstruction respectivelythe sarttv algorithm popular ct image reconstruction see detailed description 9 splitbregman technique widely use recent year high ef ciency accuracy let dd8 u formula 3 put split bregman format min u dkdk1c\u0016 2kfu\u0000fk2ckd\u00008 u \u0000bk2 4 bi bregman parameter kd0 u0d0 b0d0 eq 4 solve iteratively follow uk\u0000uk\u00001 2 2 > ukc1dmin u dk\u00008 u \u0000bk 2 2c\u0016 2kfu\u0000fk2 2 dkc1dmin d\u00008 ukc1 \u0000bk 2 2ckdk1 bkc1dbkc8 ukc1 \u0000dkc1 kdkc1 end clearly two subproblems process however procedure complicate appear rst subproblem quadratic u closed form solution rather low complexity second subproblem solve use socalled shrinkage operation 10 b intermodality synergy literature ideal solution trans form mri image ct image ct raw data collect sinogram space mri raw data measure fourier space kspace equivalently mathematical point view fourier space sinogram space fundamentally link wellknown central slice theorem however physic behind mri ct rather different mri rely nuclear magnetic resonance hydrogen nucleus ct target attenuation ability tissue hence direct onetoone mapping impossible indirect method must instead use following explain detail generate edge information mri image use ct reconstruction vice versa basic assumption propose method mri ct image well register 1 segmentation generalized l1norm solver image reconstruction rst use nearzero value smoothen keep large value gradient image case large value correspond boundary organ connect noisy image may many large value gradient image isolate highly undersampled dataset boundary information edge information may fully recover thus make l1norm 1360 volume 2 2014y lu et al edgeguided dualmodality image reconstruction figure 1 top row register ct mri image bottom row gradient image top row solution converge incorrectly side edge information prede ned l1norm solver unlikely trap local minimum yield true solution 11 inspect gradient image find edge information classi ed two category public private edge respectively public edge present image modality private edge present one imaging modality examples public private edge indicate red green arrow respectively figure 1 use edge information segmentation procedure need gradient natural segmentation method improved method canny edge detector 12 image segmentation whole image decompose many subregions label unique value 2 local mean mean value segment subregion calcu lated end iteration write back image localmean penalty extreme case ofthel1regularization enforce reconstructed image strictly piecewise constant thereby l1norm gradient zero generally piecewise polynom inal constraint could use rationale behind operation reconstruction process low frequency component region slowly change value quickly recover high frequency component noise edge gradually recover public edge establish reconstructed image gradient image much closer truth next step recover private edge image achieve solve thel1regularization problem de ned eq 3 base previous result iii simulation results numerical test perform validate pro pose method data originally synthesize ncat phantom modi cation http //dmip1radjhmiedu/ \u0018wsegars/phantom_introhtm rst experiment use ct image priori information segment 9 part iden ti ed unique value see figure 2 segmented image later use csmri algorithm 8 generate initial guess small area 10 15 respectively kspace sample pilot study even simple phantom reconstruction quite chal lenging since data sparsely sample random local mean penalty initial guess converge fast 3\u00184 iteration local mean penalty turn give small relaxation coef cient csmri algorithm execute initial guess stop criterion satis ed result figure 3 similar process perform second experiment mri image use guide ct recon struction fifteen projection uniformly generate 2\u0019range fanbeam geometry comparison reconstruction use sarttv algorithm with/without propose initial guess see figure 4 parameter \u0015was choose control strength tv term small parameter\u0015is strong tv term highly insuf cient projection data sarttv algorithm without figure 2 leave right standard ct image standard mri image segment ct image segment mri image respectively volume 2 2014 1361y lu et al edgeguided dualmodality image reconstruction figure 3 reconstructed mri image first experiment top row 15 kspace data bottom row 10 kspace data left reconstructions use direct inverse fourier transform set miss sample zero kspace middle reconstructions use csmri right reconstructions use propose method figure 4 reconstructed ct image second experiment left reconstruction use sarttv \u0015d800 middle reconstruction use sarttv \u0015d200 right reconstruction use propose method initial guess produce severely blocky artifact \u0015d800 see left image figure 4 adjusting parameter \u0015 would result oversmoothed image \u0015d200 see middle image figure 4 contrast rather large \u0015 \u0015d2000 use reconstruction initial guess since majority restore initial guessiv discussions conclusion compared ct mri soft tissue sensitive non ionizing however scanning time mri much long ct mri scanner use rf pulse generate mri signal rf energy deposition limit mri physic compromise dynamic mri performance contrast ct fast modern ct acquire thousand 1362 volume 2 2014y lu et al edgeguided dualmodality image reconstruction projection per second advance ct reconstruction algorithms allow image reconstruct incom plete dataset 9 mri integrate ct hope strength ct mri seamlessly inte grate study present methodology ctmri imaging using image one image modality priori information estimate image modality subject local mean penalty brief miss information one imaging modality effectively compensate priori image image modality thus relax requirement individual modalitybased measurement signi cantly give image quality direction promise radiation dose reduction highspeed mri particular investigate image reconstruction ctmri combination ambitious goal towards omnitomography 13 grand fusion ct mri pet spect us optical imaging individ ual imaging modality one component entire system uni ed framework data collect simultane ously share involved modality generate synergistic information functional structural cellular molecular characteristic biological system build close connection image obtain differ ent modality fully utilize prior information interesting topic future research",
    "bag_of_words": {
        "special": 2,
        "section": 4,
        "emerging": 1,
        "computed": 1,
        "tomography": 4,
        "technologies": 1,
        "received": 1,
        "october": 1,
        "accept": 1,
        "november": 3,
        "date": 2,
        "publication": 1,
        "current": 1,
        "version": 1,
        "digital": 1,
        "object": 3,
        "identifier": 1,
        "109/access20142371994": 1,
        "edgeguided": 6,
        "dualmodality": 6,
        "image": 67,
        "reconstruction": 27,
        "yang": 1,
        "lu1": 1,
        "jun": 1,
        "zhao2": 1,
        "ge": 1,
        "wang3": 1,
        "fellow": 1,
        "ieee": 3,
        "1molecular": 1,
        "imaging": 20,
        "business": 1,
        "unit": 1,
        "shanghai": 7,
        "united": 1,
        "healthcare": 2,
        "company": 1,
        "ltd": 1,
        "china": 5,
        "2school": 1,
        "biomedical": 4,
        "engineering": 3,
        "jiao": 2,
        "tong": 2,
        "university": 2,
        "3biomedical": 1,
        "center": 1,
        "department": 1,
        "rensselaer": 1,
        "polytechnic": 1,
        "institute": 2,
        "troy": 1,
        "ny": 1,
        "usa": 1,
        "corresponding": 1,
        "author": 1,
        "zhao": 1,
        "junzhao": 1,
        "sjtueducn": 1,
        "work": 5,
        "support": 1,
        "part": 7,
        "national": 4,
        "institutes": 2,
        "health": 1,
        "grant": 6,
        "u01eb017140": 1,
        "basic": 2,
        "research": 3,
        "program": 2,
        "2010cb834302": 1,
        "health/national": 1,
        "bioengineering": 1,
        "r01eb016977": 1,
        "natural": 2,
        "science": 2,
        "foundation": 1,
        "scienti": 1,
        "innovation": 1,
        "act": 1,
        "technology": 1,
        "commission": 1,
        "municipality": 1,
        "cross": 1,
        "fund": 1,
        "yg2013ms30": 1,
        "abstract": 1,
        "utilize": 2,
        "synergy": 2,
        "compute": 2,
        "ct": 33,
        "magnetic": 3,
        "resonance": 3,
        "mri": 33,
        "data": 14,
        "set": 4,
        "time": 4,
        "approach": 2,
        "propose": 5,
        "key": 2,
        "establish": 2,
        "knowledgebased": 1,
        "connection": 2,
        "two": 4,
        "tight": 1,
        "fusion": 2,
        "different": 2,
        "modality": 15,
        "scheme": 1,
        "consist": 1,
        "four": 1,
        "interrelated": 1,
        "element": 1,
        "segmentation": 5,
        "initial": 8,
        "guess": 7,
        "generation": 1,
        "experiment": 5,
        "show": 3,
        "aid": 2,
        "obtain": 3,
        "one": 5,
        "even": 3,
        "highly": 3,
        "sample": 5,
        "better": 2,
        "reconstruct": 3,
        "potentially": 1,
        "useful": 1,
        "simultaneous": 1,
        "ctmri": 7,
        "system": 5,
        "index": 1,
        "terms": 1,
        "l1norm": 9,
        "minimization": 3,
        "multimodality": 5,
        "introduction": 1,
        "general": 2,
        "classi": 2,
        "ed": 8,
        "various": 1,
        "category": 2,
        "structural": 4,
        "ct/mri/us": 1,
        "functional": 6,
        "pet/spect": 1,
        "main": 1,
        "advantage": 1,
        "weakness": 1,
        "individual": 2,
        "offset": 1,
        "strength": 3,
        "others": 1,
        "primary": 1,
        "example": 2,
        "positron": 1,
        "emission": 1,
        "pet": 3,
        "together": 1,
        "petct": 4,
        "scanner": 3,
        "study": 3,
        "become": 1,
        "common": 1,
        "tomographic": 1,
        "examination": 1,
        "oncological": 1,
        "application": 2,
        "avoid": 1,
        "inaccu": 1,
        "racy": 1,
        "registration": 1,
        "also": 3,
        "save": 1,
        "cost": 2,
        "good": 3,
        "another": 1,
        "petmr": 4,
        "commercially": 1,
        "available": 1,
        "integrates": 1,
        "despite": 1,
        "high": 3,
        "may": 5,
        "outperform": 1,
        "term": 4,
        "less": 1,
        "ionize": 1,
        "radiation": 2,
        "dose": 2,
        "soft": 3,
        "tissue": 4,
        "contrast": 5,
        "except": 1,
        "exist": 1,
        "possibil": 1,
        "ities": 1,
        "mostpopular": 1,
        "provide": 1,
        "anatomical": 2,
        "structure": 1,
        "especially": 1,
        "highcontrast": 1,
        "detail": 2,
        "whereas": 1,
        "depict": 1,
        "clarity": 1,
        "generate": 6,
        "important": 1,
        "informa": 1,
        "tion": 2,
        "classic": 1,
        "novel": 1,
        "agent": 1,
        "clinically": 1,
        "speaking": 1,
        "complementary": 1,
        "evaluation": 2,
        "calci": 2,
        "cation": 2,
        "relate": 1,
        "disease": 1,
        "eg": 1,
        "lesion": 2,
        "brain": 1,
        "hypointense": 1,
        "con": 1,
        "rmed": 1,
        "ideal": 2,
        "combination": 2,
        "imagingguided": 1,
        "cardio": 1,
        "vascular": 1,
        "intervention": 1,
        "heart": 1,
        "valve": 1,
        "replacement": 1,
        "must": 2,
        "perform": 3,
        "realtime": 1,
        "paper": 3,
        "investigate": 2,
        "feasibility": 1,
        "uni": 3,
        "scan": 3,
        "resultant": 1,
        "datasets": 1,
        "share": 2,
        "inherent": 1,
        "similarity": 1,
        "ie": 1,
        "boundary": 3,
        "organ": 2,
        "mri/ct": 1,
        "priori": 4,
        "information": 12,
        "could": 2,
        "recover": 6,
        "counterpart": 1,
        "next": 2,
        "describe": 1,
        "method": 9,
        "volume": 4,
        "translations": 1,
        "content": 1,
        "mining": 1,
        "permit": 2,
        "academic": 1,
        "personal": 1,
        "use": 22,
        "republication/redistribution": 1,
        "require": 1,
        "permission": 1,
        "see": 6,
        "http": 2,
        "//wwwieeeorg/publications_standards/publications/rights/indexhtml": 1,
        "information1359y": 1,
        "lu": 4,
        "et": 4,
        "al": 4,
        "third": 1,
        "report": 1,
        "numerical": 2,
        "simulation": 2,
        "result": 5,
        "finally": 1,
        "discuss": 2,
        "relevant": 1,
        "issue": 1,
        "conclude": 1,
        "last": 1,
        "ii": 1,
        "1regularized": 1,
        "problems": 1,
        "shannonnyquist": 1,
        "theorem": 2,
        "candes": 2,
        "donaho": 1,
        "great": 1,
        "technique": 3,
        "compressed": 4,
        "sensing": 4,
        "accurately": 1,
        "signal": 6,
        "rather": 4,
        "low": 3,
        "rate": 1,
        "success": 1,
        "com": 1,
        "press": 1,
        "base": 2,
        "assumption": 2,
        "sparse": 3,
        "transform": 5,
        "measure": 3,
        "matrix": 1,
        "satis": 2,
        "es": 1,
        "rip": 1,
        "rule": 1,
        "minimize": 1,
        "solution": 6,
        "recovery": 1,
        "problem": 6,
        "almost": 1,
        "unique": 3,
        "reality": 1,
        "ful": 1,
        "requirement": 2,
        "many": 5,
        "sense": 1,
        "theory": 1,
        "demonstrate": 1,
        "minimiza": 1,
        "know": 1,
        "manhattan": 1,
        "distance": 1,
        "calcu": 2,
        "lates": 1,
        "sum": 1,
        "absolute": 1,
        "component": 4,
        "value": 10,
        "vector": 1,
        "case": 3,
        "lpnorm": 1,
        "express": 1,
        "kxkpd": 1,
        "jx1jpcjx2jpc\u0001\u0001\u0001cjxnjp": 1,
        "pwith": 1,
        "pd1": 1,
        "strictly": 2,
        "speak": 1,
        "l0norm": 3,
        "help": 1,
        "nd": 1,
        "underdetermined": 1,
        "equation": 1,
        "however": 4,
        "nphard": 1,
        "generally": 2,
        "complex": 1,
        "computationally": 1,
        "solve": 5,
        "fortunately": 1,
        "donoho": 1,
        "suggest": 1,
        "clearly": 2,
        "thel1norm": 1,
        "alternative": 1,
        "eld": 1,
        "mini": 1,
        "mization": 1,
        "equivalent": 1,
        "ufrom": 1,
        "projection": 4,
        "partial": 1,
        "kspace": 7,
        "l1regularized": 2,
        "arg": 2,
        "minuk8uk1c\u0016": 1,
        "2kfu\u0000fk2": 3,
        "where\u0016is": 1,
        "relaxation": 2,
        "parameter": 4,
        "fis": 2,
        "space": 5,
        "either": 1,
        "sinogram": 3,
        "radon": 1,
        "fourier": 4,
        "8is": 1,
        "sparsifying": 1,
        "operator": 1,
        "upon": 1,
        "since": 3,
        "gradient": 8,
        "ct/mri": 1,
        "usually": 1,
        "contain": 1,
        "zero": 3,
        "nearlyzero": 1,
        "formula": 2,
        "write": 2,
        "minukruk1c\u0016": 1,
        "unconstraint": 1,
        "l1regularization": 1,
        "termkruk1and": 1,
        "delitykfu\u0000fk2": 1,
        "alternatively": 1,
        "iteratively": 2,
        "process": 4,
        "reach": 1,
        "converged": 1,
        "splitbregman": 2,
        "sarttv": 6,
        "algorithm": 6,
        "respectivelythe": 1,
        "popular": 1,
        "detailed": 1,
        "description": 1,
        "widely": 1,
        "recent": 1,
        "year": 1,
        "ef": 1,
        "ciency": 1,
        "accuracy": 1,
        "let": 1,
        "dd8": 1,
        "put": 1,
        "split": 1,
        "bregman": 2,
        "format": 1,
        "min": 1,
        "dkdk1c\u0016": 1,
        "2kfu\u0000fk2ckd\u00008": 1,
        "\u0000bk2": 1,
        "bi": 1,
        "kd0": 1,
        "u0d0": 1,
        "b0d0": 1,
        "eq": 2,
        "follow": 1,
        "uk\u0000uk\u00001": 1,
        "ukc1dmin": 1,
        "dk\u00008": 1,
        "\u0000bk": 2,
        "2c\u0016": 1,
        "dkc1dmin": 1,
        "d\u00008": 1,
        "ukc1": 2,
        "2ckdk1": 1,
        "bkc1dbkc8": 1,
        "\u0000dkc1": 1,
        "kdkc1": 1,
        "end": 2,
        "subproblems": 1,
        "procedure": 2,
        "complicate": 1,
        "appear": 1,
        "rst": 3,
        "subproblem": 2,
        "quadratic": 1,
        "closed": 1,
        "form": 2,
        "complexity": 1,
        "second": 4,
        "socalled": 1,
        "shrinkage": 1,
        "operation": 2,
        "intermodality": 1,
        "literature": 1,
        "trans": 1,
        "raw": 2,
        "collect": 2,
        "equivalently": 1,
        "mathematical": 1,
        "point": 1,
        "view": 1,
        "fundamentally": 1,
        "link": 1,
        "wellknown": 1,
        "central": 1,
        "slice": 1,
        "physic": 2,
        "behind": 2,
        "rely": 1,
        "nuclear": 1,
        "hydrogen": 1,
        "nucleus": 1,
        "target": 1,
        "attenuation": 1,
        "ability": 1,
        "hence": 1,
        "direct": 2,
        "onetoone": 1,
        "mapping": 1,
        "impossible": 1,
        "indirect": 1,
        "instead": 1,
        "following": 1,
        "explain": 1,
        "edge": 13,
        "vice": 1,
        "versa": 1,
        "well": 1,
        "register": 2,
        "generalized": 1,
        "solver": 2,
        "nearzero": 1,
        "smoothen": 1,
        "keep": 1,
        "large": 4,
        "correspond": 1,
        "connect": 1,
        "noisy": 1,
        "isolate": 1,
        "undersampled": 1,
        "dataset": 2,
        "fully": 2,
        "thus": 2,
        "make": 1,
        "2014y": 2,
        "figure": 10,
        "top": 3,
        "row": 5,
        "bottom": 2,
        "converge": 2,
        "incorrectly": 1,
        "side": 1,
        "prede": 1,
        "ned": 2,
        "unlikely": 1,
        "trap": 1,
        "local": 5,
        "minimum": 1,
        "yield": 1,
        "true": 1,
        "inspect": 1,
        "find": 1,
        "public": 4,
        "private": 4,
        "respectively": 4,
        "present": 3,
        "examples": 1,
        "indicate": 1,
        "red": 1,
        "green": 1,
        "arrow": 1,
        "need": 1,
        "improved": 1,
        "canny": 1,
        "detector": 1,
        "whole": 1,
        "decompose": 1,
        "subregions": 1,
        "label": 1,
        "mean": 5,
        "segment": 4,
        "subregion": 1,
        "lated": 1,
        "iteration": 2,
        "back": 1,
        "localmean": 1,
        "penalty": 4,
        "extreme": 1,
        "ofthel1regularization": 1,
        "enforce": 1,
        "reconstructed": 4,
        "piecewise": 2,
        "constant": 1,
        "thereby": 1,
        "polynom": 1,
        "inal": 1,
        "constraint": 1,
        "rationale": 1,
        "frequency": 2,
        "region": 1,
        "slowly": 1,
        "change": 1,
        "quickly": 1,
        "noise": 1,
        "gradually": 1,
        "much": 2,
        "closer": 1,
        "truth": 1,
        "step": 1,
        "achieve": 1,
        "thel1regularization": 1,
        "de": 1,
        "previous": 1,
        "iii": 1,
        "results": 1,
        "test": 1,
        "validate": 1,
        "pro": 1,
        "pose": 1,
        "originally": 1,
        "synthesize": 1,
        "ncat": 1,
        "phantom": 2,
        "modi": 1,
        "//dmip1radjhmiedu/": 1,
        "\u0018wsegars/phantom_introhtm": 1,
        "iden": 1,
        "ti": 1,
        "segmented": 1,
        "later": 1,
        "csmri": 3,
        "small": 3,
        "area": 1,
        "pilot": 1,
        "simple": 1,
        "quite": 1,
        "chal": 1,
        "lenging": 1,
        "sparsely": 1,
        "random": 1,
        "fast": 2,
        "3\u00184": 1,
        "turn": 1,
        "give": 2,
        "coef": 1,
        "cient": 2,
        "execute": 1,
        "stop": 1,
        "criterion": 1,
        "similar": 1,
        "guide": 1,
        "recon": 1,
        "struction": 1,
        "fifteen": 1,
        "uniformly": 1,
        "2\u0019range": 1,
        "fanbeam": 1,
        "geometry": 1,
        "comparison": 1,
        "with/without": 1,
        "\u0015was": 1,
        "choose": 1,
        "control": 1,
        "tv": 2,
        "parameter\u0015is": 1,
        "strong": 1,
        "insuf": 1,
        "without": 1,
        "leave": 1,
        "right": 3,
        "standard": 2,
        "1361y": 1,
        "first": 1,
        "left": 3,
        "reconstructions": 3,
        "inverse": 1,
        "miss": 2,
        "middle": 3,
        "\u0015d800": 2,
        "\u0015d200": 2,
        "produce": 1,
        "severely": 1,
        "blocky": 1,
        "artifact": 1,
        "adjusting": 1,
        "would": 1,
        "oversmoothed": 1,
        "\u0015d2000": 1,
        "majority": 1,
        "restore": 1,
        "guessiv": 1,
        "discussions": 1,
        "conclusion": 1,
        "compared": 1,
        "sensitive": 1,
        "non": 1,
        "ionizing": 1,
        "scanning": 1,
        "long": 1,
        "rf": 2,
        "pulse": 1,
        "energy": 1,
        "deposition": 1,
        "limit": 1,
        "compromise": 1,
        "dynamic": 1,
        "performance": 1,
        "modern": 1,
        "acquire": 1,
        "thousand": 1,
        "per": 1,
        "advance": 1,
        "algorithms": 1,
        "allow": 1,
        "incom": 1,
        "plete": 1,
        "integrate": 1,
        "hope": 1,
        "seamlessly": 1,
        "inte": 1,
        "grate": 1,
        "methodology": 1,
        "using": 1,
        "estimate": 1,
        "subject": 1,
        "brief": 1,
        "effectively": 1,
        "compensate": 1,
        "relax": 1,
        "modalitybased": 1,
        "measurement": 1,
        "signi": 1,
        "cantly": 1,
        "quality": 1,
        "direction": 1,
        "promise": 1,
        "reduction": 1,
        "highspeed": 1,
        "particular": 1,
        "ambitious": 1,
        "goal": 1,
        "towards": 1,
        "omnitomography": 1,
        "grand": 1,
        "spect": 1,
        "us": 1,
        "optical": 1,
        "individ": 1,
        "ual": 1,
        "entire": 1,
        "framework": 1,
        "simultane": 1,
        "ously": 1,
        "involved": 1,
        "synergistic": 1,
        "cellular": 1,
        "molecular": 1,
        "characteristic": 1,
        "biological": 1,
        "build": 1,
        "close": 1,
        "differ": 1,
        "ent": 1,
        "prior": 1,
        "interesting": 1,
        "topic": 1,
        "future": 1
    },
    "objective": [
        "abstract to utilize the synergy between compute tomography ( ct ) and magnetic resonance imaging ( mri ) data set from an object at the same time , an edge-guided dual-modality image reconstruction approach be propose .",
        "the basic assumption of the propose method be that the mri and the ct image be well register .",
        "left : reconstructions use the direct inverse fourier transform , set miss sample to zero in the k-space ; middle : reconstructions use csmri ; right : reconstructions use the propose method .",
        "left : reconstruction use sart-tv with \u0015d800 ; middle : reconstruction use sart-tv with \u0015d200 ; right : reconstruction use the propose method .",
        "in this study , we have present a methodology for ct-mri imaging ."
    ],
    "references": [
        "",
        "REFERENCES [1] M. S. Judenhofer et al. , ``Simultaneous PET-MRI: A new approach for functional and morphological imaging,'' Nature Med. , vol. 14, no. 4, pp. 459\u0015465, 2008. [2] B. Thomas et al. , ``Clinical applications of susceptibility weighted MR imaging of the brain\u0016A pictorial review,'' Neuroradiology , vol. 50, no. 2, pp. 105\u0015116, 2008. [3] J.-Q. Zhu, N.-X. Hao, W.-Q. Bao, and X.-R. Wu, ``Multiple calci\u001ced primary central nervous system lymphoma with immunode\u001cciency in a child,'' World J. Pediatrics , vol. 7, no. 3, pp. 277\u0015279, 2011. [4] D. L. Donoho, ``Compressed sensing,'' IEEE Trans. Inf. Theory , vol. 52, no. 4, pp. 1289\u00151306, Apr. 2006. [5] E. J. Candes, J. Romberg, and T. Tao, ``Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency informa- tion,'' IEEE Trans. Inf. Theory , vol. 52, no. 2, pp. 489\u0015509, Feb. 2006. [6] Y. C. Eldar and G. Kutyniok, Compressed Sensing: Theory and Applica- tions. Cambridge, U.K.: Cambridge Univ. Press, 2012. [7] B. K. Natarajan, ``Sparse approximate solutions to linear systems,'' SIAM J. Comput. , vol. 24, no. 2, pp. 227\u0015234, 1995. [8] T. Goldstein and S. Osher, ``The split Bregman method for `1-regularized problems,'' SIAM J. Imag. Sci. , vol. 2, no. 2, pp. 323\u0015343, 2009. [9] H. Yu and G. Wang, ``Compressed sensing based interior tomography,'' Phys. Med. Biol. , vol. 54, no. 9, p. 2791, 2009. [10] W. Yin, S. Osher, D. Goldfarb, and J. Darbon, ``Bregman iterative algorithms for `1-minimization with applications to compressed sensing,'' SIAM J. Imag. Sci. , vol. 1, no. 1, pp. 143\u0015168, 2008. [11] W. Guo and W. Yin, ``Edge guided reconstruction for compressive imaging,'' SIAM J. Imag. Sci. , vol. 5, no. 3, pp. 809\u0015834, Jul. 2012. [12] J. Canny, ``A computational approach to edge detection,'' IEEE Trans. Pattern Anal. Mach. Intell. , vol. PAMI-8, no. 6, pp. 679\u0015698, Nov. 1986. [13] G. Wang et al. , ``Towards omni-tomography\u0016Grand fusion of multiple modalities for simultaneous interior tomography,'' PLoS ONE , vol. 7, no. 6, p. e39700, 2012. YANG LU received the Ph.D. degree from the Department of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China, in 2012. He is currently a Senior Algorithm Engineer with the Molecular Imaging Business Unit, Shanghai United Imaging Healthcare Com- pany, Ltd., Shanghai. His research interests include computed tomography and positron emission tomography. JUN ZHAO received the Ph.D. degree from the Department of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China, in 2006, where he is currently a Professor with the School of Biomedical Engineering. He has authored over 100 journal articles and conference papers. He is also an Associate Editor of Computer Meth- ods in Biomechanics and Biomedical Engineering: Imaging & Visualization , and an Editor of the International Journal of Biomedical Imaging . His research interests include biomedical imaging and image processing. GE WANG (F'03) received the Ph.D. degree in electrical and computer engineering. He is currently a Clark & Crossan Endowed Chair Professor and the Director of Biomedical Imag- ing Center/Cluster with the Rensselaer Polytechnic Institute, Troy, NY, USA. His expertise includes X-ray computed tomography (CT) and opti- cal molecular tomography. He wrote the pio- neering papers on the \u001crst spiral cone-beam CT algorithm (1991 and 1993) that enables spiral/helical cone-beam CT imaging, which is constantly used in almost all hospitals worldwide. There are over 70 million CT scans yearly in the U.S. alone, with a majority in the spiral cone-beam/multislice mode. He and his collaborators also wrote the \u001crst paper on bio- luminescence tomography, creating a new area of optical molecular tomography. His group published the \u001crst papers on interior tomography and omnitomography for grand fusion of all relevant tomographic modal- ities (all-in-one) to acquire different datasets simultaneously (all-at-once) and capture multiphysics interactions (all-of-couplings) with simultaneous CT-MRI and simultaneous CT-SPECT as special examples. His results were featured in Nature ,Science , and the Proceedings of the National Academy of Sciences , and recognized with various academic awards. He has authored over 375 journal papers, in addition to numerous conference articles, pre- sentations, and patents. His group has been in close collaboration with multiple world-class groups, and continuously funded by federal agents (25MasPI=ContactPI=Multi\u0000PI;28M as Co-PI/Co-I/Mentor). He is the lead Guest Editor of four IEEE T RANSACTIONS ON MEDICAL IMAGING Special Issues on X-ray CT, molecular imaging, compressive sensing, and spectral CT, respectively, the founding Editor-in-Chief of the International Journal of Biomedical Imaging , and an Associate Editor of the IEEE TRANSAC- TIONS ON MEDICAL IMAGING andMedical Physics Journal . He is a fellow of the International Society for Optics and Photonics, the Optical Society of America, the American Institute for Medical and Biological Engineering, and the American Association of Physicists in Medicine. VOLUME 2, 2014 1363"
    ]
}{
    "name": "Fast and Robust Symmetric Image Registration Based on Distances Combining Intensity and Spatial Information",
    "paragraphs": [
        "3584 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 fast and robust symmetric image registration based on distances combining intensity and spatial information johan öfverstedt , joakim lindblad , member , ieee , and nataša sladoje , member , ieee abstract — intensity-based image registration approach rely on similarity measure to guide the search for geometriccorrespondences with the high afﬁnity between image .",
        "theproperties of the used measure be vital for the robustness and accuracy of the registration .",
        "in this paper , a symmetric , intensity interpolation-free , afﬁne registration framework basedon a combination of intensity and spatial information be proposed.the excellent performance of the framework be demonstrate on acombination of synthetic test , recover know transformationsin the presence of noise , and real application in biomedicaland medical image registration , for both 2d and 3d images.the method exhibit great robustness and high accuracythan similarity measure in common use , when insert intoa standard gradient-based registration framework available aspart of the open source insight segmentation and registrationtoolkit .",
        "the method be also empirically show to have a lowcomputational cost , make it practical for real application .",
        "thesource code be available .",
        "index terms — image registration , set distance , gradient meth- od , optimization , cost function , iterative algorithm , fuzzy set , magnetic resonance imaging , transmission electron microscopy .",
        "i. i ntroduction image registration [ 1 ] – [ 4 ] be the process of establish correspondence between image and a reference space , such that the content of the image have a high degree of afﬁnity in the reference space .",
        "an example of such corre- spondence be a mapping of an image ( often refer to as ﬂoating image ) of a brain to a reference space of another image ( often refer to as reference image ) of a brain where their important structure be well co-localized .",
        "there be two main category of approach for image registration : feature-based manuscript receive august 1 , 2018 ; revise january 22 , 2019 ; accept february 11 , 2019 .",
        "date of publicatio n february 18 , 2019 ; date of current version june 4 , 2019 .",
        "this work be support in part by vinnov a through medtech4health under g rant 2016-02329 and grant 2017-02447 , in part by the swedish research council under grant 2015-05878 and grant 2017-04385 , and in part by the ministry of education , science , and technical development of the republic of se rbia under grant on174008 and grant iii44006 .",
        "the associate editor coordinate the review of this manuscript andapproving it for publication be dr. christophoros nikou .",
        "( corresponding author : johan öfverstedt . )",
        "j. öfverstedt be with the centre for image analysis , department of infor- mation technology , uppsala university , 751 05 uppsala , sweden ( e-mail : johan.ofverstedt @ it.uu.se ) .",
        "j. lindblad and n. sladoje be with the centre for image analysis , department of information technology , uppsala university , 751 05 uppsala , sweden , and also with the mathematical institute , serbian academy ofsciences and arts , 11001 belgrade , serbi a ( e-mail : joakim.lindblad @ it.uu.se ; natasa.sladoje @ it.uu.se ) .",
        "digital object identiﬁer 10.1109/tip.2019.2899947methods extract a set of feature point between which a corre- spondence be find , whereas intensity-based method use the voxel-values directly , and evaluate candidate mapping base on a similarity measure ( afﬁnity ) .",
        "there be also two main category of transformation model : linear ( which include , as special case , rigid , similarity , and afﬁne transformation ) , and non-linear ( deformable ) .",
        "the combination of differentiable transformation model and differentiable similarity measure enable the use of gradient-based local optimization method .",
        "medical and biomedical image r egistration , [ 4 ] – [ 6 ] , be an important branch of general image registration and a lot of effort have be invest over the last decade to reﬁne the tool and technique [ 2 ] .",
        "although a majority of therecent research have be devote to non-linear registration technique , the most prevalent registration method use in the clinic be still linear registration .",
        "in a number of situation , the deformation allow by non-linear registration can be difﬁcult to evaluate and may affect reliability of diagnosis [ 2 ] ; hence , physician may prefer a more constrained rigid or afﬁne alignment .",
        "considering their wide usage as fundamental tool , improvement of rigid and afﬁne registration in term ofperformance and reliability be highly relevant in practice .",
        "feature-based image registration be dependent on the ability of the feature extraction method to locate distinct point of interest appearing in both ( a ll ) image .",
        "feature-extractors ( e.g .",
        "sift [ 7 ] ) typically presuppose the existence and rele-vance of speciﬁc local character istics such as edge , corner and other salient feature ; if no , or too few , such distinct point be find , the registration will fail .",
        "this be oftenthe case in medical and biome dical application [ 8 ] , [ 9 ] , where intensity-based registra tion , therefore , tend to be the method of choice .",
        "figure 1 show an illustrative example of a biomedical application where a feature-based method fails , whereas an intensity-based method can be successful .",
        "intensity-based registration be , in general , formulate as a non-convex optimization problem .",
        "the similarity measure commonly use as optimization criterion typically exhibit ahigh number of local optimum [ 10 ] , [ 11 ] ; a count which tend to rapidly increase under noi sy condition .",
        "a small region of attraction of a global optimum imposes that the start position have to be set very close to the optimal solution for it to be find by an optimizer .",
        "this lead to reliability challengesfor automated solution .",
        "in this study we develop a registration framework base on a family of symmetric distance measure , propose in [ 11 ] , which combine intensity and spatial information in a single this work be license under a creative commons attribution 3.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/3.0/öfverstedt et al .",
        ": fast and robust symmetric image registration 3585 fig .",
        "1 .",
        "illustrative example of a biomedical registration task where a wid ely use feature-based ( fb ) method ( sift , as implement in fiji-plugin li near stack alignment1 ) fail , while the propose intensity-based ( ib ) method ( sec .",
        "v-f.1 ) pe rforms well .",
        "green point in ( a ) and ( b ) be incorrectly detect as have a match , and red point do not have a match .",
        "the feature-extractor fail to detect point correspond to the relevant structure ( one approxi mately correct match , indicate with arrow , can be find manually ) , and both the cen tral ring and the outer ring be misalign .",
        "( a ) reference image .",
        "( b ) f loating image .",
        "( c ) fb rigid ( fail ) .",
        "( d ) fb afﬁne ( fail ) .",
        "( e ) ib , rigid+afﬁne .",
        "measure .",
        "these measure have be show to be characterize by smooth distance surface with signiﬁcantly few local minimum than the commonly use i ntensity-based measure , when study in the context of t emplate matching and object recognition .",
        "in this work we demonstrate that slightly modiﬁed version of these distance measure can be successfully use for fast and robust afﬁne image registration .",
        "by differentiate the distance measure we be able to use efﬁcient gradient-based optimization .",
        "the propose method outperform the commonly used similarity measure in both synthetic and real scenario of medical and biome dical registration task , which we conﬁrm by ( i ) landmark-based evaluation on transmission electron microscopy ( tem ) image of cilium [ 12 ] , with the aim of improve multi-image super-resolution reconstruction , as well as ( ii ) evaluation on the task of atlas-based segmen- tation of magnetic resonance ( mr ) image of brain , on thelpba40-dataset [ 13 ] .",
        "intensity interpolation be typically a required tool in the con- text of intensity-based registration perform with commonlyused similarity measure since the seek transformation ( and intermediate candidate ) be likely to map point to region outside of the regular grid .",
        "treating the reference and ﬂoating image differently in term of the interpolation introduce a signiﬁcant source of asymmetry [ 14 ] and may lead tosuccess or failure of a registration task depend on which image be select as reference and which be ﬂoating .o u r propose approach require no off-grid intensity value , andis interpolation-free in term of intensity ; empirical test conﬁrm that it be highly symmetric in practice .",
        "noting that intensity-based image registration can be com- putationally demand , we also include a study of execution time of ( i ) isolate distance and gradient computation throughmicro-benchmarks , and ( ii ) entire image registration task .",
        "we observe that the propose measure be fast to compute in comparison with the implementation of the measuresexisting in the itk-framework [ 14 ] .",
        "the propose registra- tion framework be implement in c++/itk , as well as in python/numpy/scipy , and its source code be available .",
        "2 ii .",
        "p reliminaries and previous work a .",
        "images as fuzzy sets first we recall a few basic concept relate to fuzzy set [ 15 ] , a theoretical framework where gray-scale image be conveniently represent .",
        "1imagej.net/linear_stac k_alignment_with_sift 2source code available from www.github.com/mida-groupafuzzy set son a reference set xsis a set of ordered pair , s= { ( x , μs ( x ) ) : x∈xs } , w h e r e μs : xs→ [ 0,1 ] be themembership function ofs .",
        "where there be no risk for confusion , we equate the set and its membership function and lets ( x ) be equivalent to μs ( x ) .",
        "a gray-scale image can directly be interpret as a spatial fuzzy set by rescale the valid intensity range to [ 0,1 ] .",
        "we assume , w.l.o.g.",
        ", that the image to be register have anintensity range [ 0,1 ] and we directly interpret them as fuzzy set deﬁned on a reference set which be the image domain , and be in most case a subset of z n.w eu s et h et e r m s image and fuzzy set interchangeably in this text .",
        "a crisp set c⊆xc ( a binary image ) be a special case of a fuzzy set , with its characteristic function as membership function μc ( x ) =\u00021 , forx∈c 0 , forx/∈c .",
        "( 1 ) theheight of a fuzzy set s⊆xsish ( s ) =max x∈xsμs ( x ) .t h e complement sof a fuzzy set sis s= { ( x,1−μs ( x ) ) : x∈ xs } .anα-cut of a fuzzy set sis a crisp set deﬁned as αs= { x∈xs : μs ( x ) ≥α } , i.e.",
        ", a thresholded image .",
        "letpbe an element of the reference set xs.afuzzy point p ( also call a fuzzy singleton ) d e ﬁ n e da t p∈xswith height h ( p ) , be deﬁned by a membership function μp ( x ) =\u0002h ( p ) , for x=p 0 , for x\u0006=p .",
        "( 2 ) b. intensity-based registration and point-wise distances intensity-based registration be a general approach to image registration deﬁned as a minimization process , where a dis- tance measure between the intensity of overlap point ( or region ) be use as optimization criterion .",
        "given a distance measure dand a set of valid transformation \u0003 , intensity-based registration of two image a ( ﬂoating ) and b ( reference ) can be formulate as the op timization problem , ˆt=arg min t∈\u0003d ( t ( a ) , b ) , ( 3 ) where t ( a ) denote a valid transform of image ainto the reference space of image b. intensity-based similarity/distance measure which be most commonly use for image registration be sum of squared differences ( ssd ) [ 16 ] , pearson c orrelation coefﬁcient ( pcc ) 3586 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 and mutual information ( mi ) [ 17 ] .",
        "these measure be point- base , i.e .",
        "they be function of the intensity of point belong to the overlap region of the two compare set .",
        "their evaluation , therefore , typically require interpolation ofimage intensity .",
        "for two image pand qdeﬁned on a common reference setx p , qof overlap point , these measure be deﬁned as ssd ( p , q ) =\u0003 v∈xp , q ( p ( v ) −q ( v ) ) 2 , ( 4 ) pcc ( p , q ) =\u0004 v∈xp , q ( p ( v ) −avg ( p ) ) ( q ( v ) −avg ( q ) ) \u0005 \u0004 v∈xp , q ( p ( v ) −avg ( p ) ) 2\u0005 \u0004 v∈xp , q ( q ( v ) −avg ( q ) ) 2 ( 5 ) and mi ( p , q ) =hp+hq−hp , q .",
        "( 6 ) in ( 5 ) avg ( p ) , a n da v g ( q ) denote mean of the resp .",
        "intensity distribution over the evaluated region .",
        "in ( 6 ) the ( joint andmarginal ) entropies h p , hqandhp , qof the image intensity distribution pand qare deﬁned in term of the estimate probability pof a randomly select point vhaving intensity p ( v ) , q ( v ) , a s hp=−\u0003 v∈xp , qp ( p ( v ) ) log ( p ( p ( v ) ) ) , ( 7 ) and hp , q=−\u0003 v∈xp , qp ( p ( v ) , q ( v ) ) log ( p ( p ( v ) , q ( v ) ) ) .",
        "( 8 ) intensity-based registration , as formulate in ( 3 ) , be , in gen- eral , a non-convex optimization problem with a large number of local optimum , especially for the commonly use point-based measure ( ssd , pcc , and mi ) .",
        "to try to overcome this optimization challenge , a resolution-pyramid-scheme be normally use [ 18 ] , [ 19 ] , where smooth low resolutionimages be ﬁrst register , follow by registration of image with increase resolution and decrease degree of smoothing , use the transform obtain from the previous stage asstarting position ( so-called coarse-to-ﬁne approach ) .",
        "c. distances combining intensity and spatial information while the distance of sec .",
        "ii-b only rely on intensity of overlap point , the distance present in this section incorporate also spatial information of non-overlapping point .",
        "for such spatial relation , we consider distance between twopoints , between a point and a set , and between two set .",
        "the most commonly use point-to-point distance be the euclidean distance , denote d e. given a point-to-point distance d ( a , b ) , the common crisp point-to-set distance between a point aand a set bis d ( a , b ) =inf b∈bd ( a , b ) .",
        "( 9 ) closely relate to the crisp point-to-set distance be the ( exter- nal ) distance transform of a crisp set b⊆xb ( with point-to- point distance d ) which be deﬁned as dt [ b ] ( x ) =min y∈b { d ( x , y ) } .",
        "( 10 ) taking into the consideration the intensity , or equivalently , theheight of a fuzzy point , the fuzzy point-to-set inwards distance dα , base on integration over α-cuts [ 11 ] , between a fuzzy point pand a fuzzy set s , i sd e ﬁ n e da s dα ( p , s ) =\u0006h ( p ) 0d ( p , αs ) dα , ( 11 ) where dis a point-to-set distance deﬁned on crisp set .",
        "the complement distance [ 20 ] of a fuzzy point-to-set distance dis d ( p , s ) =d ( p , s ) .",
        "( 12 ) the fuzzy point-to-set bidirectional distance d ¯αis d¯α ( p , s ) =dα ( p , s ) + dα ( p , s ) .",
        "( 13 ) for an arbitrary point-to-set distance d , sum of minimal distances ( smd ) [ 21 ] deﬁnes a set-to-set distance as dsmd ( a , b ) =1 2\u0007\u0003 a∈ad ( a , b ) +\u0003 b∈bd ( b , a ) \b .",
        "( 14 ) a weighted version can be deﬁned [ 11 ] , which may be useful if a priori information about relative importance ofcontributions of different point to the overall distance be available : d wsmd ( a , b ; wa , wb ) =1 2\u0007\u0003 a∈awa ( a ) d ( a , b ) +\u0003 b∈bwb ( b ) d ( b , a ) \b .",
        "( 15 ) inserting distance ( 11 ) or ( 13 ) in ( 14 ) or ( 15 ) provide extension of the smd family of distance to fuzzy set [ 11 ] .",
        "we refer to them as dα smd , d¯α smd , dα wsmdandd¯α wsmd .",
        "it have be observe for fuzzy set distance [ 22 ] in general , and for distance base on ( 11 ) and ( 13 ) in particular , that dis- tances between set with empty α-cuts may give inﬁnite or ill- deﬁned distance .",
        "we follow a previous study and introduce a parameter dmax∈r≥0 , [ 23 ] , to limit the underlying crisp point-to-set distance .",
        "this have a double beneﬁt of ( i ) reduce the effect of outlier and ( ii ) make the distance well deﬁned also for image with empty α-cuts .",
        "distances base on optimal mass transport ( omt ) , such as the wasserstein distance , also combine intensity and spatial information , and be widely study and use in image process-ing [ 24 ] .",
        "the omt can be frame as a linear programming optimization problem , which be solvable in o ( n 3 ) [ 25 ] .",
        "this be intractable for most realistic image processing scenario , and approximation be typically consider [ 25 ] , [ 26 ] .",
        "it be possible to incorporate these distance in image registration framework , but to the best of our knowledge , this have only be do for non-linear ( deformable ) registration , and have be show to be very computationally demand [ 27 ] , [ 28 ] .we perform a preliminary study of omt-based meth- od use the formulation in [ 26 ] , and observe both very high computational demand and noisy distance landscapes.öfverstedt et al .",
        ": fast and robust symmetric image registration 3587 in absence of a complete registration framework for linear registration base on omt , this family of measure be exclude from the empirical part of this study .",
        "d. transformations , interpolation , and symmetry linear transformation relate point in one space to another via application of a linear function .",
        "a transformation be rigid if only rotation and translation be permit , and afﬁne if shearing and reﬂections be also permit .",
        "afﬁne transforma- tion t : rn→rncan be express as matrix multiplication , tx=⎡ ⎢⎢⎢⎢⎢⎣a 11 a12 ... a1nt1 a21 a22 ... a2nt2 ............... a n1an2 ... ann tn 00 ... 01⎤ ⎥⎥⎥⎥⎥⎦⎡ ⎢⎢⎢⎢⎢⎣x 1 x2 ... xn 1⎤ ⎥⎥⎥⎥⎥⎦ .",
        "( 16 ) linear transformation can , i n general , transform point sample on an image grid to position outside of the grid , hence an interpolator be require for obtain the image intensity at the transformed point ’ s location .",
        "interpolation be alarge source of error , bias , and a signiﬁcant contribute factor of asymmetry in intensity-based registration [ 14 ] .",
        "commonly , interpolation be only require for one of the two image , where sampling ( for optimization ) be do from the grid of the other image space ; hence , the two image be treat asymmetrically , yield distin ct similarity surface ( over the transformation parameter ) depend on which image be take as reference .",
        "this can cau se a registration task to succeed or fail , depend on the registration direction .",
        "e. optimization registration with a differentiable distance measure as objec- tive function enable the use of gradient-based optimization algorithm , which typically ar e signiﬁcantly more efﬁcient than derivative-free algorithm for local iterative optimization.an effective and commonly use subset of gradient-based algorithm be the stochastic gradient descent method [ 29 ] , which consider a random subset of the point in each optimiza-tion iteration , incur a two-fold beneﬁt : utilizing random- ness to escape shallow local optimum in the implicit distance surface , while also decrease the computational work require per iteration .",
        "the size of the random subset be usually give as a fraction of the total number of point , and denote asthe sample fraction .",
        "approximation of the cost function by random subset sampling ( where a new random subset of point be choose in every iteration ) have be , in previousstudies , [ 17 ] , [ 30 ] , show to perform well for intensity-based registration .",
        "iii .",
        "p roposed image registration framework a. distances to extend the family of distance measure give by ( 15 ) , to be suitable for registration , optionally with random subsam- pling optimization method [ 30 ] , we here deﬁne a new relatedfamily of distance measure .",
        "deﬁnition 1 ( asymmetric average minimal distance ) : given fuzzy set aon a reference set x a⊂rn , fuzzysetbon reference set x b⊂rn , and a weight function wa : xa→r≥0 , t h e asymmetric averag e minimal distance from atob , i s d−→amd ( a , b ; wa ) =1 \u0004 x∈xawa ( x ) \u0003 x∈xawa ( x ) d ( a ( x ) , b ) .",
        "( 17 ) we consider point-to-set distance deﬁned by ( 11 ) or ( 13 ) .",
        "building on the asymmetric distance , we formulate a sym- metric distance as follow : deﬁnition 2 ( average minimal distance ) : given fuzzy set aon reference set x a⊂rn , fuzzy set bon reference set xb⊂rn , weight function wa : xa→r≥0andwb : xb→ r≥0 , t h e average minimal distance between aand b , i s damd ( a , b ; wa , wb ) =1 2\u000f d−→amd ( a , b ; wa ) +d−→amd ( b , a ; wb ) \u0010 .",
        "( 18 ) in the context of image registration , we utilize d−→amd to express a ( weight ) distance between transform fuzzy point t ( a ( x ) ) , and the image b , where the transformation of a fuzzy point a ( x ) = { ( x , μa ( x ) ) } be give by the transformation of the reference point x : t ( a ( x ) ) = { ( t ( x ) , μ a ( x ) ) } .",
        "( 19 ) to reﬂect the bounded image domain , only the transformed point fall on a predeﬁned region mb⊂rnare consider .",
        "note that , when aandbare digital image , xaandxbare typically subsets of znand the transformed point t ( x ) |x∈xa do not necessarily coincide with the point of the reference setxb ; an illustrative example be give in fig .",
        "2 .",
        "we , therefore , provide the following deﬁnitions suit for the task of image registration : deﬁnition 3 ( asymmetric average minimal distance for image registration ) : given fuzzy set aon reference set x a⊂ rn , fuzzy set bon x b⊂rn , a weight function wa : xa→ r≥0 , and a crisp subset ( mask ) m b⊂rn , t h e asymmetric average minimal distance for image registration from atob , parameterized by a transformation t : xa→rn , i s d−→r amd ( a , b ; t , wa , mb ) =1 \u0004 x∈ˆxwa ( x ) \u0003 x∈ˆxwa ( x ) d ( t ( a ( x ) ) , b ) ( 20 ) where ˆx= { x : x∈xa∧t ( x ) ∈mb } .",
        "deﬁnition 4 ( average minimal distance for image regis- tration ) : given fuzzy set aon reference set x a , fuzzy set b on x b , weight function wa : xa→r≥0andwb : xb→ r≥0 , and crisp subset ( mask ) m a , mb⊂rn , t h e average minimal distance for image registration between aand b , parameterized by an invertible transformation t : rn→rn , with inverse t−1 , be deﬁned as dr amd ( a , b ; t , wa , wb , ma , mb ) =1 2\u000fd−→r amd ( a , b ; t , wa , mb ) +d−→r amd ( b , a ; t−1 , wb , ma ) \u0010 .",
        "( 21 ) 3588 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 fig .",
        "2 .",
        "illustration of the asymmetric average minimal distance for image registration .",
        "( a ) source set a ( radius represent associated weight ; gray-level represent membership ) .",
        "( b ) target set bwith associated mask mb .",
        "( c ) t h e transform ( by rotation and translation ) aon top of b .",
        "( d ) illustration of the contribution to the point-to-set distance d¯αby the central point of a. thickness of line show the α-integrated height contribute by each point inb .",
        "( e-f ) the inwards and complement part of d¯αvisualized as 1d graph , where the x-axis be the euclidean distance ( in 2d ) from the mid-point and the point at the left and right side ( of t he origin ) respectively be the point on the left and right side of the mid-point t ( a ( x ) ) in ( d ) .",
        "the distance dr amdis base on full sampling , take into account all point in the two set which have non-zero weight , as long as they be transform to point inside the maskassociated with the other set .",
        "to reduce the computational cost of the distance and , in addition , to enable random iterative sampling , we propose an approximate version of d r amd : deﬁnition 5 ( subsampled average minimal distance for image registration ) : given fuzzy set aon reference set x a , fuzzy set bon x b , weight function wa : xa→r≥0and wb : b→r≥0 , and crisp subset ( mask ) m a , mb⊂rn , thesubsampled average minimal distance for image regis- tration between aand b , parameterized by an invertible transformation t : rn→rn , with inverse t−1 , and crisp set p a⊆xaand p b⊆xb , be deﬁned as ˜dr amd ( a , b ; pa , pb , t , wa , wb , ma , mb ) =1 2\u000f d−→r amd ( a∩pa , b ; t , wa , mb ) +d−→r amd ( b∩pb , a ; t−1 , wb , ma ) \u0010 .",
        "( 22 ) inserting ( 11 ) or ( 13 ) as point-to-set distance in ( 20 ) , and hence indirectly in ( 21 ) and ( 22 ) , provide extension ofthis family of distance to the α-cut-based distance , which we denote d−→r αamd , d¯−→r αamd , dr αamd , d¯r αamd , ˜dr αamdand ˜d¯r αamd .",
        "normalization of the weight of the sampled point , intro- duced through def .",
        "1 , render the magnitude of the distance ( and subsequently its derivative ) invariant to the size andaggregated weight of the set or of the sampled subset .",
        "since the normalization be do separately from atob and from btoa , both direction be weight equally even if the total weight of the point subset from the two set be different .",
        "this normalization can simplify the process ofchoosing e.g .",
        "step-length of various optimization method , and make it more likely that default hyper-parameter value can be find and reuse across different application .",
        "b .",
        "registration we propose to utilize symmetric distance d¯ αamd and ˜d¯αamd as cost function in ( 3 ) to deﬁne concrete image registration method .",
        "inserting d¯r αamdinto ( 3 ) we obtain ˆt=arg min t∈\u0003d¯r αamd ( a , b ; t , wa , wb , ma , mb ) .",
        "( 23 ) for the case of subset sample with set paand pb , registration be deﬁned as ˆt=arg min t∈\u0003˜d¯r αamd ( a , b ; pa , pb , t , wa , wb , ma , mb ) .",
        "( 24 ) by selection of new random subset paandpbin each itera- tion , various stochastic gradient descent optimization methodscan be realize .",
        "to solve the optimization problem state in ( 23 ) and ( 24 ) with efﬁcient gradient-based optimization method , the par- tial derivative of the distance measure with respect to the transformation parameter of tare require .",
        "c. gradients the derivative of ( 9 ) , the crisp point-to-set distance measure d ( t ( x ) , s ) ( inn-dimensional space ) , with respect to parame- ters t iof the transformation tapplied to a point x∈x , yield y=t ( x ) , can be write as ∂d ∂ti=n\u0003 j=1∂d ∂yj∂yj ∂ti .",
        "( 25 ) the values∂d ∂yjare the component ( partial derivative ) of the gradient ∇d ( y , s ) of the point-to-set distance in point y∈ y⊂rn , and be not dependent on the transformation model .",
        "the gradient of the fuzzy point-to-set distance measure ( 11 ) be give by the integral over α-cuts , of gradient of the ( crisp ) point-to-set distance : ∇d ( x , s ) =\u0006h ( x ) 0∇d ( x , αs ) dα .",
        "( 26 ) d. algorithms for digital images on rectangular grids the distance and gradient can be compute efﬁciently for the special case of digital image on rectangular grid .",
        "for image quantize to \u0005∈n > 0non-zero discrete α-levels the integral in ( 11 ) and ( 26 ) be suitably replace by sums.öfverstedt et al .",
        ": fast and robust symmetric image registration 3589 algorithm 1 distance and gradient maps the number of quantization level be typically take to be a small constant ; a choice of \u0005=7 non-zero equally space α-levels have previously show to provide a good trade-off between performance , speed and noise-sensitivity [ 11 ] , and we keep it for all experiment .",
        "we need a discrete operator to approximate the gradient of d ( x , s ) for a set sdeﬁned on a rectangular grid with space s∈rn > 0 .",
        "we propose to use the following difference operator provide a discrete approximation of ∇d ( x , s ) : \u0006d ( x ) =γx ( δ1 [ d ] ( x ) , ... , δ n [ d ] ( x ) ) , ( 27 ) where δi [ d ] ( x ) =1 2si ( d ( x+siui , s ) −d ( x−siui , s ) ) , ( 28 ) γxis an indicator function , γx=\u00021 , ford ( x , s ) \u0006=0 0 , ford ( x , s ) =0 , ( 29 ) anduiis the unit-vector along the i-th dimension .",
        "the indicator function γxcauses the operator \u0006 [ s ] ( x ) to be zero-valued for point include in s ( i.e.",
        ", where the distance transform be zero-valued ) .",
        "this prevent discretization issue along set boundary , where the standard central difference operator yield non-zero gradient , which can cause the mea- sure to overshoot a potential voxel-perfect overlap .",
        "by create table for the distance and gradient sum for each image as a pre-processing st ep , use either of the proce- dures in alg .",
        "1 ( \u0006αdt for inwards distance and \u0006αdt_bd algorithm 2 point-to-set distance and its gradient w.r.t .",
        "t for bidirectional distance ) , the distance and gradient may then be readily compute with alg .",
        "2 .",
        "|t|denotes the number of parameter of the transformation , which be 6 for two- dimensional ( 2d ) afﬁne transformation , and 12 for three- dimensional ( 3d ) afﬁne transformation .",
        "the procedure in alg .",
        "1 have linear run-time complexity o ( ( \u0005+1 ) |xa| ) , achieve by use a linear-time algorithm for compute the distance transform ( see [ 31 ] ) in line 4 of alg .",
        "1 .",
        "the space complexity of the algorithm be o ( ( \u0005+ 1 ) |xa| ) and the d , gstructures must remain in memory to enable fast lookup in alg .",
        "2 .",
        "figure 3 show an example of the distance and gradient of a sample α-level .",
        "alg .",
        "2 compute the point-to-set distance and gradient w.r.t .",
        "the transformationusing the pre-computed table and have run-time complexity o ( |t|n ) thus be independent of \u0005and the size of aandb .",
        "algorithm 3 performs a complete registration give two image , their binary mask , weight function , and an ini- tial transformation .",
        "algorithm 3 completes nfull iteration , however other termination criterion may be beneﬁcial ( see sec .",
        "iv ) .",
        "the registration consist of pre-processing , follow by a loop where the symmetric set distance and derivative be compute and tis updated.\u0006t−1 \u0006t , in line 6 of alg .",
        "3 denote a matrix\u0011∂t−1 j ∂ti\u0012of partial derivative of the parameter of the inverse transform t−1w.r.t .",
        "the parameter of the forward transform t. this matrix relate the computed partial derivatives\u0006d2 \u0006t−1with the parameterization of the forward transform .",
        "the overall run-time complexity be o ( n|t|n ( |xa|+ |xb| ) + ( \u0005+1 ) ( |xa|+|xb| ) ) .",
        "practical choice for n tend to be in the range [ 1000,3000 ] , depend on hyper- parameter ( e.g .",
        "λ ) , and distance in parameter-space between start position and the global optimum .",
        "the evaluation in sec .",
        "v conﬁrms empirically th at convergence , accord to ( 31 ) or ( 32 ) , tend to be reach after 1000 to 3000 iteration , use an optimizer with a decay λ .",
        "the quantize procedure in alg .",
        "2 take the membership of point v , μ a ( v ) , and give the index iof the minimal3590 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 fig .",
        "3 .",
        "( a ) example α-cut in a small 2d image .",
        "( b ) binary mask .",
        "( c ) α-cut after mask .",
        "( d ) ( euclidean ) distance transform ( for ( c ) ) .",
        "( e-f ) gradient approximation of the distance transform \u0006dt .",
        "algorithm 3 symmetric registration α-level ( α1 , … , α\u0005 ) f o rw h i c h μa ( v ) ≥αi .",
        "if the membership be below all α-levels , the index be 0 .",
        "for \u0005equally space α-levels , the quantization can be express as quantize ( μa ( v ) ) = \u0005μa ( v ) +0.5 .",
        "( 30 ) the interpolate procedure in alg .",
        "2 compute the value of the discrete function dand gin point ˆvwhich may not be on the grid due to application of t.t h e r ea r emany interpolation scheme propose in the literature , but we suggest that either near neighbor ( for maximal speed ) or linear interpolation ( for high accuracy ) be use here , since the distance and gradient ﬁelds be smooth .",
        "by linearityof integration and summation , near neighbor and linear interpolation may be perform on the pre-processed dandg and yield the same result as if each level be interpolatedbefore integration , allow efﬁcient computation .",
        "the ( dis- cretized ) measure do not require intensity interpolation ; the interpolation operate on distance and gradient only .",
        "iv .",
        "i mplementation we implement the propose distance measure and regis- tration method in the open-source insight segmentation andregistration toolkit ( itk ) [ 14 ] .",
        "we choose this particular software framework because it •enables the use of an exist optimization framework , •allows for a fair comparison against well write , test , and widely used implementation of reference similarity measure , with support for resolution-pyramids , •supports anisotropic/scaled voxels in relevant algorithm , •facilitates reproducible evaluation , •makes the proposed measure easily accessible for others .",
        "the built-in itk optimizer we have use for the registration tool and all the evaluation be regularstepgradientdescen- toptimizerv4 .",
        "this be an optimizer base on gradient descent , with an initial step-length λ , and a relaxation factor which reduce the used step-length gradually as the direction of the gradient change , in order to enable convergence with high accuracy .",
        "in addition to a maximum number of iteration n , two termination criterion be use : ( i ) a gradient magnitude threshold ( gmt ) , \u0005 ∂d ∂t12+ ... +∂d ∂t|t|2 < gmt , ( 31 ) and ( ii ) a minimum step-length ( msl ) , λr < msl , ( 32 ) where ris the current relaxation coefﬁcient .",
        "we use default value of 0 .0001 for both of these criterion .",
        "a relaxation factor of 0.99 be use for all experiment , since it perform well in preliminary test ; in this study we be willing to tradesome ( potential ) additional iteration for good robustness .",
        "to maximize utilization of the limited number of α-levels , image be normalize before registration to make sure that they be within the valid [ 0 ,1 ] interval .",
        "we use the following robust normalization technique : let p ρ ( x ) denote the ρ-th percentile of image xwith respect to image intensity , norm ρ ( x ) =max\u0013 0 , min\u0011 1 , ( x−pρ ( x ) ) p1−ρ ( x ) −pρ ( x ) \u0012\u0014 .",
        "( 33 ) v. p erformance analysis we evaluate performance of the propose method , both for 2d and 3d image , in two different scenario ; ( i ) we perform a statistical study on synthetically generate image , where we seek to recover know transformation and measureöfverstedt et al .",
        ": fast and robust symmetric image registration 3591 the registration error by compare the ground truth loca- tions of know landmark with the corresponding registered one ; ( ii ) we apply the propose framework to real image analysis task : landmark-based evaluation of registration oftem image in 2d , and atlas-based segmentation evaluation of 3d mr image of brain .",
        "to compare the propose measure and registration method against the most commonly use alternative method and similarity measure , we sel ect the widely use itk imple- mentation of optimization framework and similarity mea- sures ( ssd , pcc and mi ) as the b aseline of intensity-based registration accuracy .",
        "note that the pcc measure be denotednormalized cross correlation ( ncc ) in the itk framework .",
        "all experiment be perform on a workstation with a 6-core intel i7-6800k , 3.4ghz processor with 48gb of ramand 15mb cache .",
        "the operating system use be ubuntu 16.04 lts .",
        "the compiler use to build the framework be g++ version 5.4.0 ( 20160609 ) .",
        "version 4.9 of the itk-framework be use for test and evaluation .",
        "a. datasets one biomedical 2d dataset and one medical 3d dataset be use for the evaluation .",
        "1 ) tem images of cilia ( 2d ) : the dataset of 20 image of cilium [ 12 ] be acquire with the minitem 3imaging system .",
        "each image be isotropic of size 129 ×129 pixel , with a pixel-size of a few nm .",
        "an example be show in fig .",
        "1 .",
        "a particular challenge be the near-rotational symmetry of the object : 9 pair of ring be locate around a central pair of ring , which give 9 plausible solution for a registration problem .",
        "the alignment of the central pair can be take intospecial consideration to reduce the number of solution to two .",
        "the dataset come with a set of 20 landmark per image , indicate the position of each of the relevant structure tobe detect and analyse – 20 ring ( 2 in the center and 18 in a circle around the center ) .",
        "the landmark be produce by a domain expert and be only use for evaluation of the registration .",
        "2 ) lpba40 ( 3d ) : lpba40 [ 13 ] be a publicly available dataset of 40 3d image of brain of a diverse set of healthy individual , acquire with mri .",
        "the image be anisotropic , of size 256 ×124×256 voxels with voxel-size 0 .86× 1.5×0.86mm 3 .",
        "the dataset come with segmentation of the brain into 56 distinct region mark by a medical expert , which be use in this study as ground-truth for evaluation .",
        "lpba40 include two atlas : ﬁrst 20 out of 40 mr image of brain in the dataset be use to generate one brain atlas bysymmetric groupwise normalization ( sygn ) [ 32 ] ; another atlas be create analogously , from the last 20 brain in thedataset .",
        "the atlas contain both a synthesize mr image and the fuse label category in all the voxels , as well as a whole brain mask which may be use for brain extraction .",
        "b .",
        "evaluation criteria we evaluate accuracy and robustness of the registration method in presence of noise , their robustness w.r.t .",
        "change 3minitem imaging system be develop by vironova ab.of role of reference and ﬂoating image ( symmetry ) , andtheir speed .",
        "we quantify the performance of the observed framework in term of the following quality measure : 1 ) average error measure ( ae ) : the registration result be quantiﬁed as the mean euclidean distance between the set of correspond image corner landmarks l rand t ( lf ) in the reference im age space , after transformation of the ﬂoating image corner landmarks lf , w h e r e |lr|is the number of landmark ( 4 in 2d ; 8 in 3d ) .",
        "the quality measure be deﬁned as ae ( t ; lr , lf ) =1 |lr||lr|\u0003 i=1de ( lr ( i ) , t ( lf ( i ) ) ) .",
        "( 34 ) a slight variation of this measure , the average minimal error ( ame ) , be use in the real task of cilia registration : ame ( t ; lr , lf ) =1 |lr||lr|\u0003 i=1min x∈lfde ( lr ( i ) , t ( x ) ) .",
        "( 35 ) for the central pair , the error be simply ame cp=ame , whereas for the out ring we utilize the knowledge that an odd ( even ) landmark should be match with an odd ( even ) landmark of the other image .",
        "the error function for the outerrings , [ 12 ] , be therefore deﬁned as : ame outer ( t ; lodd r , lodd f , leven r , leven f ) =1 2 ( ame ( t ; lodd r , lodd f ) +ame ( t ; leven r , leven f ) ) .",
        "( 36 ) 2 ) success rate ( sr ) : a registration be consider success- ful if its ae be below one voxel ( pixel ) .",
        "success rate ( sr ) at a give ae value correspond to the ratio of successful registration ( w.r.t .",
        "the set of performed one ) .",
        "3 ) symmetric success rate ( symsr ) : be deﬁned as the ratio of perform registration which be successful ( i.e.",
        ", ae≤1 ) in both direction , i.e.",
        ", when the role of reference and ﬂoating image be exchange .",
        "4 ) inverse consistency error ( ice ) [ 33 ] : given a set of interest xa⊆a , the transformation tab : a→b , a n d tba : b→a , the ice of this pair of transformation be ice ( tab , tba ; xa ) =1 |xa|\u0003 x∈xade ( tba ( tab ( x ) ) , x ) .",
        "( 37 ) we compute ice consider all the point of the reference image for each of the case wh ere symmetric success be observe ( ae≤1 in both direction ) .",
        "5 ) jaccard index for segmentation evaluation : for two binary set , r1and r2 , the jaccard index be deﬁned as j ( r1 , r2 ) =| ( r1∩r2 ) | | ( r1∪r2 ) | .",
        "( 38 ) 6 ) execution time : we evaluate ( i ) the execution time require for one iteration in the registration procedure , i.e.",
        ", time need to compute the distance ( similarity ) measure and its derivative , with full sampling , and in full image resolution , between two distinct image from the same set , as well as ( ii ) the execution time for complete registrations.3592 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 c. parameter tuning the distance measure and optimization method have a num- ber of parameter which must be properly choose .",
        "synthetic test indicate that the follow value lead to good optimiza- tion performance : three pyramid level with downsamplingfactors ( 4,2,1 ) and gaussian smoothing σ= ( 5.0,3.0,0.0 ) , max 3000 iteration per level and an initial step-length λ= 0.5 .",
        "the number of α-levels use be \u0005=7 , which have show to provide a reasonable trade-off between computational cost , sensitivity to signiﬁcant variation in intensity and robustnessto noise [ 11 ] .",
        "the optimal value for \u0005is application-dependent ; in essentially all observed case , \u0005 > 1 ( non-crisp ) outperform a crisp ( binarized ) representation .",
        "normalization percentileis normally 5 % .",
        "this same parameter setting , if not state differently , be use in all the test , on both synthetic and real data .",
        "d. synthetic tests a synthetic evaluation framework be use to evaluate the performance of the propose method , and to compare itwith standard tool base on ssd , pcc , and mi , in a con- trolled environment .",
        "for this evaluation , we construct set of transformed version of a reference image and add ( a newinstance of ) gaussian noise to each generate image .",
        "the transformation be select at random from a multivariate uniform distribution of rotation measure in degree ( 1 angle for 2d image and 3 euler angle for 3d image ) and translation measure in fraction of the original image size .",
        "1 ) 2d tem images of cilia : three set of transformed image be build base on image nr .",
        "1 in the observed dataset , by apply on it the following three group of transforma- tions : small , contain composition of translation of up to 10 % of image size ( in any direction ) and rotation by up to 10 ◦ ; medium , contain composition of translation and rotation such that at least one of the parameter exceed the range of small , and fall within 10 −20 % of image size of translation ( in at least one direction ) , or 10 −20◦of rotation ; and large , contain composition of translation and rotation such that at least one of the parameter exceed the range of medium , and fall within 20 −30 % of image size of translation ( in at least one direction ) , or 20 −30◦of rotation .",
        "the transformed image be also corrupt by addi- tive gaussian noise , from n ( 0,0.12 ) ( σ=0.1 , correspond to a psnr ≈20 db ) .",
        "each group of transformation be applied 1000 time , and the resulting image be register to image nr .",
        "1 , each time corrupt by a new instance of gaussiannoise .",
        "to evaluate symmetry , we perform 1000 registration of image transform by randomly select translation ofup to 30 % of image size , and rotation by up to 30 ◦ , a n d corrupt by additive noise from n ( 0,0.12 ) .",
        "each of the registration be perform twice , with exchanged role of reference image and ﬂoating image .",
        "intensity-based registration with gradient-descent optimiza- tion can be computationally demand , require the distance function and its derivative for each iteration of the optimization procedure .",
        "the time to compute the distance and derivativesis directly proportional to the number of sampled point .",
        "we , therefore , evaluate inﬂuence of the sample fraction on registration success , observe registration after small transformation and add noise ( with σ=0.1 ) , over a range of sample fraction .",
        "for each evaluated sampling fraction , 1000 registration be perform and sr and ae be compute for successful registration ( ae≤1 ) .",
        "no resolution pyramid be use for these test .",
        "2 ) 3d mr images of brain : three set of transformed image be build base on image nr .",
        "1 in the observed dataset , by apply to it the following three group of transformation : small , contain composition of translation of up to 10 % of image size ( in any direction ) and rotation by up to 10◦ ( around each of the rotation ax ) ; medium , contain composition of translation an d rotation such that at least one of the parameter exceed the range of small , and fall within 10 −15 % of image size of translation ( in at least one direction ) , or 10 −15◦of rotation ( around at least one rotation ax ) ; and large , contain composition of translation and rotation such that at least one of the parameter exceed therange of medium , and fall within 15 −20 % of image size of translation ( in at least one direction ) , or 15 −20 ◦of rotation ( around at least one rotation ax ) .",
        "the transformed image arealso corrupt by additive gaussian noise , from n ( 0,0.1 2 ) .",
        "each group of transformation be apply 200 time , and the resulting image be register to image nr .",
        "1 , each time corrupt by a new instance of gaussian noise .",
        "e. results of synthetic tests 1 ) 2d tem images of cilia : figure 4 show the distrib- utions of registration error ( ae ) , for the three transforma-tion class .",
        "superiority of the propose measure , and the corresponding registration framework , be particularly clear for medium and large transformation ; it reach a 100 % success rate , with subpixel accuracy , whereas the competitor not only exhibit considerably low accuracy , but also much lowersuccess rate , i.e.",
        ", they completely fail in a large number of case .",
        "overall registration performance be summarize in table i , for complete sampling ( a ) , and for random sampling of 10 % of the point ( b ) .",
        "the propose method have 100 % success rate and also 100 % symmetric success rate .",
        "the other observed measure exhibit much low success rate and poor symmetry score ; the second best , ssd , succeed in 54 % of the case , and succeed symmetrically in only 31 % of the case .",
        "the registration error for successful registration be considerably small for the propose method , while the execution time isconsiderably lower .",
        "the reduced sampling fraction in ( b ) have a small impact on the propose method while substantially degrade the performance of the other measure .",
        "figure 5 show registration performance for vary sam- pling fraction ; small transformation , in presence of noise ( σ=0.1 ) be consider .",
        "we observe that the registration performance ﬂattens and stabilizes at approximately 0 .01 sam- pling fraction ( 1 % of the point ) .",
        "we conclude that previousﬁndings of [ 17 ] and [ 30 ] , suggest that random subsampling provide good performance even with very small sampling fraction , apply well for the propose measure.öfverstedt et al .",
        ": fast and robust symmetric image registration 3593 fig .",
        "4 .",
        "registration error for 2d tem image of cilium with gaussian noise of σ=0.1 add , for three observed transform ation class .",
        "( a-d ) examples of reference-ﬂoating image pair with correspond ma sks .",
        "( e-g ) cumulative histogram of the fractio n of registration with registration error ae be low a give value ( leave and up be well ) .",
        "the red vertical line show the chosen threshold for success , ae≤1 .",
        "( a ) reference image .",
        "( b ) reference mask .",
        "( c ) floating image .",
        "( d ) floating mask .",
        "( e ) small transformation .",
        "( f ) medium transformation .",
        "( g ) large transformation .",
        "table i registration of synthetic 2d i mages of cilia.thetables show success rate ( sr ) , a verage error ( ae ) ofsuccessful registrations , symmetric success rate ( symsr ) , a verage inverse consistency error ( ice ) and average runtime for the registration withcomplete sampling ( a ) and with random subsampling ( b ) .",
        "s uccessful registrations ( ae≤1 ) oftransformations up to ( and including ) large , areconsidered 2 ) 3d mr images of brain : figure 6 show the observed distribution of registration error ( ae ) for the three trans- formation class , and clearly conﬁrms that the proposedmethod be robust and with high performance , even for large transformation , while the magnitude of the transformation have a substantial negative effect on the performance of the other observed measure .",
        "figure 7 present bar plot correspond to the perform synthetic test on the lpba40-dataset , consist of 200 registration of image after up to ( and include ) large transformation ( with additive gaussian noise , n ( 0,0.1 2 ) ) .fig .",
        "5 .",
        "( left/blue ) sr for registration of cilium image , and ( right/red ) ae of the successful registration , a s function of sample fraction for the propose method .",
        "both measure improve ( almost ) monotonically withsampling fraction and ﬂatten out after approximately 0 .01 .",
        "successful registration ( ae≤1 ) be observe .",
        "here as well , the propose method deliver 100 % success rate , whereas the second best , ssd , succeed in only 33 % of the case .",
        "theregistration error for successful registration be the small for the propose method .",
        "we observe a relative increase in execution time of the propose registration framework in 3d case , where it be slightly slow er than the other measure .",
        "3 ) execution time analysis : the number of iteration require for convergence of the optimization ( registration ) typically range from 1000 to 3000 .",
        "measures ssd , pcc and mi use cubic spline interpolation .",
        "lookups from the distance map for d¯ r αamdare do use linear interpolation .",
        "table ii show the mean ( and standard deviation ) execution time ofone iteration , which include computation of the measure and their derivative , repeat 1000 time for 2d , and 50 time for 3d afﬁne image registration .",
        "we observe that the proposed3594 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 fig .",
        "6 .",
        "registration error for 3d mr image of brain with gaussian noise , σ=0.1 , add , for three observed trans formation magnitude class .",
        "( a-f ) example of reference-ﬂoating image pair in slice along each major axis .",
        "( g-i ) cumulative histogram of the fraction of registration with reg istration error ae below a give value ( leave and up be well ) .",
        "the red vertical line show the chosen threshold of success , ae≤1 .",
        "( a ) reference ( xy ) .",
        "( b ) reference ( xz ) .",
        "( c ) reference ( yz ) .",
        "( d ) floating ( xy ) .",
        "( e ) floating ( xz ) .",
        "( f ) floating ( yz ) .",
        "( g ) small transformation .",
        "( h ) medium transformation .",
        "( i ) large trans formation .",
        "fig .",
        "7 .",
        "results of synthetic registration of 3d brain image from the lpba40 dataset .",
        "the plot show the ( a ) success-rate ( sr ) , ( b ) mean error ( me ) for successful registration and ( c ) the average runtime in second for the re gistration with random subsampling with 0.01 sample fraction .",
        "( a ) highe r be well .",
        "( b-c ) lower be well .",
        "bold mark the best result w.r.t .",
        "each statistic .",
        "table ii time analysis of distance ( similarity ) value and deriv a tive computations for a full resolution image , r epeated to generate statistics .bold marks the fastest measure in each category ( 2d and 3d ) .",
        "t he2d i mages are of size1600×1278 , and the 3d i mages are of size256×124×256 measure be the fast per iteration both in 2d and 3d .",
        "note that these execution tim e measurement exclude pre- processing .",
        "f .",
        "evaluation on real applications 1 ) registration of cilia : registration of multiple cilium instance detect in a single tem sample , for enhancement ofdiagnostically relevant sub-stru ctures , require a pixel-accurate and robust method which be able to overcome the challenge pose by the near-rotational symmetry of a cilium .",
        "at mosttwo of the possible solution properly align the central pair , which be vital for a successful reconstruction .",
        "we compare the performance of the propose method with reported result of a previous study [ 12 ] which use intensity- base registration with pcc as similarity measure .",
        "we follow the general protocol describe in [ 12 ] and perform , as a ﬁrst step , a multi-start rigid registration ( parameterized by angle θ in radian , and translation t= ( t x , ty ) ) , follow , in a second step , by afﬁne registration initiate by the best ( low ﬁnal distance ) registration of the 9 rigid one .",
        "no resolution pyramid be use since they be observe to interfere with the multi-start approach ( by facilitate large movement ) .",
        "the registration be perform in full resolution , without stochastic subsampling .",
        "for the rigid registration we use a small circular binary mask with radius of 24 pixel , position in the center , combine with a squared circularhann window function .",
        "the afﬁne registration be perform use a circular binary mask with radius of 52 pixel ; the mask remove the outside background and the outer plasma which isnot helpful in guide the registration .",
        "no additional weight- mask be use for the afﬁne registration .",
        "step length 0 .1w a s use for the rigid and 0 .5 for the afﬁne registration .",
        "we useöfverstedt et al .",
        ": fast and robust symmetric image registration 3595 table iii registration of cilia : p erformance of the proposed method compared to reference results , s hown as the ‘ mean ( std-dev ) ’ of the registration error ( inpixels ) w.r.t.the considered sets of landmarks for the 19 r egistrations .",
        "‘ r ’ d enotes rigid , ‘ a ’ d enotes affine and ‘ d ’ dienotes deformable registration .b old marks the smallest error for each set of landmarks \u0005=7 .",
        "normalization percentile be set to 0 % for the rigid stage and 1 % for the afﬁne stage .",
        "a feature-based approach be also include in this per- formance evaluation .",
        "the sif t feature-detector [ 7 ] , with ransac [ 34 ] as model ﬁtting and correspondence point ﬁltering method , as implement in fiji , be evaluate with both rigid and afﬁne transformation model .",
        "the test areperformed with , and without , circular mask ( as describe above ) , and with systematically vary parameter setting ( use grid search ) : initial gaussian blur test with valuesin the range [ 0.4,2.4 ] , with step of 0.4 ; feature descriptor size test with { 1,2,4,6,8 } ; step per scale octave test with { 1,2,3,4,5 } .",
        "the other available parameter be set to their default value , since we observe insensitivity to those parameter in our preliminary test .",
        "2 ) atlas-based segmentation ( lpba40 ) : in [ 35 ] , a protocol for evaluation of distance/similarity measure in the context of image registration be propose .",
        "the protocol start withafﬁne registration , for which result be report , and then proceeds to deformable registra tion .",
        "since this study focus on the development of an afﬁne ( linear ) registration frameworkbased on the propose distance measure , we compare with the report afﬁne-only performance ; an improved afﬁne reg- istration be of great signiﬁcance since a very high correlation between the performance of the afﬁne registration and that of the subsequent deformable registration have be establish .",
        "we start from the two atlas create utilize the advanced neuroimaging tools ( ants ) registration software suite and the open-source evaluation script provide in the referencestudy [ 35 ] .",
        "we utilize the atlas create use mutual informa- tion since that be the one find in [ 35 ] to be best performing and be use as the basis for the whole deformable registration study .",
        "two-fold cross validation be utilize ; the ﬁrst atlas be register to the last 20 brain image and the second atlas isregistered to the ﬁrst 20 brain , hence all registration be do with brain that do not contribute to the creation of the atlas .",
        "the multi-label segmentation deﬁned by the atlas be trans- form use the transformation parameter find during the registration and compare to the ground-truth segmentation for each brain .",
        "the jaccard index [ 36 ] be calculate per region , as well as for the entire brain mask .",
        "for the propose method base on ˜d¯ r αamdwe use \u0005= 7 , normalization percentile 5 % , n=3000 , 0 .05 sample fraction , and circular hann windows as weight-masks.table iv results of atlas -based brain segmentation .thetable shows the mean jaccard index for each of the brain regions for ˜d¯r αamdand mutual information withaffine registration asreported in [ 35 ] .",
        "f or˜d¯r αamd , m ean and std .dev.are displa yed ; for the comparative results ( mia ff ) , only mean was reported g. results of real applications 1 ) results of registration of cilia : performance of the propose method , together with the best previously publish result , be show in tab .",
        "iii .",
        "the table show the mean and3596 ieee transactions on image processing , vol .",
        "28 , no .",
        "7 , july 2019 standard deviation of registration error ( ame , in pixel ) of the 19 registration , for the three consider set of land- mark : the central pair , the outer ring , and all ( 1+9 ) ring pair .",
        "‘ r ’ denote rigid ; ‘ a ’ denote afﬁne ; and ‘ d ’ denotesdeformable registration .",
        "the original study include deformable registration as a ﬁnal stage , after the rigid and afﬁne step .",
        "here presentedframework base on d¯ r αamdincludes linear ( rigid and afﬁne ) , but not deformable registration .",
        "however , as result include in tab .",
        "iii conﬁrm , the propose method outperform the previous state-of-the-art , even if use only rigid and afﬁne registration .",
        "we note that with only rigid registration we improve the alignment of the central pair while degrade the alignment of the outer ring .",
        "after the afﬁne registration , the alignmentof the central pair be improve far , plausibly due to the le constrain transformation model of afﬁne compare to rigid , and we observe that the alignment of the outer ring and the total alignment be improve substantially .",
        "the feature-based method be omit from tab .",
        "iii due to complete failure on all 19 image registration task , both with rigid and afﬁne transformation ; either too few match point be detect , or the one find result in large erroneoustransformations .",
        "one such fail registration example be illus- trated in fig .",
        "1 .",
        "2 ) results of atlas-based segmentation of brains : table iv show result of atlas-based brain segmentation .",
        "the mean jaccard index be compute for each of the brain region , for ˜d¯ r αamdand mi , with afﬁne registration as report in [ 35 ] .",
        "for ˜d¯r αamd , mean and std .",
        "dev .",
        "be display ; for the comparative result ( miaff , [ 35 ] ) , only mean be report .",
        "we observe that for the whole brain mask , for the aggre- gated overlap , and for 43 out of the 56 distinct region , the propose measure outperform the reported performance obtain with the mi metric ; mi be the best performing measure out of the three evaluate in [ 35 ] .",
        "vi .",
        "d iscussion compared to the traditional similarity measure ( ssd , pcc , mi ) , the propose measure and associate registration methodrequire substantial amount of memory to store the auxiliary data-structures .",
        "a single 3d registration of two mr image of brain may require approximately 4gb of work memorywith a reasonable set of parameter ; contemporary machine for high-end data processing typically have a lot more memory than 4gb , but this requirement can affect how many registra- tions can be perform in parallel on a single machine .",
        "vii .",
        "c onclusion in this study we have adapt a family of distance mea- sures [ 11 ] to gradient descent base image registration , for 2d and 3d image .",
        "we have show that such an extension be feasible and that the very good performance of the mea- sures observe previously for object recognition and templatematching , and their property of a large catchment basin for local optimization , also hold in the context of registration .",
        "this have be show by evaluate the method in four mainways : ( i ) on synthetic test , ( ii ) execution time measure- ment , ( iii ) registration of tem-images of cilium for multi- image super-resolution reconstruction , and ( iv ) atlas-based segmentation with annotated mr brain image .",
        "we observethat the propose method provide outstanding performance for intensity-based afﬁne regis tration in term of robustness , accuracy and symmetry .",
        "it be also faster or similar in speedto the commonly used measure , which allow its practical application .",
        "the framework develop in this study operate on single-layer ( e.g .",
        "gray-scale ) image , but can be extend to multi-layer image such as color image , either by consider a linear sum of distance , or more sophisticated method basedon simultaneous presence or absence of membership in the multiple layer [ 23 ] , [ 37 ] .",
        "future work include extend the measure to non-linear ( deforma ble ) , as well as multi-modal registration .",
        "a cknowledgments the author would like to thank dr. ida-maria sintorn for provide the cilia dataset and the landmark use for the evaluation in sec .",
        "v-f.1 ."
    ],
    "processed_text": "3584 ieee transactions image processing vol 28 7 july 2019 fast robust symmetric image registration based distances combining intensity spatial information johan ofverstedt joakim lindblad member ieee natasa sladoje member ieee abstract intensitybased image registration approach rely similarity measure guide search geometriccorrespondences high affinity image theproperties used measure vital robustness accuracy registration paper symmetric intensity interpolationfree affine registration framework basedon combination intensity spatial information proposedthe excellent performance framework demonstrate acombination synthetic test recover know transformationsin presence noise real application biomedicaland medical image registration 2d 3d imagesthe method exhibit great robustness high accuracythan similarity measure common use insert intoa standard gradientbased registration framework available aspart open source insight segmentation registrationtoolkit method also empirically show lowcomputational cost make practical real application thesource code available index terms image registration set distance gradient meth od optimization cost function iterative algorithm fuzzy set magnetic resonance imaging transmission electron microscopy ntroduction image registration 1 4 process establish correspondence image reference space content image high degree affinity reference space example corre spondence mapping image often refer floating image brain reference space another image often refer reference image brain important structure well colocalized two main category approach image registration featurebased manuscript receive august 1 2018 revise january 22 2019 accept february 11 2019 date publicatio n february 18 2019 date current version june 4 2019 work support part vinnov medtech4health g rant 201602329 grant 201702447 part swedish research council grant 201505878 grant 201704385 part ministry education science technical development republic se rbia grant on174008 grant iii44006 associate editor coordinate review manuscript andapproving publication dr christophoros nikou corresponding author johan ofverstedt j ofverstedt centre image analysis department infor mation technology uppsala university 751 05 uppsala sweden email johanofverstedt @ ituuse j lindblad n sladoje centre image analysis department information technology uppsala university 751 05 uppsala sweden also mathematical institute serbian academy ofsciences arts 11001 belgrade serbi email joakimlindblad @ ituuse natasasladoje @ ituuse digital object identifier 101109/tip20192899947methods extract set feature point corre spondence find whereas intensitybased method use voxelvalues directly evaluate candidate mapping base similarity measure affinity also two main category transformation model linear include special case rigid similarity affine transformation nonlinear deformable combination differentiable transformation model differentiable similarity measure enable use gradientbased local optimization method medical biomedical image r egistration 4 6 important branch general image registration lot effort invest last decade refine tool technique 2 although majority therecent research devote nonlinear registration technique prevalent registration method use clinic still linear registration number situation deformation allow nonlinear registration difficult evaluate may affect reliability diagnosis 2 hence physician may prefer constrained rigid affine alignment considering wide usage fundamental tool improvement rigid affine registration term ofperformance reliability highly relevant practice featurebased image registration dependent ability feature extraction method locate distinct point interest appearing image featureextractors eg sift 7 typically presuppose existence relevance specific local character istics edge corner salient feature distinct point find registration fail oftenthe case medical biome dical application 8 9 intensitybased registra tion therefore tend method choice figure 1 show illustrative example biomedical application featurebased method fails whereas intensitybased method successful intensitybased registration general formulate nonconvex optimization problem similarity measure commonly use optimization criterion typically exhibit ahigh number local optimum 10 11 count tend rapidly increase noi sy condition small region attraction global optimum imposes start position set close optimal solution find optimizer lead reliability challengesfor automated solution study develop registration framework base family symmetric distance measure propose 11 combine intensity spatial information single work license creative commons attribution 30 license information see http //creativecommonsorg/licenses/by/30/ofverstedt et al fast robust symmetric image registration 3585 fig 1 illustrative example biomedical registration task wid ely use featurebased fb method sift implement fijiplugin li near stack alignment1 fail propose intensitybased ib method sec vf1 pe rforms well green point b incorrectly detect match red point match featureextractor fail detect point correspond relevant structure one approxi mately correct match indicate arrow find manually cen tral ring outer ring misalign reference image b f loating image c fb rigid fail fb affine fail e ib rigid+affine measure measure show characterize smooth distance surface significantly local minimum commonly use ntensitybased measure study context emplate matching object recognition work demonstrate slightly modified version distance measure successfully use fast robust affine image registration differentiate distance measure able use efficient gradientbased optimization propose method outperform commonly used similarity measure synthetic real scenario medical biome dical registration task confirm landmarkbased evaluation transmission electron microscopy tem image cilium 12 aim improve multiimage superresolution reconstruction well ii evaluation task atlasbased segmen tation magnetic resonance mr image brain thelpba40dataset 13 intensity interpolation typically required tool con text intensitybased registration perform commonlyused similarity measure since seek transformation intermediate candidate likely map point region outside regular grid treating reference floating image differently term interpolation introduce significant source asymmetry 14 may lead tosuccess failure registration task depend image select reference floating u r propose approach require offgrid intensity value andis interpolationfree term intensity empirical test confirm highly symmetric practice noting intensitybased image registration com putationally demand also include study execution time isolate distance gradient computation throughmicrobenchmarks ii entire image registration task observe propose measure fast compute comparison implementation measuresexisting itkframework 14 propose registra tion framework implement c++/itk well python/numpy/scipy source code available 2 ii p reliminaries previous work images fuzzy sets first recall basic concept relate fuzzy set 15 theoretical framework grayscale image conveniently represent 1imagejnet/linear_stac k_alignment_with_sift 2source code available wwwgithubcom/midagroupafuzzy set son reference set xsis set ordered pair s= { x x xxs } w h e r e xs 01 themembership function ofs risk confusion equate set membership function lets x equivalent x grayscale image directly interpret spatial fuzzy set rescale valid intensity range 01 assume wlog image register anintensity range 01 directly interpret fuzzy set defined reference set image domain case subset z nw eu et h et e r image fuzzy set interchangeably text crisp set cxc binary image special case fuzzy set characteristic function membership function c x =\u00021 forxc 0 forx/c 1 theheight fuzzy set sxsish =max xxss x h e complement sof fuzzy set sis s= { x1s x x xs } ancut fuzzy set sis crisp set defined s= { xxs x } ie thresholded image letpbe element reference set xsafuzzy point p also call fuzzy singleton e fi n e da pxswith height h p defined membership function p x =\u0002h p x=p 0 x\u0006=p 2 b intensitybased registration pointwise distances intensitybased registration general approach image registration defined minimization process dis tance measure intensity overlap point region use optimization criterion given distance measure dand set valid transformation \u0003 intensitybased registration two image floating b reference formulate op timization problem t=arg min t\u0003d b 3 denote valid transform image ainto reference space image b intensitybased similarity/distance measure commonly use image registration sum squared differences ssd 16 pearson c orrelation coefficient pcc 3586 ieee transactions image processing vol 28 7 july 2019 mutual information mi 17 measure point base ie function intensity point belong overlap region two compare set evaluation therefore typically require interpolation ofimage intensity two image pand qdefined common reference setx p qof overlap point measure defined ssd p q =\u0003 vxp q p v q v 2 4 pcc p q =\u0004 vxp q p v avg p q v avg q \u0005 \u0004 vxp q p v avg p 2\u0005 \u0004 vxp q q v avg q 2 5 mi p q =hp+hqhp q 6 5 avg p n da v g q denote mean resp intensity distribution evaluated region 6 joint andmarginal entropies h p hqandhp qof image intensity distribution pand qare defined term estimate probability pof randomly select point vhaving intensity p v q v hp=\u0003 vxp qp p v log p p v 7 hp q=\u0003 vxp qp p v q v log p p v q v 8 intensitybased registration formulate 3 gen eral nonconvex optimization problem large number local optimum especially commonly use pointbased measure ssd pcc mi try overcome optimization challenge resolutionpyramidscheme normally use 18 19 smooth low resolutionimages first register follow registration image increase resolution decrease degree smoothing use transform obtain previous stage asstarting position socalled coarsetofine approach c distances combining intensity spatial information distance sec iib rely intensity overlap point distance present section incorporate also spatial information nonoverlapping point spatial relation consider distance twopoints point set two set commonly use pointtopoint distance euclidean distance denote e given pointtopoint distance b common crisp pointtoset distance point aand set bis b =inf bbd b 9 closely relate crisp pointtoset distance exter nal distance transform crisp set bxb pointto point distance defined dt b x =min yb { x } 10 taking consideration intensity equivalently theheight fuzzy point fuzzy pointtoset inwards distance base integration cuts 11 fuzzy point pand fuzzy set sd e fi n e da p =\u0006h p 0d p 11 dis pointtoset distance defined crisp set complement distance 20 fuzzy pointtoset distance dis p =d p 12 fuzzy pointtoset bidirectional distance p =d p + p 13 arbitrary pointtoset distance sum minimal distances smd 21 defines settoset distance dsmd b =1 2\u0007\u0003 aad b +\u0003 bbd b \b 14 weighted version defined 11 may useful priori information relative importance ofcontributions different point overall distance available wsmd b wa wb =1 2\u0007\u0003 aawa b +\u0003 bbwb b b \b 15 inserting distance 11 13 14 15 provide extension smd family distance fuzzy set 11 refer smd smd wsmdandd wsmd observe fuzzy set distance 22 general distance base 11 13 particular dis tances set empty cuts may give infinite ill defined distance follow previous study introduce parameter dmaxr0 23 limit underlying crisp pointtoset distance double benefit reduce effect outlier ii make distance well defined also image empty cuts distances base optimal mass transport omt wasserstein distance also combine intensity spatial information widely study use image processing 24 omt frame linear programming optimization problem solvable n 3 25 intractable realistic image processing scenario approximation typically consider 25 26 possible incorporate distance image registration framework best knowledge nonlinear deformable registration show computationally demand 27 28 perform preliminary study omtbased meth od use formulation 26 observe high computational demand noisy distance landscapesofverstedt et al fast robust symmetric image registration 3587 absence complete registration framework linear registration base omt family measure exclude empirical part study transformations interpolation symmetry linear transformation relate point one space another via application linear function transformation rigid rotation translation permit affine shearing reflections also permit affine transforma tion rnrncan express matrix multiplication tx= 11 a12 a1nt1 a21 a22 a2nt2 n1an2 ann tn 00 01 x 1 x2 xn 1 16 linear transformation n general transform point sample image grid position outside grid hence interpolator require obtain image intensity transformed point location interpolation alarge source error bias significant contribute factor asymmetry intensitybased registration 14 commonly interpolation require one two image sampling optimization grid image space hence two image treat asymmetrically yield distin ct similarity surface transformation parameter depend image take reference cau se registration task succeed fail depend registration direction e optimization registration differentiable distance measure objec tive function enable use gradientbased optimization algorithm typically ar e significantly efficient derivativefree algorithm local iterative optimizationan effective commonly use subset gradientbased algorithm stochastic gradient descent method 29 consider random subset point optimization iteration incur twofold benefit utilizing random ness escape shallow local optimum implicit distance surface also decrease computational work require per iteration size random subset usually give fraction total number point denote asthe sample fraction approximation cost function random subset sampling new random subset point choose every iteration previousstudies 17 30 show perform well intensitybased registration iii p roposed image registration framework distances extend family distance measure give 15 suitable registration optionally random subsam pling optimization method 30 define new relatedfamily distance measure definition 1 asymmetric average minimal distance given fuzzy set aon reference set x arn fuzzysetbon reference set x brn weight function wa xar0 h e asymmetric averag e minimal distance atob damd b wa =1 \u0004 xxawa x \u0003 xxawa x x b 17 consider pointtoset distance defined 11 13 building asymmetric distance formulate sym metric distance follow definition 2 average minimal distance given fuzzy set aon reference set x arn fuzzy set bon reference set xbrn weight function wa xar0andwb xb r0 h e average minimal distance aand b damd b wa wb =1 2\u000f damd b wa +damd b wb \u0010 18 context image registration utilize damd express weight distance transform fuzzy point x image b transformation fuzzy point x = { x x } give transformation reference point x x = { x x } 19 reflect bounded image domain transformed point fall predefined region mbrnare consider note aandbare digital image xaandxbare typically subsets znand transformed point x xxa necessarily coincide point reference setxb illustrative example give fig 2 therefore provide following definitions suit task image registration definition 3 asymmetric average minimal distance image registration given fuzzy set aon reference set x rn fuzzy set bon x brn weight function wa xa r0 crisp subset mask brn h e asymmetric average minimal distance image registration atob parameterized transformation xarn dr amd b wa mb =1 \u0004 xxwa x \u0003 xxwa x x b 20 x= { x xxat x mb } definition 4 average minimal distance image regis tration given fuzzy set aon reference set x fuzzy set b x b weight function wa xar0andwb xb r0 crisp subset mask mbrn h e average minimal distance image registration aand b parameterized invertible transformation rnrn inverse t1 defined dr amd b wa wb mb =1 2\u000fdr amd b wa mb +dr amd b t1 wb \u0010 21 3588 ieee transactions image processing vol 28 7 july 2019 fig 2 illustration asymmetric average minimal distance image registration source set radius represent associated weight graylevel represent membership b target set bwith associated mask mb c h e transform rotation translation aon top b illustration contribution pointtoset distance central point thickness line show integrated height contribute point inb ef inwards complement part visualized 1d graph xaxis euclidean distance 2d midpoint point left right side origin respectively point left right side midpoint x distance dr amdis base full sampling take account point two set nonzero weight long transform point inside maskassociated set reduce computational cost distance addition enable random iterative sampling propose approximate version r amd definition 5 subsampled average minimal distance image registration given fuzzy set aon reference set x fuzzy set bon x b weight function wa xar0and wb br0 crisp subset mask mbrn thesubsampled average minimal distance image regis tration aand b parameterized invertible transformation rnrn inverse t1 crisp set p axaand p bxb defined dr amd b pa pb wa wb mb =1 2\u000f dr amd apa b wa mb +dr amd bpb t1 wb \u0010 22 inserting 11 13 pointtoset distance 20 hence indirectly 21 22 provide extension ofthis family distance cutbased distance denote dr amd r amd dr amd r amd dr amdand r amd normalization weight sampled point intro duced def 1 render magnitude distance subsequently derivative invariant size andaggregated weight set sampled subset since normalization separately atob btoa direction weight equally even total weight point subset two set different normalization simplify process ofchoosing eg steplength various optimization method make likely default hyperparameter value find reuse across different application b registration propose utilize symmetric distance amd amd cost function 3 define concrete image registration method inserting r amdinto 3 obtain t=arg min t\u0003d r amd b wa wb mb 23 case subset sample set paand pb registration defined t=arg min t\u0003 r amd b pa pb wa wb mb 24 selection new random subset paandpbin itera tion various stochastic gradient descent optimization methodscan realize solve optimization problem state 23 24 efficient gradientbased optimization method par tial derivative distance measure respect transformation parameter tare require c gradients derivative 9 crisp pointtoset distance measure x inndimensional space respect parame ters iof transformation tapplied point xx yield y=t x write ti=n\u0003 j=1d yjyj ti 25 valuesd yjare component partial derivative gradient pointtoset distance point yrn dependent transformation model gradient fuzzy pointtoset distance measure 11 give integral cuts gradient crisp pointtoset distance x =\u0006h x 0d x 26 algorithms digital images rectangular grids distance gradient compute efficiently special case digital image rectangular grid image quantize \u0005n > 0nonzero discrete levels integral 11 26 suitably replace sumsofverstedt et al fast robust symmetric image registration 3589 algorithm 1 distance gradient maps number quantization level typically take small constant choice \u0005=7 nonzero equally space levels previously show provide good tradeoff performance speed noisesensitivity 11 keep experiment need discrete operator approximate gradient x set sdefined rectangular grid space srn > 0 propose use following difference operator provide discrete approximation x \u0006d x =x 1 x n x 27 x =1 2si x+siui xsiui 28 xis indicator function x=\u00021 ford x \u0006=0 0 ford x =0 29 anduiis unitvector along ith dimension indicator function xcauses operator \u0006 x zerovalued point include ie distance transform zerovalued prevent discretization issue along set boundary standard central difference operator yield nonzero gradient cause mea sure overshoot potential voxelperfect overlap create table distance gradient sum image preprocessing st ep use either proce dures alg 1 \u0006dt inwards distance \u0006dt_bd algorithm 2 pointtoset distance gradient wrt bidirectional distance distance gradient may readily compute alg 2 tdenotes number parameter transformation 6 two dimensional 2d affine transformation 12 three dimensional 3d affine transformation procedure alg 1 linear runtime complexity \u0005+1 xa achieve use lineartime algorithm compute distance transform see 31 line 4 alg 1 space complexity algorithm \u0005+ 1 xa gstructures must remain memory enable fast lookup alg 2 figure 3 show example distance gradient sample level alg 2 compute pointtoset distance gradient wrt transformationusing precomputed table runtime complexity tn thus independent \u0005and size aandb algorithm 3 performs complete registration give two image binary mask weight function ini tial transformation algorithm 3 completes nfull iteration however termination criterion may beneficial see sec iv registration consist preprocessing follow loop symmetric set distance derivative compute tis updated\u0006t1 \u0006t line 6 alg 3 denote matrix\u0011t1 j ti\u0012of partial derivative parameter inverse transform t1wrt parameter forward transform matrix relate computed partial derivatives\u0006d2 \u0006t1with parameterization forward transform overall runtime complexity ntn xa+ xb + \u0005+1 xa+xb practical choice n tend range 10003000 depend hyper parameter eg distance parameterspace start position global optimum evaluation sec v confirms empirically th convergence accord 31 32 tend reach 1000 3000 iteration use optimizer decay quantize procedure alg 2 take membership point v v give index iof minimal3590 ieee transactions image processing vol 28 7 july 2019 fig 3 example cut small 2d image b binary mask c cut mask euclidean distance transform c ef gradient approximation distance transform \u0006dt algorithm 3 symmetric registration level 1 \u0005 f rw h c h v membership levels index 0 \u0005equally space levels quantization express quantize v = \u0005a v +05 30 interpolate procedure alg 2 compute value discrete function dand gin point vwhich may grid due application tt h e r ea r emany interpolation scheme propose literature suggest either near neighbor maximal speed linear interpolation high accuracy use since distance gradient fields smooth linearityof integration summation near neighbor linear interpolation may perform preprocessed dandg yield result level interpolatedbefore integration allow efficient computation dis cretized measure require intensity interpolation interpolation operate distance gradient iv mplementation implement propose distance measure regis tration method opensource insight segmentation andregistration toolkit itk 14 choose particular software framework enables use exist optimization framework allows fair comparison well write test widely used implementation reference similarity measure support resolutionpyramids supports anisotropic/scaled voxels relevant algorithm facilitates reproducible evaluation makes proposed measure easily accessible others builtin itk optimizer use registration tool evaluation regularstepgradientdescen toptimizerv4 optimizer base gradient descent initial steplength relaxation factor reduce used steplength gradually direction gradient change order enable convergence high accuracy addition maximum number iteration n two termination criterion use gradient magnitude threshold gmt \u0005 t12+ +d tt2 < gmt 31 ii minimum steplength msl r < msl 32 ris current relaxation coefficient use default value 0 0001 criterion relaxation factor 099 use experiment since perform well preliminary test study willing tradesome potential additional iteration good robustness maximize utilization limited number levels image normalize registration make sure within valid 0 1 interval use following robust normalization technique let p x denote th percentile image xwith respect image intensity norm x =max\u0013 0 min\u0011 1 xp x p1 x p x \u0012\u0014 33 v p erformance analysis evaluate performance propose method 2d 3d image two different scenario perform statistical study synthetically generate image seek recover know transformation measureofverstedt et al fast robust symmetric image registration 3591 registration error compare ground truth loca tions know landmark corresponding registered one ii apply propose framework real image analysis task landmarkbased evaluation registration oftem image 2d atlasbased segmentation evaluation 3d mr image brain compare propose measure registration method commonly use alternative method similarity measure sel ect widely use itk imple mentation optimization framework similarity mea sures ssd pcc mi b aseline intensitybased registration accuracy note pcc measure denotednormalized cross correlation ncc itk framework experiment perform workstation 6core intel i76800k 34ghz processor 48gb ramand 15mb cache operating system use ubuntu 1604 lts compiler use build framework g++ version 540 20160609 version 49 itkframework use test evaluation datasets one biomedical 2d dataset one medical 3d dataset use evaluation 1 tem images cilia 2d dataset 20 image cilium 12 acquire minitem 3imaging system image isotropic size 129 129 pixel pixelsize nm example show fig 1 particular challenge nearrotational symmetry object 9 pair ring locate around central pair ring give 9 plausible solution registration problem alignment central pair take intospecial consideration reduce number solution two dataset come set 20 landmark per image indicate position relevant structure tobe detect analyse 20 ring 2 center 18 circle around center landmark produce domain expert use evaluation registration 2 lpba40 3d lpba40 13 publicly available dataset 40 3d image brain diverse set healthy individual acquire mri image anisotropic size 256 124256 voxels voxelsize 0 86 15086mm 3 dataset come segmentation brain 56 distinct region mark medical expert use study groundtruth evaluation lpba40 include two atlas first 20 40 mr image brain dataset use generate one brain atlas bysymmetric groupwise normalization sygn 32 another atlas create analogously last 20 brain thedataset atlas contain synthesize mr image fuse label category voxels well whole brain mask may use brain extraction b evaluation criteria evaluate accuracy robustness registration method presence noise robustness wrt change 3minitem imaging system develop vironova abof role reference floating image symmetry andtheir speed quantify performance observed framework term following quality measure 1 average error measure ae registration result quantified mean euclidean distance set correspond image corner landmarks l rand lf reference im age space transformation floating image corner landmarks lf w h e r e lris number landmark 4 2d 8 3d quality measure defined ae lr lf =1 lrlr\u0003 i=1de lr lf 34 slight variation measure average minimal error ame use real task cilia registration ame lr lf =1 lrlr\u0003 i=1min xlfde lr x 35 central pair error simply ame cp=ame whereas ring utilize knowledge odd even landmark match odd even landmark image error function outerrings 12 therefore defined ame outer lodd r lodd f leven r leven f =1 2 ame lodd r lodd f +ame leven r leven f 36 2 success rate sr registration consider success ful ae one voxel pixel success rate sr give ae value correspond ratio successful registration wrt set performed one 3 symmetric success rate symsr defined ratio perform registration successful ie ae1 direction ie role reference floating image exchange 4 inverse consistency error ice 33 given set interest xaa transformation tab ab n tba ba ice pair transformation ice tab tba xa =1 xa\u0003 xxade tba tab x x 37 compute ice consider point reference image case wh ere symmetric success observe ae1 direction 5 jaccard index segmentation evaluation two binary set r1and r2 jaccard index defined j r1 r2 = r1r2 r1r2 38 6 execution time evaluate execution time require one iteration registration procedure ie time need compute distance similarity measure derivative full sampling full image resolution two distinct image set well ii execution time complete registrations3592 ieee transactions image processing vol 28 7 july 2019 c parameter tuning distance measure optimization method num ber parameter must properly choose synthetic test indicate follow value lead good optimiza tion performance three pyramid level downsamplingfactors 421 gaussian smoothing = 503000 max 3000 iteration per level initial steplength = 05 number levels use \u0005=7 show provide reasonable tradeoff computational cost sensitivity significant variation intensity robustnessto noise 11 optimal value \u0005is applicationdependent essentially observed case \u0005 > 1 noncrisp outperform crisp binarized representation normalization percentileis normally 5 parameter setting state differently use test synthetic real data synthetic tests synthetic evaluation framework use evaluate performance propose method compare itwith standard tool base ssd pcc mi con trolled environment evaluation construct set transformed version reference image add newinstance gaussian noise generate image transformation select random multivariate uniform distribution rotation measure degree 1 angle 2d image 3 euler angle 3d image translation measure fraction original image size 1 2d tem images cilia three set transformed image build base image nr 1 observed dataset apply following three group transforma tions small contain composition translation 10 image size direction rotation 10 medium contain composition translation rotation least one parameter exceed range small fall within 10 20 image size translation least one direction 10 20of rotation large contain composition translation rotation least one parameter exceed range medium fall within 20 30 image size translation least one direction 20 30of rotation transformed image also corrupt addi tive gaussian noise n 0012 =01 correspond psnr 20 db group transformation applied 1000 time resulting image register image nr 1 time corrupt new instance gaussiannoise evaluate symmetry perform 1000 registration image transform randomly select translation ofup 30 image size rotation 30 n corrupt additive noise n 0012 registration perform twice exchanged role reference image floating image intensitybased registration gradientdescent optimiza tion computationally demand require distance function derivative iteration optimization procedure time compute distance derivativesis directly proportional number sampled point therefore evaluate influence sample fraction registration success observe registration small transformation add noise =01 range sample fraction evaluated sampling fraction 1000 registration perform sr ae compute successful registration ae1 resolution pyramid use test 2 3d mr images brain three set transformed image build base image nr 1 observed dataset apply following three group transformation small contain composition translation 10 image size direction rotation 10 around rotation ax medium contain composition translation rotation least one parameter exceed range small fall within 10 15 image size translation least one direction 10 15of rotation around least one rotation ax large contain composition translation rotation least one parameter exceed therange medium fall within 15 20 image size translation least one direction 15 20 rotation around least one rotation ax transformed image arealso corrupt additive gaussian noise n 001 2 group transformation apply 200 time resulting image register image nr 1 time corrupt new instance gaussian noise e results synthetic tests 1 2d tem images cilia figure 4 show distrib utions registration error ae three transformation class superiority propose measure corresponding registration framework particularly clear medium large transformation reach 100 success rate subpixel accuracy whereas competitor exhibit considerably low accuracy also much lowersuccess rate ie completely fail large number case overall registration performance summarize table complete sampling random sampling 10 point b propose method 100 success rate also 100 symmetric success rate observed measure exhibit much low success rate poor symmetry score second best ssd succeed 54 case succeed symmetrically 31 case registration error successful registration considerably small propose method execution time isconsiderably lower reduced sampling fraction b small impact propose method substantially degrade performance measure figure 5 show registration performance vary sam pling fraction small transformation presence noise =01 consider observe registration performance flattens stabilizes approximately 0 01 sam pling fraction 1 point conclude previousfindings 17 30 suggest random subsampling provide good performance even small sampling fraction apply well propose measureofverstedt et al fast robust symmetric image registration 3593 fig 4 registration error 2d tem image cilium gaussian noise =01 add three observed transform ation class ad examples referencefloating image pair correspond sks eg cumulative histogram fractio n registration registration error ae low give value leave well red vertical line show chosen threshold success ae1 reference image b reference mask c floating image floating mask e small transformation f medium transformation g large transformation table registration synthetic 2d mages ciliathetables show success rate sr verage error ae ofsuccessful registrations symmetric success rate symsr verage inverse consistency error ice average runtime registration withcomplete sampling random subsampling b uccessful registrations ae1 oftransformations including large areconsidered 2 3d mr images brain figure 6 show observed distribution registration error ae three trans formation class clearly confirms proposedmethod robust high performance even large transformation magnitude transformation substantial negative effect performance observed measure figure 7 present bar plot correspond perform synthetic test lpba40dataset consist 200 registration image include large transformation additive gaussian noise n 001 2 fig 5 left/blue sr registration cilium image right/red ae successful registration function sample fraction propose method measure improve almost monotonically withsampling fraction flatten approximately 0 01 successful registration ae1 observe well propose method deliver 100 success rate whereas second best ssd succeed 33 case theregistration error successful registration small propose method observe relative increase execution time propose registration framework 3d case slightly slow er measure 3 execution time analysis number iteration require convergence optimization registration typically range 1000 3000 measures ssd pcc mi use cubic spline interpolation lookups distance map r amdare use linear interpolation table ii show mean standard deviation execution time ofone iteration include computation measure derivative repeat 1000 time 2d 50 time 3d affine image registration observe proposed3594 ieee transactions image processing vol 28 7 july 2019 fig 6 registration error 3d mr image brain gaussian noise =01 add three observed trans formation magnitude class af example referencefloating image pair slice along major axis gi cumulative histogram fraction registration reg istration error ae give value leave well red vertical line show chosen threshold success ae1 reference xy b reference xz c reference yz floating xy e floating xz f floating yz g small transformation h medium transformation large trans formation fig 7 results synthetic registration 3d brain image lpba40 dataset plot show successrate sr b mean error successful registration c average runtime second gistration random subsampling 001 sample fraction highe r well bc lower well bold mark best result wrt statistic table ii time analysis distance similarity value deriv tive computations full resolution image r epeated generate statistics bold marks fastest measure category 2d 3d he2d mages size16001278 3d mages size256124256 measure fast per iteration 2d 3d note execution tim e measurement exclude pre processing f evaluation real applications 1 registration cilia registration multiple cilium instance detect single tem sample enhancement ofdiagnostically relevant substru ctures require pixelaccurate robust method able overcome challenge pose nearrotational symmetry cilium mosttwo possible solution properly align central pair vital successful reconstruction compare performance propose method reported result previous study 12 use intensity base registration pcc similarity measure follow general protocol describe 12 perform first step multistart rigid registration parameterized angle radian translation t= x ty follow second step affine registration initiate best low final distance registration 9 rigid one resolution pyramid use since observe interfere multistart approach facilitate large movement registration perform full resolution without stochastic subsampling rigid registration use small circular binary mask radius 24 pixel position center combine squared circularhann window function affine registration perform use circular binary mask radius 52 pixel mask remove outside background outer plasma isnot helpful guide registration additional weight mask use affine registration step length 0 1w use rigid 0 5 affine registration useofverstedt et al fast robust symmetric image registration 3595 table iii registration cilia p erformance proposed method compared reference results hown mean stddev registration error inpixels wrtthe considered sets landmarks 19 r egistrations r enotes rigid enotes affine dienotes deformable registration b old marks smallest error set landmarks \u0005=7 normalization percentile set 0 rigid stage 1 affine stage featurebased approach also include per formance evaluation sif featuredetector 7 ransac 34 model fitting correspondence point filtering method implement fiji evaluate rigid affine transformation model test areperformed without circular mask describe systematically vary parameter setting use grid search initial gaussian blur test valuesin range 0424 step 04 feature descriptor size test { 12468 } step per scale octave test { 12345 } available parameter set default value since observe insensitivity parameter preliminary test 2 atlasbased segmentation lpba40 35 protocol evaluation distance/similarity measure context image registration propose protocol start withaffine registration result report proceeds deformable registra tion since study focus development affine linear registration frameworkbased propose distance measure compare report affineonly performance improved affine reg istration great significance since high correlation performance affine registration subsequent deformable registration establish start two atlas create utilize advanced neuroimaging tools ants registration software suite opensource evaluation script provide referencestudy 35 utilize atlas create use mutual informa tion since one find 35 best performing use basis whole deformable registration study twofold cross validation utilize first atlas register last 20 brain image second atlas isregistered first 20 brain hence registration brain contribute creation atlas multilabel segmentation defined atlas trans form use transformation parameter find registration compare groundtruth segmentation brain jaccard index 36 calculate per region well entire brain mask propose method base r amdwe use \u0005= 7 normalization percentile 5 n=3000 0 05 sample fraction circular hann windows weightmaskstable iv results atlas based brain segmentation thetable shows mean jaccard index brain regions r amdand mutual information withaffine registration asreported 35 f r amd ean std devare displa yed comparative results mia ff mean reported g results real applications 1 results registration cilia performance propose method together best previously publish result show tab iii table show mean and3596 ieee transactions image processing vol 28 7 july 2019 standard deviation registration error ame pixel 19 registration three consider set land mark central pair outer ring 1+9 ring pair r denote rigid denote affine denotesdeformable registration original study include deformable registration final stage rigid affine step presentedframework base r amdincludes linear rigid affine deformable registration however result include tab iii confirm propose method outperform previous stateoftheart even use rigid affine registration note rigid registration improve alignment central pair degrade alignment outer ring affine registration alignmentof central pair improve far plausibly due le constrain transformation model affine compare rigid observe alignment outer ring total alignment improve substantially featurebased method omit tab iii due complete failure 19 image registration task rigid affine transformation either match point detect one find result large erroneoustransformations one fail registration example illus trated fig 1 2 results atlasbased segmentation brains table iv show result atlasbased brain segmentation mean jaccard index compute brain region r amdand mi affine registration report 35 r amd mean std dev display comparative result miaff 35 mean report observe whole brain mask aggre gated overlap 43 56 distinct region propose measure outperform reported performance obtain mi metric mi best performing measure three evaluate 35 vi iscussion compared traditional similarity measure ssd pcc mi propose measure associate registration methodrequire substantial amount memory store auxiliary datastructures single 3d registration two mr image brain may require approximately 4gb work memorywith reasonable set parameter contemporary machine highend data processing typically lot memory 4gb requirement affect many registra tions perform parallel single machine vii c onclusion study adapt family distance mea sures 11 gradient descent base image registration 2d 3d image show extension feasible good performance mea sures observe previously object recognition templatematching property large catchment basin local optimization also hold context registration show evaluate method four mainways synthetic test ii execution time measure ment iii registration temimages cilium multi image superresolution reconstruction iv atlasbased segmentation annotated mr brain image observethat propose method provide outstanding performance intensitybased affine regis tration term robustness accuracy symmetry also faster similar speedto commonly used measure allow practical application framework develop study operate singlelayer eg grayscale image extend multilayer image color image either consider linear sum distance sophisticated method basedon simultaneous presence absence membership multiple layer 23 37 future work include extend measure nonlinear deforma ble well multimodal registration cknowledgments author would like thank dr idamaria sintorn provide cilia dataset landmark use evaluation sec vf1",
    "bag_of_words": {
        "ieee": 9,
        "transactions": 7,
        "image": 155,
        "processing": 11,
        "vol": 7,
        "july": 7,
        "fast": 11,
        "robust": 11,
        "symmetric": 17,
        "registration": 153,
        "based": 2,
        "distances": 6,
        "combining": 2,
        "intensity": 23,
        "spatial": 8,
        "information": 11,
        "johan": 2,
        "ofverstedt": 3,
        "joakim": 1,
        "lindblad": 2,
        "member": 2,
        "natasa": 1,
        "sladoje": 2,
        "abstract": 1,
        "intensitybased": 18,
        "approach": 7,
        "rely": 2,
        "similarity": 16,
        "measure": 62,
        "guide": 2,
        "search": 2,
        "geometriccorrespondences": 1,
        "high": 8,
        "affinity": 3,
        "theproperties": 1,
        "used": 5,
        "vital": 2,
        "robustness": 6,
        "accuracy": 8,
        "paper": 1,
        "interpolationfree": 2,
        "affine": 30,
        "framework": 20,
        "basedon": 2,
        "combination": 2,
        "proposedthe": 1,
        "excellent": 1,
        "performance": 20,
        "demonstrate": 2,
        "acombination": 1,
        "synthetic": 11,
        "test": 15,
        "recover": 2,
        "know": 3,
        "transformationsin": 1,
        "presence": 4,
        "noise": 13,
        "real": 8,
        "application": 8,
        "biomedicaland": 1,
        "medical": 6,
        "2d": 18,
        "3d": 20,
        "imagesthe": 1,
        "method": 41,
        "exhibit": 4,
        "great": 2,
        "accuracythan": 1,
        "common": 3,
        "use": 60,
        "insert": 1,
        "intoa": 1,
        "standard": 5,
        "gradientbased": 6,
        "available": 7,
        "aspart": 1,
        "open": 1,
        "source": 5,
        "insight": 2,
        "segmentation": 12,
        "registrationtoolkit": 1,
        "also": 16,
        "empirically": 2,
        "show": 23,
        "lowcomputational": 1,
        "cost": 6,
        "make": 4,
        "practical": 3,
        "thesource": 1,
        "code": 3,
        "index": 8,
        "terms": 1,
        "set": 73,
        "distance": 97,
        "gradient": 23,
        "meth": 2,
        "od": 2,
        "optimization": 24,
        "function": 24,
        "iterative": 3,
        "algorithm": 12,
        "fuzzy": 31,
        "magnetic": 2,
        "resonance": 2,
        "imaging": 2,
        "transmission": 2,
        "electron": 2,
        "microscopy": 2,
        "ntroduction": 1,
        "process": 3,
        "establish": 2,
        "correspondence": 2,
        "reference": 36,
        "space": 12,
        "content": 1,
        "degree": 3,
        "example": 9,
        "corre": 2,
        "spondence": 2,
        "mapping": 2,
        "often": 2,
        "refer": 3,
        "floating": 13,
        "brain": 27,
        "another": 3,
        "important": 2,
        "structure": 3,
        "well": 18,
        "colocalized": 1,
        "two": 20,
        "main": 2,
        "category": 4,
        "featurebased": 6,
        "manuscript": 2,
        "receive": 1,
        "august": 1,
        "revise": 1,
        "january": 1,
        "accept": 1,
        "february": 2,
        "date": 2,
        "publicatio": 1,
        "current": 2,
        "version": 7,
        "june": 1,
        "work": 7,
        "support": 2,
        "part": 5,
        "vinnov": 1,
        "medtech4health": 1,
        "rant": 1,
        "grant": 5,
        "swedish": 1,
        "research": 2,
        "council": 1,
        "ministry": 1,
        "education": 1,
        "science": 1,
        "technical": 1,
        "development": 2,
        "republic": 1,
        "se": 2,
        "rbia": 1,
        "on174008": 1,
        "iii44006": 1,
        "associate": 2,
        "editor": 1,
        "coordinate": 1,
        "review": 1,
        "andapproving": 1,
        "publication": 1,
        "dr": 10,
        "christophoros": 1,
        "nikou": 1,
        "corresponding": 3,
        "author": 2,
        "centre": 2,
        "analysis": 6,
        "department": 2,
        "infor": 1,
        "mation": 1,
        "technology": 2,
        "uppsala": 4,
        "university": 2,
        "sweden": 2,
        "email": 2,
        "johanofverstedt": 1,
        "ituuse": 3,
        "mathematical": 1,
        "institute": 1,
        "serbian": 1,
        "academy": 1,
        "ofsciences": 1,
        "arts": 1,
        "belgrade": 1,
        "serbi": 1,
        "joakimlindblad": 1,
        "natasasladoje": 1,
        "digital": 4,
        "object": 4,
        "identifier": 1,
        "101109/tip20192899947methods": 1,
        "extract": 1,
        "feature": 4,
        "point": 52,
        "find": 8,
        "whereas": 5,
        "voxelvalues": 1,
        "directly": 4,
        "evaluate": 11,
        "candidate": 2,
        "base": 16,
        "transformation": 45,
        "model": 6,
        "linear": 14,
        "include": 10,
        "special": 3,
        "case": 13,
        "rigid": 19,
        "nonlinear": 5,
        "deformable": 8,
        "differentiable": 3,
        "enable": 5,
        "local": 8,
        "biomedical": 4,
        "egistration": 1,
        "branch": 1,
        "general": 6,
        "lot": 2,
        "effort": 1,
        "invest": 1,
        "last": 3,
        "decade": 1,
        "refine": 1,
        "tool": 5,
        "technique": 3,
        "although": 1,
        "majority": 1,
        "therecent": 1,
        "devote": 1,
        "prevalent": 1,
        "clinic": 1,
        "still": 1,
        "number": 14,
        "situation": 1,
        "deformation": 1,
        "allow": 3,
        "difficult": 1,
        "may": 11,
        "affect": 2,
        "reliability": 3,
        "diagnosis": 1,
        "hence": 5,
        "physician": 1,
        "prefer": 1,
        "constrained": 1,
        "alignment": 6,
        "considering": 1,
        "wide": 1,
        "usage": 1,
        "fundamental": 1,
        "improvement": 1,
        "term": 6,
        "ofperformance": 1,
        "highly": 2,
        "relevant": 5,
        "practice": 2,
        "dependent": 2,
        "ability": 1,
        "extraction": 2,
        "locate": 2,
        "distinct": 5,
        "interest": 2,
        "appearing": 1,
        "featureextractors": 1,
        "eg": 5,
        "sift": 2,
        "typically": 10,
        "presuppose": 1,
        "existence": 1,
        "relevance": 1,
        "specific": 1,
        "character": 1,
        "istics": 1,
        "edge": 1,
        "corner": 3,
        "salient": 1,
        "fail": 8,
        "oftenthe": 1,
        "biome": 2,
        "dical": 2,
        "registra": 4,
        "tion": 8,
        "therefore": 5,
        "tend": 4,
        "choice": 3,
        "figure": 6,
        "illustrative": 3,
        "fails": 1,
        "successful": 10,
        "formulate": 4,
        "nonconvex": 2,
        "problem": 6,
        "commonly": 10,
        "criterion": 5,
        "ahigh": 1,
        "optimum": 5,
        "count": 1,
        "rapidly": 1,
        "increase": 3,
        "noi": 1,
        "sy": 1,
        "condition": 1,
        "small": 16,
        "region": 10,
        "attraction": 1,
        "global": 2,
        "imposes": 1,
        "start": 4,
        "position": 6,
        "close": 1,
        "optimal": 3,
        "solution": 5,
        "optimizer": 4,
        "lead": 3,
        "challengesfor": 1,
        "automated": 1,
        "study": 16,
        "develop": 3,
        "family": 6,
        "propose": 33,
        "combine": 3,
        "single": 4,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "see": 3,
        "http": 1,
        "//creativecommonsorg/licenses/by/30/ofverstedt": 1,
        "et": 8,
        "al": 6,
        "fig": 10,
        "task": 10,
        "wid": 1,
        "ely": 1,
        "fb": 3,
        "implement": 4,
        "fijiplugin": 1,
        "li": 1,
        "near": 3,
        "stack": 1,
        "alignment1": 1,
        "ib": 2,
        "sec": 5,
        "vf1": 2,
        "pe": 1,
        "rforms": 1,
        "green": 1,
        "incorrectly": 1,
        "detect": 5,
        "match": 5,
        "red": 3,
        "featureextractor": 1,
        "correspond": 6,
        "one": 24,
        "approxi": 1,
        "mately": 1,
        "correct": 1,
        "indicate": 3,
        "arrow": 1,
        "manually": 1,
        "cen": 1,
        "tral": 1,
        "ring": 10,
        "outer": 6,
        "misalign": 1,
        "loating": 1,
        "rigid+affine": 1,
        "characterize": 1,
        "smooth": 3,
        "surface": 3,
        "significantly": 2,
        "minimum": 2,
        "ntensitybased": 1,
        "context": 4,
        "emplate": 1,
        "matching": 1,
        "recognition": 2,
        "slightly": 2,
        "modified": 1,
        "successfully": 1,
        "differentiate": 1,
        "able": 2,
        "efficient": 4,
        "outperform": 4,
        "scenario": 3,
        "confirm": 3,
        "landmarkbased": 2,
        "evaluation": 21,
        "tem": 6,
        "cilium": 7,
        "aim": 1,
        "improve": 5,
        "multiimage": 1,
        "superresolution": 2,
        "reconstruction": 3,
        "ii": 10,
        "atlasbased": 6,
        "segmen": 1,
        "tation": 1,
        "mr": 9,
        "thelpba40dataset": 1,
        "interpolation": 13,
        "required": 1,
        "con": 2,
        "text": 2,
        "perform": 16,
        "commonlyused": 1,
        "since": 9,
        "seek": 2,
        "intermediate": 1,
        "likely": 2,
        "map": 2,
        "outside": 3,
        "regular": 1,
        "grid": 8,
        "treating": 1,
        "differently": 2,
        "introduce": 2,
        "significant": 3,
        "asymmetry": 2,
        "tosuccess": 1,
        "failure": 2,
        "depend": 4,
        "select": 4,
        "require": 12,
        "offgrid": 1,
        "value": 11,
        "andis": 1,
        "empirical": 2,
        "noting": 1,
        "com": 1,
        "putationally": 1,
        "demand": 4,
        "execution": 10,
        "time": 18,
        "isolate": 1,
        "computation": 3,
        "throughmicrobenchmarks": 1,
        "entire": 2,
        "observe": 14,
        "compute": 12,
        "comparison": 2,
        "implementation": 2,
        "measuresexisting": 1,
        "itkframework": 2,
        "c++/itk": 1,
        "python/numpy/scipy": 1,
        "reliminaries": 1,
        "previous": 5,
        "images": 7,
        "sets": 2,
        "first": 6,
        "recall": 1,
        "basic": 1,
        "concept": 1,
        "relate": 4,
        "theoretical": 1,
        "grayscale": 3,
        "conveniently": 1,
        "represent": 3,
        "1imagejnet/linear_stac": 1,
        "k_alignment_with_sift": 1,
        "2source": 1,
        "wwwgithubcom/midagroupafuzzy": 1,
        "son": 1,
        "xsis": 1,
        "ordered": 1,
        "pair": 13,
        "s=": 3,
        "xxs": 2,
        "xs": 2,
        "themembership": 1,
        "ofs": 1,
        "risk": 1,
        "confusion": 1,
        "equate": 1,
        "membership": 7,
        "lets": 1,
        "equivalent": 1,
        "interpret": 2,
        "rescale": 1,
        "valid": 4,
        "range": 9,
        "assume": 1,
        "wlog": 1,
        "register": 5,
        "anintensity": 1,
        "defined": 20,
        "domain": 3,
        "subset": 13,
        "nw": 1,
        "eu": 1,
        "interchangeably": 1,
        "crisp": 14,
        "cxc": 1,
        "binary": 6,
        "characteristic": 1,
        "=\u00021": 1,
        "forxc": 1,
        "forx/c": 1,
        "theheight": 2,
        "sxsish": 1,
        "=max": 1,
        "xxss": 1,
        "complement": 3,
        "sof": 1,
        "sis": 2,
        "x1s": 1,
        "ancut": 1,
        "ie": 7,
        "thresholded": 1,
        "letpbe": 1,
        "element": 1,
        "xsafuzzy": 1,
        "call": 1,
        "singleton": 1,
        "fi": 2,
        "da": 3,
        "pxswith": 1,
        "height": 2,
        "=\u0002h": 1,
        "x=p": 1,
        "x\u0006=p": 1,
        "pointwise": 1,
        "minimization": 1,
        "dis": 5,
        "tance": 1,
        "overlap": 6,
        "given": 8,
        "dand": 2,
        "op": 1,
        "timization": 1,
        "t=arg": 3,
        "min": 3,
        "t\u0003d": 2,
        "denote": 9,
        "transform": 16,
        "ainto": 1,
        "similarity/distance": 1,
        "sum": 4,
        "squared": 2,
        "differences": 1,
        "ssd": 9,
        "pearson": 1,
        "orrelation": 1,
        "coefficient": 2,
        "pcc": 9,
        "mutual": 3,
        "mi": 10,
        "belong": 1,
        "compare": 8,
        "ofimage": 1,
        "pand": 3,
        "qdefined": 1,
        "setx": 1,
        "qof": 2,
        "=\u0003": 1,
        "vxp": 6,
        "=\u0004": 1,
        "avg": 5,
        "2\u0005": 1,
        "=hp+hqhp": 1,
        "mean": 11,
        "resp": 1,
        "distribution": 4,
        "evaluated": 2,
        "joint": 1,
        "andmarginal": 1,
        "entropies": 1,
        "hqandhp": 1,
        "qare": 1,
        "estimate": 1,
        "probability": 1,
        "pof": 1,
        "randomly": 2,
        "vhaving": 1,
        "hp=\u0003": 1,
        "qp": 2,
        "log": 2,
        "hp": 1,
        "q=\u0003": 1,
        "gen": 1,
        "eral": 1,
        "large": 13,
        "especially": 1,
        "pointbased": 1,
        "try": 1,
        "overcome": 2,
        "challenge": 3,
        "resolutionpyramidscheme": 1,
        "normally": 2,
        "low": 5,
        "resolutionimages": 1,
        "follow": 7,
        "resolution": 6,
        "decrease": 2,
        "smoothing": 2,
        "obtain": 4,
        "stage": 4,
        "asstarting": 1,
        "socalled": 1,
        "coarsetofine": 1,
        "iib": 1,
        "present": 2,
        "section": 1,
        "incorporate": 2,
        "nonoverlapping": 1,
        "relation": 1,
        "consider": 10,
        "twopoints": 1,
        "pointtopoint": 2,
        "euclidean": 4,
        "pointtoset": 17,
        "aand": 4,
        "bis": 1,
        "=inf": 1,
        "bbd": 2,
        "closely": 1,
        "exter": 1,
        "nal": 1,
        "bxb": 2,
        "pointto": 1,
        "dt": 1,
        "=min": 1,
        "yb": 1,
        "taking": 1,
        "consideration": 2,
        "equivalently": 1,
        "inwards": 3,
        "integration": 3,
        "cuts": 4,
        "sd": 1,
        "=\u0006h": 2,
        "0d": 2,
        "=d": 2,
        "bidirectional": 2,
        "arbitrary": 1,
        "minimal": 13,
        "smd": 4,
        "defines": 1,
        "settoset": 1,
        "dsmd": 1,
        "=1": 12,
        "2\u0007\u0003": 2,
        "aad": 1,
        "+\u0003": 2,
        "weighted": 1,
        "useful": 1,
        "priori": 1,
        "relative": 2,
        "importance": 1,
        "ofcontributions": 1,
        "different": 4,
        "overall": 3,
        "wsmd": 2,
        "wa": 16,
        "wb": 10,
        "aawa": 1,
        "bbwb": 1,
        "inserting": 3,
        "provide": 10,
        "extension": 3,
        "wsmdandd": 1,
        "particular": 3,
        "tances": 1,
        "empty": 2,
        "give": 12,
        "infinite": 1,
        "ill": 1,
        "parameter": 19,
        "dmaxr0": 1,
        "limit": 1,
        "underlying": 1,
        "double": 1,
        "benefit": 2,
        "reduce": 4,
        "effect": 2,
        "outlier": 1,
        "mass": 1,
        "transport": 1,
        "omt": 3,
        "wasserstein": 1,
        "widely": 3,
        "frame": 1,
        "programming": 1,
        "solvable": 1,
        "intractable": 1,
        "realistic": 1,
        "approximation": 4,
        "possible": 2,
        "best": 8,
        "knowledge": 2,
        "computationally": 2,
        "preliminary": 3,
        "omtbased": 1,
        "formulation": 1,
        "computational": 4,
        "noisy": 1,
        "landscapesofverstedt": 1,
        "absence": 2,
        "complete": 5,
        "exclude": 2,
        "transformations": 1,
        "symmetry": 7,
        "via": 1,
        "rotation": 17,
        "translation": 15,
        "permit": 2,
        "shearing": 1,
        "reflections": 1,
        "transforma": 2,
        "rnrncan": 1,
        "express": 3,
        "matrix": 2,
        "multiplication": 1,
        "tx=": 1,
        "a12": 1,
        "a1nt1": 1,
        "a21": 1,
        "a22": 1,
        "a2nt2": 1,
        "n1an2": 1,
        "ann": 1,
        "tn": 2,
        "x2": 1,
        "xn": 1,
        "sample": 10,
        "interpolator": 1,
        "transformed": 8,
        "location": 1,
        "alarge": 1,
        "error": 21,
        "bias": 1,
        "contribute": 3,
        "factor": 3,
        "sampling": 11,
        "treat": 1,
        "asymmetrically": 1,
        "yield": 4,
        "distin": 1,
        "ct": 1,
        "take": 5,
        "cau": 1,
        "succeed": 4,
        "direction": 11,
        "objec": 1,
        "tive": 3,
        "ar": 1,
        "derivativefree": 1,
        "optimizationan": 1,
        "effective": 1,
        "stochastic": 3,
        "descent": 4,
        "random": 13,
        "iteration": 13,
        "incur": 1,
        "twofold": 2,
        "utilizing": 1,
        "ness": 1,
        "escape": 1,
        "shallow": 1,
        "implicit": 1,
        "per": 7,
        "size": 14,
        "usually": 1,
        "fraction": 15,
        "total": 3,
        "asthe": 1,
        "new": 5,
        "choose": 3,
        "every": 1,
        "previousstudies": 1,
        "iii": 6,
        "roposed": 1,
        "extend": 3,
        "suitable": 1,
        "optionally": 1,
        "subsam": 1,
        "pling": 3,
        "define": 2,
        "relatedfamily": 1,
        "definition": 5,
        "asymmetric": 6,
        "average": 14,
        "aon": 6,
        "arn": 2,
        "fuzzysetbon": 1,
        "brn": 3,
        "weight": 14,
        "xar0": 1,
        "averag": 1,
        "atob": 3,
        "damd": 4,
        "xxawa": 2,
        "building": 1,
        "sym": 1,
        "metric": 2,
        "bon": 3,
        "xbrn": 1,
        "xar0andwb": 2,
        "xb": 3,
        "r0": 3,
        "2\u000f": 2,
        "+damd": 1,
        "utilize": 6,
        "reflect": 1,
        "bounded": 1,
        "fall": 5,
        "predefined": 1,
        "mbrnare": 1,
        "note": 4,
        "aandbare": 1,
        "xaandxbare": 1,
        "subsets": 1,
        "znand": 1,
        "xxa": 1,
        "necessarily": 1,
        "coincide": 1,
        "setxb": 1,
        "following": 6,
        "definitions": 1,
        "suit": 1,
        "rn": 1,
        "xa": 4,
        "mask": 17,
        "parameterized": 4,
        "xarn": 1,
        "amd": 19,
        "mb": 9,
        "xxwa": 2,
        "x=": 1,
        "xxat": 1,
        "regis": 4,
        "tration": 4,
        "mbrn": 2,
        "invertible": 2,
        "rnrn": 2,
        "inverse": 5,
        "t1": 4,
        "2\u000fdr": 1,
        "+dr": 2,
        "illustration": 2,
        "radius": 3,
        "associated": 2,
        "graylevel": 1,
        "target": 1,
        "bwith": 1,
        "top": 1,
        "contribution": 1,
        "central": 9,
        "thickness": 1,
        "line": 5,
        "integrated": 1,
        "inb": 1,
        "ef": 2,
        "visualized": 1,
        "1d": 1,
        "graph": 1,
        "xaxis": 1,
        "midpoint": 2,
        "left": 2,
        "right": 2,
        "side": 2,
        "origin": 1,
        "respectively": 1,
        "amdis": 1,
        "full": 5,
        "account": 1,
        "nonzero": 3,
        "long": 1,
        "inside": 1,
        "maskassociated": 1,
        "addition": 2,
        "approximate": 2,
        "subsampled": 1,
        "xar0and": 1,
        "br0": 1,
        "thesubsampled": 1,
        "axaand": 1,
        "pa": 2,
        "pb": 3,
        "apa": 1,
        "bpb": 1,
        "indirectly": 1,
        "ofthis": 1,
        "cutbased": 1,
        "amdand": 3,
        "normalization": 8,
        "sampled": 3,
        "intro": 1,
        "duced": 1,
        "def": 1,
        "render": 1,
        "magnitude": 4,
        "subsequently": 1,
        "derivative": 9,
        "invariant": 1,
        "andaggregated": 1,
        "separately": 1,
        "btoa": 1,
        "equally": 2,
        "even": 6,
        "simplify": 1,
        "ofchoosing": 1,
        "steplength": 5,
        "various": 2,
        "default": 3,
        "hyperparameter": 1,
        "reuse": 1,
        "across": 1,
        "concrete": 1,
        "amdinto": 1,
        "paand": 1,
        "t\u0003": 1,
        "selection": 1,
        "paandpbin": 1,
        "itera": 1,
        "methodscan": 1,
        "realize": 1,
        "solve": 1,
        "state": 2,
        "par": 1,
        "tial": 2,
        "respect": 3,
        "tare": 1,
        "gradients": 1,
        "inndimensional": 1,
        "parame": 1,
        "ters": 1,
        "iof": 2,
        "tapplied": 1,
        "xx": 1,
        "y=t": 1,
        "write": 2,
        "ti=n\u0003": 1,
        "j=1d": 1,
        "yjyj": 1,
        "ti": 1,
        "valuesd": 1,
        "yjare": 1,
        "component": 1,
        "partial": 3,
        "yrn": 1,
        "integral": 2,
        "algorithms": 1,
        "rectangular": 3,
        "grids": 1,
        "efficiently": 1,
        "quantize": 3,
        "\u0005n": 1,
        "0nonzero": 1,
        "discrete": 4,
        "levels": 6,
        "suitably": 1,
        "replace": 1,
        "sumsofverstedt": 1,
        "maps": 1,
        "quantization": 2,
        "level": 6,
        "constant": 1,
        "\u0005=7": 3,
        "previously": 3,
        "good": 5,
        "tradeoff": 2,
        "speed": 3,
        "noisesensitivity": 1,
        "keep": 1,
        "experiment": 3,
        "need": 2,
        "operator": 4,
        "sdefined": 1,
        "srn": 1,
        "difference": 2,
        "\u0006d": 1,
        "=x": 1,
        "2si": 1,
        "x+siui": 1,
        "xsiui": 1,
        "xis": 1,
        "indicator": 2,
        "x=\u00021": 1,
        "ford": 2,
        "\u0006=0": 1,
        "=0": 1,
        "anduiis": 1,
        "unitvector": 1,
        "along": 3,
        "ith": 1,
        "dimension": 1,
        "xcauses": 1,
        "zerovalued": 2,
        "prevent": 1,
        "discretization": 1,
        "issue": 1,
        "boundary": 1,
        "cause": 1,
        "mea": 4,
        "sure": 2,
        "overshoot": 1,
        "potential": 2,
        "voxelperfect": 1,
        "create": 4,
        "table": 9,
        "preprocessing": 2,
        "st": 1,
        "ep": 1,
        "either": 4,
        "proce": 1,
        "dures": 1,
        "alg": 9,
        "\u0006dt": 2,
        "\u0006dt_bd": 1,
        "wrt": 5,
        "readily": 1,
        "tdenotes": 1,
        "dimensional": 2,
        "three": 12,
        "procedure": 5,
        "runtime": 5,
        "complexity": 4,
        "\u0005+1": 2,
        "achieve": 1,
        "lineartime": 1,
        "\u0005+": 1,
        "gstructures": 1,
        "must": 2,
        "remain": 1,
        "memory": 3,
        "lookup": 1,
        "transformationusing": 1,
        "precomputed": 1,
        "thus": 1,
        "independent": 1,
        "\u0005and": 1,
        "aandb": 1,
        "performs": 1,
        "ini": 1,
        "completes": 1,
        "nfull": 1,
        "however": 2,
        "termination": 2,
        "beneficial": 1,
        "iv": 5,
        "consist": 2,
        "loop": 1,
        "tis": 1,
        "updated\u0006t1": 1,
        "\u0006t": 1,
        "matrix\u0011t1": 1,
        "ti\u0012of": 1,
        "t1wrt": 1,
        "forward": 2,
        "computed": 1,
        "derivatives\u0006d2": 1,
        "\u0006t1with": 1,
        "parameterization": 1,
        "ntn": 1,
        "xa+": 1,
        "xa+xb": 1,
        "hyper": 1,
        "parameterspace": 1,
        "confirms": 2,
        "th": 2,
        "convergence": 3,
        "accord": 1,
        "reach": 2,
        "decay": 1,
        "minimal3590": 1,
        "cut": 2,
        "rw": 1,
        "\u0005equally": 1,
        "\u0005a": 1,
        "+05": 1,
        "interpolate": 1,
        "gin": 1,
        "vwhich": 1,
        "due": 3,
        "tt": 1,
        "ea": 1,
        "emany": 1,
        "scheme": 1,
        "literature": 1,
        "suggest": 2,
        "neighbor": 2,
        "maximal": 1,
        "fields": 1,
        "linearityof": 1,
        "summation": 1,
        "preprocessed": 1,
        "dandg": 1,
        "result": 10,
        "interpolatedbefore": 1,
        "cretized": 1,
        "operate": 2,
        "mplementation": 1,
        "opensource": 2,
        "andregistration": 1,
        "toolkit": 1,
        "itk": 4,
        "software": 2,
        "enables": 1,
        "exist": 1,
        "allows": 1,
        "fair": 1,
        "resolutionpyramids": 1,
        "supports": 1,
        "anisotropic/scaled": 1,
        "voxels": 3,
        "facilitates": 1,
        "reproducible": 1,
        "makes": 1,
        "proposed": 2,
        "easily": 1,
        "accessible": 1,
        "others": 1,
        "builtin": 1,
        "regularstepgradientdescen": 1,
        "toptimizerv4": 1,
        "initial": 3,
        "relaxation": 3,
        "gradually": 1,
        "change": 2,
        "order": 1,
        "maximum": 1,
        "threshold": 3,
        "gmt": 2,
        "t12+": 1,
        "+d": 1,
        "tt2": 1,
        "msl": 2,
        "ris": 1,
        "willing": 1,
        "tradesome": 1,
        "additional": 2,
        "maximize": 1,
        "utilization": 1,
        "limited": 1,
        "normalize": 1,
        "within": 5,
        "interval": 1,
        "let": 1,
        "percentile": 3,
        "xwith": 1,
        "norm": 1,
        "=max\u0013": 1,
        "min\u0011": 1,
        "xp": 1,
        "p1": 1,
        "\u0012\u0014": 1,
        "erformance": 2,
        "statistical": 1,
        "synthetically": 1,
        "generate": 4,
        "measureofverstedt": 2,
        "ground": 1,
        "truth": 1,
        "loca": 1,
        "tions": 3,
        "landmark": 7,
        "registered": 1,
        "apply": 5,
        "oftem": 1,
        "alternative": 1,
        "sel": 1,
        "ect": 1,
        "imple": 1,
        "mentation": 1,
        "sures": 3,
        "aseline": 1,
        "denotednormalized": 1,
        "cross": 2,
        "correlation": 2,
        "ncc": 1,
        "workstation": 1,
        "6core": 1,
        "intel": 1,
        "i76800k": 1,
        "34ghz": 1,
        "processor": 1,
        "48gb": 1,
        "ramand": 1,
        "15mb": 1,
        "cache": 1,
        "operating": 1,
        "system": 3,
        "ubuntu": 1,
        "lts": 1,
        "compiler": 1,
        "build": 3,
        "g++": 1,
        "datasets": 1,
        "dataset": 11,
        "cilia": 8,
        "acquire": 2,
        "minitem": 1,
        "3imaging": 1,
        "isotropic": 1,
        "pixel": 5,
        "pixelsize": 1,
        "nm": 1,
        "nearrotational": 2,
        "around": 5,
        "plausible": 1,
        "intospecial": 1,
        "come": 2,
        "tobe": 1,
        "analyse": 1,
        "center": 3,
        "circle": 1,
        "produce": 1,
        "expert": 2,
        "lpba40": 5,
        "publicly": 1,
        "diverse": 1,
        "healthy": 1,
        "individual": 1,
        "mri": 1,
        "anisotropic": 1,
        "voxelsize": 1,
        "15086mm": 1,
        "mark": 3,
        "groundtruth": 2,
        "atlas": 11,
        "bysymmetric": 1,
        "groupwise": 1,
        "sygn": 1,
        "analogously": 1,
        "thedataset": 1,
        "contain": 7,
        "synthesize": 1,
        "fuse": 1,
        "label": 1,
        "whole": 3,
        "criteria": 1,
        "3minitem": 1,
        "vironova": 1,
        "abof": 1,
        "role": 3,
        "andtheir": 1,
        "quantify": 1,
        "observed": 9,
        "quality": 2,
        "ae": 11,
        "quantified": 1,
        "landmarks": 4,
        "rand": 1,
        "lf": 5,
        "im": 1,
        "age": 1,
        "lris": 1,
        "lr": 4,
        "lrlr\u0003": 2,
        "i=1de": 1,
        "slight": 1,
        "variation": 2,
        "ame": 6,
        "i=1min": 1,
        "xlfde": 1,
        "simply": 1,
        "cp=ame": 1,
        "odd": 2,
        "outerrings": 1,
        "lodd": 4,
        "leven": 4,
        "+ame": 1,
        "success": 15,
        "rate": 11,
        "sr": 6,
        "ful": 1,
        "voxel": 1,
        "ratio": 2,
        "performed": 1,
        "symsr": 2,
        "ae1": 7,
        "exchange": 1,
        "consistency": 2,
        "ice": 5,
        "xaa": 1,
        "tab": 6,
        "ab": 1,
        "tba": 3,
        "ba": 1,
        "xa\u0003": 1,
        "xxade": 1,
        "wh": 1,
        "ere": 1,
        "jaccard": 5,
        "r1and": 1,
        "r2": 2,
        "r1": 1,
        "r1r2": 2,
        "registrations3592": 1,
        "tuning": 1,
        "num": 1,
        "ber": 1,
        "properly": 2,
        "optimiza": 2,
        "pyramid": 3,
        "downsamplingfactors": 1,
        "gaussian": 9,
        "max": 1,
        "reasonable": 2,
        "sensitivity": 1,
        "robustnessto": 1,
        "\u0005is": 1,
        "applicationdependent": 1,
        "essentially": 1,
        "noncrisp": 1,
        "binarized": 1,
        "representation": 1,
        "percentileis": 1,
        "setting": 2,
        "data": 2,
        "tests": 2,
        "itwith": 1,
        "trolled": 1,
        "environment": 1,
        "construct": 1,
        "add": 4,
        "newinstance": 1,
        "multivariate": 1,
        "uniform": 1,
        "angle": 3,
        "euler": 1,
        "original": 2,
        "nr": 4,
        "group": 4,
        "composition": 6,
        "medium": 7,
        "least": 10,
        "exceed": 4,
        "20of": 1,
        "30of": 1,
        "corrupt": 5,
        "addi": 1,
        "=01": 5,
        "psnr": 1,
        "db": 1,
        "applied": 1,
        "resulting": 2,
        "instance": 3,
        "gaussiannoise": 1,
        "ofup": 1,
        "additive": 3,
        "twice": 1,
        "exchanged": 1,
        "gradientdescent": 1,
        "derivativesis": 1,
        "proportional": 1,
        "influence": 1,
        "ax": 3,
        "15of": 1,
        "therange": 1,
        "arealso": 1,
        "results": 8,
        "distrib": 1,
        "utions": 1,
        "class": 4,
        "superiority": 1,
        "particularly": 1,
        "clear": 1,
        "subpixel": 1,
        "competitor": 1,
        "considerably": 2,
        "much": 2,
        "lowersuccess": 1,
        "completely": 1,
        "summarize": 1,
        "poor": 1,
        "score": 1,
        "second": 5,
        "symmetrically": 1,
        "isconsiderably": 1,
        "lower": 2,
        "reduced": 1,
        "impact": 1,
        "substantially": 2,
        "degrade": 2,
        "vary": 2,
        "sam": 2,
        "flattens": 1,
        "stabilizes": 1,
        "approximately": 3,
        "conclude": 1,
        "previousfindings": 1,
        "subsampling": 4,
        "ation": 1,
        "ad": 1,
        "examples": 1,
        "referencefloating": 2,
        "sks": 1,
        "cumulative": 2,
        "histogram": 2,
        "fractio": 1,
        "leave": 2,
        "vertical": 2,
        "chosen": 2,
        "mages": 3,
        "ciliathetables": 1,
        "verage": 2,
        "ofsuccessful": 1,
        "registrations": 2,
        "withcomplete": 1,
        "uccessful": 1,
        "oftransformations": 1,
        "including": 1,
        "areconsidered": 1,
        "trans": 4,
        "formation": 3,
        "clearly": 1,
        "proposedmethod": 1,
        "substantial": 2,
        "negative": 1,
        "bar": 1,
        "plot": 2,
        "lpba40dataset": 1,
        "left/blue": 1,
        "right/red": 1,
        "almost": 1,
        "monotonically": 1,
        "withsampling": 1,
        "flatten": 1,
        "deliver": 1,
        "theregistration": 1,
        "slow": 1,
        "er": 1,
        "measures": 1,
        "cubic": 1,
        "spline": 1,
        "lookups": 1,
        "amdare": 1,
        "deviation": 2,
        "ofone": 1,
        "repeat": 1,
        "proposed3594": 1,
        "af": 1,
        "slice": 1,
        "major": 1,
        "axis": 1,
        "gi": 1,
        "reg": 2,
        "istration": 2,
        "xy": 2,
        "xz": 2,
        "yz": 2,
        "successrate": 1,
        "gistration": 1,
        "highe": 1,
        "bc": 1,
        "bold": 2,
        "statistic": 1,
        "deriv": 1,
        "computations": 1,
        "epeated": 1,
        "statistics": 1,
        "marks": 2,
        "fastest": 1,
        "he2d": 1,
        "size16001278": 1,
        "size256124256": 1,
        "tim": 1,
        "measurement": 1,
        "pre": 1,
        "applications": 2,
        "multiple": 2,
        "enhancement": 1,
        "ofdiagnostically": 1,
        "substru": 1,
        "ctures": 1,
        "pixelaccurate": 1,
        "pose": 1,
        "mosttwo": 1,
        "align": 1,
        "reported": 3,
        "protocol": 3,
        "describe": 2,
        "step": 6,
        "multistart": 2,
        "radian": 1,
        "t=": 1,
        "ty": 1,
        "initiate": 1,
        "final": 2,
        "interfere": 1,
        "facilitate": 1,
        "movement": 1,
        "without": 2,
        "circular": 4,
        "circularhann": 1,
        "window": 1,
        "remove": 1,
        "background": 1,
        "plasma": 1,
        "isnot": 1,
        "helpful": 1,
        "length": 1,
        "1w": 1,
        "useofverstedt": 1,
        "compared": 2,
        "hown": 1,
        "stddev": 1,
        "inpixels": 1,
        "wrtthe": 1,
        "considered": 1,
        "egistrations": 1,
        "enotes": 2,
        "dienotes": 1,
        "old": 1,
        "smallest": 1,
        "formance": 1,
        "sif": 1,
        "featuredetector": 1,
        "ransac": 1,
        "fitting": 1,
        "filtering": 1,
        "fiji": 1,
        "areperformed": 1,
        "systematically": 1,
        "blur": 1,
        "valuesin": 1,
        "descriptor": 1,
        "scale": 1,
        "octave": 1,
        "insensitivity": 1,
        "distance/similarity": 1,
        "withaffine": 2,
        "report": 4,
        "proceeds": 1,
        "focus": 1,
        "frameworkbased": 1,
        "affineonly": 1,
        "improved": 1,
        "significance": 1,
        "subsequent": 1,
        "advanced": 1,
        "neuroimaging": 1,
        "tools": 1,
        "ants": 1,
        "suite": 1,
        "script": 1,
        "referencestudy": 1,
        "informa": 1,
        "performing": 2,
        "basis": 1,
        "validation": 1,
        "isregistered": 1,
        "creation": 1,
        "multilabel": 1,
        "form": 1,
        "calculate": 1,
        "amdwe": 1,
        "\u0005=": 1,
        "n=3000": 1,
        "hann": 1,
        "windows": 1,
        "weightmaskstable": 1,
        "thetable": 1,
        "shows": 1,
        "regions": 1,
        "asreported": 1,
        "ean": 1,
        "std": 2,
        "devare": 1,
        "displa": 1,
        "yed": 1,
        "comparative": 2,
        "mia": 1,
        "ff": 1,
        "together": 1,
        "publish": 1,
        "and3596": 1,
        "land": 1,
        "1+9": 1,
        "denotesdeformable": 1,
        "presentedframework": 1,
        "amdincludes": 1,
        "stateoftheart": 1,
        "alignmentof": 1,
        "far": 1,
        "plausibly": 1,
        "le": 1,
        "constrain": 1,
        "omit": 1,
        "erroneoustransformations": 1,
        "illus": 1,
        "trated": 1,
        "brains": 1,
        "dev": 1,
        "display": 1,
        "miaff": 1,
        "aggre": 1,
        "gated": 1,
        "vi": 1,
        "iscussion": 1,
        "traditional": 1,
        "methodrequire": 1,
        "amount": 1,
        "store": 1,
        "auxiliary": 1,
        "datastructures": 1,
        "4gb": 2,
        "memorywith": 1,
        "contemporary": 1,
        "machine": 2,
        "highend": 1,
        "requirement": 1,
        "many": 1,
        "parallel": 1,
        "vii": 1,
        "onclusion": 1,
        "adapt": 1,
        "feasible": 1,
        "templatematching": 1,
        "property": 1,
        "catchment": 1,
        "basin": 1,
        "hold": 1,
        "four": 1,
        "mainways": 1,
        "ment": 1,
        "temimages": 1,
        "multi": 1,
        "annotated": 1,
        "observethat": 1,
        "outstanding": 1,
        "faster": 1,
        "similar": 1,
        "speedto": 1,
        "singlelayer": 1,
        "multilayer": 1,
        "color": 1,
        "sophisticated": 1,
        "simultaneous": 1,
        "layer": 1,
        "future": 1,
        "deforma": 1,
        "ble": 1,
        "multimodal": 1,
        "cknowledgments": 1,
        "would": 1,
        "like": 1,
        "thank": 1,
        "idamaria": 1,
        "sintorn": 1
    },
    "objective": [
        "in this paper , a symmetric , intensity interpolation-free , afﬁne registration framework basedon a combination of intensity and spatial information be proposed.the excellent performance of the framework be demonstrate on acombination of synthetic test , recover know transformationsin the presence of noise , and real application in biomedicaland medical image registration , for both 2d and 3d images.the method exhibit great robustness and high accuracythan similarity measure in common use , when insert intoa standard gradient-based registration framework available aspart of the open source insight segmentation and registrationtoolkit .",
        "in this study we develop a registration framework base on a family of symmetric distance measure , propose in [ 11 ] , which combine intensity and spatial information in a single this work be license under a creative commons attribution 3.0 license .",
        "illustrative example of a biomedical registration task where a wid ely use feature-based ( fb ) method ( sift , as implement in fiji-plugin li near stack alignment1 ) fail , while the propose intensity-based ( ib ) method ( sec .",
        "the propose method outperform the commonly used similarity measure in both synthetic and real scenario of medical and biome dical registration task , which we conﬁrm by ( i ) landmark-based evaluation on transmission electron microscopy ( tem ) image of cilium [ 12 ] , with the aim of improve multi-image super-resolution reconstruction , as well as ( ii ) evaluation on the task of atlas-based segmen- tation of magnetic resonance ( mr ) image of brain , on thelpba40-dataset [ 13 ] .",
        "i mplementation we implement the propose distance measure and regis- tration method in the open-source insight segmentation andregistration toolkit ( itk ) [ 14 ] .",
        "( 33 ) v. p erformance analysis we evaluate performance of the propose method , both for 2d and 3d image , in two different scenario ; ( i ) we perform a statistical study on synthetically generate image , where we seek to recover know transformation and measureöfverstedt et al .",
        "to compare the propose measure and registration method against the most commonly use alternative method and similarity measure , we sel ect the widely use itk imple- mentation of optimization framework and similarity mea- sures ( ssd , pcc and mi ) as the b aseline of intensity-based registration accuracy .",
        "d. synthetic tests a synthetic evaluation framework be use to evaluate the performance of the propose method , and to compare itwith standard tool base on ssd , pcc , and mi , in a con- trolled environment .",
        "the propose method have 100 % success rate and also 100 % symmetric success rate .",
        "the registration error for successful registration be considerably small for the propose method , while the execution time isconsiderably lower .",
        "the reduced sampling fraction in ( b ) have a small impact on the propose method while substantially degrade the performance of the other measure .",
        "s uccessful registrations ( ae≤1 ) oftransformations up to ( and including ) large , areconsidered 2 ) 3d mr images of brain : figure 6 show the observed distribution of registration error ( ae ) for the three trans- formation class , and clearly conﬁrms that the proposedmethod be robust and with high performance , even for large transformation , while the magnitude of the transformation have a substantial negative effect on the performance of the other observed measure .",
        "( left/blue ) sr for registration of cilium image , and ( right/red ) ae of the successful registration , a s function of sample fraction for the propose method .",
        "here as well , the propose method deliver 100 % success rate , whereas the second best , ssd , succeed in only 33 % of the case .",
        "theregistration error for successful registration be the small for the propose method .",
        "we compare the performance of the propose method with reported result of a previous study [ 12 ] which use intensity- base registration with pcc as similarity measure .",
        ": fast and robust symmetric image registration 3595 table iii registration of cilia : p erformance of the proposed method compared to reference results , s hown as the ‘ mean ( std-dev ) ’ of the registration error ( inpixels ) w.r.t.the considered sets of landmarks for the 19 r egistrations .",
        "since this study focus on the development of an afﬁne ( linear ) registration frameworkbased on the propose distance measure , we compare with the report afﬁne-only performance ; an improved afﬁne reg- istration be of great signiﬁcance since a very high correlation between the performance of the afﬁne registration and that of the subsequent deformable registration have be establish .",
        "for the propose method base on ˜d¯ r αamdwe use \u0005= 7 , normalization percentile 5 % , n=3000 , 0 .05 sample fraction , and circular hann windows as weight-masks.table iv results of atlas -based brain segmentation .thetable shows the mean jaccard index for each of the brain regions for ˜d¯r αamdand mutual information withaffine registration asreported in [ 35 ] .",
        "f or˜d¯r αamd , m ean and std .dev.are displa yed ; for the comparative results ( mia ff ) , only mean was reported g. results of real applications 1 ) results of registration of cilia : performance of the propose method , together with the best previously publish result , be show in tab .",
        "iii conﬁrm , the propose method outperform the previous state-of-the-art , even if use only rigid and afﬁne registration .",
        "d iscussion compared to the traditional similarity measure ( ssd , pcc , mi ) , the propose measure and associate registration methodrequire substantial amount of memory to store the auxiliary data-structures .",
        "we observethat the propose method provide outstanding performance for intensity-based afﬁne regis tration in term of robustness , accuracy and symmetry ."
    ],
    "references": [
        "",
        "REFERENCES [1] J. B. A. Maintz and M. A. Viergever, “A survey of medical image registration,” Med. Image Anal. , vol. 2, no. 1, pp. 1–36, Mar. 1998. [ 2 ] M .A .V i e r g e v e r ,J .B .A .M a i n t z, S. Klein, K. Murphy, M. Staring, and J. P. W. Pluim, “A survey of medical image registration—Underrevieww,” Med. Image Anal. , vol. 33, pp. 140–144, Oct. 2016. [3] B. Zitová and J. Flusser, “Image registration methods: A survey,” Image Vis. Comput. , vol. 21, pp. 977–1000, Oct. 2003. [4] F. P. M. Oliveira and J. M. R. S. Tavares, “Medical image registration: Ar e v i e w , ” Comput. Methods Biomech. Biomed. Eng. , vol. 17, no. 2, pp. 73–93, 2014. [5] A. Sotiras, C. Davatzikos, and N. Paragios, “Deformable medical image registration: A survey,” IEEE Trans. Med. Imag. , vol. 32, no. 7, pp. 1153–1190, Jul. 2013. [6] S. Matl, R. Brosig, M. Baust, N. Navab, and S. Demirci, “Vascular image registration techniques: A living review,” Med. Image Anal. , vol. 35, pp. 1–17, Jan. 2017. [7] D. G. Lowe, “Object recognition from local scale-invariant features,” inProc. 7th IEEE Int. Conf. Comput. Vis. , vol. 2. Sep. 1999, pp. 1150–1157. [ 8 ] B .B e r k e l s ,P .B i n e v ,D .A .B l o m ,W .D a h m e n ,R .C .S h a r p l e y ,a n d T. V ogt, “Optimized imaging using non-rigid registration,” Ultrami- croscopy , vol. 138, pp. 46–56, Mar. 2014. [9] B. Fischer and J. Modersitzki, “Ill-posed medicine—An introduc- tion to image registration,” Inverse Problems , vol. 24, no. 3, 2008, Art. no. 034008. [10] D. Skerl, B. Likar, and F. Pernus, “A protocol for evaluation of similarity measures for rigid registration,” IEEE Trans. Med. Imag. , vol. 25, no. 6, pp. 779–791, Jun. 2006. [11] J. Lindblad and N. Sladoje, “Lin ear time distances between fuzzy sets with applications to pattern matching and classiﬁcation,” IEEE Trans. Image Process. , vol. 23, no. 1, pp. 126–136, Jan. 2014. [12] A. Suveer, N. Sladoje, J. Lindblad, A. Dragomir, and I.-M. Sintorn, “Enhancement of cilia sub-structures by multiple instance registrationand super-resolution reconstruction,” in Proc. Scand. Conf. Image Anal. Cham, Switzerland: Springer, 2017, pp. 362–374. [13] D. W. Shattuck et al. , “Construction of a 3D probabilistic atlas of human cortical structures,” NeuroImage , vol. 39, no. 3, pp. 1064–1080, Feb. 2008. [14] B. B. Avants, N. J. Tustison, M. Stauffer, G. Song, B. Wu, and J. C. Gee, “The insight toolkit image registration framework,” Frontiers Neuroinformatics , vol. 8, p. 44, Apr. 2014. [15] L. A. Zadeh, “Information and control,” Fuzzy sets , vol. 8, no. 3, pp. 338–353, 1965. [16] J. V . Hajnal, N. Saeed, E. J. Soar, A. Oatridge, I. R. Young, and G. M. Bydder, “A registration and inte rpolation procedure for subvoxel matching of serially acquired MR images,” J. Comput. Assist. Tomogr. , vol. 19, no. 2, pp. 289–296, 1995.ÖFVERSTEDT et al. : FAST AND ROBUST SYMMETRIC IMAGE REGISTRATION 3597 [17] P. Viola and W. M. Wells, III, “Alignment by maximization of mutual information,” Int. J. Comput. Vis. , vol. 24, no. 2, pp. 137–154, Sep. 1997. [18] M. Irani and S. Peleg, “Improving resolution by image registration,” CVGIP , Graph. Models Image Process. , vol. 53, no. 3, pp. 231–239, May 1991. [19] A. Rosenfeld, Multiresolution Image Processing and Analysis , vol. 12. Berlin, Germany: Springer, 1984. doi: 10.1007/978-3-642-51590-3. [20] J. Lindblad, V . Curic, and N. Sladoje, “On set distances and their application to image registration,” in Proc. Int. Symp. Image Signal Process. Anal. , Sep. 2009, pp. 449–454. [21] T. Eiter and H. Mannila, “Distance measures for point sets and their computation,” Acta Inf. , vol. 34, no. 2, pp. 109–133, Feb. 1997. [22] P. Brass, “On the nonexistence of Hausdorff-like metrics for fuzzy sets,” Pattern Recognit. Lett. , vol. 23, nos. 1–3, pp. 39–43, 2002. [23] J. Öfverstedt, N. Sladoje, and J. Lindblad, “Distance between vector- valued fuzzy sets based on intersection decomposition with applicationsin object detection,” in Proc. Int. Symp. Math. Morphol. Appl. Signal Image Process. Cham, Switzerland: Springer, 2017, pp. 395–407. [24] Y . Rubner, C. Tomasi, and L. J. Guibas, “The earth mover’s distance as a metric for image retrieval,” Int. J. Comput. Vis. , vol. 40, no. 2, pp. 99–121, Nov. 2000. [25] W. Wang, D. Slepˇ cev, S. Basu, J. A. Ozolek, and G. K. Rohde, “A linear optimal transportation framework for quantifying and visual-izing variations in sets of images,” Int. J. Comput. Vis. , vol. 101, no. 2, pp. 254–269, 2013. [26] O. Pele and M. Werman, “Fast and robust earth mover’s distances,” in Proc. ICCV , vol. 9, Sep./Oct. 2009, pp. 460–467. [27] S. Haker, L. Zhu, A. Tannenbaum , and S. Angenent, “Optimal mass transport for registration and warping,” Int. J. Comput. Vis. , vol. 60, no. 3, pp. 225–240, 2004. [28] T. ur Rehman, E. Haber, G. Pryor, J. Melonakos, and A. Tannenbaum, “3D nonrigid registration via optimal mass transport on the GPU,” Med. Image Anal. , vol. 13, no. 6, pp. 931–940, 2009. [29] S. Ruder. (2016). “An overview of gradient descent optimization algo- rithms.” [Online]. Available: https://arxiv.org/abs/1609.04747 [30] S. Klein, M. Staring, and J. P. W. Pluim, “Evaluation of optimization methods for nonrigid medical image registration using mutual infor-mation and B-splines,” IEEE Trans. Image Process. , vol. 16, no. 12, pp. 2879–2890, Dec. 2007. [31] C. R. Maurer, R. Qi, and V . Raghavan, “A linear time algorithm for computing exact Euclidean distan ce transforms of binary images in arbitrary dimensions,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 25, no. 2, pp. 265–270, Feb. 2003. [32] B. B. Avants et al. , “The optimal template effect in hippocampus studies of diseased populations,” NeuroImage , vol. 49, no. 3, pp. 2457–2466, 2010. [33] G. E. Christensen and H. J. Johnson, “Consistent image registration,” IEEE Trans. Med. Imag. , vol. 20, no. 7, pp. 568–582, Jul. 2001. [34] M. A. Fischler and R. Bolles, “Random sample consensus: A paradigm for model ﬁtting with applications to image analysis and automatedcartography,” Commun. ACM , vol. 24, no. 6, pp. 381–395, 1981.[35] B. B. Avants, N. J. Tustison, G. Song, P. A. Cook, A. Klein, and J. C. Gee, “A reproducible evaluation of ANTs similarity metric per-formance in brain image registration,” NeuroImage , vol. 54, no. 3, pp. 2033–2044, 2011. [36] A. A. Taha and A. Hanbury, “Metrics for evaluating 3D medical image segmentation: Analysis, selection, and tool,” BMC Med. Imag. , vol. 15, no. 1, p. 29, 2015. [37] N. Sladoje and J. Lindblad, “Distan ce between vector-valued represen- tations of objects in images with application in object detection andclassiﬁcation,” in Proc. Int. Workshop Combinat. Image Anal. Cham, Switzerland: Springer, 2017, pp. 243–255. Johan Öfverstedt received the B.Sc. and M.Sc. degrees in computer science from the Department of Information Technology, Uppsala University, Sweden in 2012 and 2017, respectively, where heis currently pursuing the Ph.D. degree in computer-ized image processing with the Centre for Image Analysis. His research interests include distance measures, image registration, object recognition, andoptimization. Joakim Lindblad received the M.Sc. degree in engineering physics and the Ph.D. degree in com- puterized image analysis from Uppsala University, Sweden, in 1997 and 2003, respectively. He is cur-rently a Researcher with the Centre for Image Analy-sis, Uppsala University, Sweden, a Senior Research Associate with the Mathematical Institute, Serbian Academy of Sciences and Arts, Serbia, and the Headof Research at Topgolf Sweden AB, Stockholm, Sweden. His research interests include the devel- opment of general and robust methods for image processing and analysis. Nataša Sladoje received the B.Sc. and M.Sc. degrees in mathematics from the Faculty of Science,University of Novi Sad, Serbia, in 1992 and 1998,respectively, and the Ph.D. degree in computerized image analysis from the Centre for Image Analy- sis, Swedish University of Agricultural Sciences,Uppsala, Sweden, in 2005. She is currently a Senior Lecturer with the Centre for Image Analysis, Upp- sala University, Sweden. She is also with the Mathe-matical Institute, Serbian Academy of Sciences andArts, Belgrade. Her research interests include the theoretical development of image analysis methods with applications in biomedicine and medicine."
    ]
}{
    "name": "Fast Automatic Step Size Estimation for Gradient Descent Optimization of Image Registration",
    "paragraphs": [
        "ieeetransactions on medicalimaging , vol.35 , no.2 , february 2016 391 fast automatic step size estimation for gradient descent optimization of image registration yuchuan qiao * , baldur van lew , boudewijn p. f. lelieveldt , and marius sta ring abstract— fast automatic image registration be an important prerequisite for image-guided cli nical procedure .",
        "however , due to the large number of voxels in an image and the complexity of registration algorithm , this proc es be often very slow .",
        "stochastic gradient descent be a powerful method to iteratively solve the reg- istrationproblem , butreliesforconvergenceonaproperselection of the optimization step size .",
        "this selection be difﬁcult to performmanually , since it depend on the input data , similarity measure and transformation model .",
        "the adaptive stochastic gradient descent ( asgd ) method be an automatic approach , but it comesat a high computational cost .",
        "in this paper , we propose a new computationally efﬁcient method ( fast asgd ) to automatically determine the step size for gradient descent method , by consid-eringtheobserveddistributionof thevoxeldisplacementsbetween iteration .",
        "a relation between the step size and the expectation andvarianceoftheobserveddist ributionisderived.whileasgd have quadratic complexity with respect to the transformation parameter , fast asgd only have linear complexity .",
        "extensive validationhasbeenperformedondifferentdatasetswithdifferentmodalities , inter/intra subject , di fferent similarity measure and transformation model .",
        "for all e xperiments , we obtain similar accuracyasasgd.moreover , thee stimationtimeoffastasgdis r e d u c e dt oav e r y m a l lv a l u e , f r o m4 0st ol e s st h a n1sw h e nt h e number of parameter be 105 , almost 40 time faster .",
        "depending on the registration setting , the total registration time be reducedby a factor of 2.5–7 for the experiment in this paper .",
        "index terms— ( stochastic ) gradient de scent , gradient descent optimization , image registration , optimization step size .",
        "i .",
        "introduction imageregistrationaimstoaligntwoormoreimagesandis an important technique in the ﬁeld of medical image anal- ysis .",
        "it have be use in clinical procedure include radio-therapyandimage-gui desurgery , andothergeneralimageanal- ysis task , such as automatic seg mentation [ 1 ] – [ 4 ] .",
        "however , due to the large number of image voxels , the large amount oftransformation parameter and g eneral algorithm complexity , this process be often very slow [ 5 ] .",
        "this render the technique manuscript receive august 07 , 2 015 ; accept august 30 , 2015 .",
        "date of publicationseptember03,2015 ; dateofcurrentversionfebruary01,2016 .this researchwassupportedbythenetherlandsorganizationforscientiﬁcres earch ( nwoveni639.021.919 ) , bythedutchnationale-infrastructurewiththes up- port of the surf foundation ( e-infra140085 ) , and by the china scholarshipcouncil ( 201206130066 ) .",
        "asterisk indicate correspond author .",
        "* y.qiaoiswiththedivisionofimageprocessing , departmentofradiology , leiden university medical center , 2300rc leiden , the netherlands .",
        "b. van lew , b. p. f. lelieveldt , and m. staring be with the division of imageprocessing , departmentofradi ology , leidenuniversitymedicalce nter , 2300rc leiden , the netherlands .",
        "colorversionsofoneormoreoftheﬁguresinthispaperareavailableonlin e at http : //ieeexplore.ieee.org .",
        "digital object identiﬁer 10.1109/tmi.2015.2476354impractical in time-critical clini cal situation , such as intra-op- erative procedure .",
        "to accelerate image registra tion , multiple method have be develop target the transformation model , the inter-polation scheme or the optimizer .",
        "several study investigate the use of state-of-the-art pro cessing technique exploit multi-threading on the cpu or also the gpu [ 6 ] , [ 7 ] .",
        "othersfocusontheoptimizationschemethatisusedforsolvingimageregistration problem [ 8 ] – [ 10 ] .",
        "methods include gradient de-scent [ 11 ] , [ 12 ] , levenberg-marquardt [ 13 ] , [ 14 ] , quasi-newton [ 15 ] , [ 16 ] , conjugate gradient descent [ 10 ] , evolution strate- gy [ 17 ] , particle swarm method [ 18 ] , [ 19 ] , and stochasticgradient descent method [ 20 ] , [ 21 ] .",
        "among these scheme , the stochastic gradient descent method be a powerful methodfor large scale optimization problem and have a superb perfor-mance in term of computation t ime , with similar accuracy as deterministic ﬁrst order method [ 10 ] .",
        "deterministic secondorder method give slightly bett er accuracy in that study , but at heavily increase computational cost .",
        "it may therefore beconsideredforcaseswhereahighlevelofaccuracyisrequired , in a setting where real-time p erformance be not need .",
        "inthisstudy , webuildonthestochasticgradientdescenttech- nique to solve the optimization problem of image registration [ 12 ] : ( 1 ) in which be the-dimensional ﬁxed image , be the -dimensional moving image , be a parameterized co- ordinate transformation , and thecostfunction to measure the dissimilaritybetweentheﬁxedandmovingimage.tosolvethisproblem , thestochasticgradien tdescentmethodadoptsiterative update to obtain the optimal parameter use the followingform : ( 2 ) where be the iteration number , the step size at iteration , the stochastic gradient of the cost function , with the true gradient and the approximation error .",
        "the stochastic gradient can be efﬁciently calculate use a subset of voxels from the ﬁxed image [ 21 ] or usingsimultaneous perturbation approximation [ 22 ] .",
        "as show pre-viously [ 10 ] , stochastic gradient descent have superior perfor-mance in term of computation time compare to deterministicgradient descent and deterministic second order method suchas quasi-newton , although the latter frequently obtain some-what lower objective value .",
        "similar to second order method , stochastic gradient descent be less prone to get stick in small 0278-0062 © 2015 ieee .",
        "translations and content mining be permit for a cademic research only .",
        "personal use be also permit , but republication / redistribution require ieee permission .",
        "see http : //www.ieee.org/pub lications_standards/publications/rights/index.html for more inform ation.392 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 local minimum compare to deterministic gradient descent [ 23 ] , [ 24 ] .",
        "almost-sure convergence of the stochastic gradient de- scent method be guarantee ( mean that it will converge tothelocalminimum ” withprobability1 ” ) , providedthatthestepsize sequence be a non-increasin g and non-zero sequence with and [ 25 ] .",
        "a suitable step size sequence be very important , because a poorly chosen step sizewill cause problem of estimate value ” bounce ” if this stepsizeistoolarge , orslowconvergenceifitistoosmall [ 26 ] , [ 27 ] .therefore , anexactandautomati callyestimatedstepsize , inde- pendent of problem setting , be essential for the gradient-basedoptimization of image registration .",
        "note that for deterministicquasi-newtonmethodsthestepsizeiscommonlychosenusingan ( in ) exact line search .",
        "methodsthataimtosolvetheproblemofstepsizeestimation can be categorize in three group : manual , semi-automatic , and automatic methods.in 1952 , robbins and monro [ 25 ] pro-posed to manually select a suitable step size sequence .",
        "severalmethodswereproposedafterwardstoimprovetheconvergenceof therobbins-monro method , which focus on the construc-tion of the step size sequence , but still require manual selec-tionoftheinitialstepsize.examplesincludekesten'srule [ 28 ] , gaivoronski 's rule [ 29 ] , and the adaptive two-point step sizegradient method [ 30 ] .",
        "an overview of these method can befound here [ 31 ] , [ 32 ] .",
        "these manual selection method , how-ever , be difﬁcult to use in the practice , because different ap- plication require different se ttings .",
        "especially for image reg- istration , different ﬁxed or move image , different similaritymeasuresortransformationmode lsrequireadifferentstepsize .",
        "for example , it have be report that the step size can differseveralordersofmagnitudebe tweencostfunctions [ 21 ] .more- over , manual selection be time-consuming .",
        "spall [ 22 ] use a step size follow a rule-of-thumb that the step size time the magnitude of the gradient be approxi-mately equal to the small desired change of in the early iterations.theestimationisbasedonapreliminaryregistration , afterwhichthestepsizeismanuallyestimatedandusedinsub-sequent registration .",
        "this manual procedure be not adaptive tothespeciﬁcimages , depend ontheparameterization , an dre- quire set an nonintuitive ‘ desire change ’ in .",
        "forthesemi-automaticselection , suri [ 26 ] andbrennan [ 27 ] propose to use a step size with the same scale as the mag-nitude of observe in the ﬁrst few iteration of a prelimi- nary simulation experiment , in which a latent difference of thestep size between the preliminary experiment and the currentone be inevitable .",
        "bhagalia also use a training method to es-timate the step size of stochasti c gradient descent optimization forimageregistration [ 33 ] .first , apseudogroundtruthwasob-tained use deterministic gradient descent .",
        "then , after severalattempts , the optimal step size be choose to ﬁnd the optimalwarp estimate which have the small error value comparedwiththepseudogroundtruthwarpobtainedintheﬁrststep.thismethod be complex and time-consuming as it require trainingdata , and moreover generalizes train result to new case .",
        "the adaptive stochastic gradient descent method ( asgd ) [ 21 ] propose by klein et al.automatically estimate the step size .",
        "asgd estimate the distribution of the gradient and thedistribution of voxel displacemen t , and ﬁnally calculate theinitial step size base on the vox el displacement .",
        "this method worksforfewparameterswithin reasonabletime , butforalarge numberoftransformationpar ameters , i.e.",
        ", intheorderof or high , the run time be unacceptable and the time use in esti-mating the step size will dominate the optimization [ 34 ] .",
        "thisdisqualiﬁes asgd for real-time image registration task .",
        "in this paper , we propose a new computationally efﬁcient method , fastasgd ( hereafterfasgd ) , toautomaticallyselectthe optimization step sizefor gradient descent optimization , byderiving a relation with the observed voxel displacement .",
        "thispaper extend a conference paper [ 34 ] with detailed method-ology and extensive validation , use many different datasetsofdifferentmodalityandanatomi calstructure.furthermore , we have develop tool to perform extensive validation of ourmethod by interfacing with a large international compute fa-cility.insectionii , themethodtocalculatethestepsizeisintro-duced.thedatasetdescriptionisgiveninsectioniii.theexper-imentalsetuptoevaluatetheperformanceofthenewmethodispresented in section iv .",
        "in section v , the experimental resultsare give .",
        "finally , sections vi and vii conclude the paper .",
        "ii .",
        "m ethod a commonly use choice for the step size estimation in gra- dientdescentistouseamonotoni callynon-increasingsequence .",
        "inthispaperweusethefollowi ngdecayingfunction , whichcan adaptivelytunethestepsizeacco rdingtothedirectionandmag- nitudeofconsecutivegradients , andhasbeenusedfrequentlyinthe stochastic optimization literature [ 5 ] , [ 20 ] , [ 21 ] , [ 25 ] , [ 29 ] , [ 31 ] , [ 32 ] , [ 35 ] , [ 36 ] : ( 3 ) with , , , w h e r e give a theoretically optimal rate of convergence [ 35 ] , and be usedthroughout this paper .",
        "the iteration number be denote by , and .",
        "the function be a sigmoid function with : ( 4 ) in which determine the maximum gain at each iteration , determine the maximal step backward in time , and af- fectstheshapeofthesigmoidfun ction [ 21 ] .areasonablechoice for the maximum of the sigmoid function be , w h i c h implies that the maximum step forward in time equal that ofthe robbins-monro method [ 21 ] .",
        "it have be prove that con-vergenceisguaranteedaslongas [ 21 ] , [ 36 ] .speciﬁcally , fromassumptiona4 [ 36 ] andassumptionb5 [ 21 ] , asymptoticnormalityandconvergencecanbeassuredwhen and .in [ 21 , ( equation ( 59 ) ) ] be use , whichrequirestheestimat ionofthedistributionoftheap- proximation error for the gradient , which be time consuming.moreover , a parameter be introduce which be empirically setto10 % .setting avoidsacostlycomputation , and stillguaranteestheconditionsrequiredforconvergence.fortheqiao et al .",
        ": fast automatic step size estimationfor gradientdescent optimization o f image registr ation 393 minimum of the sigmoid function we choose in this paper , fulﬁlling the convergence criterion .",
        "in the step size sequence , all parameter need to be se- lectedbeforetheoptimizationprocedure.theparameter con- trols the decay rate ; the theoretically optimal value be 1 [ 21 ] , [ 37 ] .theparameter providesastartingpoint , whichhasmost inﬂuenceatthebeginningofthe optimization.fromexperience [ 21 ] , [ 37 ] , provide a reasonable value for most situa- tions .",
        "the parameter in the numerator determine the overall scale of the step size sequence , wh ich be important but difﬁcult to select , since it be dependent on , ,and.t h e t e p sizecandiffersubstantiallybetweenresolutions ( [ 21 , figure4 ] ) and fordifferentcost function ( [ 21 , table2 ] ) .thismeansthatthe problem of estimate the step size sequence be mainly de-terminedby .inthiswork , wethereforefocusonautomatically select the parameter in a less time-consuming manner .",
        "a .",
        "maximum voxel displacement the intuition of the propose step size selection method be thatthevoxeldispl acementsshouldstartwithareasonablevalue and gradually diminish to zero .",
        "the incremental displacement of a voxel in a ﬁxed image domain between iteration and for an iterative optimization scheme be deﬁned as ( 5 ) to ensure that the incremental displacement between each iter- ation be neither too big nor too small , we need to constrain thevoxel 's incremental displacement into a reasonable range .",
        "we assume that the magnitude of the voxel 's incremental dis-placement follow some distribution , whichhas expectation andvariance , inwhich isthenorm.for a translation transform , the vo xel displacement be all equal , sothevarianceiszero ; fornon-rigidregistration , thevoxeldis-placementsvaryspatially , sothevarianceislargerthanzero.tocalculate the magnitude of the incremental displacement , we use the ﬁrst-order taylor expansion to make an approxima-tion of around : ( 6 ) inwhich isthejacobianmatrixofsize .d e ﬁ n i n g and combine with the update rule , can be rewrite as : ( 7 ) for a maximum allow voxe l displacement , klein [ 21 ] introduce a user-deﬁned parameter , which have a physical meaning with the same unit as the image dimension , usuallyin mm .",
        "this imply that the maximum voxel displacement foreach voxel between two iteration s should be not large than : i.e we can use a weakened form for this assumption : ( 8 ) whereis a small probability value often 0.05 .",
        "according to thevysochanskijpetunininequality [ 38 ] , forarandomvariablewithunimodaldistribution , mean andﬁnite , non-zerovari- ance , i f , the following theorem hold : ( 9 ) this can be rewrite as : ( 10 ) based on this boundary , we can approximate ( 8 ) with the fol- lowing expression : ( 11 ) this be slightly different from the square use in [ 21 , equa- tion ( 42 ) ] , which avoid takin g square root for performance reason .",
        "in this paper we be interested in the incremental dis-placements , notitssquare.combi ningwith ( 7 ) , weobtainthere- lationship between step size an d maximum voxel displacement as follow : ( 12 ) b .",
        "maximum step size for deterministic gradient descent from thestepsizefunction itiseasyto ﬁndthemaximumstepsize , andthemax- imum value of , .",
        "this mean that the large stepsizeistakenatthebeginningoftheoptimizationprocedurefor each resolution .",
        "using ( 12 ) , we obtain the following equa- tion of : ( 13 ) for a give , the value of can be estimate from the initial distribution of at the beginning of each resolution .",
        "c. noise compensation for stochastic gradient descent the stochastic gradient descent method combine fast con- vergencewithareasonableaccur acy [ 10 ] .fastestimatesofthe gradient be obtain use a small subset of the ﬁxed imagevoxels , randomly choose in each iteration .",
        "this procedure in- troduces noise to the gradient estimate , thereby inﬂuencing theconvergence rate .",
        "this in turn mean that the optimal step sizeforstochastic gradientdescentwillbedifferentcomparedto de- terministic gradientdescent.whentheapproximationerror increase , the search direction be more unpredictable , thusa small and more careful step sizeisrequired.similarto [ 21 ] we assume that be a zero mean gaussian variable with small variance , and we adopt th e ratio between the expectation of the exact and approximated g radient to modify the step size as follow : ( 14 ) d. summary and implementation details 1 ) the calculation of for exact gradient descent : the cost function use in voxel-based image registration usually394 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 take the following form : ( 15 ) inwhich isasimilaritymeasure , isadiscretesetofvoxel coordinate from the ﬁxed image and be the cardinality of this set .",
        "the gradient of this cost function be : ( 16 ) the reliable estimate of relies on the calculation of the exact gradient .",
        "we obtain a trad e-off between the accuracy of compute with its computation time , by randomly select a sufﬁciently large number of sample from the ﬁxed image.speciﬁcally , to compute ( 16 ) weuseasubset of size equal to the number of transformation parameter .",
        "then , iscomputedateachvoxelco- ordinate .",
        "the expectation and variance of can be calculate use the f ollowing expression : ( 17 ) ( 18 ) 2 ) the calculation of : the above analysis reveals that the noise compensation factor also inﬂuences the initial step size .",
        "this factor require comp utation of the exact gradient andtheapproximategradient .becausethecomputationofthe exact gradientusingall voxelsi stooslow , uniform samplingis use , where the number of sample be determined empiricallyas .",
        "to obtain the stochastic gradient , w ep e r t u r b by add gaussian noise and recompute the gradient , as detail in [ 21 ] .",
        "3 ) the final formula : the noise compensate step size be obtain use the following formula : ( 19 ) in summary , the gradient be ﬁrst calculate use ( 16 ) , and then the magnitude be compute at each voxel , ﬁ - nally be obtain .",
        "in step 2 , the noise compensation be calculate through the pertu rbation process .",
        "finally , be ob- tained through ( 19 ) .",
        "e. performance of proposed method in this section , we compare the time complexity of the fast asgd method with the asgd method .",
        "here we only give theﬁnal formula of the asgd method , for more detail see refer-ence [ 21 ] .",
        "the asgd method use the following equation : ( 20 ) where be a scalar constant relate to the distribution of the exact gradient [ 21 ] , be the covari- ance of the jacobian , and denote the frobenius norm .",
        "from ( 13 ) , the time complexity of fasgd be dominate by three term : the jacobian with size , the gradient of size , and the number of voxels from which the ex- pectation and variance of be calculate .",
        "the matrix com- putation require multiplicationsand addition for each of the voxels , and therefore the time complexity of the propose method be .",
        "the domi- nant term in ( 20 ) be the jacobian ( size ) and its covari- ance matrix ( size ) .",
        "calculating from right to leave require multiplication and addition for and an additional operation for the multiplication with the left-most matrix .",
        "taking into account the number of voxels , thetimecomplexityoftheoriginalasgdmethodisthere- fore , as .this meansthatfasgdhasalineartimecomplexitywithrespecttothe dimension of , while asgd be quadratic in .",
        "for the b-spline transformation model , the size of the non- zeropartofthejacobianismuchsmallerthanthefulljacobian , i.e.",
        ", only , where isdeterminedby theb-splineorder use in this model .",
        "for a cubic b-spline transformation model , eachvoxel isinﬂuencedby controlpoints , so in 2d and in 3d .",
        "forthe fastasgd method the time complexity reduces to for the cubic b-spline model .",
        "however , as the total number of operation for the cal-culation of be still , the time complexity of asgd be .s i n c e , t h ed o m i - nanttermoffasgdbecomesthenumberofsamples , while for asgd it be still a potentially very large number .",
        "iii .",
        "datasets inthissectionwedescribethedatasetsthatwereusedtoeval- uatetheproposedmethod.datas etswerechosentorepresenta broadcategoryofusecases , i.e.",
        ", mono-modalandmulti-modal , intra-patient as well as inter-pat ient , from different anatomical site , and have rigid as well as nonrigid underlie deforma- tions .",
        "the overview of all data s ets be present in table i .",
        "a. rire brain data – multi-modality rigid registration the retrospective image registration evaluation ( rire ) projectprovidesmulti -modalitybrainscanswithagroundtruth for rigid registration evaluation [ 39 ] .",
        "these brain scan wereobtained from 9 patient , where we select ct scan and mrt1scans.fiducialmarkerswereimplanted ineachpatient , andserved as a ground truth .",
        "these marker be manually erasedfrom the image and replace with a simulated backgroundpattern .",
        "inourexperiments , weregisteredthet1mrimage ( move image ) to the ct image ( ﬁxed image ) use rigid registration.atthewebsiteofrire , eightcornerpointsofbothctandmrt1 imagesare provide to evaluate the registration accuracy .",
        "b .",
        "spread lung data – intra-subject nonrigid registration during the spread study [ 40 ] , 3d lung ct image of 19 patient be scan without contrast medium use a toshibaqiao et al .",
        ": fast automatic step size estimationfor gradientdescent optimization o f image registr ation 395 aquilion 4 scanner with scan parameter : 135 kvp ; 20 mas perrotation ; rotationtime0.5s ; collimation:4 5mm.images be reconstruct with a standa rdized protocol optimize for lung densitometry , include a soft fc12 kernel , use a slicethicknessof5mmandanincrementof2.5mm , withaninplaneresolution of around 0.7 0.7 mm .",
        "the patient group , age from 49 to 78 with36 % -87 % predict have moderateto severe copd at gold stage ii and iii , without antitrypsin deﬁciency .",
        "one hundred anatomical co rresponding point from each lung ct image be semi-automa tically extract as a ground truthusingmurphy'smethod [ 41 ] .thealgorithmautomaticallyﬁnds100evenlydistributedpoin tsinthebaseline , onlyatchar- acteristic location .",
        "subsequen tly , correspond point in the follow-up scan be predict by the algorithm and show in a graphical user interface for insp ection and possible correction .",
        "more detail can be find in [ 42 ] .",
        "c. hammers brain data – inter-subject nonrigid registration we use the brain data set develop by ham mers et al .",
        "[ 43 ] , whichcontainsmrimagesof30healthya dultsubjects.theme- dianageofallsubjectswas31years ( r ange 20~ 54 ) , and25of the30subjectswerestronglyrighth andedasdeterminedbyrou- tine pre-scanning screening .",
        "mri sc an be obtain on a 1.5 teslagesigmaechospeedscanne r.acoronalt1weighted3d volumewasacquiredusinganin versionrecoverypreparedfast spoil gradient recall seque nce ( ge ) , te/tr/nex 4.2 msec ( fatandwaterinphase ) /15.5 msec/1 , timeofinversion ( ti ) 450 msec , ﬂip angle 20 , t oo b t a i n 124 slice of 1.5 mm thickness with a ﬁeld of view of 18 24 cmw i t ha1 9 2 256 matrix [ 44 ] .thiscoversthewho lebrainwithvoxelsizesof0.94 0.94 1.5.i m a g e sw e r er e s l i ced to create isotropic voxels of 0.940.940.94 , u s i n gwindowed sinc interpolation .",
        "eachimageismanually segmentedinto83regionsofinterest , which serve as a groun d truth .",
        "all structure be delineate by one investigator o n each mri in turn before the next struc- turewascommenced , thenaseparateneuroanatomicallytrained operator evaluat ed each structure to ensure that consensus be reachedforthed ifﬁcultcases.inourexperiment , weperformed inter-subject r egistration between all patient .",
        "each mr image be treat as a ﬁxed image as well as a move image , so the total number of registration for 30 patient be 870 for each particular pa rameter set .",
        "d. ultrasound data – 4d nonrigid registration we use the 4d abdominal u ltrasound dataset provide by vijayan et al .",
        "[ 45 ] , which contai ns 9 scan from three healthy volunteer at three different position and angle .",
        "eachscan be take over several breathing cycle ( 12 second percycle ) .",
        "these scan be perform on a ge healthcare vivide9 scanner by a skilled physician use an active matrix 4dvolume phase array probe .",
        "the ground truth be 22 well-de ﬁned anatomical landmark , ﬁrst indicate in the ﬁrst time frame by the physician who ac-quired the data , and then manua lly annotate in all 96 time frame by engineer use vv software [ 46 ] .iv .",
        "e xperiment setup in this section , the general experimental setup and the eval- uation measurement be prese nted and more detail about the experimental environment be give .",
        "a .",
        "experimental setup the experiment focus on the property of the fast asgd method in term of registration accuracy , registration runtimeand convergence of the algorithm .",
        "we will compare the pro-posed method with two variant of the original asgd method.whileforfasgd andare ﬁxed , the asgd methodau- tomatically estimate them .",
        "for a fair comparison , a variant oftheasgdmethodisincludedinthecomparison , thatsetstheseparameters to the same value as fasgd : and .",
        "in summary , three method be compare in all the experiment : the original asgd method that automatically es-timatesallparameters ( asgd ) , theasgdmethodwithdefaultsettingsonlyestimating ( ) andthefastasgdmethod ( fasgd ) .thefastasgdmethodhasbeenimplementedusingthec++languageintheopensourceimageregistrationtoolboxelastix [ 37 ] , wheretheasgdmethodisalreadyintegrated .",
        "to thoroughly evaluate fasgd , a variety of image prob- lemsincludingdifferentmodalitiesanddifferentsimilaritymea-suresareconsideredintheexper iments.speciﬁcally , theexper- iments be perform use four different datasets , rigid and nonrigid transformation model , inter/intra subject , four dif-ferentdissimilaritymeasuresan dthreeimagingmodalities.the experiment be group by the experimental aim : registrationaccuracy in section v-a , registr ation time in section v-b and algorithm convergence in sec tion v-c .",
        "the rire brain data be use for the evaluation of rigid registration .",
        "the spreadlung ct data be especially use to verify the performance offasgd on four different dissimilarity measure , include themean square intensity differ ence ( msd ) [ 2 ] , normalized cor- relation ( nc ) [ 2 ] , mutualinformation ( mi ) [ 12 ] andnormalizedmutualinformation ( nmi ) [ 47 ] .thehammers braindataisin-tended to verify inter-subject registration performance .",
        "the ul-trasound data be speciﬁc for 4-d imensional medical image reg- istration , which be more complex .",
        "an overview of the experi-mental setting be give in table i .",
        "for the evaluation of the registration accuracy , the exper- iments on the rire brain data , the spread lung ct dataand the ultrasound abdominal data , be perform on a localw o r k s t a t i o nw i t h2 4g bm e m o r y , l i n u xu b u n t u1 2 .",
        "0 4 .",
        "2l t s64 bit operation system and an intel xeon e5620 cpu with8 core run at 2.4 ghz .",
        "to see the inﬂuence of the pa-rameters andon the registration accuracy , we perform an extremely large scale experiment on the hammers brain datausing the life science grid ( lsgrid ) [ 48 ] , which be a high performancecomputing ( hpc ) facility.wetestedallcombina-tions of the following setting : , ( in mm ) and .",
        "this amount to 252 combination of registra- tion setting and a total of 657,720 registration , see table i.each registration require abo ut 15 minute of computation time , which total about 164,000 core hour of computation , i.e , make the use of an hpc resource essential .",
        "with the lsgrid the run time of the hammers experiment is396 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 table i overview of datasets and experiments .",
        "reducedto2–3days.moredetailsaboutthe lsgrid aregiven in the appendix .",
        "for a fair comparison , all timi ng experiment be carry out on the local workstation .",
        "timings be report for all theregistrations , except for the hammers data set , where we onlyreport timing from a subset .",
        "from ( 19 ) , we know that the run-time be independent of the parameter and .",
        "therefore , for the hammers data , we use andequal to the voxel size .",
        "we randomly select 100 out of the 870 registration , asa sufﬁciently accurate approximation .",
        "the convergence of the algorithm be evaluate in term of the step size , the euclidean dist ance errorand the cost function value , as a function of the iteration number .",
        "all experiment be do use the following routine : ( 1 ) performalinearregistrationbetweenﬁxedandmovingimagetogetacoarsetransformation , usingarigidtransformationfor the rire brain data , an afﬁne transformation for the spread lung ct data , a similarity transformation rigid plus isotropicscaling for the hammers brain dat a , and no initial transforma- tion for the 4d ultrasound data ; ( 2 ) perform a non-linear cubic b-splinebasedregistration [ 49 ] foralldatasetsexcepttheriredata to get the transformation .",
        "for the ultrasound data , the b-spline transformation model propose by metz et al .",
        "[ 50 ] be use , which register all 3d image sequence in a group-wisestrategy toﬁndtheoptimal transformationthatisbothspatially andtemporallysmooth.amoredetailedexplanationofthereg- istration methodology be in [ 45 ] ; ( 3 ) transform the landmarksormovingimagesegmentationsusing ; ( 4 ) evaluatethe result use the evaluation measure deﬁned in section iv-b .",
        "for each experiment , a three lev el multi-resolution strategy be use .",
        "the gaussian smoothing ﬁlter have a standard devi- ation of 2 , 1 and 0.5 mm for each resolution .",
        "for the b-spline transformationmodel , thegridsizeoftheb-splinecontrolpointmeshishalvedineachresolutiontoincreasethetransformation accuracy [ 49 ] .",
        "we use iteration and 5000 sample , except for the ultrasound experiment where we use 2000 it-erations and 2000 sample accord to vijayan [ 45 ] .",
        "we setandequal to the voxel size ( the mean length of the voxel edge ) .",
        "b .",
        "evaluation measures twoevaluationmeasureswereusedtoverifytheregistration accuracy : theeuclideandistanceandthemeanoverlap.theeu-clidean distance measure be give by : ( 21 ) inwhich andarecoordinatesfromtheﬁxedandmoving image , respectively .",
        "for the ri re brain data , 8 corner point and for the spread data 100 co rresponding point be use to evaluate the performance .",
        "fo r the 4d ultrasound image , we adopt the following measure from [ 45 ] : ( 22 ) inwhich andisalandmarkattime place by observer , be the mean of landmark after inverse transformation .",
        "the mean overlap of two segmentation from the image be calculate by the dice similarity coefﬁcient ( dsc ) [ 5 ] : ( 23 ) in which be a labelled region and the total number of region for the hammers data .",
        "to assess the registration accuracy , a wilcoxon sign rank test ( ) for the registration result be perform .",
        "for the spread data , we ﬁrst obtain the mean distance error of100 point for each patient and then perform the wilcoxonsigned rank test to these mean error .",
        "registration smoothness be assess for the spread exper- iment by measure the determinant of the spatial jacobian ofthe transformation , [ 51 ] .",
        "because the ﬂuctuationqiao et al .",
        ": fast automatic step size estimationfor gradientdescent optimization o f image registr ation 397 fig.1 .",
        "euclideandistanceerrorinmmfortherirebraindataperformedusi ng mi .",
        "table ii themedianeuclidean distanceerror ( mm ) for the spread lungct data.thesymbols andindicate a statistically significant difference withasgd and , respectively .",
        "denotesnosignificant difference .",
        "ofshould be relatively small for s mooth transformation , we use the standard deviation of to represent smoothness .",
        "thecomputationtimeisdeterminedbythenumberofparam- eters and the number of voxels sample from the ﬁxed image .",
        "for a small number of parameter the estimation time can beignored , and therefore we only provide the comparison for theb-spline transformation .",
        "both the parameter estimation timeand pure registration time wer emeasured , for each resolution .",
        "v. r esults a .",
        "accuracy results inthissection , wecomparethe registrationaccuracybetween asgd , and fasgd .",
        "1 ) rire brain data : the result show in fig .",
        "1 present the euclidean distance error of the eight corner point from thebrainimages.themedianeuclidean distancebeforeregistration be 21.7 mm.theresult ofthe fasgd method be very similartotheasgdmethod : medianaccuracyis1.6,1.6and1.7mmforasgd , and fasgd , respectively .",
        "the value of the wilcoxonsignedranktestoffasgdcomparedwithasgdand be 0.36 and 0.30 , respectively , indicate no statistical difference .",
        "2 ) spread lung ct data : table ii show the median of the mean euclidean distance error of the 100 correspond pointsof 19 patient for four different similarity measure .",
        "comparedwith asgd , fasgd have a signiﬁcant difference for msd , mi and nmi , but the median error difference be small than0.03 mm .",
        "to compare fasgd and with asgd we deﬁne the euclidean landmark error difference asfig .",
        "2 .",
        "the difference of euclidean distance error in mm compare to asgd forthespreadlungctdata.thetwonumbersonthetopofeachboxdenotethe number of the landmark error large ( leave ) and small ( right ) than 2 a nd , respectively .",
        "all those landmark , except one for nmi , belong to the same patient .",
        "fig .",
        "3 .",
        "box plot of the standard deviation of the jacobian determinant for the four similarity measure .",
        ", for each landmark , a n d i m i l a r l yf o r .t h i s difference be show as a box plot in fig .",
        "2 .",
        "negative numbersmean that fasgd be good than asgd , and vice versa .",
        "it canbeseenthatboth andfasgdprovideresultssimilarto asgd , foralltestedcostfunctions.thespreadofthe box plot for be small than that of fasgd , as this method be almost identical to asgd .",
        "smoothness of the resulting transformation be give in fig .",
        "3 for all similarity measure .",
        "fasgd generate somewhatsmoother transformation over asgd and for the msd , mi and nmi measures.398 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 fig .",
        "4 .",
        "median dice overlap after registration of the hammers brain data , a s a function of and .",
        "a high dsc indicate well reg istration accuracy .",
        "note that in this large scale experiment , each square represent 870 registration , require about 870 15 minutesof computation , i.e.",
        ", almost 200 core hour .",
        "3 ) hammers brain data : inthisexperiment , fasgdiscom- p a r e dw i t ha s g da n d in a large scale intersubject ex- periments on brain mr data , for a range of value of , and the number of iteration .",
        "fig.4showstheoverlapresultsofthe83brainregions.each squarerepresentsthemediandscresultof870brainimagereg-istration pair for a certain parameter combination of , and .",
        "these result show that the original asgd method have a slightly high dsc than fasgd with the same parameter set-ting , but the median dsc difference be small than 0.01 .",
        "notethat the dark black color indicate dsc value between 0 and0.5 , i.e.",
        ", anything between registration failure and low perfor-mance .",
        "the asgd and method fail for , while fasgd fail for .",
        "4 ) ultrasound abdomen data : the result show in fig .",
        "5 present the euclidean distance of 22 landmark fromultrasound image after nonrigid registration .",
        "the medianeuclidean distance before registration be 3.6 mm .",
        "the resultof fasgd be very similar to the original method .",
        "the value of the wilcoxon sign rank test of fasgd compare withasgd and is0.485 and 0.465 , respectively , indicate no statistical difference .",
        "b. runtime results in this section the runtime of the three method , asgd , and fasgd be compare .",
        "1 ) spread lung ct data : theruntimeonspreadlungct dataisshowninfig.6 , inwhichthetimeusedintheestimationsoftheoriginalmethodtakesalargepartofthetotalruntimeperfig.5 .",
        "euclideandistanceinmmoftheregistrationresultsforultrasoun ddata perform use mi .",
        "resolution , whilefasgdconsumesonlyasmallfractionofthe total runtime .",
        "from resolution 1 ( r1 ) to resolution 3 ( r3 ) , thenumber of transformation parameter increasesfrom 4 to 9 .",
        "for both asgd and the estimation time in- crease from 3 second in r1 to 40 second in r3 .",
        "however , fasgdmaintainsaconstantestimationtimeofnomorethan1second .",
        "2 ) hammers brain data : theruntimeresultofthehammers brain data be show in fig .",
        "7 .",
        "for this dataset , in r3 , i.e.",
        ", large than for thespread data , result in largerestimationtimes.forasgdand theestimationtimeinqiao et al .",
        ": fast automatic step size estimationfor gradientdescent optimization o f image registr ation 399 fig .",
        "6 .",
        "runtime of spread lung ct dat a in second .",
        "the black , green and redbarindicateestimationtime , pureregistrationtimeandtotaltimeel apsedin eachresolution , respectively.r1 , r2 , r3indicateathreelevelmulti-re solution strategy from low resolution to high resolution .",
        "thethirdresolutionisalmost95seconds , whileforfasgditis almost 2 order of magnitude small ( ) .",
        "3 ) 4d ultrasound data : the grid spacing of b-spline con- trolpointsusedinthe4dultrasounddataexperimentis15 15 151 and the image size be 227 22922796 , so the total number of b-spline parameter for the third resolution r3is around 8.7 .",
        "from the timing result in fig .",
        "8 , the orig- inalmethodtakesalmost1400seconds , i.e.",
        ", around23minutes , while fasgd only take 40 seconds.fig .",
        "7 .",
        "runtime of hammers brain data experiment in second .",
        "the black , greenandredbarindicateestimationtime , pureregistrationtimeandtot altime elapsedineachresolution , respectively.r1 , r2 , r3indicateathreeleve lmulti- resolution strategy from low resolution to high resolution .",
        "fig .",
        "8 .",
        "runtime of ultrasound data experiment in second .",
        "the black , greenandredbarindicateestimationtime , pureregistrationtimeandtotaltim eelapsed in each resolution , respectively .",
        "r1 , r2 , r3 indicate a three level multi- resolu- tion strategy from low resolution to high resolution .",
        "fig.9 .",
        "runtimeinsecondsoffasgdforultrasoundexperiment.theleftbarindicate estimation time of and the right bar be the estimation time of .",
        "r1 , r2 , r3 indicate a three level multi-resolution strategy from low resol ution to high resolution .",
        "fig .",
        "9 present the runtime of estimate andfor the ultrasounddata.theestimationof takesaconstanttimeduring eachresolution , soforsmall theestimationof dominatesthe total estimation time.400 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 0510152025303540 r2asgd asgdʹ fasgd ( a ) rire01000200030004000500060007000 r2asgd asgdʹ fasgd ( b ) spread 0200040006000800010000 r2asgd asgdʹ fasgd ( c ) hammers0500100015002000 r2asgd asgdʹ fasgd ( d ) ultrasound fig .",
        "10 .",
        "an example of the step size decay use 500 iteration except ul- trasound image data ( 2000 iteration ) in last resolution from four experi ments .",
        "the red line be the original asgd , the black line be and the green line be fasgd .",
        "( a ) rire .",
        "( b ) spread .",
        "( c ) hammers .",
        "( d ) ultrasound .",
        "c. convergence fromeachofthefourexperiments , werandomlyselectedone patientandanalyzedthestepsizesequence .theresultsare present in fig .",
        "10 and show that fasgd take a large step sizethanasgdand forrigidregistrationandasmaller step size for nonrigid regis tration , when use the same .i n addition , the original asgd and take a very similar stepsizeinallexperimentsevenwhen usesthedefault setting for and .",
        "convergence result of the three method be present in fig .",
        "11 for several patient .",
        "fig .",
        "11 ( a ) and ( b ) present the eu- clideandistance ( mm ) ateachiterat ionforthreeresolutionswith respect to the iteration number .",
        "the cost function value be showninfig.11 ( c ) and ( d ) .thethreemethodsbehavesimilarly .",
        "vi .",
        "discussion all experiment in this paper show that the fast asgd method work well both in rigid and nonrigid image regis-tration , show that the method can deal with differently parameterized transformation .",
        "the method be thoroughly evaluatedonavarietyofimaging problem , includingdifferent modality such as ct , mri and ultrasound , intra and inter subject registration , and different anatomical site such as the brain , lung and abdomen .",
        "vari ous image registration setting be test , include four popular similarity measure .",
        "a very large scale experiment investigate the sensitivity of the method to the parameter and .",
        "all experiment show that fasgd have similar accuracy as the asgd method .",
        "for the rigid registration on the rire data and the nonrigid 4d ultrasound experiment there be no sig-niﬁcant statistical differen ce .",
        "for the nonrigid spread lung ctexperimentandthehammersbraindataweobservedstatis- tically signiﬁcant difference , however , these difference wereverysmall : onaveragelessthan0.03mmonthespreaddatafig .",
        "11 .",
        "convergence plot for four different patient .",
        "top row show the e u- clidean distance error ( mm ) as a function of the iteration number .",
        "bottom r ow show the cost function value ( msd ) .",
        "each plot show three resolution .",
        "( a ) ed , patient 1 .",
        "( b ) ed , patient 2 .",
        "( c ) msd , patient 3 .",
        "( d ) msd , patient 4 .",
        "( lessthan5 % ofthevoxelsize ) , andlessthan0.01diceoverlap on brain data .",
        "we conclude that fasgd obtain a very similar registration accuracy as the original asgd method .",
        "all result indicate that there be little difference between asgd and .especiallyfrom fig.10itcanbeobserved that both method take very sim ilar step size during the opti- mization , as well as similar cost function value and euclidean distance error ( fig .",
        "11 ) .",
        "this s uggests that the default value of the parameter andare sufﬁciently accurate , and that indeed the parameter be the most important parameter to estimate .",
        "from fig .",
        "10 it can be observe that fasgd typically esti- mate small step size than asgd , for identical .t h i sw a s also observe for the other patie nt .",
        "fig .",
        "4 conﬁrms this obser- vation , as the accuracy plot for fasgd be somewhat shifted totherightcomparedtotheothertwomethods.thissuggeststhat moresimilarstepsizesmaybeobtainedwhenchoosing about twiceaslargeasforasgd , i.e.",
        ", toincreasethedefaultfromonevoxel size to two .",
        "the accuracy result for the hammers experiment show in fig .",
        "4 present an apparent accuracy increase when forfasgd.rememberthat representsthemaximumallowed voxel displacement per iteration in mm , and that for the med- ical data use in this paper large be unrealistic .",
        "note that for asgd the registration start fail when , a n df o r fasgd when .thetemporaryincreaseinaccuracyat forfasgdisduetoanundesireddecreasein .note thatasgdusestheexactsameterm , see ( 20 ) , butthisdoesnot result in increased accuracy , since asgd be already fail for .",
        "the time performance of the propose method show in section v-b implies that fasgd have a large reduction in time consumption of the step size estimation .",
        "for the spreadexperiment the estimation time in the last resolution be reducedqiao et al .",
        ": fast automatic step size estimationfor gradientdescent optimization o f image registr ation 401 from 40 second to 1 second .",
        "this improvement be crucial for near real-time registration in high dimensional image registration .",
        "from fig .",
        "9 it be observe that a new bottle neck in the step size estimation be the estimation of the noise compensation pa- rameter .",
        "this be because in this work the calculation of the gradient isperformedwitharelativelyhighnumberofvoxels fromtheﬁxedimage.futureworkwillincludetheinvestigation of accelerated method to estimate and so further redu ce the step size estimation time , especially for 4d registration prob- lem .",
        "a direct acceleration possib ility be the use of paralleliza- tion , for example by a gpu implementation , as the gradient computation consist ofan independentloop overthe voxels .",
        "the fasgd method provide a solution for step size se- lection for gradient descent optimi zers .",
        "for newton-like opti- mizers this be typically solve by a line search strategy .",
        "note thatsuchastrategycannotreadil ybeadoptedforstochasticop- timizationduetothestochast icapproximationofthecostfunc- tion [ 52 ] .strengthsofquasi-newtonoptimizersaretheiradapt- abilitytoproblemswheretheparametersarescaledwithrespect to each other , and the a vailability of stop condition .",
        "for fasgd as well as other stochastic gradient descent optimiza- tionroutinestypicallythenumbe rofiterationsisusedtotermi- nate the optimiza tion .",
        "more sophisticated stop condition from deterministic gradient d escent method can not be readily adopted.forexample , duetotheestimationnoise , stoppingcon- ditions ba sed on cost function value or cost function gradient can not be trust .",
        "the alterna tive to compute exact objective value every ( few ) iteration ( s ) , be also not attractive due to the required computation time .",
        "in the elastix implementation a stochastic gradient computation be in the order of 50 m , while exact metric value computation be at least in the order of sec- onds .",
        "a feasible possibility would be to create a stopping con- dition base on a moving average of the noisy objective value or gradient .",
        "the use of the lsgrid for the hammers data experiment be essential , and reduce com putation time from 19 year to about2–3days.ithoweverdidrequireaone-timeinvestmentoftimetodevelopthesoftwaresupportingtheregistrationjobson thegrid.typicalissuesweencounteredwasattemptingtostore the result from hundred of simultaneous execution , whichproved incompatible with maximum transaction rate support by the lsgrid storage resource management service .",
        "we be able to solve this by pool multiple result into a singlestorage operation .",
        "the infrastructure we build therefore screens thesoftwareunderexecutionfr omthecomplexitiesthatareen- counteredwhenrunningonthe lsgrid.atthesametimeitis generic enough to provide a conﬁgurable set of execution en- vironmentstosupportotherexperimentsnotjustthe elastix w o r k ﬂ o wu s e di nt h i sw o r k , a n d can therefore be re-used .",
        "vii .",
        "c onclusion in this paper , a new automatic method ( fasgd ) for es- timating the optimization step size parameter , need for gradient descent optimization method , have be present for image registration .",
        "the parameter be automatically estimate fromthemagnitudeofvoxeldis placement , randomlysampled from the ﬁxed image .",
        "a relation between the step size and theexpectationandvarianceoftheo bservedvoxelsdisplacementis derive .",
        "the propose method have a free parameter , d e ﬁ n i n g the maximally allow incremental displacement between iter- ations .",
        "unlike , it can be interpret in termsof the voxel size ( mm ) .",
        "in addition , it be mostly independent of the application domain , i.e.",
        ", set it equal to the voxel size provide good resultsforallapplicationsevaluatedinthispaper.comparedtotheoriginalasgdmethod , thetimecomplexityofthefasgd method be reduce from quadratic to linear with respect to the dimensionofthetransformationparameters .fortheb-spline transformation , duetoitscompactsupport , thetimecomplexity be far reduce , mak ing the propose method i ndependent of .",
        "the fasgd method be publicly available via the open source image registration toolbox elastix [ 37 ] .",
        "thefasgdmethodwasevaluatedonala rgenumberofreg- istrationscenario'sandshowsasimilaraccuracyastheoriginal asgdmethod.ithoweverimprovesthetimecomplexityofthe stepsizeestimationfrom40se condstonomorethan1second , whenthenumberofparametersis : almost40timesfaster .",
        "dependingontheregistrationsettings , thetotalregistrationtime be reduce by a factor o f 2.5–7 for the experiment in this paper .",
        "appendix thelsgrid infrastructurecomprisesdistributedcomputing and storage resource along with a central grid facility .",
        "in total there be potential forapproximately10000job slots.jobsched-uling be perform use gl ite grid middleware [ 53 ] via the glite workload management s ystem ( wms ) [ 54 ] , which be develop for the european grid infrastructure [ 55 ] .",
        "while it be possible to use this di rectly to schedule registra- tion pipeline job , in practice these relatively short job be a poor ﬁt to the standard queue length in lsgrid .",
        "in addition , unforseen delay in the push schedule mechanism result in a considerable overhead [ 56 ] .",
        "these issue can be address by layer a pull schedule system base on pilot job onto thegrid software infrastructure .",
        "matching job to workload nodes occursonceatpilotjobstartupafterwhichjobtokensarepulled into the pilot job environment .",
        "the concept of pilot jobs wasﬁrst pioneer in the egi grid within dirac [ 57 ] , but we em- ployed a light weight pilot job system develop by surfsara call picas [ 58 ] , [ 59 ] .",
        "the pilot job architecture show in fig .",
        "12 be use to exe- cutethehammerspipeline.picaswasextendedwithawrapper job to perform standard element of the pipeline such as envi-ronmentsetupanddataretrieval.thewrapperjobandtheham- merspipelinearecodedusingpython [ 60 ] .thejobtokenscon- tain the registration parameter to be use and the storage lo-cations for the ﬁxed and move image .",
        "ganga [ 61 ] be use to schedule and monitor pilot job which pull and execute the job-tokensfromthepicasdata base.theoverallprogressofthe executioncanbecheckedbymonito ringthestatusofthejobto- ken use the web browser to access job-token view deﬁned in database .",
        "execution of the hammers pipeline use picas on the ls- gridfollows these step : 1 ) initialize the hammers job token .",
        "( a ) create the job to- ken for each hammers pipeline run .",
        "job tokens contain402 ieee transactions on medicalimaging , vol.35 , no .",
        "2 , february 2016 fig .",
        "12 .",
        "running the hammers pipeline in the pilot job architecture use on the lsgrid .",
        "arrows represent the ﬂow of information .",
        "job parameter and the grid location of the input data .",
        "( b ) upload the input data need to speciﬁc location in grid storage .",
        "( c ) monitor executio np r o g r e s sb yc h e c k i n gj o b token consumption in a browser .",
        "2 ) schedule the pilot job to commence grid execution .",
        "( a ) schedule pilot job with the necessary job requirement usingglitewmsfrominsideganga.additionalinforma- tion be pass to the pilot job concern the runtime en-vironment need .",
        "( b ) monitor the progress of the pilot job use ganga job monitoring .",
        "( c ) glite wms identi- ﬁes cluster match the job r equirements and schedule pilotjobs.oncethepilotisstartedthepicaswrapperjob set up the runtime environment on the worker node .",
        "3 ) job token be consume and execute by the run pilot job .",
        "( a ) retrieve a job token from the picas job token database and mark it as lock .",
        "( b ) the necessary data identiﬁed in the job token for each hammers job isdownloaded by the picas wrap per from grid storage and the hammers pipeline be execute .",
        "( c ) any result be uploaded to the grid storage location as speciﬁed in thejob token .",
        "( d ) the job token be update with the result : success or failure .",
        "in failure case log-ﬁles be append to assist in debug .",
        "4 ) job result can be immediately download while the run be in progress .",
        "all tool that be create be r eusable for other large scale image processing with the lsgrid .",
        "a cknowledgment the rire project be acknowledge for provide a platform for rigid registration evaluati on .",
        "the author be grateful to dr. a. hammers et al.for the adult maximum probability brain atlas .",
        "dr. m.e .",
        "bakker and j. stolk be acknowledge for pro-viding a ground truth for the spread study data use in thispaper .",
        "the 4d ultrasound data be make available by sintefdept .",
        "medical technology and t he norwegian university ofscience and technology in the context of the iiios project ( marie curie itn no 238802 ) ."
    ],
    "processed_text": "ieeetransactions medicalimaging vol35 no2 february 2016 391 fast automatic step size estimation gradient descent optimization image registration yuchuan qiao baldur van lew boudewijn p f lelieveldt marius sta ring abstract fast automatic image registration important prerequisite imageguided cli nical procedure however due large number voxels image complexity registration algorithm proc es often slow stochastic gradient descent powerful method iteratively solve reg istrationproblem butreliesforconvergenceonaproperselection optimization step size selection difficult performmanually since depend input data similarity measure transformation model adaptive stochastic gradient descent asgd method automatic approach comesat high computational cost paper propose new computationally efficient method fast asgd automatically determine step size gradient descent method consideringtheobserveddistributionof thevoxeldisplacementsbetween iteration relation step size expectation andvarianceoftheobserveddist ributionisderivedwhileasgd quadratic complexity respect transformation parameter fast asgd linear complexity extensive validationhasbeenperformedondifferentdatasetswithdifferentmodalities inter/intra subject di fferent similarity measure transformation model e xperiments obtain similar accuracyasasgdmoreover thee stimationtimeoffastasgdis r e u c e dt oav e r l lv l u e f r m4 0st ol e st h n1sw h e nt h e number parameter 105 almost 40 time faster depending registration setting total registration time reducedby factor 257 experiment paper index terms stochastic gradient de scent gradient descent optimization image registration optimization step size introduction imageregistrationaimstoaligntwoormoreimagesandis important technique field medical image anal ysis use clinical procedure include radiotherapyandimagegui desurgery andothergeneralimageanal ysis task automatic seg mentation 1 4 however due large number image voxels large amount oftransformation parameter g eneral algorithm complexity process often slow 5 render technique manuscript receive august 07 2 015 accept august 30 2015 date publicationseptember032015 dateofcurrentversionfebruary012016 researchwassupportedbythenetherlandsorganizationforscientificres earch nwoveni639021919 bythedutchnationaleinfrastructurewiththes port surf foundation einfra140085 china scholarshipcouncil 201206130066 asterisk indicate correspond author yqiaoiswiththedivisionofimageprocessing departmentofradiology leiden university medical center 2300rc leiden netherlands b van lew b p f lelieveldt staring division imageprocessing departmentofradi ology leidenuniversitymedicalce nter 2300rc leiden netherlands colorversionsofoneormoreofthefiguresinthispaperareavailableonlin e http //ieeexploreieeeorg digital object identifier 101109/tmi20152476354impractical timecritical clini cal situation intraop erative procedure accelerate image registra tion multiple method develop target transformation model interpolation scheme optimizer several study investigate use stateoftheart pro cessing technique exploit multithreading cpu also gpu 6 7 othersfocusontheoptimizationschemethatisusedforsolvingimageregistration problem 8 10 methods include gradient descent 11 12 levenbergmarquardt 13 14 quasinewton 15 16 conjugate gradient descent 10 evolution strate gy 17 particle swarm method 18 19 stochasticgradient descent method 20 21 among scheme stochastic gradient descent method powerful methodfor large scale optimization problem superb performance term computation ime similar accuracy deterministic first order method 10 deterministic secondorder method give slightly bett er accuracy study heavily increase computational cost may therefore beconsideredforcaseswhereahighlevelofaccuracyisrequired setting realtime p erformance need inthisstudy webuildonthestochasticgradientdescenttech nique solve optimization problem image registration 12 1 thedimensional fixed image dimensional moving image parameterized co ordinate transformation thecostfunction measure dissimilaritybetweenthefixedandmovingimagetosolvethisproblem thestochasticgradien tdescentmethodadoptsiterative update obtain optimal parameter use followingform 2 iteration number step size iteration stochastic gradient cost function true gradient approximation error stochastic gradient efficiently calculate use subset voxels fixed image 21 usingsimultaneous perturbation approximation 22 show previously 10 stochastic gradient descent superior performance term computation time compare deterministicgradient descent deterministic second order method suchas quasinewton although latter frequently obtain somewhat lower objective value similar second order method stochastic gradient descent less prone get stick small 02780062 2015 ieee translations content mining permit cademic research personal use also permit republication / redistribution require ieee permission see http //wwwieeeorg/pub lications_standards/publications/rights/indexhtml inform ation392 ieee transactions medicalimaging vol35 2 february 2016 local minimum compare deterministic gradient descent 23 24 almostsure convergence stochastic gradient de scent method guarantee mean converge tothelocalminimum withprobability1 providedthatthestepsize sequence nonincreasin g nonzero sequence 25 suitable step size sequence important poorly chosen step sizewill cause problem estimate value bounce stepsizeistoolarge orslowconvergenceifitistoosmall 26 27 therefore anexactandautomati callyestimatedstepsize inde pendent problem setting essential gradientbasedoptimization image registration note deterministicquasinewtonmethodsthestepsizeiscommonlychosenusingan exact line search methodsthataimtosolvetheproblemofstepsizeestimation categorize three group manual semiautomatic automatic methodsin 1952 robbins monro 25 proposed manually select suitable step size sequence severalmethodswereproposedafterwardstoimprovetheconvergenceof therobbinsmonro method focus construction step size sequence still require manual selectionoftheinitialstepsizeexamplesincludekesten'srule 28 gaivoronski 's rule 29 adaptive twopoint step sizegradient method 30 overview method befound 31 32 manual selection method however difficult use practice different ap plication require different se ttings especially image reg istration different fixed move image different similaritymeasuresortransformationmode lsrequireadifferentstepsize example report step size differseveralordersofmagnitudebe tweencostfunctions 21 manual selection timeconsuming spall 22 use step size follow ruleofthumb step size time magnitude gradient approximately equal small desired change early iterationstheestimationisbasedonapreliminaryregistration afterwhichthestepsizeismanuallyestimatedandusedinsubsequent registration manual procedure adaptive tothespecificimages depend ontheparameterization dre quire set nonintuitive desire change forthesemiautomaticselection suri 26 andbrennan 27 propose use step size scale magnitude observe first iteration prelimi nary simulation experiment latent difference thestep size preliminary experiment currentone inevitable bhagalia also use training method estimate step size stochasti c gradient descent optimization forimageregistration 33 first apseudogroundtruthwasobtained use deterministic gradient descent severalattempts optimal step size choose find optimalwarp estimate small error value comparedwiththepseudogroundtruthwarpobtainedinthefirststepthismethod complex timeconsuming require trainingdata moreover generalizes train result new case adaptive stochastic gradient descent method asgd 21 propose klein et alautomatically estimate step size asgd estimate distribution gradient thedistribution voxel displacemen finally calculate theinitial step size base vox el displacement method worksforfewparameterswithin reasonabletime butforalarge numberoftransformationpar ameters ie intheorderof high run time unacceptable time use estimating step size dominate optimization 34 thisdisqualifies asgd realtime image registration task paper propose new computationally efficient method fastasgd hereafterfasgd toautomaticallyselectthe optimization step sizefor gradient descent optimization byderiving relation observed voxel displacement thispaper extend conference paper 34 detailed methodology extensive validation use many different datasetsofdifferentmodalityandanatomi calstructurefurthermore develop tool perform extensive validation ourmethod interfacing large international compute facilityinsectionii themethodtocalculatethestepsizeisintroducedthedatasetdescriptionisgiveninsectioniiitheexperimentalsetuptoevaluatetheperformanceofthenewmethodispresented section iv section v experimental resultsare give finally sections vi vii conclude paper ii ethod commonly use choice step size estimation gra dientdescentistouseamonotoni callynonincreasingsequence inthispaperweusethefollowi ngdecayingfunction whichcan adaptivelytunethestepsizeacco rdingtothedirectionandmag nitudeofconsecutivegradients andhasbeenusedfrequentlyinthe stochastic optimization literature 5 20 21 25 29 31 32 35 36 3 w h e r e give theoretically optimal rate convergence 35 usedthroughout paper iteration number denote function sigmoid function 4 determine maximum gain iteration determine maximal step backward time af fectstheshapeofthesigmoidfun ction 21 areasonablechoice maximum sigmoid function w h c h implies maximum step forward time equal ofthe robbinsmonro method 21 prove convergenceisguaranteedaslongas 21 36 specifically fromassumptiona4 36 andassumptionb5 21 asymptoticnormalityandconvergencecanbeassuredwhen 21 equation 59 use whichrequirestheestimat ionofthedistributionoftheap proximation error gradient time consumingmoreover parameter introduce empirically setto10 setting avoidsacostlycomputation stillguaranteestheconditionsrequiredforconvergencefortheqiao et al fast automatic step size estimationfor gradientdescent optimization f image registr ation 393 minimum sigmoid function choose paper fulfilling convergence criterion step size sequence parameter need se lectedbeforetheoptimizationproceduretheparameter con trols decay rate theoretically optimal value 1 21 37 theparameter providesastartingpoint whichhasmost influenceatthebeginningofthe optimizationfromexperience 21 37 provide reasonable value situa tions parameter numerator determine overall scale step size sequence wh ich important difficult select since dependent andt h e e p sizecandiffersubstantiallybetweenresolutions 21 figure4 fordifferentcost function 21 table2 thismeansthatthe problem estimate step size sequence mainly determinedby inthiswork wethereforefocusonautomatically select parameter less timeconsuming manner maximum voxel displacement intuition propose step size selection method thatthevoxeldispl acementsshouldstartwithareasonablevalue gradually diminish zero incremental displacement voxel fixed image domain iteration iterative optimization scheme defined 5 ensure incremental displacement iter ation neither big small need constrain thevoxel 's incremental displacement reasonable range assume magnitude voxel 's incremental displacement follow distribution whichhas expectation andvariance inwhich isthenormfor translation transform vo xel displacement equal sothevarianceiszero fornonrigidregistration thevoxeldisplacementsvaryspatially sothevarianceislargerthanzerotocalculate magnitude incremental displacement use firstorder taylor expansion make approximation around 6 inwhich isthejacobianmatrixofsize e fi n n g combine update rule rewrite 7 maximum allow voxe l displacement klein 21 introduce userdefined parameter physical meaning unit image dimension usuallyin mm imply maximum voxel displacement foreach voxel two iteration large ie use weakened form assumption 8 whereis small probability value often 005 according thevysochanskijpetunininequality 38 forarandomvariablewithunimodaldistribution mean andfinite nonzerovari ance f following theorem hold 9 rewrite 10 based boundary approximate 8 fol lowing expression 11 slightly different square use 21 equa tion 42 avoid takin g square root performance reason paper interested incremental displacements notitssquarecombi ningwith 7 weobtainthere lationship step size maximum voxel displacement follow 12 b maximum step size deterministic gradient descent thestepsizefunction itiseasyto findthemaximumstepsize andthemax imum value mean large stepsizeistakenatthebeginningoftheoptimizationprocedurefor resolution using 12 obtain following equa tion 13 give value estimate initial distribution beginning resolution c noise compensation stochastic gradient descent stochastic gradient descent method combine fast con vergencewithareasonableaccur acy 10 fastestimatesofthe gradient obtain use small subset fixed imagevoxels randomly choose iteration procedure troduces noise gradient estimate thereby influencing theconvergence rate turn mean optimal step sizeforstochastic gradientdescentwillbedifferentcomparedto de terministic gradientdescentwhentheapproximationerror increase search direction unpredictable thusa small careful step sizeisrequiredsimilarto 21 assume zero mean gaussian variable small variance adopt th e ratio expectation exact approximated g radient modify step size follow 14 summary implementation details 1 calculation exact gradient descent cost function use voxelbased image registration usually394 ieee transactions medicalimaging vol35 2 february 2016 take following form 15 inwhich isasimilaritymeasure isadiscretesetofvoxel coordinate fixed image cardinality set gradient cost function 16 reliable estimate relies calculation exact gradient obtain trad eoff accuracy compute computation time randomly select sufficiently large number sample fixed imagespecifically compute 16 weuseasubset size equal number transformation parameter iscomputedateachvoxelco ordinate expectation variance calculate use f ollowing expression 17 18 2 calculation analysis reveals noise compensation factor also influences initial step size factor require comp utation exact gradient andtheapproximategradient becausethecomputationofthe exact gradientusingall voxelsi stooslow uniform samplingis use number sample determined empiricallyas obtain stochastic gradient w ep e r u r b add gaussian noise recompute gradient detail 21 3 final formula noise compensate step size obtain use following formula 19 summary gradient first calculate use 16 magnitude compute voxel fi nally obtain step 2 noise compensation calculate pertu rbation process finally ob tained 19 e performance proposed method section compare time complexity fast asgd method asgd method give thefinal formula asgd method detail see reference 21 asgd method use following equation 20 scalar constant relate distribution exact gradient 21 covari ance jacobian denote frobenius norm 13 time complexity fasgd dominate three term jacobian size gradient size number voxels ex pectation variance calculate matrix com putation require multiplicationsand addition voxels therefore time complexity propose method domi nant term 20 jacobian size covari ance matrix size calculating right leave require multiplication addition additional operation multiplication leftmost matrix taking account number voxels thetimecomplexityoftheoriginalasgdmethodisthere fore meansthatfasgdhasalineartimecomplexitywithrespecttothe dimension asgd quadratic bspline transformation model size non zeropartofthejacobianismuchsmallerthanthefulljacobian ie isdeterminedby thebsplineorder use model cubic bspline transformation model eachvoxel isinfluencedby controlpoints 2d 3d forthe fastasgd method time complexity reduces cubic bspline model however total number operation calculation still time complexity asgd n c e h ed nanttermoffasgdbecomesthenumberofsamples asgd still potentially large number iii datasets inthissectionwedescribethedatasetsthatwereusedtoeval uatetheproposedmethoddatas etswerechosentorepresenta broadcategoryofusecases ie monomodalandmultimodal intrapatient well interpat ient different anatomical site rigid well nonrigid underlie deforma tions overview data ets present table rire brain data multimodality rigid registration retrospective image registration evaluation rire projectprovidesmulti modalitybrainscanswithagroundtruth rigid registration evaluation 39 brain scan wereobtained 9 patient select ct scan mrt1scansfiducialmarkerswereimplanted ineachpatient andserved ground truth marker manually erasedfrom image replace simulated backgroundpattern inourexperiments weregisteredthet1mrimage move image ct image fixed image use rigid registrationatthewebsiteofrire eightcornerpointsofbothctandmrt1 imagesare provide evaluate registration accuracy b spread lung data intrasubject nonrigid registration spread study 40 3d lung ct image 19 patient scan without contrast medium use toshibaqiao et al fast automatic step size estimationfor gradientdescent optimization f image registr ation 395 aquilion 4 scanner scan parameter 135 kvp 20 mas perrotation rotationtime05s collimation4 5mmimages reconstruct standa rdized protocol optimize lung densitometry include soft fc12 kernel use slicethicknessof5mmandanincrementof25mm withaninplaneresolution around 07 07 mm patient group age 49 78 with36 87 predict moderateto severe copd gold stage ii iii without antitrypsin deficiency one hundred anatomical co rresponding point lung ct image semiautoma tically extract ground truthusingmurphy'smethod 41 thealgorithmautomaticallyfinds100evenlydistributedpoin tsinthebaseline onlyatchar acteristic location subsequen tly correspond point followup scan predict algorithm show graphical user interface insp ection possible correction detail find 42 c hammers brain data intersubject nonrigid registration use brain data set develop ham mers et al 43 whichcontainsmrimagesof30healthya dultsubjectstheme dianageofallsubjectswas31years r ange 20~ 54 and25of the30subjectswerestronglyrighth andedasdeterminedbyrou tine prescanning screening mri sc obtain 15 teslagesigmaechospeedscanne racoronalt1weighted3d volumewasacquiredusinganin versionrecoverypreparedfast spoil gradient recall seque nce ge te/tr/nex 42 msec fatandwaterinphase /155 msec/1 timeofinversion ti 450 msec flip angle 20 oo b n 124 slice 15 mm thickness field view 18 24 cmw ha1 9 2 256 matrix 44 thiscoversthewho lebrainwithvoxelsizesof094 094 15i g e sw e r er e l ced create isotropic voxels 094094094 u n gwindowed sinc interpolation eachimageismanually segmentedinto83regionsofinterest serve groun truth structure delineate one investigator n mri turn next struc turewascommenced thenaseparateneuroanatomicallytrained operator evaluat ed structure ensure consensus reachedforthed ifficultcasesinourexperiment weperformed intersubject r egistration patient mr image treat fixed image well move image total number registration 30 patient 870 particular pa rameter set ultrasound data 4d nonrigid registration use 4d abdominal u ltrasound dataset provide vijayan et al 45 contai ns 9 scan three healthy volunteer three different position angle eachscan take several breathing cycle 12 second percycle scan perform ge healthcare vivide9 scanner skilled physician use active matrix 4dvolume phase array probe ground truth 22 wellde fined anatomical landmark first indicate first time frame physician acquired data manua lly annotate 96 time frame engineer use vv software 46 iv e xperiment setup section general experimental setup eval uation measurement prese nted detail experimental environment give experimental setup experiment focus property fast asgd method term registration accuracy registration runtimeand convergence algorithm compare proposed method two variant original asgd methodwhileforfasgd andare fixed asgd methodau tomatically estimate fair comparison variant oftheasgdmethodisincludedinthecomparison thatsetstheseparameters value fasgd summary three method compare experiment original asgd method automatically estimatesallparameters asgd theasgdmethodwithdefaultsettingsonlyestimating andthefastasgdmethod fasgd thefastasgdmethodhasbeenimplementedusingthec++languageintheopensourceimageregistrationtoolboxelastix 37 wheretheasgdmethodisalreadyintegrated thoroughly evaluate fasgd variety image prob lemsincludingdifferentmodalitiesanddifferentsimilaritymeasuresareconsideredintheexper imentsspecifically theexper iments perform use four different datasets rigid nonrigid transformation model inter/intra subject four differentdissimilaritymeasuresan dthreeimagingmodalitiesthe experiment group experimental aim registrationaccuracy section va registr ation time section vb algorithm convergence sec tion vc rire brain data use evaluation rigid registration spreadlung ct data especially use verify performance offasgd four different dissimilarity measure include themean square intensity differ ence msd 2 normalized cor relation nc 2 mutualinformation mi 12 andnormalizedmutualinformation nmi 47 thehammers braindataisintended verify intersubject registration performance ultrasound data specific 4d imensional medical image reg istration complex overview experimental setting give table evaluation registration accuracy exper iments rire brain data spread lung ct dataand ultrasound abdominal data perform localw r k nw h2 4g bm e r l n u xu b u n u1 2 0 4 2l s64 bit operation system intel xeon e5620 cpu with8 core run 24 ghz see influence parameters andon registration accuracy perform extremely large scale experiment hammers brain datausing life science grid lsgrid 48 high performancecomputing hpc facilitywetestedallcombinations following setting mm amount 252 combination registra tion setting total 657720 registration see table ieach registration require abo ut 15 minute computation time total 164000 core hour computation ie make use hpc resource essential lsgrid run time hammers experiment is396 ieee transactions medicalimaging vol35 2 february 2016 table overview datasets experiments reducedto23daysmoredetailsaboutthe lsgrid aregiven appendix fair comparison timi ng experiment carry local workstation timings report theregistrations except hammers data set onlyreport timing subset 19 know runtime independent parameter therefore hammers data use andequal voxel size randomly select 100 870 registration asa sufficiently accurate approximation convergence algorithm evaluate term step size euclidean dist ance errorand cost function value function iteration number experiment use following routine 1 performalinearregistrationbetweenfixedandmovingimagetogetacoarsetransformation usingarigidtransformationfor rire brain data affine transformation spread lung ct data similarity transformation rigid plus isotropicscaling hammers brain dat initial transforma tion 4d ultrasound data 2 perform nonlinear cubic bsplinebasedregistration 49 foralldatasetsexcepttheriredata get transformation ultrasound data bspline transformation model propose metz et al 50 use register 3d image sequence groupwisestrategy tofindtheoptimal transformationthatisbothspatially andtemporallysmoothamoredetailedexplanationofthereg istration methodology 45 3 transform landmarksormovingimagesegmentationsusing 4 evaluatethe result use evaluation measure defined section ivb experiment three lev el multiresolution strategy use gaussian smoothing filter standard devi ation 2 1 05 mm resolution bspline transformationmodel thegridsizeofthebsplinecontrolpointmeshishalvedineachresolutiontoincreasethetransformation accuracy 49 use iteration 5000 sample except ultrasound experiment use 2000 iterations 2000 sample accord vijayan 45 setandequal voxel size mean length voxel edge b evaluation measures twoevaluationmeasureswereusedtoverifytheregistration accuracy theeuclideandistanceandthemeanoverlaptheeuclidean distance measure give 21 inwhich andarecoordinatesfromthefixedandmoving image respectively ri brain data 8 corner point spread data 100 co rresponding point use evaluate performance fo r 4d ultrasound image adopt following measure 45 22 inwhich andisalandmarkattime place observer mean landmark inverse transformation mean overlap two segmentation image calculate dice similarity coefficient dsc 5 23 labelled region total number region hammers data assess registration accuracy wilcoxon sign rank test registration result perform spread data first obtain mean distance error of100 point patient perform wilcoxonsigned rank test mean error registration smoothness assess spread exper iment measure determinant spatial jacobian ofthe transformation 51 fluctuationqiao et al fast automatic step size estimationfor gradientdescent optimization f image registr ation 397 fig1 euclideandistanceerrorinmmfortherirebraindataperformedusi ng mi table ii themedianeuclidean distanceerror mm spread lungct datathesymbols andindicate statistically significant difference withasgd respectively denotesnosignificant difference ofshould relatively small mooth transformation use standard deviation represent smoothness thecomputationtimeisdeterminedbythenumberofparam eters number voxels sample fixed image small number parameter estimation time beignored therefore provide comparison thebspline transformation parameter estimation timeand pure registration time wer emeasured resolution v r esults accuracy results inthissection wecomparethe registrationaccuracybetween asgd fasgd 1 rire brain data result show fig 1 present euclidean distance error eight corner point thebrainimagesthemedianeuclidean distancebeforeregistration 217 mmtheresult ofthe fasgd method similartotheasgdmethod medianaccuracyis1616and17mmforasgd fasgd respectively value wilcoxonsignedranktestoffasgdcomparedwithasgdand 036 030 respectively indicate statistical difference 2 spread lung ct data table ii show median mean euclidean distance error 100 correspond pointsof 19 patient four different similarity measure comparedwith asgd fasgd significant difference msd mi nmi median error difference small than003 mm compare fasgd asgd define euclidean landmark error difference asfig 2 difference euclidean distance error mm compare asgd forthespreadlungctdatathetwonumbersonthetopofeachboxdenotethe number landmark error large leave small right 2 nd respectively landmark except one nmi belong patient fig 3 box plot standard deviation jacobian determinant four similarity measure landmark n l r l yf r h difference show box plot fig 2 negative numbersmean fasgd good asgd vice versa canbeseenthatboth andfasgdprovideresultssimilarto asgd foralltestedcostfunctionsthespreadofthe box plot small fasgd method almost identical asgd smoothness resulting transformation give fig 3 similarity measure fasgd generate somewhatsmoother transformation asgd msd mi nmi measures398 ieee transactions medicalimaging vol35 2 february 2016 fig 4 median dice overlap registration hammers brain data function high dsc indicate well reg istration accuracy note large scale experiment square represent 870 registration require 870 15 minutesof computation ie almost 200 core hour 3 hammers brain data inthisexperiment fasgdiscom p r e dw ha g da n large scale intersubject ex periments brain mr data range value number iteration fig4showstheoverlapresultsofthe83brainregionseach squarerepresentsthemediandscresultof870brainimageregistration pair certain parameter combination result show original asgd method slightly high dsc fasgd parameter setting median dsc difference small 001 notethat dark black color indicate dsc value 0 and05 ie anything registration failure low performance asgd method fail fasgd fail 4 ultrasound abdomen data result show fig 5 present euclidean distance 22 landmark fromultrasound image nonrigid registration medianeuclidean distance registration 36 mm resultof fasgd similar original method value wilcoxon sign rank test fasgd compare withasgd is0485 0465 respectively indicate statistical difference b runtime results section runtime three method asgd fasgd compare 1 spread lung ct data theruntimeonspreadlungct dataisshowninfig6 inwhichthetimeusedintheestimationsoftheoriginalmethodtakesalargepartofthetotalruntimeperfig5 euclideandistanceinmmoftheregistrationresultsforultrasoun ddata perform use mi resolution whilefasgdconsumesonlyasmallfractionofthe total runtime resolution 1 r1 resolution 3 r3 thenumber transformation parameter increasesfrom 4 9 asgd estimation time crease 3 second r1 40 second r3 however fasgdmaintainsaconstantestimationtimeofnomorethan1second 2 hammers brain data theruntimeresultofthehammers brain data show fig 7 dataset r3 ie large thespread data result largerestimationtimesforasgdand theestimationtimeinqiao et al fast automatic step size estimationfor gradientdescent optimization f image registr ation 399 fig 6 runtime spread lung ct dat second black green redbarindicateestimationtime pureregistrationtimeandtotaltimeel apsedin eachresolution respectivelyr1 r2 r3indicateathreelevelmultire solution strategy low resolution high resolution thethirdresolutionisalmost95seconds whileforfasgditis almost 2 order magnitude small 3 4d ultrasound data grid spacing bspline con trolpointsusedinthe4dultrasounddataexperimentis15 15 151 image size 227 22922796 total number bspline parameter third resolution r3is around 87 timing result fig 8 orig inalmethodtakesalmost1400seconds ie around23minutes fasgd take 40 secondsfig 7 runtime hammers brain data experiment second black greenandredbarindicateestimationtime pureregistrationtimeandtot altime elapsedineachresolution respectivelyr1 r2 r3indicateathreeleve lmulti resolution strategy low resolution high resolution fig 8 runtime ultrasound data experiment second black greenandredbarindicateestimationtime pureregistrationtimeandtotaltim eelapsed resolution respectively r1 r2 r3 indicate three level multi resolu tion strategy low resolution high resolution fig9 runtimeinsecondsoffasgdforultrasoundexperimenttheleftbarindicate estimation time right bar estimation time r1 r2 r3 indicate three level multiresolution strategy low resol ution high resolution fig 9 present runtime estimate andfor ultrasounddatatheestimationof takesaconstanttimeduring eachresolution soforsmall theestimationof dominatesthe total estimation time400 ieee transactions medicalimaging vol35 2 february 2016 0510152025303540 r2asgd asgd fasgd rire01000200030004000500060007000 r2asgd asgd fasgd b spread 0200040006000800010000 r2asgd asgd fasgd c hammers0500100015002000 r2asgd asgd fasgd ultrasound fig 10 example step size decay use 500 iteration except ul trasound image data 2000 iteration last resolution four experi ments red line original asgd black line green line fasgd rire b spread c hammers ultrasound c convergence fromeachofthefourexperiments werandomlyselectedone patientandanalyzedthestepsizesequence theresultsare present fig 10 show fasgd take large step sizethanasgdand forrigidregistrationandasmaller step size nonrigid regis tration use n addition original asgd take similar stepsizeinallexperimentsevenwhen usesthedefault setting convergence result three method present fig 11 several patient fig 11 b present eu clideandistance mm ateachiterat ionforthreeresolutionswith respect iteration number cost function value showninfig11 c thethreemethodsbehavesimilarly vi discussion experiment paper show fast asgd method work well rigid nonrigid image registration show method deal differently parameterized transformation method thoroughly evaluatedonavarietyofimaging problem includingdifferent modality ct mri ultrasound intra inter subject registration different anatomical site brain lung abdomen vari ous image registration setting test include four popular similarity measure large scale experiment investigate sensitivity method parameter experiment show fasgd similar accuracy asgd method rigid registration rire data nonrigid 4d ultrasound experiment significant statistical differen ce nonrigid spread lung ctexperimentandthehammersbraindataweobservedstatis tically significant difference however difference wereverysmall onaveragelessthan003mmonthespreaddatafig 11 convergence plot four different patient top row show e u clidean distance error mm function iteration number bottom r ow show cost function value msd plot show three resolution ed patient 1 b ed patient 2 c msd patient 3 msd patient 4 lessthan5 ofthevoxelsize andlessthan001diceoverlap brain data conclude fasgd obtain similar registration accuracy original asgd method result indicate little difference asgd especiallyfrom fig10itcanbeobserved method take sim ilar step size opti mization well similar cost function value euclidean distance error fig 11 uggests default value parameter andare sufficiently accurate indeed parameter important parameter estimate fig 10 observe fasgd typically esti mate small step size asgd identical h sw also observe patie nt fig 4 confirms obser vation accuracy plot fasgd somewhat shifted totherightcomparedtotheothertwomethodsthissuggeststhat moresimilarstepsizesmaybeobtainedwhenchoosing twiceaslargeasforasgd ie toincreasethedefaultfromonevoxel size two accuracy result hammers experiment show fig 4 present apparent accuracy increase forfasgdrememberthat representsthemaximumallowed voxel displacement per iteration mm med ical data use paper large unrealistic note asgd registration start fail n df r fasgd thetemporaryincreaseinaccuracyat forfasgdisduetoanundesireddecreasein note thatasgdusestheexactsameterm see 20 butthisdoesnot result increased accuracy since asgd already fail time performance propose method show section vb implies fasgd large reduction time consumption step size estimation spreadexperiment estimation time last resolution reducedqiao et al fast automatic step size estimationfor gradientdescent optimization f image registr ation 401 40 second 1 second improvement crucial near realtime registration high dimensional image registration fig 9 observe new bottle neck step size estimation estimation noise compensation pa rameter work calculation gradient isperformedwitharelativelyhighnumberofvoxels fromthefixedimagefutureworkwillincludetheinvestigation accelerated method estimate redu ce step size estimation time especially 4d registration prob lem direct acceleration possib ility use paralleliza tion example gpu implementation gradient computation consist ofan independentloop overthe voxels fasgd method provide solution step size se lection gradient descent optimi zers newtonlike opti mizers typically solve line search strategy note thatsuchastrategycannotreadil ybeadoptedforstochasticop timizationduetothestochast icapproximationofthecostfunc tion 52 strengthsofquasinewtonoptimizersaretheiradapt abilitytoproblemswheretheparametersarescaledwithrespect vailability stop condition fasgd well stochastic gradient descent optimiza tionroutinestypicallythenumbe rofiterationsisusedtotermi nate optimiza tion sophisticated stop condition deterministic gradient escent method readily adoptedforexample duetotheestimationnoise stoppingcon ditions ba sed cost function value cost function gradient trust alterna tive compute exact objective value every iteration also attractive due required computation time elastix implementation stochastic gradient computation order 50 exact metric value computation least order sec onds feasible possibility would create stopping con dition base moving average noisy objective value gradient use lsgrid hammers data experiment essential reduce com putation time 19 year about23daysithoweverdidrequireaonetimeinvestmentoftimetodevelopthesoftwaresupportingtheregistrationjobson thegridtypicalissuesweencounteredwasattemptingtostore result hundred simultaneous execution whichproved incompatible maximum transaction rate support lsgrid storage resource management service able solve pool multiple result singlestorage operation infrastructure build therefore screens thesoftwareunderexecutionfr omthecomplexitiesthatareen counteredwhenrunningonthe lsgridatthesametimeitis generic enough provide configurable set execution en vironmentstosupportotherexperimentsnotjustthe elastix w r k fl wu e di nt h sw r k n therefore reused vii c onclusion paper new automatic method fasgd es timating optimization step size parameter need gradient descent optimization method present image registration parameter automatically estimate fromthemagnitudeofvoxeldis placement randomlysampled fixed image relation step size theexpectationandvarianceoftheo bservedvoxelsdisplacementis derive propose method free parameter e fi n n g maximally allow incremental displacement iter ations unlike interpret termsof voxel size mm addition mostly independent application domain ie set equal voxel size provide good resultsforallapplicationsevaluatedinthispapercomparedtotheoriginalasgdmethod thetimecomplexityofthefasgd method reduce quadratic linear respect dimensionofthetransformationparameters forthebspline transformation duetoitscompactsupport thetimecomplexity far reduce mak ing propose method ndependent fasgd method publicly available via open source image registration toolbox elastix 37 thefasgdmethodwasevaluatedonala rgenumberofreg istrationscenario'sandshowsasimilaraccuracyastheoriginal asgdmethodithoweverimprovesthetimecomplexityofthe stepsizeestimationfrom40se condstonomorethan1second whenthenumberofparametersis almost40timesfaster dependingontheregistrationsettings thetotalregistrationtime reduce factor f 257 experiment paper appendix thelsgrid infrastructurecomprisesdistributedcomputing storage resource along central grid facility total potential forapproximately10000job slotsjobscheduling perform use gl ite grid middleware 53 via glite workload management ystem wms 54 develop european grid infrastructure 55 possible use di rectly schedule registra tion pipeline job practice relatively short job poor fit standard queue length lsgrid addition unforseen delay push schedule mechanism result considerable overhead 56 issue address layer pull schedule system base pilot job onto thegrid software infrastructure matching job workload nodes occursonceatpilotjobstartupafterwhichjobtokensarepulled pilot job environment concept pilot jobs wasfirst pioneer egi grid within dirac 57 em ployed light weight pilot job system develop surfsara call picas 58 59 pilot job architecture show fig 12 use exe cutethehammerspipelinepicaswasextendedwithawrapper job perform standard element pipeline environmentsetupanddataretrievalthewrapperjobandtheham merspipelinearecodedusingpython 60 thejobtokenscon tain registration parameter use storage locations fixed move image ganga 61 use schedule monitor pilot job pull execute jobtokensfromthepicasdata basetheoverallprogressofthe executioncanbecheckedbymonito ringthestatusofthejobto ken use web browser access jobtoken view defined database execution hammers pipeline use picas ls gridfollows step 1 initialize hammers job token create job ken hammers pipeline run job tokens contain402 ieee transactions medicalimaging vol35 2 february 2016 fig 12 running hammers pipeline pilot job architecture use lsgrid arrows represent flow information job parameter grid location input data b upload input data need specific location grid storage c monitor executio np r g r e sb yc h e c k n gj b token consumption browser 2 schedule pilot job commence grid execution schedule pilot job necessary job requirement usingglitewmsfrominsidegangaadditionalinforma tion pass pilot job concern runtime environment need b monitor progress pilot job use ganga job monitoring c glite wms identi fies cluster match job r equirements schedule pilotjobsoncethepilotisstartedthepicaswrapperjob set runtime environment worker node 3 job token consume execute run pilot job retrieve job token picas job token database mark lock b necessary data identified job token hammers job isdownloaded picas wrap per grid storage hammers pipeline execute c result uploaded grid storage location specified thejob token job token update result success failure failure case logfiles append assist debug 4 job result immediately download run progress tool create r eusable large scale image processing lsgrid cknowledgment rire project acknowledge provide platform rigid registration evaluati author grateful dr hammers et alfor adult maximum probability brain atlas dr bakker j stolk acknowledge providing ground truth spread study data use thispaper 4d ultrasound data make available sintefdept medical technology norwegian university ofscience technology context iiios project marie curie itn 238802",
    "bag_of_words": {
        "ieeetransactions": 1,
        "medicalimaging": 7,
        "vol35": 7,
        "no2": 1,
        "february": 7,
        "fast": 13,
        "automatic": 11,
        "step": 54,
        "size": 57,
        "estimation": 13,
        "gradient": 47,
        "descent": 24,
        "optimization": 19,
        "image": 52,
        "registration": 50,
        "yuchuan": 1,
        "qiao": 1,
        "baldur": 1,
        "van": 2,
        "lew": 2,
        "boudewijn": 1,
        "lelieveldt": 2,
        "marius": 1,
        "sta": 1,
        "ring": 1,
        "abstract": 1,
        "important": 5,
        "prerequisite": 1,
        "imageguided": 1,
        "cli": 1,
        "nical": 1,
        "procedure": 5,
        "however": 6,
        "due": 3,
        "large": 19,
        "number": 22,
        "voxels": 9,
        "complexity": 9,
        "algorithm": 6,
        "proc": 1,
        "es": 2,
        "often": 3,
        "slow": 2,
        "stochastic": 16,
        "powerful": 2,
        "method": 59,
        "iteratively": 1,
        "solve": 4,
        "reg": 4,
        "istrationproblem": 1,
        "butreliesforconvergenceonaproperselection": 1,
        "selection": 4,
        "difficult": 3,
        "performmanually": 1,
        "since": 3,
        "depend": 2,
        "input": 3,
        "data": 46,
        "similarity": 8,
        "measure": 12,
        "transformation": 22,
        "model": 9,
        "adaptive": 4,
        "asgd": 43,
        "approach": 1,
        "comesat": 1,
        "high": 10,
        "computational": 2,
        "cost": 11,
        "paper": 12,
        "propose": 10,
        "new": 5,
        "computationally": 2,
        "efficient": 2,
        "automatically": 3,
        "determine": 4,
        "consideringtheobserveddistributionof": 1,
        "thevoxeldisplacementsbetween": 1,
        "iteration": 18,
        "relation": 4,
        "expectation": 4,
        "andvarianceoftheobserveddist": 1,
        "ributionisderivedwhileasgd": 1,
        "quadratic": 3,
        "respect": 3,
        "parameter": 27,
        "linear": 2,
        "extensive": 3,
        "validationhasbeenperformedondifferentdatasetswithdifferentmodalities": 1,
        "inter/intra": 2,
        "subject": 3,
        "di": 3,
        "fferent": 1,
        "xperiments": 1,
        "obtain": 12,
        "similar": 8,
        "accuracyasasgdmoreover": 1,
        "thee": 1,
        "stimationtimeoffastasgdis": 1,
        "dt": 1,
        "oav": 1,
        "lv": 1,
        "m4": 1,
        "0st": 1,
        "ol": 1,
        "st": 1,
        "n1sw": 1,
        "nt": 3,
        "almost": 4,
        "time": 31,
        "faster": 1,
        "depending": 1,
        "setting": 10,
        "total": 10,
        "reducedby": 1,
        "factor": 4,
        "experiment": 22,
        "index": 1,
        "terms": 1,
        "de": 3,
        "scent": 2,
        "introduction": 1,
        "imageregistrationaimstoaligntwoormoreimagesandis": 1,
        "technique": 3,
        "field": 2,
        "medical": 4,
        "anal": 1,
        "ysis": 2,
        "use": 61,
        "clinical": 1,
        "include": 5,
        "radiotherapyandimagegui": 1,
        "desurgery": 1,
        "andothergeneralimageanal": 1,
        "task": 2,
        "seg": 1,
        "mentation": 1,
        "amount": 2,
        "oftransformation": 1,
        "eneral": 1,
        "process": 2,
        "render": 1,
        "manuscript": 1,
        "receive": 1,
        "august": 2,
        "accept": 1,
        "date": 1,
        "publicationseptember032015": 1,
        "dateofcurrentversionfebruary012016": 1,
        "researchwassupportedbythenetherlandsorganizationforscientificres": 1,
        "earch": 1,
        "nwoveni639021919": 1,
        "bythedutchnationaleinfrastructurewiththes": 1,
        "port": 1,
        "surf": 1,
        "foundation": 1,
        "einfra140085": 1,
        "china": 1,
        "scholarshipcouncil": 1,
        "asterisk": 1,
        "indicate": 9,
        "correspond": 3,
        "author": 2,
        "yqiaoiswiththedivisionofimageprocessing": 1,
        "departmentofradiology": 1,
        "leiden": 3,
        "university": 2,
        "center": 1,
        "2300rc": 2,
        "netherlands": 2,
        "staring": 1,
        "division": 1,
        "imageprocessing": 1,
        "departmentofradi": 1,
        "ology": 1,
        "leidenuniversitymedicalce": 1,
        "nter": 1,
        "colorversionsofoneormoreofthefiguresinthispaperareavailableonlin": 1,
        "http": 2,
        "//ieeexploreieeeorg": 1,
        "digital": 1,
        "object": 1,
        "identifier": 1,
        "101109/tmi20152476354impractical": 1,
        "timecritical": 1,
        "clini": 1,
        "cal": 1,
        "situation": 1,
        "intraop": 1,
        "erative": 1,
        "accelerate": 1,
        "registra": 3,
        "tion": 12,
        "multiple": 2,
        "develop": 5,
        "target": 1,
        "interpolation": 2,
        "scheme": 3,
        "optimizer": 1,
        "several": 3,
        "study": 4,
        "investigate": 2,
        "stateoftheart": 1,
        "pro": 1,
        "cessing": 1,
        "exploit": 1,
        "multithreading": 1,
        "cpu": 2,
        "also": 6,
        "gpu": 2,
        "othersfocusontheoptimizationschemethatisusedforsolvingimageregistration": 1,
        "problem": 7,
        "methods": 1,
        "levenbergmarquardt": 1,
        "quasinewton": 2,
        "conjugate": 1,
        "evolution": 1,
        "strate": 1,
        "gy": 1,
        "particle": 1,
        "swarm": 1,
        "stochasticgradient": 1,
        "among": 1,
        "methodfor": 1,
        "scale": 8,
        "superb": 1,
        "performance": 9,
        "term": 6,
        "computation": 10,
        "ime": 1,
        "accuracy": 18,
        "deterministic": 7,
        "first": 7,
        "order": 6,
        "secondorder": 1,
        "give": 9,
        "slightly": 3,
        "bett": 1,
        "er": 2,
        "heavily": 1,
        "increase": 3,
        "may": 1,
        "therefore": 7,
        "beconsideredforcaseswhereahighlevelofaccuracyisrequired": 1,
        "realtime": 3,
        "erformance": 1,
        "need": 6,
        "inthisstudy": 1,
        "webuildonthestochasticgradientdescenttech": 1,
        "nique": 1,
        "thedimensional": 1,
        "fixed": 13,
        "dimensional": 2,
        "moving": 2,
        "parameterized": 2,
        "co": 3,
        "ordinate": 2,
        "thecostfunction": 1,
        "dissimilaritybetweenthefixedandmovingimagetosolvethisproblem": 1,
        "thestochasticgradien": 1,
        "tdescentmethodadoptsiterative": 1,
        "update": 3,
        "optimal": 5,
        "followingform": 1,
        "function": 17,
        "true": 1,
        "approximation": 4,
        "error": 13,
        "efficiently": 1,
        "calculate": 7,
        "subset": 3,
        "usingsimultaneous": 1,
        "perturbation": 1,
        "show": 18,
        "previously": 1,
        "superior": 1,
        "compare": 9,
        "deterministicgradient": 1,
        "second": 10,
        "suchas": 1,
        "although": 1,
        "latter": 1,
        "frequently": 1,
        "somewhat": 2,
        "lower": 1,
        "objective": 3,
        "value": 22,
        "less": 2,
        "prone": 1,
        "get": 2,
        "stick": 1,
        "small": 16,
        "ieee": 8,
        "translations": 1,
        "content": 1,
        "mining": 1,
        "permit": 2,
        "cademic": 1,
        "research": 1,
        "personal": 1,
        "republication": 1,
        "redistribution": 1,
        "require": 9,
        "permission": 1,
        "see": 5,
        "//wwwieeeorg/pub": 1,
        "lications_standards/publications/rights/indexhtml": 1,
        "inform": 1,
        "ation392": 1,
        "transactions": 6,
        "local": 2,
        "minimum": 2,
        "almostsure": 1,
        "convergence": 9,
        "guarantee": 1,
        "mean": 11,
        "converge": 1,
        "tothelocalminimum": 1,
        "withprobability1": 1,
        "providedthatthestepsize": 1,
        "sequence": 9,
        "nonincreasin": 1,
        "nonzero": 1,
        "suitable": 2,
        "poorly": 1,
        "chosen": 1,
        "sizewill": 1,
        "cause": 1,
        "estimate": 14,
        "bounce": 1,
        "stepsizeistoolarge": 1,
        "orslowconvergenceifitistoosmall": 1,
        "anexactandautomati": 1,
        "callyestimatedstepsize": 1,
        "inde": 1,
        "pendent": 1,
        "essential": 3,
        "gradientbasedoptimization": 1,
        "note": 5,
        "deterministicquasinewtonmethodsthestepsizeiscommonlychosenusingan": 1,
        "exact": 9,
        "line": 5,
        "search": 3,
        "methodsthataimtosolvetheproblemofstepsizeestimation": 1,
        "categorize": 1,
        "three": 11,
        "group": 3,
        "manual": 5,
        "semiautomatic": 1,
        "methodsin": 1,
        "robbins": 1,
        "monro": 1,
        "proposed": 3,
        "manually": 2,
        "select": 6,
        "severalmethodswereproposedafterwardstoimprovetheconvergenceof": 1,
        "therobbinsmonro": 1,
        "focus": 2,
        "construction": 1,
        "still": 3,
        "selectionoftheinitialstepsizeexamplesincludekesten'srule": 1,
        "gaivoronski": 1,
        "rule": 2,
        "twopoint": 1,
        "sizegradient": 1,
        "overview": 4,
        "befound": 1,
        "practice": 2,
        "different": 13,
        "ap": 1,
        "plication": 1,
        "se": 3,
        "ttings": 1,
        "especially": 3,
        "istration": 4,
        "move": 4,
        "similaritymeasuresortransformationmode": 1,
        "lsrequireadifferentstepsize": 1,
        "example": 3,
        "report": 2,
        "differseveralordersofmagnitudebe": 1,
        "tweencostfunctions": 1,
        "timeconsuming": 3,
        "spall": 1,
        "follow": 4,
        "ruleofthumb": 1,
        "magnitude": 6,
        "approximately": 1,
        "equal": 5,
        "desired": 1,
        "change": 2,
        "early": 1,
        "iterationstheestimationisbasedonapreliminaryregistration": 1,
        "afterwhichthestepsizeismanuallyestimatedandusedinsubsequent": 1,
        "tothespecificimages": 1,
        "ontheparameterization": 1,
        "dre": 1,
        "quire": 1,
        "set": 8,
        "nonintuitive": 1,
        "desire": 1,
        "forthesemiautomaticselection": 1,
        "suri": 1,
        "andbrennan": 1,
        "observe": 4,
        "prelimi": 1,
        "nary": 1,
        "simulation": 1,
        "latent": 1,
        "difference": 14,
        "thestep": 1,
        "preliminary": 1,
        "currentone": 1,
        "inevitable": 1,
        "bhagalia": 1,
        "training": 1,
        "stochasti": 1,
        "forimageregistration": 1,
        "apseudogroundtruthwasobtained": 1,
        "severalattempts": 1,
        "choose": 3,
        "find": 2,
        "optimalwarp": 1,
        "comparedwiththepseudogroundtruthwarpobtainedinthefirststepthismethod": 1,
        "complex": 2,
        "trainingdata": 1,
        "moreover": 1,
        "generalizes": 1,
        "train": 1,
        "result": 18,
        "case": 2,
        "klein": 2,
        "et": 10,
        "alautomatically": 1,
        "distribution": 4,
        "thedistribution": 1,
        "voxel": 15,
        "displacemen": 1,
        "finally": 3,
        "theinitial": 1,
        "base": 3,
        "vox": 1,
        "el": 2,
        "displacement": 14,
        "worksforfewparameterswithin": 1,
        "reasonabletime": 1,
        "butforalarge": 1,
        "numberoftransformationpar": 1,
        "ameters": 1,
        "ie": 11,
        "intheorderof": 1,
        "run": 6,
        "unacceptable": 1,
        "estimating": 1,
        "dominate": 2,
        "thisdisqualifies": 1,
        "fastasgd": 2,
        "hereafterfasgd": 1,
        "toautomaticallyselectthe": 1,
        "sizefor": 1,
        "byderiving": 1,
        "observed": 1,
        "thispaper": 2,
        "extend": 1,
        "conference": 1,
        "detailed": 1,
        "methodology": 2,
        "validation": 2,
        "many": 1,
        "datasetsofdifferentmodalityandanatomi": 1,
        "calstructurefurthermore": 1,
        "tool": 2,
        "perform": 11,
        "ourmethod": 1,
        "interfacing": 1,
        "international": 1,
        "compute": 5,
        "facilityinsectionii": 1,
        "themethodtocalculatethestepsizeisintroducedthedatasetdescriptionisgiveninsectioniiitheexperimentalsetuptoevaluatetheperformanceofthenewmethodispresented": 1,
        "section": 9,
        "iv": 2,
        "experimental": 6,
        "resultsare": 1,
        "sections": 1,
        "vi": 2,
        "vii": 2,
        "conclude": 2,
        "ii": 4,
        "ethod": 1,
        "commonly": 1,
        "choice": 1,
        "gra": 1,
        "dientdescentistouseamonotoni": 1,
        "callynonincreasingsequence": 1,
        "inthispaperweusethefollowi": 1,
        "ngdecayingfunction": 1,
        "whichcan": 1,
        "adaptivelytunethestepsizeacco": 1,
        "rdingtothedirectionandmag": 1,
        "nitudeofconsecutivegradients": 1,
        "andhasbeenusedfrequentlyinthe": 1,
        "literature": 1,
        "theoretically": 2,
        "rate": 4,
        "usedthroughout": 1,
        "denote": 2,
        "sigmoid": 3,
        "maximum": 10,
        "gain": 1,
        "maximal": 1,
        "backward": 1,
        "af": 1,
        "fectstheshapeofthesigmoidfun": 1,
        "ction": 1,
        "areasonablechoice": 1,
        "implies": 2,
        "forward": 1,
        "ofthe": 3,
        "robbinsmonro": 1,
        "prove": 1,
        "convergenceisguaranteedaslongas": 1,
        "specifically": 1,
        "fromassumptiona4": 1,
        "andassumptionb5": 1,
        "asymptoticnormalityandconvergencecanbeassuredwhen": 1,
        "equation": 2,
        "whichrequirestheestimat": 1,
        "ionofthedistributionoftheap": 1,
        "proximation": 1,
        "consumingmoreover": 1,
        "introduce": 2,
        "empirically": 1,
        "setto10": 1,
        "avoidsacostlycomputation": 1,
        "stillguaranteestheconditionsrequiredforconvergencefortheqiao": 1,
        "al": 8,
        "estimationfor": 5,
        "gradientdescent": 5,
        "registr": 6,
        "ation": 8,
        "fulfilling": 1,
        "criterion": 1,
        "lectedbeforetheoptimizationproceduretheparameter": 1,
        "con": 4,
        "trols": 1,
        "decay": 2,
        "theparameter": 1,
        "providesastartingpoint": 1,
        "whichhasmost": 1,
        "influenceatthebeginningofthe": 1,
        "optimizationfromexperience": 1,
        "provide": 8,
        "reasonable": 2,
        "situa": 1,
        "tions": 2,
        "numerator": 1,
        "overall": 1,
        "wh": 1,
        "ich": 1,
        "dependent": 1,
        "andt": 1,
        "sizecandiffersubstantiallybetweenresolutions": 1,
        "figure4": 1,
        "fordifferentcost": 1,
        "table2": 1,
        "thismeansthatthe": 1,
        "mainly": 1,
        "determinedby": 1,
        "inthiswork": 1,
        "wethereforefocusonautomatically": 1,
        "manner": 1,
        "intuition": 1,
        "thatthevoxeldispl": 1,
        "acementsshouldstartwithareasonablevalue": 1,
        "gradually": 1,
        "diminish": 1,
        "zero": 2,
        "incremental": 7,
        "domain": 2,
        "iterative": 1,
        "defined": 3,
        "ensure": 2,
        "iter": 2,
        "neither": 1,
        "big": 1,
        "constrain": 1,
        "thevoxel": 1,
        "range": 2,
        "assume": 2,
        "whichhas": 1,
        "andvariance": 1,
        "inwhich": 5,
        "isthenormfor": 1,
        "translation": 1,
        "transform": 2,
        "vo": 1,
        "xel": 1,
        "sothevarianceiszero": 1,
        "fornonrigidregistration": 1,
        "thevoxeldisplacementsvaryspatially": 1,
        "sothevarianceislargerthanzerotocalculate": 1,
        "firstorder": 1,
        "taylor": 1,
        "expansion": 1,
        "make": 3,
        "around": 3,
        "isthejacobianmatrixofsize": 1,
        "fi": 3,
        "combine": 2,
        "rewrite": 2,
        "allow": 2,
        "voxe": 1,
        "userdefined": 1,
        "physical": 1,
        "meaning": 1,
        "unit": 1,
        "dimension": 2,
        "usuallyin": 1,
        "mm": 13,
        "imply": 1,
        "foreach": 1,
        "two": 4,
        "weakened": 1,
        "form": 2,
        "assumption": 1,
        "whereis": 1,
        "probability": 2,
        "according": 1,
        "thevysochanskijpetunininequality": 1,
        "forarandomvariablewithunimodaldistribution": 1,
        "andfinite": 1,
        "nonzerovari": 1,
        "ance": 4,
        "following": 8,
        "theorem": 1,
        "hold": 1,
        "based": 1,
        "boundary": 1,
        "approximate": 1,
        "fol": 1,
        "lowing": 1,
        "expression": 2,
        "square": 4,
        "equa": 2,
        "avoid": 1,
        "takin": 1,
        "root": 1,
        "reason": 1,
        "interested": 1,
        "displacements": 1,
        "notitssquarecombi": 1,
        "ningwith": 1,
        "weobtainthere": 1,
        "lationship": 1,
        "thestepsizefunction": 1,
        "itiseasyto": 1,
        "findthemaximumstepsize": 1,
        "andthemax": 1,
        "imum": 1,
        "stepsizeistakenatthebeginningoftheoptimizationprocedurefor": 1,
        "resolution": 20,
        "using": 1,
        "initial": 3,
        "beginning": 1,
        "noise": 7,
        "compensation": 4,
        "vergencewithareasonableaccur": 1,
        "acy": 1,
        "fastestimatesofthe": 1,
        "imagevoxels": 1,
        "randomly": 3,
        "troduces": 1,
        "thereby": 1,
        "influencing": 1,
        "theconvergence": 1,
        "turn": 2,
        "sizeforstochastic": 1,
        "gradientdescentwillbedifferentcomparedto": 1,
        "terministic": 1,
        "gradientdescentwhentheapproximationerror": 1,
        "direction": 1,
        "unpredictable": 1,
        "thusa": 1,
        "careful": 1,
        "sizeisrequiredsimilarto": 1,
        "gaussian": 3,
        "variable": 1,
        "variance": 3,
        "adopt": 2,
        "th": 1,
        "ratio": 1,
        "approximated": 1,
        "radient": 1,
        "modify": 1,
        "summary": 3,
        "implementation": 3,
        "details": 1,
        "calculation": 5,
        "voxelbased": 1,
        "usually394": 1,
        "take": 6,
        "isasimilaritymeasure": 1,
        "isadiscretesetofvoxel": 1,
        "coordinate": 1,
        "cardinality": 1,
        "reliable": 1,
        "relies": 1,
        "trad": 1,
        "eoff": 1,
        "sufficiently": 3,
        "sample": 5,
        "imagespecifically": 1,
        "weuseasubset": 1,
        "iscomputedateachvoxelco": 1,
        "ollowing": 1,
        "analysis": 1,
        "reveals": 1,
        "influences": 1,
        "comp": 1,
        "utation": 1,
        "andtheapproximategradient": 1,
        "becausethecomputationofthe": 1,
        "gradientusingall": 1,
        "voxelsi": 1,
        "stooslow": 1,
        "uniform": 1,
        "samplingis": 1,
        "determined": 1,
        "empiricallyas": 1,
        "ep": 1,
        "add": 1,
        "recompute": 1,
        "detail": 4,
        "final": 1,
        "formula": 3,
        "compensate": 1,
        "nally": 1,
        "pertu": 1,
        "rbation": 1,
        "ob": 1,
        "tained": 1,
        "thefinal": 1,
        "reference": 1,
        "scalar": 1,
        "constant": 1,
        "relate": 1,
        "covari": 2,
        "jacobian": 5,
        "frobenius": 1,
        "norm": 1,
        "fasgd": 34,
        "ex": 2,
        "pectation": 1,
        "matrix": 5,
        "com": 2,
        "putation": 2,
        "multiplicationsand": 1,
        "addition": 5,
        "domi": 1,
        "nant": 1,
        "calculating": 1,
        "right": 3,
        "leave": 2,
        "multiplication": 2,
        "additional": 1,
        "operation": 4,
        "leftmost": 1,
        "taking": 1,
        "account": 1,
        "thetimecomplexityoftheoriginalasgdmethodisthere": 1,
        "fore": 1,
        "meansthatfasgdhasalineartimecomplexitywithrespecttothe": 1,
        "bspline": 7,
        "non": 1,
        "zeropartofthejacobianismuchsmallerthanthefulljacobian": 1,
        "isdeterminedby": 1,
        "thebsplineorder": 1,
        "cubic": 3,
        "eachvoxel": 1,
        "isinfluencedby": 1,
        "controlpoints": 1,
        "2d": 1,
        "3d": 3,
        "forthe": 1,
        "reduces": 1,
        "ed": 4,
        "nanttermoffasgdbecomesthenumberofsamples": 1,
        "potentially": 1,
        "iii": 2,
        "datasets": 3,
        "inthissectionwedescribethedatasetsthatwereusedtoeval": 1,
        "uatetheproposedmethoddatas": 1,
        "etswerechosentorepresenta": 1,
        "broadcategoryofusecases": 1,
        "monomodalandmultimodal": 1,
        "intrapatient": 1,
        "well": 7,
        "interpat": 1,
        "ient": 1,
        "anatomical": 4,
        "site": 2,
        "rigid": 10,
        "nonrigid": 10,
        "underlie": 1,
        "deforma": 1,
        "ets": 1,
        "present": 9,
        "table": 6,
        "rire": 9,
        "brain": 20,
        "multimodality": 1,
        "retrospective": 1,
        "evaluation": 6,
        "projectprovidesmulti": 1,
        "modalitybrainscanswithagroundtruth": 1,
        "scan": 7,
        "wereobtained": 1,
        "patient": 14,
        "ct": 11,
        "mrt1scansfiducialmarkerswereimplanted": 1,
        "ineachpatient": 1,
        "andserved": 1,
        "ground": 4,
        "truth": 4,
        "marker": 1,
        "erasedfrom": 1,
        "replace": 1,
        "simulated": 1,
        "backgroundpattern": 1,
        "inourexperiments": 1,
        "weregisteredthet1mrimage": 1,
        "registrationatthewebsiteofrire": 1,
        "eightcornerpointsofbothctandmrt1": 1,
        "imagesare": 1,
        "evaluate": 4,
        "spread": 15,
        "lung": 11,
        "intrasubject": 1,
        "without": 2,
        "contrast": 1,
        "medium": 1,
        "toshibaqiao": 1,
        "aquilion": 1,
        "scanner": 2,
        "kvp": 1,
        "mas": 1,
        "perrotation": 1,
        "rotationtime05s": 1,
        "collimation4": 1,
        "5mmimages": 1,
        "reconstruct": 1,
        "standa": 1,
        "rdized": 1,
        "protocol": 1,
        "optimize": 1,
        "densitometry": 1,
        "soft": 1,
        "fc12": 1,
        "kernel": 1,
        "slicethicknessof5mmandanincrementof25mm": 1,
        "withaninplaneresolution": 1,
        "age": 1,
        "with36": 1,
        "predict": 2,
        "moderateto": 1,
        "severe": 1,
        "copd": 1,
        "gold": 1,
        "stage": 1,
        "antitrypsin": 1,
        "deficiency": 1,
        "one": 3,
        "hundred": 2,
        "rresponding": 2,
        "point": 6,
        "semiautoma": 1,
        "tically": 2,
        "extract": 1,
        "truthusingmurphy'smethod": 1,
        "thealgorithmautomaticallyfinds100evenlydistributedpoin": 1,
        "tsinthebaseline": 1,
        "onlyatchar": 1,
        "acteristic": 1,
        "location": 4,
        "subsequen": 1,
        "tly": 1,
        "followup": 1,
        "graphical": 1,
        "user": 1,
        "interface": 1,
        "insp": 1,
        "ection": 1,
        "possible": 2,
        "correction": 1,
        "hammers": 21,
        "intersubject": 4,
        "ham": 1,
        "mers": 1,
        "whichcontainsmrimagesof30healthya": 1,
        "dultsubjectstheme": 1,
        "dianageofallsubjectswas31years": 1,
        "ange": 1,
        "20~": 1,
        "and25of": 1,
        "the30subjectswerestronglyrighth": 1,
        "andedasdeterminedbyrou": 1,
        "tine": 1,
        "prescanning": 1,
        "screening": 1,
        "mri": 3,
        "sc": 1,
        "teslagesigmaechospeedscanne": 1,
        "racoronalt1weighted3d": 1,
        "volumewasacquiredusinganin": 1,
        "versionrecoverypreparedfast": 1,
        "spoil": 1,
        "recall": 1,
        "seque": 1,
        "nce": 1,
        "ge": 2,
        "te/tr/nex": 1,
        "msec": 2,
        "fatandwaterinphase": 1,
        "/155": 1,
        "msec/1": 1,
        "timeofinversion": 1,
        "ti": 1,
        "flip": 1,
        "angle": 2,
        "oo": 1,
        "slice": 1,
        "thickness": 1,
        "view": 2,
        "cmw": 1,
        "ha1": 1,
        "thiscoversthewho": 1,
        "lebrainwithvoxelsizesof094": 1,
        "15i": 1,
        "sw": 3,
        "ced": 1,
        "create": 4,
        "isotropic": 1,
        "gwindowed": 1,
        "sinc": 1,
        "eachimageismanually": 1,
        "segmentedinto83regionsofinterest": 1,
        "serve": 1,
        "groun": 1,
        "structure": 2,
        "delineate": 1,
        "investigator": 1,
        "next": 1,
        "struc": 1,
        "turewascommenced": 1,
        "thenaseparateneuroanatomicallytrained": 1,
        "operator": 1,
        "evaluat": 1,
        "consensus": 1,
        "reachedforthed": 1,
        "ifficultcasesinourexperiment": 1,
        "weperformed": 1,
        "egistration": 1,
        "mr": 2,
        "treat": 1,
        "particular": 1,
        "pa": 2,
        "rameter": 2,
        "ultrasound": 15,
        "4d": 9,
        "abdominal": 2,
        "ltrasound": 1,
        "dataset": 2,
        "vijayan": 2,
        "contai": 1,
        "ns": 1,
        "healthy": 1,
        "volunteer": 1,
        "position": 1,
        "eachscan": 1,
        "breathing": 1,
        "cycle": 1,
        "percycle": 1,
        "healthcare": 1,
        "vivide9": 1,
        "skilled": 1,
        "physician": 2,
        "active": 1,
        "4dvolume": 1,
        "phase": 1,
        "array": 1,
        "probe": 1,
        "wellde": 1,
        "fined": 1,
        "landmark": 7,
        "frame": 2,
        "acquired": 1,
        "manua": 1,
        "lly": 1,
        "annotate": 1,
        "engineer": 1,
        "vv": 1,
        "software": 2,
        "xperiment": 1,
        "setup": 3,
        "general": 1,
        "eval": 1,
        "uation": 1,
        "measurement": 1,
        "prese": 1,
        "nted": 1,
        "environment": 4,
        "property": 1,
        "runtimeand": 1,
        "variant": 2,
        "original": 7,
        "methodwhileforfasgd": 1,
        "andare": 2,
        "methodau": 1,
        "tomatically": 1,
        "fair": 2,
        "comparison": 3,
        "oftheasgdmethodisincludedinthecomparison": 1,
        "thatsetstheseparameters": 1,
        "estimatesallparameters": 1,
        "theasgdmethodwithdefaultsettingsonlyestimating": 1,
        "andthefastasgdmethod": 1,
        "thefastasgdmethodhasbeenimplementedusingthec++languageintheopensourceimageregistrationtoolboxelastix": 1,
        "wheretheasgdmethodisalreadyintegrated": 1,
        "thoroughly": 2,
        "variety": 1,
        "prob": 2,
        "lemsincludingdifferentmodalitiesanddifferentsimilaritymeasuresareconsideredintheexper": 1,
        "imentsspecifically": 1,
        "theexper": 1,
        "iments": 2,
        "four": 8,
        "differentdissimilaritymeasuresan": 1,
        "dthreeimagingmodalitiesthe": 1,
        "aim": 1,
        "registrationaccuracy": 1,
        "va": 1,
        "vb": 2,
        "sec": 2,
        "vc": 1,
        "spreadlung": 1,
        "verify": 2,
        "offasgd": 1,
        "dissimilarity": 1,
        "themean": 1,
        "intensity": 1,
        "differ": 1,
        "ence": 1,
        "msd": 6,
        "normalized": 1,
        "cor": 1,
        "nc": 1,
        "mutualinformation": 1,
        "mi": 5,
        "andnormalizedmutualinformation": 1,
        "nmi": 4,
        "thehammers": 1,
        "braindataisintended": 1,
        "specific": 2,
        "imensional": 1,
        "exper": 2,
        "dataand": 1,
        "localw": 1,
        "nw": 1,
        "h2": 1,
        "4g": 1,
        "bm": 1,
        "xu": 1,
        "u1": 1,
        "2l": 1,
        "s64": 1,
        "bit": 1,
        "system": 3,
        "intel": 1,
        "xeon": 1,
        "e5620": 1,
        "with8": 1,
        "core": 3,
        "ghz": 1,
        "influence": 1,
        "parameters": 1,
        "andon": 1,
        "extremely": 1,
        "datausing": 1,
        "life": 1,
        "science": 1,
        "grid": 11,
        "lsgrid": 8,
        "performancecomputing": 1,
        "hpc": 2,
        "facilitywetestedallcombinations": 1,
        "combination": 2,
        "ieach": 1,
        "abo": 1,
        "ut": 1,
        "minute": 1,
        "hour": 2,
        "resource": 3,
        "is396": 1,
        "experiments": 1,
        "reducedto23daysmoredetailsaboutthe": 1,
        "aregiven": 1,
        "appendix": 2,
        "timi": 1,
        "ng": 2,
        "carry": 1,
        "workstation": 1,
        "timings": 1,
        "theregistrations": 1,
        "except": 4,
        "onlyreport": 1,
        "timing": 2,
        "know": 1,
        "runtime": 10,
        "independent": 2,
        "andequal": 1,
        "asa": 1,
        "accurate": 2,
        "euclidean": 7,
        "dist": 1,
        "errorand": 1,
        "routine": 1,
        "performalinearregistrationbetweenfixedandmovingimagetogetacoarsetransformation": 1,
        "usingarigidtransformationfor": 1,
        "affine": 1,
        "plus": 1,
        "isotropicscaling": 1,
        "dat": 2,
        "transforma": 1,
        "nonlinear": 1,
        "bsplinebasedregistration": 1,
        "foralldatasetsexcepttheriredata": 1,
        "metz": 1,
        "register": 1,
        "groupwisestrategy": 1,
        "tofindtheoptimal": 1,
        "transformationthatisbothspatially": 1,
        "andtemporallysmoothamoredetailedexplanationofthereg": 1,
        "landmarksormovingimagesegmentationsusing": 1,
        "evaluatethe": 1,
        "ivb": 1,
        "lev": 1,
        "multiresolution": 2,
        "strategy": 6,
        "smoothing": 1,
        "filter": 1,
        "standard": 5,
        "devi": 1,
        "transformationmodel": 1,
        "thegridsizeofthebsplinecontrolpointmeshishalvedineachresolutiontoincreasethetransformation": 1,
        "iterations": 1,
        "accord": 1,
        "setandequal": 1,
        "length": 2,
        "edge": 1,
        "measures": 1,
        "twoevaluationmeasureswereusedtoverifytheregistration": 1,
        "theeuclideandistanceandthemeanoverlaptheeuclidean": 1,
        "distance": 9,
        "andarecoordinatesfromthefixedandmoving": 1,
        "respectively": 7,
        "ri": 1,
        "corner": 2,
        "fo": 1,
        "andisalandmarkattime": 1,
        "place": 1,
        "observer": 1,
        "inverse": 1,
        "overlap": 2,
        "segmentation": 1,
        "dice": 2,
        "coefficient": 1,
        "dsc": 5,
        "labelled": 1,
        "region": 2,
        "assess": 2,
        "wilcoxon": 2,
        "sign": 2,
        "rank": 3,
        "test": 4,
        "of100": 1,
        "wilcoxonsigned": 1,
        "smoothness": 3,
        "iment": 1,
        "determinant": 2,
        "spatial": 1,
        "fluctuationqiao": 1,
        "fig1": 1,
        "euclideandistanceerrorinmmfortherirebraindataperformedusi": 1,
        "themedianeuclidean": 1,
        "distanceerror": 1,
        "lungct": 1,
        "datathesymbols": 1,
        "andindicate": 1,
        "statistically": 1,
        "significant": 4,
        "withasgd": 2,
        "denotesnosignificant": 1,
        "ofshould": 1,
        "relatively": 2,
        "mooth": 1,
        "deviation": 2,
        "represent": 3,
        "thecomputationtimeisdeterminedbythenumberofparam": 1,
        "eters": 1,
        "beignored": 1,
        "thebspline": 1,
        "timeand": 1,
        "pure": 1,
        "wer": 1,
        "emeasured": 1,
        "esults": 1,
        "results": 2,
        "inthissection": 1,
        "wecomparethe": 1,
        "registrationaccuracybetween": 1,
        "fig": 22,
        "eight": 1,
        "thebrainimagesthemedianeuclidean": 1,
        "distancebeforeregistration": 1,
        "mmtheresult": 1,
        "similartotheasgdmethod": 1,
        "medianaccuracyis1616and17mmforasgd": 1,
        "wilcoxonsignedranktestoffasgdcomparedwithasgdand": 1,
        "statistical": 3,
        "median": 4,
        "pointsof": 1,
        "comparedwith": 1,
        "than003": 1,
        "define": 1,
        "asfig": 1,
        "forthespreadlungctdatathetwonumbersonthetopofeachboxdenotethe": 1,
        "nd": 1,
        "belong": 1,
        "box": 3,
        "plot": 6,
        "yf": 1,
        "negative": 1,
        "numbersmean": 1,
        "good": 2,
        "vice": 1,
        "versa": 1,
        "canbeseenthatboth": 1,
        "andfasgdprovideresultssimilarto": 1,
        "foralltestedcostfunctionsthespreadofthe": 1,
        "identical": 2,
        "resulting": 1,
        "generate": 1,
        "somewhatsmoother": 1,
        "measures398": 1,
        "minutesof": 1,
        "inthisexperiment": 1,
        "fasgdiscom": 1,
        "dw": 1,
        "ha": 1,
        "da": 1,
        "periments": 1,
        "fig4showstheoverlapresultsofthe83brainregionseach": 1,
        "squarerepresentsthemediandscresultof870brainimageregistration": 1,
        "pair": 1,
        "certain": 1,
        "notethat": 1,
        "dark": 1,
        "black": 5,
        "color": 1,
        "and05": 1,
        "anything": 1,
        "failure": 3,
        "low": 5,
        "fail": 4,
        "abdomen": 2,
        "fromultrasound": 1,
        "medianeuclidean": 1,
        "resultof": 1,
        "is0485": 1,
        "theruntimeonspreadlungct": 1,
        "dataisshowninfig6": 1,
        "inwhichthetimeusedintheestimationsoftheoriginalmethodtakesalargepartofthetotalruntimeperfig5": 1,
        "euclideandistanceinmmoftheregistrationresultsforultrasoun": 1,
        "ddata": 1,
        "whilefasgdconsumesonlyasmallfractionofthe": 1,
        "r1": 4,
        "r3": 5,
        "thenumber": 1,
        "increasesfrom": 1,
        "crease": 1,
        "fasgdmaintainsaconstantestimationtimeofnomorethan1second": 1,
        "theruntimeresultofthehammers": 1,
        "thespread": 1,
        "largerestimationtimesforasgdand": 1,
        "theestimationtimeinqiao": 1,
        "green": 2,
        "redbarindicateestimationtime": 1,
        "pureregistrationtimeandtotaltimeel": 1,
        "apsedin": 1,
        "eachresolution": 2,
        "respectivelyr1": 2,
        "r2": 4,
        "r3indicateathreelevelmultire": 1,
        "solution": 2,
        "thethirdresolutionisalmost95seconds": 1,
        "whileforfasgditis": 1,
        "spacing": 1,
        "trolpointsusedinthe4dultrasounddataexperimentis15": 1,
        "third": 1,
        "r3is": 1,
        "orig": 1,
        "inalmethodtakesalmost1400seconds": 1,
        "around23minutes": 1,
        "secondsfig": 1,
        "greenandredbarindicateestimationtime": 2,
        "pureregistrationtimeandtot": 1,
        "altime": 1,
        "elapsedineachresolution": 1,
        "r3indicateathreeleve": 1,
        "lmulti": 1,
        "pureregistrationtimeandtotaltim": 1,
        "eelapsed": 1,
        "level": 2,
        "multi": 1,
        "resolu": 1,
        "fig9": 1,
        "runtimeinsecondsoffasgdforultrasoundexperimenttheleftbarindicate": 1,
        "bar": 1,
        "resol": 1,
        "ution": 1,
        "andfor": 1,
        "ultrasounddatatheestimationof": 1,
        "takesaconstanttimeduring": 1,
        "soforsmall": 1,
        "theestimationof": 1,
        "dominatesthe": 1,
        "time400": 1,
        "r2asgd": 4,
        "rire01000200030004000500060007000": 1,
        "hammers0500100015002000": 1,
        "ul": 1,
        "trasound": 1,
        "last": 2,
        "experi": 1,
        "ments": 1,
        "red": 1,
        "fromeachofthefourexperiments": 1,
        "werandomlyselectedone": 1,
        "patientandanalyzedthestepsizesequence": 1,
        "theresultsare": 1,
        "sizethanasgdand": 1,
        "forrigidregistrationandasmaller": 1,
        "regis": 1,
        "tration": 1,
        "stepsizeinallexperimentsevenwhen": 1,
        "usesthedefault": 1,
        "eu": 1,
        "clideandistance": 1,
        "ateachiterat": 1,
        "ionforthreeresolutionswith": 1,
        "showninfig11": 1,
        "thethreemethodsbehavesimilarly": 1,
        "discussion": 1,
        "work": 2,
        "deal": 1,
        "differently": 1,
        "evaluatedonavarietyofimaging": 1,
        "includingdifferent": 1,
        "modality": 1,
        "intra": 1,
        "inter": 1,
        "vari": 1,
        "ous": 1,
        "popular": 1,
        "sensitivity": 1,
        "differen": 1,
        "ce": 2,
        "ctexperimentandthehammersbraindataweobservedstatis": 1,
        "wereverysmall": 1,
        "onaveragelessthan003mmonthespreaddatafig": 1,
        "top": 1,
        "row": 1,
        "clidean": 1,
        "bottom": 1,
        "ow": 1,
        "lessthan5": 1,
        "ofthevoxelsize": 1,
        "andlessthan001diceoverlap": 1,
        "little": 1,
        "especiallyfrom": 1,
        "fig10itcanbeobserved": 1,
        "sim": 1,
        "ilar": 1,
        "opti": 2,
        "mization": 1,
        "uggests": 1,
        "default": 1,
        "indeed": 1,
        "typically": 2,
        "esti": 1,
        "mate": 1,
        "patie": 1,
        "confirms": 1,
        "obser": 1,
        "vation": 1,
        "shifted": 1,
        "totherightcomparedtotheothertwomethodsthissuggeststhat": 1,
        "moresimilarstepsizesmaybeobtainedwhenchoosing": 1,
        "twiceaslargeasforasgd": 1,
        "toincreasethedefaultfromonevoxel": 1,
        "apparent": 1,
        "forfasgdrememberthat": 1,
        "representsthemaximumallowed": 1,
        "per": 2,
        "med": 1,
        "ical": 1,
        "unrealistic": 1,
        "start": 1,
        "df": 1,
        "thetemporaryincreaseinaccuracyat": 1,
        "forfasgdisduetoanundesireddecreasein": 1,
        "thatasgdusestheexactsameterm": 1,
        "butthisdoesnot": 1,
        "increased": 1,
        "already": 1,
        "reduction": 1,
        "consumption": 2,
        "spreadexperiment": 1,
        "reducedqiao": 1,
        "improvement": 1,
        "crucial": 1,
        "near": 1,
        "bottle": 1,
        "neck": 1,
        "isperformedwitharelativelyhighnumberofvoxels": 1,
        "fromthefixedimagefutureworkwillincludetheinvestigation": 1,
        "accelerated": 1,
        "redu": 1,
        "lem": 1,
        "direct": 1,
        "acceleration": 1,
        "possib": 1,
        "ility": 1,
        "paralleliza": 1,
        "consist": 1,
        "ofan": 1,
        "independentloop": 1,
        "overthe": 1,
        "lection": 1,
        "optimi": 1,
        "zers": 1,
        "newtonlike": 1,
        "mizers": 1,
        "thatsuchastrategycannotreadil": 1,
        "ybeadoptedforstochasticop": 1,
        "timizationduetothestochast": 1,
        "icapproximationofthecostfunc": 1,
        "strengthsofquasinewtonoptimizersaretheiradapt": 1,
        "abilitytoproblemswheretheparametersarescaledwithrespect": 1,
        "vailability": 1,
        "stop": 2,
        "condition": 2,
        "optimiza": 2,
        "tionroutinestypicallythenumbe": 1,
        "rofiterationsisusedtotermi": 1,
        "nate": 1,
        "sophisticated": 1,
        "escent": 1,
        "readily": 1,
        "adoptedforexample": 1,
        "duetotheestimationnoise": 1,
        "stoppingcon": 1,
        "ditions": 1,
        "ba": 1,
        "sed": 1,
        "trust": 1,
        "alterna": 1,
        "tive": 1,
        "every": 1,
        "attractive": 1,
        "required": 1,
        "elastix": 3,
        "metric": 1,
        "least": 1,
        "onds": 1,
        "feasible": 1,
        "possibility": 1,
        "would": 1,
        "stopping": 1,
        "dition": 1,
        "average": 1,
        "noisy": 1,
        "reduce": 4,
        "year": 1,
        "about23daysithoweverdidrequireaonetimeinvestmentoftimetodevelopthesoftwaresupportingtheregistrationjobson": 1,
        "thegridtypicalissuesweencounteredwasattemptingtostore": 1,
        "simultaneous": 1,
        "execution": 4,
        "whichproved": 1,
        "incompatible": 1,
        "transaction": 1,
        "support": 1,
        "storage": 6,
        "management": 2,
        "service": 1,
        "able": 1,
        "pool": 1,
        "singlestorage": 1,
        "infrastructure": 3,
        "build": 1,
        "screens": 1,
        "thesoftwareunderexecutionfr": 1,
        "omthecomplexitiesthatareen": 1,
        "counteredwhenrunningonthe": 1,
        "lsgridatthesametimeitis": 1,
        "generic": 1,
        "enough": 1,
        "configurable": 1,
        "en": 1,
        "vironmentstosupportotherexperimentsnotjustthe": 1,
        "fl": 1,
        "wu": 1,
        "reused": 1,
        "onclusion": 1,
        "timating": 1,
        "fromthemagnitudeofvoxeldis": 1,
        "placement": 1,
        "randomlysampled": 1,
        "theexpectationandvarianceoftheo": 1,
        "bservedvoxelsdisplacementis": 1,
        "derive": 1,
        "free": 1,
        "maximally": 1,
        "ations": 1,
        "unlike": 1,
        "interpret": 1,
        "termsof": 1,
        "mostly": 1,
        "application": 1,
        "resultsforallapplicationsevaluatedinthispapercomparedtotheoriginalasgdmethod": 1,
        "thetimecomplexityofthefasgd": 1,
        "dimensionofthetransformationparameters": 1,
        "forthebspline": 1,
        "duetoitscompactsupport": 1,
        "thetimecomplexity": 1,
        "far": 1,
        "mak": 1,
        "ing": 1,
        "ndependent": 1,
        "publicly": 1,
        "available": 2,
        "via": 2,
        "open": 1,
        "source": 1,
        "toolbox": 1,
        "thefasgdmethodwasevaluatedonala": 1,
        "rgenumberofreg": 1,
        "istrationscenario'sandshowsasimilaraccuracyastheoriginal": 1,
        "asgdmethodithoweverimprovesthetimecomplexityofthe": 1,
        "stepsizeestimationfrom40se": 1,
        "condstonomorethan1second": 1,
        "whenthenumberofparametersis": 1,
        "almost40timesfaster": 1,
        "dependingontheregistrationsettings": 1,
        "thetotalregistrationtime": 1,
        "thelsgrid": 1,
        "infrastructurecomprisesdistributedcomputing": 1,
        "along": 1,
        "central": 1,
        "facility": 1,
        "potential": 1,
        "forapproximately10000job": 1,
        "slotsjobscheduling": 1,
        "gl": 1,
        "ite": 1,
        "middleware": 1,
        "glite": 2,
        "workload": 2,
        "ystem": 1,
        "wms": 2,
        "european": 1,
        "rectly": 1,
        "schedule": 7,
        "pipeline": 6,
        "job": 29,
        "short": 1,
        "poor": 1,
        "fit": 1,
        "queue": 1,
        "unforseen": 1,
        "delay": 1,
        "push": 1,
        "mechanism": 1,
        "considerable": 1,
        "overhead": 1,
        "issue": 1,
        "address": 1,
        "layer": 1,
        "pull": 2,
        "pilot": 12,
        "onto": 1,
        "thegrid": 1,
        "matching": 1,
        "nodes": 1,
        "occursonceatpilotjobstartupafterwhichjobtokensarepulled": 1,
        "concept": 1,
        "jobs": 1,
        "wasfirst": 1,
        "pioneer": 1,
        "egi": 1,
        "within": 1,
        "dirac": 1,
        "em": 1,
        "ployed": 1,
        "light": 1,
        "weight": 1,
        "surfsara": 1,
        "call": 1,
        "picas": 4,
        "architecture": 2,
        "exe": 1,
        "cutethehammerspipelinepicaswasextendedwithawrapper": 1,
        "element": 1,
        "environmentsetupanddataretrievalthewrapperjobandtheham": 1,
        "merspipelinearecodedusingpython": 1,
        "thejobtokenscon": 1,
        "tain": 1,
        "locations": 1,
        "ganga": 2,
        "monitor": 3,
        "execute": 3,
        "jobtokensfromthepicasdata": 1,
        "basetheoverallprogressofthe": 1,
        "executioncanbecheckedbymonito": 1,
        "ringthestatusofthejobto": 1,
        "ken": 2,
        "web": 1,
        "browser": 2,
        "access": 1,
        "jobtoken": 1,
        "database": 2,
        "ls": 1,
        "gridfollows": 1,
        "initialize": 1,
        "token": 8,
        "tokens": 1,
        "contain402": 1,
        "running": 1,
        "arrows": 1,
        "flow": 1,
        "information": 1,
        "upload": 1,
        "executio": 1,
        "np": 1,
        "sb": 1,
        "yc": 1,
        "gj": 1,
        "commence": 1,
        "necessary": 2,
        "requirement": 1,
        "usingglitewmsfrominsidegangaadditionalinforma": 1,
        "pass": 1,
        "concern": 1,
        "progress": 2,
        "monitoring": 1,
        "identi": 1,
        "fies": 1,
        "cluster": 1,
        "match": 1,
        "equirements": 1,
        "pilotjobsoncethepilotisstartedthepicaswrapperjob": 1,
        "worker": 1,
        "node": 1,
        "consume": 1,
        "retrieve": 1,
        "mark": 1,
        "lock": 1,
        "identified": 1,
        "isdownloaded": 1,
        "wrap": 1,
        "uploaded": 1,
        "specified": 1,
        "thejob": 1,
        "success": 1,
        "logfiles": 1,
        "append": 1,
        "assist": 1,
        "debug": 1,
        "immediately": 1,
        "download": 1,
        "eusable": 1,
        "processing": 1,
        "cknowledgment": 1,
        "project": 2,
        "acknowledge": 2,
        "platform": 1,
        "evaluati": 1,
        "grateful": 1,
        "dr": 2,
        "alfor": 1,
        "adult": 1,
        "atlas": 1,
        "bakker": 1,
        "stolk": 1,
        "providing": 1,
        "sintefdept": 1,
        "technology": 2,
        "norwegian": 1,
        "ofscience": 1,
        "context": 1,
        "iiios": 1,
        "marie": 1,
        "curie": 1,
        "itn": 1
    },
    "objective": [
        "in this paper , we propose a new computationally efﬁcient method ( fast asgd ) to automatically determine the step size for gradient descent method , by consid-eringtheobserveddistributionof thevoxeldisplacementsbetween iteration .",
        "in this paper , we propose a new computationally efﬁcient method , fastasgd ( hereafterfasgd ) , toautomaticallyselectthe optimization step sizefor gradient descent optimization , byderiving a relation with the observed voxel displacement .",
        "maximum voxel displacement the intuition of the propose step size selection method be thatthevoxeldispl acementsshouldstartwithareasonablevalue and gradually diminish to zero .",
        "the matrix com- putation require multiplicationsand addition for each of the voxels , and therefore the time complexity of the propose method be .",
        "4 present an apparent accuracy increase when forfasgd.rememberthat representsthemaximumallowed voxel displacement per iteration in mm , and that for the med- ical data use in this paper large be unrealistic .",
        "the time performance of the propose method show in section v-b implies that fasgd have a large reduction in time consumption of the step size estimation .",
        "c onclusion in this paper , a new automatic method ( fasgd ) for es- timating the optimization step size parameter , need for gradient descent optimization method , have be present for image registration .",
        "the propose method have a free parameter , d e ﬁ n i n g the maximally allow incremental displacement between iter- ations .",
        ", set it equal to the voxel size provide good resultsforallapplicationsevaluatedinthispaper.comparedtotheoriginalasgdmethod , thetimecomplexityofthefasgd method be reduce from quadratic to linear with respect to the dimensionofthetransformationparameters .fortheb-spline transformation , duetoitscompactsupport , thetimecomplexity be far reduce , mak ing the propose method i ndependent of ."
    ],
    "references": [
        "",
        "R EFERENCES [1] J. Maintz and M. A. Viergever, “A survey of medical image registra- tion,” Med. Image Anal. , vol. 2, no. 1, pp. 1–36, 1998. [2] B. Zitova and J. Flusser, “Image registration methods: A survey,” Image Vis. Comput. , vol. 21, no. 11, pp. 977–1000, 2003. [ 3 ]J .P .P l u i m ,J .A .M a i n t z ,a n dM .A .V i e r g e v e r ,“ M u t u a l - i n f o r m a t i o n - based registration of medical images: A survey,” IEEE Trans. Med. Imag., vol. 22, no. 8, pp. 986–1004, Aug. 2003. [4] A. Sotiras, C. Davatzikos, and N . Paragios, “Deformable medical image registration: A survey,” IEEE Trans. Med. Imag. , vol. 32, no. 7, pp. 1153–1190, Jul. 2013. [5] A. Klein et al., “Evaluation of 14 nonlinear deformation algorithms appliedtohumanbrainMRIregistration,” Neuroimage ,vo l.46 ,no .3, pp. 786–802, 2009. [ 6 ] R .S h a m s ,P .Sa d eg h i ,R .A .K en n e d y ,a n dR .I .H a rt l e y ,“ As u rv e yo f medical image registration on multicore and the GPU,” IEEE Signal Process. Mag. , vol. 27, no. 2, pp. 50–60, Mar. 2010. [ 7 ]D .P .S h a m o n i n et al., “Fast parallel image registration on CPU and GPUfordiagnosticclassiﬁcationofAlzheimer'sdisease,” Front. Neu- roinformat. , vol. 7, 2013. [8] F. Maes, D. Vandermeulen, and P. Suetens, “Comparative evaluation ofmultiresolutionoptimizationstrategiesformultimodalityimagereg - istration by maximization of mutual information,” Med. Image Anal. , vol. 3, no. 4, pp. 373–386, 1999. [9] J. Kybic and M. Unser, “Fast parametric elastic image registration,” IEEE Trans. Image Process. ,vol.12,no.11,pp.1427–1442,Nov.2003. [10] S. Klein, M. Staring, and J. P. Pluim, “Evaluation of optimization methods for nonrigid medical image registration using mutual infor-mation and B-splines,” IEEE Trans. Image Process. , vol. 16, no. 12, pp. 2879–2890, Dec. 2007. [11] R. C. Hardie, K. J. Barnard, and E. E. Armstrong, “Joint map regis- tration and high-resolution image estimation using a sequence of un-dersampled images,” IEEE Trans. Image Process. ,v o l .6 ,n o .1 2 ,p p . 1621–1633, Dec. 1997. [12] P. Thevenaz and M. Unser, “Optim ization of mutual information for multiresolution image registration,” IEEE Trans. Image Process. , vol. 9, no. 12, pp. 2083–2099, Dec. 2000. [13] S.Kabus,T.Netsch,B.Fischer,andJ.Modersitzki,“B-splineregist ra- tion of 3D images with Levenberg-Marquardt optimization,” in Med. Imag., 2004, pp. 304–313. [14] M. Kisaki et al., “High speed image registration of head CT and MR images based on Levenberg-Marquardt algorithms,” in Soft Comput. Intell. Syst., 2014 Joint 7th Int. Conf. Adv. Intell. Syst. , 2014, pp. 1481–1485. [15] D.Mattes,D.R.Haynor,H.Vesselle,T.K.Lewellen,andW.Eubank, “PET-CTimageregistrationinthechestusingfree-formdeformations,”IEEE Trans. Med. Imag. ,vol.22,no.1,pp.120–128,Jan.2003. [16] M.Sdika,“Afastnonrigidimageregistrationwithconstraintsonthe Ja- cobian using large scale constrained optimization,” IEEE Trans. Med. Imag., vol. 27, no. 2, pp. 271–281, Feb. 2008. [17] S. Damas, O. Cordón, and J. Santamaría, “Medical image registra- tion using evolutionary computation: An experimental survey,” IEEE Comput. Intell. Mag. , vol. 6, no. 4, pp. 26–42, 2011. [18] M.P.Wachowiak,R.Smolíková,Y.Zheng,J.M.Zurada,andA.S.El- maghraby,“Anapproachtomultimodalbiomedicalimageregistrationutilizing particle swarm optimization,” IEEE Trans. Evolut. Comput. , vol. 8, no. 3, pp. 289–301, Jun. 2004. [19] Y.-W. Chen, C.-L. Lin, and A. Mimori, “Multimodal medical image registrationusingparticleswarmoptimization,”in Proc. 8th Int. Conf. Intell. Syst. Design Appl. , 2008, vol. 3, pp. 127–131. [20] A.A.Cole-Rhodes,K.L.Johnson,J.LeMoigne,andI.Zavorin,“Mul- tiresolution registration of remote sensing imagery by optimization ofmutual information using a stochastic gradient,” IEEE Trans. Image Process., vol. 12, no. 12, pp. 1495–1511, Dec. 2003. [21] S.Klein,J.Pluim,M.Staring,an dM.V ier gever,“Ad aptivestochasti c gradient descent optimisation for image registration,” Int. J. Comput. Vis., vol. 81, no. 3, pp. 227–239, 2009. [22] J. C. Spall, “Implementation of the simultaneous perturbation algo- rithm for stochastic optimization,” IEEE Trans. Aerospace Electron. Syst., vol. 34, no. 3, pp. 817–823, Jul. 1998. [23] L. Bottou, “Stochastic gradient learning in neural networks,” Proc. Neuro-N ımes, vol. 91, no. 8, 1991.QIAO et al.: FAST AUTOMATIC STEP SIZE ESTIMATIONFOR GRADIENTDESCENT OPTIMIZATION O F IMAGE REGISTR ATION 403 [24] A.Harju,B.Barbiellini,S.Siljamäki,R.Nieminen,andG.Ortiz,“St o- chasticgradientapproximation:Anefﬁcientmethodtooptimizemany-body wave functions,” Phys. Rev. Lett. ,vol. 79, no. 7, p. 1173,1997. [25] H.RobbinsandS.Monro,“Astochasticapproximationmethod,” Ann. Math. Stat. , vol. 22, no. 3, pp. 400–407, Sep. 1951. [26] R.Suri andY.T.Leung,“Single run optimization of aSIMAN model forclosedloopﬂexibleassemblysystems,”in Proc. 19th Conf. Winter Simulat., New York, 1987, pp. 738–748. [27] R. Brennan and P. Rogers, “Stochastic optimization applied to a man- ufacturingsystemoperationproblem,”in Proc. Winter Simulat. Conf. , Dec. 1995, pp. 857–864. [28] H. Kesten, “Accelerated stochastic approximation,” Ann. Math. Stat. , pp. 41–59, 1958. [29] A. Gaivoronski, “Stochastic quasigradient methods and their imple- mentation,” Numerical Tech. Stochastic Optimization , vol. 10, pp. 313–351, 1988. [30] Y.-H. Dai and H. Zhang, “Adaptive two-point stepsize gradient algo- rithm,” Numerical Algorithms , vol. 27, no. 4, pp. 377–385, 2001. [31] J. C. Spall , Introduction to Stochastic Search and Optimization: Esti- mation, Simulation, and Control . New York: Wiley, 2005, vol. 65. [32] A. P. George and W. B. Powell, “Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming,”Mach. Learn. , vol. 65, no. 1, pp. 167–198, 2006. [ 3 3 ]R .B h a g a l i a ,J .A .F e s s l e r ,a n dB . Kim, “Accelerated nonrigid inten- sity-basedimageregistrationusingimportancesampling,” IEEE Trans. Med. Imag. , vol. 28, no. 8, pp. 1208–1216, Aug. 2009. [34] Y. Qiao, B. Lelieveldt, and M. Staring, “Fast automatic estimation of the optimization step size for nonrigid image registration,” in SPIE Medical Imaging , 2014, pp. 90 341A–90 341A. [35] H. J. Kushner and G. Yin , Stochastic Approximation and Recursive Algorithms and Applications . New York: Springer Science Business Media, 2003, vol. 35. [36] A. Plakhov and P. Cruz, “A stochastic approximation algorithm with step-sizeadaptation,” J. Math. Sci. ,vol.120,no.1,pp.964–973,2004. [37] S. Klein, M. Staring, K. Murphy, M. A. Viergever, and J. P. Pluim, “elastix :Atoolboxforintensity-basedmedicalimageregistration,” I E E ET r a n s .M e d .I m a g . , vol. 29, no. 1, pp. 196–205, Jan. 2010. [38] D.VysochanskijandY.I.Petunin,“Justiﬁcationofthe ruleforuni- modaldistributions,” Theory Probabil. Math. Stat. ,vol.21,pp.25–36, 1980. [39] J. West et al., “Comparison and evaluation of retrospective inter- modality brain image registration techniques,” J. Comput. Assist. Tomogr., vol. 21, no. 4, pp. 554–568, 1997. [40] J. Stolk et al., “Progression parameters for emphysema: A clinical in- vestigation,” Respiratory Med. , vol. 101, no. 9, pp. 1924–1930, 2007. [41] K.Murphy et al.,“Semi-automaticconstructionofreferencestandards forevaluationofimageregistration,” Med. Image Anal. ,vol.15,no.1, pp. 71–84, 2011. [42] M.Staring et al.,“Towardslocalprogressionestimationofpulmonary emphysemausing CT,” Med. Phys. , vol. 41, no. 2,p. 021905, 2014.[43] A. Hammers et al., “Three-dimensional maximum probability atlas of the human brain, with particular reference to the temporal lobe,”Human Brain Mapp. , vol. 19, no. 4, pp. 224–247, 2003. [44] I. S. Gousias et al., “Automatic segmentation of brain MRIs of 2-year-olds into 83 regions of interest,” NeuroImage ,v o l .4 0 ,n o .2 , pp. 672–684, 2008. [45] S.Vijayan et al.,“Motiontrackingintheliver:Validationofa method basedon4Dultrasoundusinganonrigidregistrationtechnique,” Med. Phys., vol. 41, no. 8, 2014. [46] P.SeroulandD.Sarrut,“VV:Aviewerfortheevaluationof4Dimage registration,” in Proc. MICCAI , 2008, pp. 1–8. [47] F.Maes,A.Collignon,D.Vander meulen,G.Marchal,andP.Suetens, “Multimodality image registration by maximization of mutual infor-mation,” IEEE Trans. Med. Imag. , vol.16, no. 2, pp. 187–198, 1997. [48] Life science grid [Online]. Available: https://surfsara.nl/proje ct/life- science-grid [49] D. Rueckert et al., “Nonrigid registration using free-form deforma- tions:ApplicationtobreastMRimages,” IEEE Trans. Med. Imag. ,vol. 18, no. 8, pp. 712–721, Aug. 1999. [50] C. Metz, S. Klein, M. Schaap, T. van Walsum, and W. J. Niessen, “Nonrigidregistrationofdynamicmedicalimagingdatausing B-splinesandagroupwiseoptimizationapproach,” Med. Image Anal. , vol. 15, no. 2, pp. 238–249, 2011. [51] W.Sun,W.Niessen,M.vanStralen,andS.Klein,“Simultaneousmul- tiresolution strategies for nonrigid image registration,” IEEE Trans. Image Process. , vol. 22, no. 12, pp. 4905–4917, Dec. 2013. [52] N. N. Schraudolph and T. Graepel, “Combining conjugate direction methods with stochastic approximation of gradients,” in Proc. 9th Int. Workshop Artif. Intell. Stat. , Jan. 2003. [53] E.Laure et al.,ProgrammingtheGridwithgLite2006[Online].Avail- able: http://cds.cern.ch/record/936685 [54] P. Andreetto et al., “The gLite workload management system,” in J. Phys. Conf. Ser. , Jul. 2008, vol. 119, p. 062007, 6. [55] EGI Site [Online]. Available: http://www.egi.eu/[56] C. Marco, C. Fabio, D. Alvise, G. Antonia, G. Francesco, M. Alessandro, M. Moreno, M. Salvatore, P. Fabrizio, P. Luca, andP. Francesco, “The gLite work load management system,” in Ad- vances in Grid and Per vasive Computing , N. Abdennadher and D. Petcu, Eds. Berlin, Germany: Spr inger, 2009, vol. 5529, LNCS, pp. 256–268. [57] A. Casajus, R.Graciani, S. Paterson,and A. Tsaregorodtsev,“DIRAC pilotframeworkandtheDIRACworkloadmanagementsystem,”in J. Phys., Conf. Ser. , Apr. 2010, vol. 219, p. 062049, 6. [58] jjbot/picasclient [Online]. Available: https://github.com/jjbo t/picas- client [59] RP3/Grid Training GitLab [Online]. Available: https://git.lumc.nl/ rp3/grid_training/tree/1c654deb90d85a4c62cbc1cfac6f2fb64572a78b [60] Python [Online]. Available: https://www.python.org/[61] Ganga: Gaudi/Athena and Grid Alliance [Online]. Available: http:// ganga.web.cern.ch/ganga/ ,"
    ]
}{
    "name": null,
    "paragraphs": [
        "tsinghua science and technology issnll1007-0214ll11/11llpp112–118 volume 22 , number 1 , february 2017 hyperdb : a hyperspectral land class database designed for an image processing system yizhou fan\u0003 , ding ni , and hongbing ma abstract : hyperspectral remote sensing be become more and more important amongst remote sense technique .",
        "in this paper , we present a hyperspectral database ( hyperdb ) design to cooperate with an embedded hyperspectral image processing system develop by the author .",
        "hyperspectral data be recognize and categorize by their land coverage class and band information , and can be import from various source such as airborne and spaceborne sensor carry by airplane or satellite , as well as handhold instrument base on in situground observation .",
        "spectral library ﬁles can be easily store , indexed , view , and export .",
        "since hyperdb follow standard design principles—independence , data safety , and compatibility—it satisﬁes the practical demand for manage categorized hyperspectral data , and can be readily expand to other peripheral application .",
        "key word : hyperspectral database ; spectral library ; image processing 1 introduction hyperspectral remote sensing be deﬁned as the acquisition of image from hundred of contiguous , register , spectral band such that for each pixel a radiance spectrum can be derive [ 1 ] .",
        "in over three decade , hyperspectral remote sensing have play an increasingly important role in the remote sense image ﬁeld .",
        "compared to traditional multispectral remote sense method , hyperspectral imaging have several advantage .",
        "by create a dense and continuous radiance spectrum , hyperspectral imaging can delineate the spectral characteristic of different genre of land class in detail , hence make precise spectral operation possible , such as identify surface material , remove atmospheric effect , correlate pixel spectrum with \u000fyizhou fan , ding ni , and hongbing ma be with the department of electronic engineering , tsinghua university , beijing 100084 , china .",
        "e-mail : fyz13 @ mails.tsinghua.edu.cn .",
        "\u0003to whom correspondence should be address .",
        "manuscript receive : 2016-09-19 ; revise : 2016-12-14 ; accept : 2016-12-28spectral database , etc .",
        "[ 2 , 3 ] the versatility of hyperspectral remote sensing have inspire its application in a wide range of area .",
        "the retrievable and manipulatable data content type include plant and vegetation specie [ 4 ] , wildlife and livestock [ 5 , 6 ] , soil and wetland [ 7 ] , mineralogy product [ 8 ] , ﬁre monitoring [ 9 ] , etc .",
        "the importance of hyperspectral remote sense yield an urgent requirement for a corresponding spectral library or database .",
        "to date , many database that support hyperspectral remote sense data have be establish and develop .",
        "the advanced spaceborne thermal emission radiometer ( aster ) spectral library be a collection of contribution of spectral data compile by the jet propulsion laboratory ( jpl ) , johns hopkins university ( jhu ) , and the united stated geological survey ( usgs ) [ 10 ] .",
        "the spectral input/output ( specchio ) database be design to manage heterogeneous data from different source , with logical relation and consistency , intuitive interface , ﬂexibility to change in science context , ﬁle format independence , and data size scalability [ 11 ] .",
        "moreover , a redesign of specchio be undertake in ref .",
        "[ 12 ] to strengthen the issue of user friendliness and inconsistency in the data model .",
        "in contrast to theseyizhou fan et al .",
        ": hyperdb : a hyperspectral land class database designed for an image processing system 113 integrated database , the spectraproc db be design exclusively for the rapid , precise , and repeatable operation of the analytical system devise ( asd ) fieldspec pro hyperspectral data format [ 13 ] .",
        "in this paper , we present a hyperspectral database , name hyperdb , which can store , index , and process hyperspectral data ﬁles , independent of the data content type .",
        "hyperdb have some distinguish trait .",
        "it be inherently base on land-class indexing , which require compulsory categorizing of the data ﬁles with the land- class tag .",
        "it allow data ﬁle input from multiple source , include those retrieve from spaceborne and airborne sensor , as well as those provide by in situ ground observation apparatus .",
        "hyperdb collaborate with an embedded hyperspectral image processing system develop by the author , which can perform various image processing operation , while pass data and result to and from hyperdb use the uniﬁed data format , eliminate the gap between database and application .",
        "the next section be organize as follow .",
        "after brieﬂy introduce the embedded image processing system in section 2 , the design principle and implementation detail of hyperdb be depict in section 3 .",
        "the main signiﬁcant function of hyperdb be elaborate in section 4 , and conclude remark of our work be provide in section 5 .",
        "2 hyperspectral image processing system as previously indicate , hyperdb be embed with a hyperspectral image processing system develop by the author .",
        "this image processing system , a very direct application of hyperdb per se , whose main interface be show in fig .",
        "1 , be design to perform a series of operation on different spectral band .",
        "the function of the hyperspectral image processing system be brieﬂy introduce below .",
        "fig .",
        "1 main interface of the embedded hyperspectral image process system.false-color composition and band selection .",
        "amongst the band whose number often easily transcend 1000 , three band be select and normalize to represent the r , g , and b component of an image , to generate a visually-friendly false-color view .",
        "the three band can either be select manually by the user , or determine by an automatic band selection strategy base on ref .",
        "[ 14 ] implement in the system , which select those band with high signal-noise ratio and mutual information .",
        "note that the band select by this strategy be not only optimal for the false-color view , but also ready for the classiﬁcation function describe below .",
        "image pre-processing .",
        "the system contain various ﬁlters to support image pre-processing operation such as noise elimination , topological and morphological transformation , etc .",
        "spectra importation and exportation .",
        "the system maintain an interactive relationship with hyperdb , which be distinct and crucial in this study .",
        "the system allow the user to select pixel in the false-color image , tag the pixel with its correspond land-class category , and export its hyperspectral signature into hyperdb .",
        "conversely , the system also allow spectral data to be import from hyperdb , serve as the reference and training set for the classiﬁcation function .",
        "land cover classiﬁcation .",
        "the system performs land cover classiﬁcation use a support vector machine method [ 15 ] .",
        "this procedure can tag each pixel in the region of interest in the hyperspectral image with a land cover class in the known land class set .",
        "the classiﬁcation can be execute use the training set from either the same series of the hyperspectral imagery , or from spectra import from hyperdb .",
        "an example of the result obtain for land cover classiﬁcation be show in fig .",
        "2 .",
        "fig .",
        "2 land cover classiﬁcation result use the support vector machine method in a single hyperspectral image .",
        "different land cover class be distinguish by a unique color.114 tsinghua science and technology , february 2017 , 22 ( 1 ) : 112–118 3 design and implementation of hyperdb the structure of the hyperspectral database of spectral signature should provide easy access for the user , include importing , export , view , compare , and search operation .",
        "spectral data need to be organize and categorize by appropriate metadata to meet the research requirement [ 16 ] .",
        "3.1 design principle to elaborate on the basic requirement of the hyperspectral database , three fundamental principle in design hyperdb be propose .",
        "3.1.1 independence the independence principle of hyperdb can be explain in two aspect .",
        "firstly , the spectral library ﬁles be independent from hyperdb , so that the data and software do not rely on each other .",
        "in this way , the data can be utilize by other software design to use the data , and the update and modiﬁcations of the software should not affect the data .",
        "secondly , the compulsory tagging of every hyperspectral signature with a certain land-class guarantee the independence between data of different land-classes .",
        "this ensure that the hyperdb be index exclusively by the land- class tag and hence provide a convenient method for classiﬁcation and other categorize operation .",
        "3.1.2 data safety the intactness and security of the spectral library ﬁles must be ensure during any operation .",
        "the incidental data safety check must be conduct prior to any operation occur in both read and write direction .",
        "read transaction should check the validity of the format and content of the ﬁle to be read , as well as its homogeneity against the data that already exist in hyperdb .",
        "write transaction must protect the target ﬁle before hyperdb perform an inspection of the data to be write .",
        "3.1.3 compatibility given the wide use of hyperspectral remote sensing and imagery , hyperdb should be compatible with commonly use software and operating system , and spectral library ﬁles need to be compatible with the universal standard format use in remote sense area .",
        "3.2 data ﬂow hyperdb be design to manage and view the spectral library ﬁles and provide data to the hyperspectral image processing system .",
        "this intent grant hyperdb apivotal position in the data ﬂow structure , as illustrate in fig .",
        "3 .",
        "from fig .",
        "3 , hyperdb have complete access to the spectral library ﬁles , which include spectral library data ﬁles and spectral library metadata ﬁles , depict in detail in section 3.3 .",
        "hyperdb have permission to read and write spectral library ﬁles , enable one to view and compare different spectrum in its workspace , and modify exist spectral data upon safety inspection .",
        "peripheral application , such as the embedded hyperspectral image processing system show in fig .",
        "3 , have no direct access to the spectral library ﬁles .",
        "instead , they can only retrieve desire data from hyperdb .",
        "the data retrieval process start with the application send an operation request to hyperdb , where the latter responds to the request and read data from the spectral library ﬁles , then export the required spectral data ( tag by the land-class ) to the application , satisfy correspond operation request .",
        "the data source of hyperdb be multiple , as previously outline .",
        "in most case , data retrieve by handheld instrument from in situ ground observation be often organize as spectral data of separate single pixel , while data retrieve by airborne and spaceborne sensor be often organize in a regional manner , as in hyperspectral imagery .",
        "the former case correspond to the external source spectral data in fig .",
        "3 , which can be directly import to hyperdb after tag with certain land-classes , and can then be view and write to the spectral library ﬁles .",
        "the latter case be recommend to be pre-processed in the hyperspectral image processing system before the spectral data of certain pixel be extract and tag , then import into hyperdb .",
        "fig .",
        "3 general data ﬂow diagram with hyperdb in the pivotal position.yizhou fan et al .",
        ": hyperdb : a hyperspectral land class database designed for an image processing system 115 hyperdb clearly play a mediator role in the data ﬂow structure , separate the spectral library ﬁles from the peripheral application as well as the external source spectral data .",
        "this structural characteristic abides by the independence design principle of hyperdb .",
        "3.3 spectral library ﬁles spectral library ﬁles be the object that be manage and categorize by hyperdb .",
        "these ﬁles be exclusively recognize by the land class tag , and an ancillary band information label , so that data from different land class category can be rigidly separate , follow the independence design principle of hyperdb .",
        "two pairwise spectral library ﬁles be distribute to each land-class with speciﬁc band information .",
        "figure 4 depict the process of hyperdb respond to an operation request send by the user or peripheral application .",
        "spectral metadata ﬁle .",
        "this ﬁle store the mutual information of the land-class .",
        "it have the ﬁlename extension of .hdr , and contain the key word list in table 1 .",
        "spectral metadata ﬁles be store in text format , and organize in the same way as the standardized format of envi , a commonly use geospatial analysis and spectral image processing software .",
        "although some fig .",
        "4 data and safety inspection ﬂow diagram inside hyperdb involve two kind of spectral library ﬁles .",
        "table 1 main key-words use in spectral metadata ﬁles .",
        "key-word explanation storage format class land class tag string samples number of band integer lines number of spectra integer spectra name name of spectra string array wavelength unit band wavelength unit string wavelength band wavelength float array description additional ﬁle description stringof the key-words do not already exist in the standardized format , it do not affect the compatiblity design principle of hyperdb , since customize key-words will automatically be ignore when the ﬁle be read by envi .",
        "actually , the key-words list in table 1 be mostly customize by hyperdb , and there be more area of standardized key-words recognizable by envi and other popular software in spectral metadata ﬁles .",
        "spectral data ﬁle .",
        "this ﬁle store every spectrum in the land class .",
        "it be assign with the ﬁlename extension of.sli , and compress into a binary ﬁle , design to save memory space .",
        "each spectrum in the land class , namely the reﬂectance value at each band arrange consecutively , be far place next to each other .",
        "3.4 file safety inspection the ﬁle safety inspection procedure be highlight with the dashed rectangle in fig .",
        "4 .",
        "it contain two inspection step , execute on different spectral library ﬁles .",
        "validity inspection be ﬁrst perform on the spectral metadata ﬁle immediately after hyperdb read the spectral library ﬁles of the requested land-class .",
        "it ensure the spectral metadata ﬁle be valid by check every key-word area be ﬁlled with content of the correct format , and be also check by some logical integrity veriﬁcation .",
        "for example , the number of band should be identical to the number of element in the wavelength array .",
        "homogeneity inspection be next perform on both the spectral metadata and spectral data ﬁles .",
        "it mainly consist of a memory space veriﬁcation between the two spectral library ﬁles , that be , ensure the length of the binary spectral data ﬁle be identical to the product of the number of band multiply by the number of spectrum in the spectral metadata ﬁle .",
        "the validity inspection be perform prior to the homogeneity inspection , because the spectral metadata ﬁle be always signiﬁcantly small than the spectral data ﬁle in size ; hence , the calculation time cost of validity inspection be trivial compare to that of homogeneity inspection .",
        "hyperdb will assertively deny access to the spectral library ﬁles whose metadata ﬁle fail the validity inspection , with no further homogeneity inspection require .",
        "if the requested spectral library ﬁles pass both inspection , they be permit to be call into the hyperdb workspace , or alternatively export to peripheral application .",
        "however , if the operation ultimately cast a request to update the spectral116 tsinghua science and technology , february 2017 , 22 ( 1 ) : 112–118 library ﬁles , a safety re-inspection must be perform in a similar two-step manner , validate that the modiﬁcation of the spectral library ﬁles will not violate the exist ﬁles .",
        "4 principal functions of hyperdb based on its design and direct access to the spectral library ﬁles , hyperdb have several function relate to spectra processing and management , some of which be introduce below .",
        "4.1 viewing , comparing , and resampling spectra upon pass the ﬁle safety inspection , the spectral library ﬁles can be read into the hyperdb workspace .",
        "after analyze the metadata ﬁles , their basic information be display in the upper leave dialog area , as show in fig .",
        "5 after analyze the metadata ﬁles .",
        "when a land-class be select , its spectrum will appear in the low left area .",
        "the spectrum can be view in the upper right area , while accurate value at arbitrary band can be read by the tracking cursor , depict as the white dashed cross line in fig .",
        "5 .",
        "if multiple spectrum be select to be view , the user can compare them , either from an identical or different land-class .",
        "each unique land-class will be assign a corresponding color to distinguish different land class .",
        "the track cursor always automatically lock to the near point in the monitoring spectrum , display its coordinate in the text box in the low right area .",
        "hyperdb also support the resampling of spectrum , for those case in which the band region or sample rate of interest do not coordinate with the band information in the spectral library ﬁles .",
        "this resampling include both up-sampling and down-sampling , and fig .",
        "5 hyperdb read spectra from the spectral library ﬁles , provide a clear view and enable comparison with spectrum from the same , or different land-class .",
        "resampling parameter could be input in the text entry box below the ﬁgure area.is implement by a linear interpolation method .",
        "resampled spectrum can then be export into other application for further use .",
        "4.2 importing spectrum and write to the spectral library ﬁles as mention in section 1 , hyperdb allow import spectral data from multiple genre of source .",
        "irrespective of which source will be use , all spectrum must be tag with the land-class and ancillary band information while be import , to ensure their validity and make them possible to pass the re- inspection before be write to the spectral library ﬁles .",
        "if the tagged land-class already exist , these spectrum will be merge into correspond exist spectral library ﬁles .",
        "if not , new spectral library ﬁles will be create use the information of these spectrum .",
        "two type of data source have be clariﬁed in section 3.2 .",
        "in hyperdb , the single spectrum data ﬁle with standardized format can be directly import , while the hyperspectral imagery data be recommend to be pre-processed in the hyperspectral image processing system .",
        "the pixel to be import can be select in the false-color image , display as red cross in fig .",
        "6 .",
        "after import into hyperdb , these spectrum can be view , compare , and resampled , as describe in section 4.1 , and write to the spectral library ﬁles upon successfully pass the ﬁle safety re- inspection .",
        "4.3 exporting spectrum to expand the adaptability of hyperdb , the spectrum should be able to be export to other peripheral fig .",
        "6 pixels of interest be select in the false-color image generate by the hyperspectral image processing system , their spectral signature be then transmit into hyperdb and write to spectral library ﬁles after tag and inspection.yizhou fan et al .",
        ": hyperdb : a hyperspectral land class database designed for an image processing system 117 application to satisfy their requirement .",
        "for example , in the land cover classiﬁcation procedure in the hyperspectral image processing system , after decide the list of possible land cover category in the region of interest to be classiﬁed , the user should select these category from hyperdb and export the spectrum of these category into the image processing system , which will perform the classiﬁcation use these spectrum as the training set and provide result in fig .",
        "2 .",
        "the hyperdb interface for this operation be show in fig .",
        "7 .",
        "note that there exist a potential problem regard band matching .",
        "data export from hyperdb be completely compatible with the peripheral application if their band information be identical to those send with the request .",
        "if not , the data will be resampled before export .",
        "however , only the coincident range of band between the hyperdb spectral library ﬁles and the request from the peripheral application be able to be resampled and export , since hyperdb do not support extrapolation due to its unacceptable loss of accuracy .",
        "5 conclusion a hyperspectral database that categorize related spectral library ﬁles by land-class , name hyperdb , be design and implement .",
        "hyperdb attempt to provide a reliable and expandable database under the fundamental design principle of independence , data safety , and compatibility .",
        "hyperdb be originally design to collaborate with an embedded hyperspectral image processing system , perform mainly land cover classiﬁcation procedure .",
        "however , more peripheral application in different platform can deﬁnitely utilize hyperdb , provide they support the standardized spectral library data ﬁle format .",
        "this adaptability by other application will enable the usage of hyperdb fig .",
        "7 spectra from a speciﬁc land-class be export to peripheral applications.in such task as land object and land use classiﬁcation , vegetation or mineral categorization , etc .",
        "since hyperdb support numerous data source , it can serve as an intermediary role between in situ ground observation , airborne and spaceborne sensor .",
        "data from multiple source can be integrate , compare , and merge if they share the same land-class ; hence , provide good data abundance and heterogeneity , which be the ultimate target of build a database ."
    ],
    "processed_text": "tsinghua science technology issnll10070214ll11/11llpp112118 volume 22 number 1 february 2017 hyperdb hyperspectral land class database designed image processing system yizhou fan\u0003 ding ni hongbing abstract hyperspectral remote sensing become important amongst remote sense technique paper present hyperspectral database hyperdb design cooperate embedded hyperspectral image processing system develop author hyperspectral data recognize categorize land coverage class band information import various source airborne spaceborne sensor carry airplane satellite well handhold instrument base situground observation spectral library files easily store indexed view export since hyperdb follow standard design principlesindependence data safety compatibilityit satisfies practical demand manage categorized hyperspectral data readily expand peripheral application key word hyperspectral database spectral library image processing 1 introduction hyperspectral remote sensing defined acquisition image hundred contiguous register spectral band pixel radiance spectrum derive 1 three decade hyperspectral remote sensing play increasingly important role remote sense image field compared traditional multispectral remote sense method hyperspectral imaging several advantage create dense continuous radiance spectrum hyperspectral imaging delineate spectral characteristic different genre land class detail hence make precise spectral operation possible identify surface material remove atmospheric effect correlate pixel spectrum \u000fyizhou fan ding ni hongbing department electronic engineering tsinghua university beijing 100084 china email fyz13 @ mailstsinghuaeducn \u0003to correspondence address manuscript receive 20160919 revise 20161214 accept 20161228spectral database etc 2 3 versatility hyperspectral remote sensing inspire application wide range area retrievable manipulatable data content type include plant vegetation specie 4 wildlife livestock 5 6 soil wetland 7 mineralogy product 8 fire monitoring 9 etc importance hyperspectral remote sense yield urgent requirement corresponding spectral library database date many database support hyperspectral remote sense data establish develop advanced spaceborne thermal emission radiometer aster spectral library collection contribution spectral data compile jet propulsion laboratory jpl johns hopkins university jhu united stated geological survey usgs 10 spectral input/output specchio database design manage heterogeneous data different source logical relation consistency intuitive interface flexibility change science context file format independence data size scalability 11 moreover redesign specchio undertake ref 12 strengthen issue user friendliness inconsistency data model contrast theseyizhou fan et al hyperdb hyperspectral land class database designed image processing system 113 integrated database spectraproc db design exclusively rapid precise repeatable operation analytical system devise asd fieldspec pro hyperspectral data format 13 paper present hyperspectral database name hyperdb store index process hyperspectral data files independent data content type hyperdb distinguish trait inherently base landclass indexing require compulsory categorizing data files land class tag allow data file input multiple source include retrieve spaceborne airborne sensor well provide situ ground observation apparatus hyperdb collaborate embedded hyperspectral image processing system develop author perform various image processing operation pass data result hyperdb use unified data format eliminate gap database application next section organize follow briefly introduce embedded image processing system section 2 design principle implementation detail hyperdb depict section 3 main significant function hyperdb elaborate section 4 conclude remark work provide section 5 2 hyperspectral image processing system previously indicate hyperdb embed hyperspectral image processing system develop author image processing system direct application hyperdb per se whose main interface show fig 1 design perform series operation different spectral band function hyperspectral image processing system briefly introduce fig 1 main interface embedded hyperspectral image process systemfalsecolor composition band selection amongst band whose number often easily transcend 1000 three band select normalize represent r g b component image generate visuallyfriendly falsecolor view three band either select manually user determine automatic band selection strategy base ref 14 implement system select band high signalnoise ratio mutual information note band select strategy optimal falsecolor view also ready classification function describe image preprocessing system contain various filters support image preprocessing operation noise elimination topological morphological transformation etc spectra importation exportation system maintain interactive relationship hyperdb distinct crucial study system allow user select pixel falsecolor image tag pixel correspond landclass category export hyperspectral signature hyperdb conversely system also allow spectral data import hyperdb serve reference training set classification function land cover classification system performs land cover classification use support vector machine method 15 procedure tag pixel region interest hyperspectral image land cover class known land class set classification execute use training set either series hyperspectral imagery spectra import hyperdb example result obtain land cover classification show fig 2 fig 2 land cover classification result use support vector machine method single hyperspectral image different land cover class distinguish unique color114 tsinghua science technology february 2017 22 1 112118 3 design implementation hyperdb structure hyperspectral database spectral signature provide easy access user include importing export view compare search operation spectral data need organize categorize appropriate metadata meet research requirement 16 31 design principle elaborate basic requirement hyperspectral database three fundamental principle design hyperdb propose 311 independence independence principle hyperdb explain two aspect firstly spectral library files independent hyperdb data software rely way data utilize software design use data update modifications software affect data secondly compulsory tagging every hyperspectral signature certain landclass guarantee independence data different landclasses ensure hyperdb index exclusively land class tag hence provide convenient method classification categorize operation 312 data safety intactness security spectral library files must ensure operation incidental data safety check must conduct prior operation occur read write direction read transaction check validity format content file read well homogeneity data already exist hyperdb write transaction must protect target file hyperdb perform inspection data write 313 compatibility given wide use hyperspectral remote sensing imagery hyperdb compatible commonly use software operating system spectral library files need compatible universal standard format use remote sense area 32 data flow hyperdb design manage view spectral library files provide data hyperspectral image processing system intent grant hyperdb apivotal position data flow structure illustrate fig 3 fig 3 hyperdb complete access spectral library files include spectral library data files spectral library metadata files depict detail section 33 hyperdb permission read write spectral library files enable one view compare different spectrum workspace modify exist spectral data upon safety inspection peripheral application embedded hyperspectral image processing system show fig 3 direct access spectral library files instead retrieve desire data hyperdb data retrieval process start application send operation request hyperdb latter responds request read data spectral library files export required spectral data tag landclass application satisfy correspond operation request data source hyperdb multiple previously outline case data retrieve handheld instrument situ ground observation often organize spectral data separate single pixel data retrieve airborne spaceborne sensor often organize regional manner hyperspectral imagery former case correspond external source spectral data fig 3 directly import hyperdb tag certain landclasses view write spectral library files latter case recommend preprocessed hyperspectral image processing system spectral data certain pixel extract tag import hyperdb fig 3 general data flow diagram hyperdb pivotal positionyizhou fan et al hyperdb hyperspectral land class database designed image processing system 115 hyperdb clearly play mediator role data flow structure separate spectral library files peripheral application well external source spectral data structural characteristic abides independence design principle hyperdb 33 spectral library files spectral library files object manage categorize hyperdb files exclusively recognize land class tag ancillary band information label data different land class category rigidly separate follow independence design principle hyperdb two pairwise spectral library files distribute landclass specific band information figure 4 depict process hyperdb respond operation request send user peripheral application spectral metadata file file store mutual information landclass filename extension hdr contain key word list table 1 spectral metadata files store text format organize way standardized format envi commonly use geospatial analysis spectral image processing software although fig 4 data safety inspection flow diagram inside hyperdb involve two kind spectral library files table 1 main keywords use spectral metadata files keyword explanation storage format class land class tag string samples number band integer lines number spectra integer spectra name name spectra string array wavelength unit band wavelength unit string wavelength band wavelength float array description additional file description stringof keywords already exist standardized format affect compatiblity design principle hyperdb since customize keywords automatically ignore file read envi actually keywords list table 1 mostly customize hyperdb area standardized keywords recognizable envi popular software spectral metadata files spectral data file file store every spectrum land class assign filename extension ofsli compress binary file design save memory space spectrum land class namely reflectance value band arrange consecutively far place next 34 file safety inspection file safety inspection procedure highlight dashed rectangle fig 4 contain two inspection step execute different spectral library files validity inspection first perform spectral metadata file immediately hyperdb read spectral library files requested landclass ensure spectral metadata file valid check every keyword area filled content correct format also check logical integrity verification example number band identical number element wavelength array homogeneity inspection next perform spectral metadata spectral data files mainly consist memory space verification two spectral library files ensure length binary spectral data file identical product number band multiply number spectrum spectral metadata file validity inspection perform prior homogeneity inspection spectral metadata file always significantly small spectral data file size hence calculation time cost validity inspection trivial compare homogeneity inspection hyperdb assertively deny access spectral library files whose metadata file fail validity inspection homogeneity inspection require requested spectral library files pass inspection permit call hyperdb workspace alternatively export peripheral application however operation ultimately cast request update spectral116 tsinghua science technology february 2017 22 1 112118 library files safety reinspection must perform similar twostep manner validate modification spectral library files violate exist files 4 principal functions hyperdb based design direct access spectral library files hyperdb several function relate spectra processing management introduce 41 viewing comparing resampling spectra upon pass file safety inspection spectral library files read hyperdb workspace analyze metadata files basic information display upper leave dialog area show fig 5 analyze metadata files landclass select spectrum appear low left area spectrum view upper right area accurate value arbitrary band read tracking cursor depict white dashed cross line fig 5 multiple spectrum select view user compare either identical different landclass unique landclass assign corresponding color distinguish different land class track cursor always automatically lock near point monitoring spectrum display coordinate text box low right area hyperdb also support resampling spectrum case band region sample rate interest coordinate band information spectral library files resampling include upsampling downsampling fig 5 hyperdb read spectra spectral library files provide clear view enable comparison spectrum different landclass resampling parameter could input text entry box figure areais implement linear interpolation method resampled spectrum export application use 42 importing spectrum write spectral library files mention section 1 hyperdb allow import spectral data multiple genre source irrespective source use spectrum must tag landclass ancillary band information import ensure validity make possible pass inspection write spectral library files tagged landclass already exist spectrum merge correspond exist spectral library files new spectral library files create use information spectrum two type data source clarified section 32 hyperdb single spectrum data file standardized format directly import hyperspectral imagery data recommend preprocessed hyperspectral image processing system pixel import select falsecolor image display red cross fig 6 import hyperdb spectrum view compare resampled describe section 41 write spectral library files upon successfully pass file safety inspection 43 exporting spectrum expand adaptability hyperdb spectrum able export peripheral fig 6 pixels interest select falsecolor image generate hyperspectral image processing system spectral signature transmit hyperdb write spectral library files tag inspectionyizhou fan et al hyperdb hyperspectral land class database designed image processing system 117 application satisfy requirement example land cover classification procedure hyperspectral image processing system decide list possible land cover category region interest classified user select category hyperdb export spectrum category image processing system perform classification use spectrum training set provide result fig 2 hyperdb interface operation show fig 7 note exist potential problem regard band matching data export hyperdb completely compatible peripheral application band information identical send request data resampled export however coincident range band hyperdb spectral library files request peripheral application able resampled export since hyperdb support extrapolation due unacceptable loss accuracy 5 conclusion hyperspectral database categorize related spectral library files landclass name hyperdb design implement hyperdb attempt provide reliable expandable database fundamental design principle independence data safety compatibility hyperdb originally design collaborate embedded hyperspectral image processing system perform mainly land cover classification procedure however peripheral application different platform definitely utilize hyperdb provide support standardized spectral library data file format adaptability application enable usage hyperdb fig 7 spectra specific landclass export peripheral applicationsin task land object land use classification vegetation mineral categorization etc since hyperdb support numerous data source serve intermediary role situ ground observation airborne spaceborne sensor data multiple source integrate compare merge share landclass hence provide good data abundance heterogeneity ultimate target build database",
    "bag_of_words": {
        "tsinghua": 4,
        "science": 4,
        "technology": 3,
        "issnll10070214ll11/11llpp112118": 1,
        "volume": 1,
        "number": 8,
        "february": 3,
        "hyperdb": 68,
        "hyperspectral": 43,
        "land": 26,
        "class": 18,
        "database": 18,
        "designed": 4,
        "image": 33,
        "processing": 23,
        "system": 27,
        "yizhou": 1,
        "fan\u0003": 1,
        "ding": 2,
        "ni": 2,
        "hongbing": 2,
        "abstract": 1,
        "remote": 11,
        "sensing": 5,
        "become": 1,
        "important": 2,
        "amongst": 2,
        "sense": 6,
        "technique": 1,
        "paper": 2,
        "present": 2,
        "design": 19,
        "cooperate": 1,
        "embedded": 6,
        "develop": 4,
        "author": 3,
        "data": 62,
        "recognize": 2,
        "categorize": 5,
        "coverage": 1,
        "band": 25,
        "information": 10,
        "import": 10,
        "various": 3,
        "source": 11,
        "airborne": 4,
        "spaceborne": 5,
        "sensor": 4,
        "carry": 1,
        "airplane": 1,
        "satellite": 1,
        "well": 4,
        "handhold": 1,
        "instrument": 2,
        "base": 3,
        "situground": 1,
        "observation": 4,
        "spectral": 70,
        "library": 40,
        "files": 46,
        "easily": 2,
        "store": 5,
        "indexed": 1,
        "view": 11,
        "export": 12,
        "since": 4,
        "follow": 3,
        "standard": 2,
        "principlesindependence": 1,
        "safety": 11,
        "compatibilityit": 1,
        "satisfies": 1,
        "practical": 1,
        "demand": 1,
        "manage": 4,
        "categorized": 1,
        "readily": 1,
        "expand": 2,
        "peripheral": 10,
        "application": 16,
        "key": 2,
        "word": 2,
        "introduction": 1,
        "defined": 1,
        "acquisition": 1,
        "hundred": 1,
        "contiguous": 1,
        "register": 1,
        "pixel": 8,
        "radiance": 2,
        "spectrum": 24,
        "derive": 1,
        "three": 4,
        "decade": 1,
        "play": 2,
        "increasingly": 1,
        "role": 3,
        "field": 1,
        "compared": 1,
        "traditional": 1,
        "multispectral": 1,
        "method": 5,
        "imaging": 2,
        "several": 2,
        "advantage": 1,
        "create": 2,
        "dense": 1,
        "continuous": 1,
        "delineate": 1,
        "characteristic": 2,
        "different": 12,
        "genre": 2,
        "detail": 3,
        "hence": 4,
        "make": 2,
        "precise": 2,
        "operation": 14,
        "possible": 3,
        "identify": 1,
        "surface": 1,
        "material": 1,
        "remove": 1,
        "atmospheric": 1,
        "effect": 1,
        "correlate": 1,
        "\u000fyizhou": 1,
        "fan": 4,
        "department": 1,
        "electronic": 1,
        "engineering": 1,
        "university": 2,
        "beijing": 1,
        "china": 1,
        "email": 1,
        "fyz13": 1,
        "mailstsinghuaeducn": 1,
        "\u0003to": 1,
        "correspondence": 1,
        "address": 1,
        "manuscript": 1,
        "receive": 1,
        "revise": 1,
        "accept": 1,
        "20161228spectral": 1,
        "etc": 4,
        "versatility": 1,
        "inspire": 1,
        "wide": 2,
        "range": 2,
        "area": 8,
        "retrievable": 1,
        "manipulatable": 1,
        "content": 4,
        "type": 3,
        "include": 5,
        "plant": 1,
        "vegetation": 2,
        "specie": 1,
        "wildlife": 1,
        "livestock": 1,
        "soil": 1,
        "wetland": 1,
        "mineralogy": 1,
        "product": 2,
        "fire": 1,
        "monitoring": 2,
        "importance": 1,
        "yield": 1,
        "urgent": 1,
        "requirement": 4,
        "corresponding": 2,
        "date": 1,
        "many": 1,
        "support": 8,
        "establish": 1,
        "advanced": 1,
        "thermal": 1,
        "emission": 1,
        "radiometer": 1,
        "aster": 1,
        "collection": 1,
        "contribution": 1,
        "compile": 1,
        "jet": 1,
        "propulsion": 1,
        "laboratory": 1,
        "jpl": 1,
        "johns": 1,
        "hopkins": 1,
        "jhu": 1,
        "united": 1,
        "stated": 1,
        "geological": 1,
        "survey": 1,
        "usgs": 1,
        "input/output": 1,
        "specchio": 2,
        "heterogeneous": 1,
        "logical": 2,
        "relation": 1,
        "consistency": 1,
        "intuitive": 1,
        "interface": 4,
        "flexibility": 1,
        "change": 1,
        "context": 1,
        "file": 24,
        "format": 12,
        "independence": 7,
        "size": 2,
        "scalability": 1,
        "moreover": 1,
        "redesign": 1,
        "undertake": 1,
        "ref": 2,
        "strengthen": 1,
        "issue": 1,
        "user": 7,
        "friendliness": 1,
        "inconsistency": 1,
        "model": 1,
        "contrast": 1,
        "theseyizhou": 1,
        "et": 3,
        "al": 3,
        "integrated": 1,
        "spectraproc": 1,
        "db": 1,
        "exclusively": 3,
        "rapid": 1,
        "repeatable": 1,
        "analytical": 1,
        "devise": 1,
        "asd": 1,
        "fieldspec": 1,
        "pro": 1,
        "name": 4,
        "index": 2,
        "process": 4,
        "independent": 2,
        "distinguish": 3,
        "trait": 1,
        "inherently": 1,
        "landclass": 16,
        "indexing": 1,
        "require": 2,
        "compulsory": 2,
        "categorizing": 1,
        "tag": 11,
        "allow": 4,
        "input": 2,
        "multiple": 5,
        "retrieve": 4,
        "provide": 10,
        "situ": 3,
        "ground": 3,
        "apparatus": 1,
        "collaborate": 2,
        "perform": 9,
        "pass": 5,
        "result": 4,
        "use": 15,
        "unified": 1,
        "eliminate": 1,
        "gap": 1,
        "next": 3,
        "section": 9,
        "organize": 5,
        "briefly": 2,
        "introduce": 3,
        "principle": 8,
        "implementation": 2,
        "depict": 4,
        "main": 4,
        "significant": 1,
        "function": 5,
        "elaborate": 2,
        "conclude": 1,
        "remark": 1,
        "work": 1,
        "previously": 2,
        "indicate": 1,
        "embed": 1,
        "direct": 3,
        "per": 1,
        "se": 1,
        "whose": 3,
        "show": 5,
        "fig": 19,
        "series": 2,
        "systemfalsecolor": 1,
        "composition": 1,
        "selection": 2,
        "often": 3,
        "transcend": 1,
        "select": 10,
        "normalize": 1,
        "represent": 1,
        "component": 1,
        "generate": 2,
        "visuallyfriendly": 1,
        "falsecolor": 5,
        "either": 3,
        "manually": 1,
        "determine": 1,
        "automatic": 1,
        "strategy": 2,
        "implement": 3,
        "high": 1,
        "signalnoise": 1,
        "ratio": 1,
        "mutual": 2,
        "note": 2,
        "optimal": 1,
        "also": 4,
        "ready": 1,
        "classification": 12,
        "describe": 2,
        "preprocessing": 2,
        "contain": 3,
        "filters": 1,
        "noise": 1,
        "elimination": 1,
        "topological": 1,
        "morphological": 1,
        "transformation": 1,
        "spectra": 9,
        "importation": 1,
        "exportation": 1,
        "maintain": 1,
        "interactive": 1,
        "relationship": 1,
        "distinct": 1,
        "crucial": 1,
        "study": 1,
        "correspond": 4,
        "category": 5,
        "signature": 4,
        "conversely": 1,
        "serve": 2,
        "reference": 1,
        "training": 3,
        "set": 4,
        "cover": 9,
        "performs": 1,
        "vector": 2,
        "machine": 2,
        "procedure": 4,
        "region": 3,
        "interest": 4,
        "known": 1,
        "execute": 2,
        "imagery": 4,
        "example": 3,
        "obtain": 1,
        "single": 3,
        "unique": 2,
        "color114": 1,
        "structure": 3,
        "easy": 1,
        "access": 5,
        "importing": 2,
        "compare": 6,
        "search": 1,
        "need": 2,
        "appropriate": 1,
        "metadata": 14,
        "meet": 1,
        "research": 1,
        "basic": 2,
        "fundamental": 2,
        "propose": 1,
        "explain": 1,
        "two": 6,
        "aspect": 1,
        "firstly": 1,
        "software": 6,
        "rely": 1,
        "way": 2,
        "utilize": 2,
        "update": 2,
        "modifications": 1,
        "affect": 2,
        "secondly": 1,
        "tagging": 1,
        "every": 3,
        "certain": 3,
        "guarantee": 1,
        "landclasses": 2,
        "ensure": 5,
        "convenient": 1,
        "intactness": 1,
        "security": 1,
        "must": 5,
        "incidental": 1,
        "check": 4,
        "conduct": 1,
        "prior": 2,
        "occur": 1,
        "read": 10,
        "write": 9,
        "direction": 1,
        "transaction": 2,
        "validity": 6,
        "homogeneity": 5,
        "already": 3,
        "exist": 7,
        "protect": 1,
        "target": 2,
        "inspection": 18,
        "compatibility": 2,
        "given": 1,
        "compatible": 3,
        "commonly": 2,
        "operating": 1,
        "universal": 1,
        "flow": 5,
        "intent": 1,
        "grant": 1,
        "apivotal": 1,
        "position": 1,
        "illustrate": 1,
        "complete": 1,
        "permission": 1,
        "enable": 3,
        "one": 1,
        "workspace": 3,
        "modify": 1,
        "upon": 3,
        "instead": 1,
        "desire": 1,
        "retrieval": 1,
        "start": 1,
        "send": 3,
        "request": 7,
        "latter": 2,
        "responds": 1,
        "required": 1,
        "satisfy": 2,
        "outline": 1,
        "case": 4,
        "handheld": 1,
        "separate": 3,
        "regional": 1,
        "manner": 2,
        "former": 1,
        "external": 2,
        "directly": 2,
        "recommend": 2,
        "preprocessed": 2,
        "extract": 1,
        "general": 1,
        "diagram": 2,
        "pivotal": 1,
        "positionyizhou": 1,
        "clearly": 1,
        "mediator": 1,
        "structural": 1,
        "abides": 1,
        "object": 2,
        "ancillary": 2,
        "label": 1,
        "rigidly": 1,
        "pairwise": 1,
        "distribute": 1,
        "specific": 2,
        "figure": 2,
        "respond": 1,
        "filename": 2,
        "extension": 2,
        "hdr": 1,
        "list": 3,
        "table": 3,
        "text": 3,
        "standardized": 5,
        "envi": 3,
        "geospatial": 1,
        "analysis": 1,
        "although": 1,
        "inside": 1,
        "involve": 1,
        "kind": 1,
        "keywords": 5,
        "keyword": 2,
        "explanation": 1,
        "storage": 1,
        "string": 3,
        "samples": 1,
        "integer": 2,
        "lines": 1,
        "array": 3,
        "wavelength": 5,
        "unit": 2,
        "float": 1,
        "description": 2,
        "additional": 1,
        "stringof": 1,
        "compatiblity": 1,
        "customize": 2,
        "automatically": 2,
        "ignore": 1,
        "actually": 1,
        "mostly": 1,
        "recognizable": 1,
        "popular": 1,
        "assign": 2,
        "ofsli": 1,
        "compress": 1,
        "binary": 2,
        "save": 1,
        "memory": 2,
        "space": 2,
        "namely": 1,
        "reflectance": 1,
        "value": 2,
        "arrange": 1,
        "consecutively": 1,
        "far": 1,
        "place": 1,
        "highlight": 1,
        "dashed": 2,
        "rectangle": 1,
        "step": 1,
        "first": 1,
        "immediately": 1,
        "requested": 2,
        "valid": 1,
        "filled": 1,
        "correct": 1,
        "integrity": 1,
        "verification": 2,
        "identical": 4,
        "element": 1,
        "mainly": 2,
        "consist": 1,
        "length": 1,
        "multiply": 1,
        "always": 2,
        "significantly": 1,
        "small": 1,
        "calculation": 1,
        "time": 1,
        "cost": 1,
        "trivial": 1,
        "assertively": 1,
        "deny": 1,
        "fail": 1,
        "permit": 1,
        "call": 1,
        "alternatively": 1,
        "however": 3,
        "ultimately": 1,
        "cast": 1,
        "spectral116": 1,
        "reinspection": 1,
        "similar": 1,
        "twostep": 1,
        "validate": 1,
        "modification": 1,
        "violate": 1,
        "principal": 1,
        "functions": 1,
        "based": 1,
        "relate": 1,
        "management": 1,
        "viewing": 1,
        "comparing": 1,
        "resampling": 4,
        "analyze": 2,
        "display": 3,
        "upper": 2,
        "leave": 1,
        "dialog": 1,
        "appear": 1,
        "low": 2,
        "left": 1,
        "right": 2,
        "accurate": 1,
        "arbitrary": 1,
        "tracking": 1,
        "cursor": 2,
        "white": 1,
        "cross": 2,
        "line": 1,
        "color": 1,
        "track": 1,
        "lock": 1,
        "near": 1,
        "point": 1,
        "coordinate": 2,
        "box": 2,
        "sample": 1,
        "rate": 1,
        "upsampling": 1,
        "downsampling": 1,
        "clear": 1,
        "comparison": 1,
        "parameter": 1,
        "could": 1,
        "entry": 1,
        "areais": 1,
        "linear": 1,
        "interpolation": 1,
        "resampled": 4,
        "mention": 1,
        "irrespective": 1,
        "tagged": 1,
        "merge": 2,
        "new": 1,
        "clarified": 1,
        "red": 1,
        "successfully": 1,
        "exporting": 1,
        "adaptability": 2,
        "able": 2,
        "pixels": 1,
        "transmit": 1,
        "inspectionyizhou": 1,
        "decide": 1,
        "classified": 1,
        "potential": 1,
        "problem": 1,
        "regard": 1,
        "matching": 1,
        "completely": 1,
        "coincident": 1,
        "extrapolation": 1,
        "due": 1,
        "unacceptable": 1,
        "loss": 1,
        "accuracy": 1,
        "conclusion": 1,
        "related": 1,
        "attempt": 1,
        "reliable": 1,
        "expandable": 1,
        "originally": 1,
        "platform": 1,
        "definitely": 1,
        "usage": 1,
        "applicationsin": 1,
        "task": 1,
        "mineral": 1,
        "categorization": 1,
        "numerous": 1,
        "intermediary": 1,
        "integrate": 1,
        "share": 1,
        "good": 1,
        "abundance": 1,
        "heterogeneity": 1,
        "ultimate": 1,
        "build": 1
    },
    "objective": [
        "in this paper , we present a hyperspectral database ( hyperdb ) design to cooperate with an embedded hyperspectral image processing system develop by the author .",
        "in this paper , we present a hyperspectral database , name hyperdb , which can store , index , and process hyperspectral data ﬁles , independent of the data content type ."
    ],
    "references": [
        "",
        "References [1] J. Solomon and B. Rock, Imaging spectrometry for earth remote sensing, Science , vol. 228, no. 4704, pp. 1147– 1152, 1985. [2] A. F. Goetz, Three decades of hyperspectral remote sensing of the earth: A personal view, Remote Sensing of Environment , vol. 113, pp. S5–S16, 2009. [3] F. D. Van der Meer, H. M. Van der Werff, F. J. van Ruitenbeek, C. A. Hecker, W. H. Bakker, M. F. Noomen, M. van der Meijde, E. J. M. Carranza, J. B. de Smeth, and T. Woldai, Multi-and hyperspectral geologic remote sensing: A review, International Journal of Applied Earth Observation and Geoinformation , vol. 14, no. 1, pp. 112– 128, 2012. [4] K. Manjunath, A. Kumar, M. Meenakshi, R. Renu, S. Uniyal, R. Singh, P. Ahuja, S. Ray, and S. Panigrahy, Developing spectral library of major plant species of western himalayas using ground observations, Journal of the Indian Society of Remote Sensing , vol. 42, no. 1, pp. 201–216, 2014. [5] P. Hyde, R. Dubayah, W. Walker, J. B. Blair, M. Hofton, and C. Hunsaker, Mapping forest structure for wildlife habitat analysis using multi-sensor (lidar, sar/insar, etm+, quickbird) synergy, Remote Sensing of Environment , vol. 102, no. 1, pp. 63–73, 2006. [6] R.-G. Zhu, B.-X. Ma, Z.-J. Gao, and J.-B. Ge, Research progress in nondestructive detection of livestock product quality based on hyperspectral imaging, Laser & Infrared , vol. 10, p. 003, 2011. [7] R. Zomer, A. Trabucco, and S. Ustin, Building spectral libraries for wetlands land cover classiﬁcation and hyperspectral remote sensing, Journal of Environmental Management , vol. 90, no. 7, pp. 2170–2177, 2009. [8] A. T. DePersia, A. P. Bowman, P. G. Lucey, and E. M. Winter, Phenomenology considerations for hyperspectral mine detection, in SPIE’s 1995 Symposium on OE/Aerospace Sensing and Dual Use Photonics , International Society for Optics and Photonics, 1995, pp. 159–167. [9] Y . Fan and H. Ma, Forest-ﬁre smoke detection method based on video signal, (in Chinese), Journal of Tsinghua University (Science and Technology) , vol. 55, no. 2, pp. 243–250, 2015. [10] A. Baldridge, S. Hook, C. Grove, and G. Rivera, The aster spectral library version 2.0, Remote Sensing of Environment , vol. 113, no. 4, pp. 711–715, 2009.118 Tsinghua Science and Technology, February 2017, 22(1): 112–118 [11] S. Bojinski, M. Schaepman, D. Schl ¨apfer, and K. Itten, Specchio: A spectrum database for remote sensing applications, Computers & Geosciences , vol. 29, no. 1, pp. 27–38, 2003. [12] A. H ¨uni, J. Nieke, J. Schopfer, M. Kneub ¨uhler, and K. Itten, 2nd generation of RSL’s spectrum database “SPECCHIO”, presented at 10th Intl. Symposium on Physical Measurements and Spectral Signatures in Remote Sensing, Davos, Switzerland, 2007. [13] A. Hueni and M. Tuohy, Spectroradiometer data structuring, pre-processing and analysis—An IT based approach, Journal of Spatial Science , vol. 51, no. 2, pp. 93–102, 2006.[14] B. Guo, S. R. Gunn, R. Damper, and J. Nelson, Band selection for hyperspectral image classiﬁcation using mutual information, Geoscience and Remote Sensing Letters, IEEE , vol. 3, no. 4, pp. 522–526, 2006. [15] T. Kavzoglu and I. Colkesen, A kernel functions analysis for support vector machines for land cover classiﬁcation, International Journal of Applied Earth Observation and Geoinformation , vol. 11, no. 5, pp. 352–359, 2009. [16] A. Hueni, J. Nieke, J. Schopfer, M. Kneub ¨uhler, and K. I. Itten, The spectral database specchio for improved long- term usability and data sharing, Computers & Geosciences , vol. 35, no. 3, pp. 557–565, 2009. Yizhou Fan received the BEng degree from Tsinghua University, China, in 2013. He is currently a PhD candidate at the Department of Electronic Engineering, Tsinghua University, China. His research interest includes image processing, remote sensing, and machine learning. Ding Ni received the BS degree from Huazhong University of Science and Technology, China, in 2012. He is currently a PhD candidate at the Department of Electronic Engineering, Tsinghua University, China. His research interest covers remote sensing image processing, hyperspectral data classiﬁcation, pattern recognition, and machine learning. Hongbing Ma received the PhD degree from Peking University, China in 1999. He is currently an associate professor with the Department of Electronic Engineering, Tsinghua University, China. His research interests include image processing, pattern recognition, and spatial information processing and application."
    ]
}{
    "name": "Low Dose CT Perfusion With K-Space Weighted Image Average (KWIA)",
    "paragraphs": [
        "ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 3879 low dose ct perfusion with k-space weighted image average ( kwia ) chenyang zhao , thomas martin , xingfeng shao , jeffry r. alger , vinay duddalwar , and danny j. j. wang abstract —ctp ( computed tomography perfusion ) be widely use in clinical practice for the evaluation of cere-brovascular disorder .",
        "however , ctp involve high radi-ation dose ( ≥∼200mgy ) as the x-ray source remain continuously on during the passage of contrast medium .",
        "thepurpose of this study be to present a low dose ctp techniquetermed k-space weighted image average ( kwia ) usinga novel projection view-shared average algorithm withreduced tube current .",
        "kwia take advantage of k-space sig-nal property that the image contrast be primarily determinedby the k-space center with low spatial frequency and over-sampled projection .",
        "kwia divide each 2d fourier trans-form ( ft ) or k-space ctp data into multiple ring .",
        "the outerrings be average with neighboring time frame to achieveadequatesignal-to-noiseratio ( snr ) , while the center regionof k-space remain unchanged to preserve high temporalresolution .",
        "reduced dose sinogram data be simulate byadding poisson distribute noise with zero mean on digitalphantom and clinical ctp scan .",
        "a physical ctp phantomstudy be also perform with different x-ray tube currents.the sinogram data with simulated and real low dos werethen reconstruct with kwia , and compare with thosereconstructed by standard ﬁltered back projection ( fbp ) and simultaneous algebraic reconstruction with regulariza-tion of total variation ( sart-tv ) .",
        "evaluation of image qualityand perfusion metric use parameter include snr , cnr ( contrast-to-noise ratio ) , auc ( area-under-the-curve ) , and cbf ( cerebral blood ﬂow ) demonstrate that kwia be manuscript receive may 8 , 2020 ; revise june 26 , 2020 ; accept june 28 , 2020 .",
        "date of publication july 2 , 2020 ; date of current version november 30 , 2020 .",
        "this work be support by the nih under grantr41-eb024438 and grant r01-eb028297 .",
        "( corresponding author : danny j. j .",
        "wang . )",
        "chenyang zhao , xingfeng shao , and vinay duddalwar be with the keck school of medicine , stevens neuroimaging and infor-matics institute , university of southern california , los angeles , ca 90033 usa ( e-mail : c.zhao @ usc.edu ; evanshaoxf @ gmail.com ; vinay.duddalwar @ med.usc.edu ) .",
        "thomas martin be with the mays cancer center , radiation oncology , university of texas health science center , san antonio , tx 78229 usa , and also with hura imaging , inc. , calabasas , ca 91302 usa ( e-mail : thomas.martin @ aggiemail.usu.edu ) .",
        "jeffry r. alger be with the department of neurology , university of california at los angeles , los angeles , ca 90095 usa , also with the advanced imaging research center , university of texas southwesternmedical center , dallas , tx 75390 usa , and also with hura imaging , inc. , calabasas , ca 91302 usa ( e-mail : jalger @ huraimaging.com ) .",
        "danny j. j. wang be with the keck school of medicine , stevens neuroimaging and informatics institute , university of southerncalifornia , los angeles , ca 90033 usa , and also with hura imaging , inc. , calabasas , ca 91302 usa ( e-mail : jwang71 @ gmail.com ) .",
        "color version of one or more of the ﬁgures in this article be available online at http : //ieeexplore.ieee.org .",
        "digital object identiﬁer 10.1109/tmi.2020.3006461able to preserve the image quality , spatial and temporal resolution , as well as the accuracy of perfusion quantiﬁca-tion of ctp scan with considerable ( 50-75 % ) dose-savings .",
        "index terms —perfusion imaging , x-ray imaging and compute tomography , brain , image reconstruction - ana-lytical method , image enhancement .",
        "i .",
        "introduction computed tomography perfusion ( ctp ) of the brain be a widely use imaging technique that provide assess- ments of regional blood supply , and hemodynamic informa-tion to distinguish the ischemic core from penumbral tissue , help with decision making for recanalization therapy in cerebral ischemia [ 1 ] – [ 4 ] .",
        "in a typical ctp scan , a dataset of time-resolved ct image be acquire over the scan duration ( ∼1 min ) to track the passage of the contrast bolus through the intracranial vasculature .",
        "t he contrast enhancement of the tissue over time be depict by the time density curve ( tdc ) , and multiple perfusion parameter such as cerebral bloodﬂow ( cbf ) , cerebral blood volume ( cbv ) , mean transit time ( mtt ) , can be derive from the tdc information [ 5 ] .",
        "the repeated ct scan that be perform on the same brain region during the passage of a contrast bolus result in a high radiation dose to patient .",
        "for example , with a typicalclinical setting of ctp scan acquisition parameter use a tube voltage of 80 kev , tube current of 150 mas , and temporal sample rate of 1 image/2s acco rding to the alara ( as low as reasonably achievable ) principle , the resultant dose can be about 200 mgy which be approximately 3 time high than that of a standard head ct [ 6 ] .",
        "recently , several technique have be apply for radiation dose reduction in ctp scan , include reduction of tubecurrent and/or tube voltage , as well as the use of noise reduction technique such as iterative reconstruction ( ir ) [ 7 ] , [ 8 ] .",
        "typical ir method include the adaptive statisticaliterative reconstruction ( asir ) [ 9 ] , and model-based iterative reconstruction ( mbir ) [ 10 ] .",
        "however , ir method often yield blotchy image appearance and long computational time [ 11 ] .",
        "although the application of ir in standard ct scan have be improve due to enhance computational power , its applica-tion in ctp be very limited due to the high complexity and signiﬁcant computational overhead for process dynamic ctp image series .",
        "it be also possible to lower the radiation doseby reduce the temporal sampling frequency of ctp , however , this work be license under a creative commons attrib ution 4.0 license .",
        "for more information , see http s : //creativecommons.o rg/licenses/by/4.0/3880 ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 this approach yield insufﬁci ent temporal information for accurate quantiﬁcation of hemodynamic parameter [ 12 ] .",
        "during the past 3 year , deep learning ( dl ) technique have be explore for ct image to reduce radiation dose [ 13 ] – [ 17 ] , such as residual neural network [ 14 ] and generative adversarial network ( gan ) [ 16 ] , [ 18 ] , [ 19 ] base denoising .",
        "the deep network have be expand to incorporate iterativesteps [ 20 ] , [ 21 ] to improve the performance and robustness for denoising low-dose ct image .",
        "more recently , dl method have be apply for low-dose ctp use iterative residual- artifact learning net ( irlnet ) [ 22 ] and spatial-temporal image restoration net ( stir-ne t ) [ 12 ] .",
        "the advantage of dl technique , as compare to exist ir method for low-dose ct , include short computation time ( nearly instantaneous once train ) and well retainment of the texture and resolution ofct image .",
        "however , dl method be highly dependent on the training datasets which may be speciﬁc to the ct scanner and protocol use for data collection .",
        "k-space weighted image contrast ( kwic ) be a technique originally use in 4d dynamic mri with radial trajectoriesto shorten the scan time use sparse sample [ 23 ] .",
        "based on the central slice theorem , ct sinogram data can be convert to 2d fourier space ( equivalent to k-space inmri ) , make it feasible for the adaptation of kwic to ct perfusion with reduce dose through the sparse sampling of projection follow by view-sharing .",
        "in our proof-of-concept study , a speciﬁc sparse sample scheme be employ to achieve up to 75 % dose reduction while maintain bothhigh image quality and quantiﬁcation accuracy of ctp scan [ 24 ] .",
        "however , the implementation of the kwic algorithm require rapid-switching pulsed x-ray at pre-speciﬁed rotationangles–a hardware capability yet to be implement by commercial ct vendor .",
        "the purpose of this study be to introduce a variant of the kwic algorithm term k-space weighted image average ( kwia ) that preserve high spatial and temporalresolutions as well as image quality of low-dose ctp data ( 50-75 % dose reduction ) , y ielding image comparable to those of standard ctp scan .",
        "there be three majoradvantages and contribution of kwia compare to exist denoising method for low-dose ctp : 1 ) kwia do not require modiﬁcation of exist ct hardware , and can use standard low-dose technique s uch as tube current reduction ; 2 ) kwia be computationally simple and fast ( non-iterative ) , therefore doesn ’ t affect clini cal workﬂow ; 3 ) kwia preserve the texture as well as spatial and temporal resolution of ctp image .",
        "in this paper , we ﬁrst present the theoreticalframework of kwia , and demonstrate its feasibility use a digital phantom , a physical phantom , and clinical data .",
        "ii .",
        "t heory in a typical ct scan , the x-ray tube and detector contin- uously rotate around a center point .",
        "at each speciﬁc constant angular interval , the x-ray tube emit a fan beam x-ray which will be receive by an array of detector and process toform a fan beam projection signal .",
        "based on the central slice theorem , 1d fourier transform ( ft ) can be perform along each parallel beam projection , which can be obtain fromfan beam projection after rebinning , to form a ‘ k-space ’ like ct data .",
        "to meet the nyquist theory of radial sampling , the sample rate on the periphery of this k-space should be no less than the sample rat e on each projection to avoid streak .",
        "thus , the number of projection in a ct scan n proj , in theory , should satisfy nproj≥π 2ndetector ( 1 ) in practice , the number of projection use in a ct scan can be slightly low than the theoretical number , since the ﬁeld-of-view ( fov ) of ct image be generally small than the width of the detector array .",
        "assuming ris the radius of the radial k-space region that satisﬁes the nyquist theory , it be determine by r=nproj π ( 2 ) the most common practice for low dose ct include reduction of tube current and/or tube voltage .",
        "without loss of generality , we will focus on low dose ct with reduced tube current in this paper ( tube voltage reduction will be discuss later ) .",
        "there be a direct proportional relationship betweenthe apply tube current and the square root of the snr in reconstructed ct image [ 25 ] .",
        "for example , reduce the tube current by 1 2will result in the snr of ct image to be√ 2 2of the original snr .",
        "however , the effect of snr reduction be not evenly distribute across the 2d ft or k-space .",
        "as show infig .",
        "1 , the center of the k-space ( ring 1 ) have effectively high snr due to the average effect of high sample density of projection .",
        "for the outer k-space , however , the progressivelysparser projection will lead to deﬁcient snr .",
        "for ctp image , such k-space property and the time- resolved image acquisition can be exploit for reduce radiation dose .",
        "here we introduce a new algorithm term k-space weighted image average ( kwia ) to preserve highspatial and temporal resolution as well as the image quality of low-dose ctp data ( 50-75 % dose reduction ) .",
        "the propose kwia method divide each 2d ft or k-space ctp datainto multiple ring .",
        "the central part of k-space ( ring 1 ) will directly use the data from a single time frame ( e.g .",
        "t 1in fig .",
        "1 ) , while out k-space region will be progressively average between neighbor time frame to increase snr ( e.g .",
        "ring 2 will be average by 2 time frame t1andt2 , a n d ring 3 average by 4 time frame t0tot3 ) .",
        "since the image contrast be primarily determine by the central k-space region , kwia can preserve the high eff ective temporal resolution of low dose ctp while maintain high snr and spatial resolution by view-sharing in the outer k-space region .",
        "the kwia reconstruct k-space data , s , can be express by the following equation si , k=\u0005m−1 2\u0006/summationdisplay d=\u0005−m−1 2\u0006wd , ksi+d , k ( 3 ) where ii the image time frame , kis the distance from the k-space center , mis the average window size , and wd , kis the weighting function .",
        "note the averaging window shift atzhao et al .",
        ": low dose ct perfusion with kwia 3881 fig .",
        "1 .",
        "schematic diagram of kwia .",
        "four time frame of ctp data ( t0−t3 ) with reduce radiation dose be acquire .",
        "each 2d ft or k-space can be divide into multiple ring .",
        "outer ring can be average betweenneighboring time frame to improve snr .",
        "the beginning and end of ctp time series to keep all averaged image within range .",
        "the k-space be divide into discrete ringsand move average be apply to each ring accordingly .",
        "as a proof-of-concept study , we use a short averaging window size of 1 , 2 , 4 for ring 1 , 2 , 3 respectively ( base on the originalkwic algorithm ) to minimize potential temporal blurring .",
        "alternative window size and weight function will be discuss below .",
        "since the number of received x-ray photon n d , o na detector , can be estimate as the poisson distribution of thenumber of incident photon ( see section 3 .",
        "b for detail ) , which be the number of emitted photon n eafter attenuation , snr can be derive as follow .",
        "snr=mean sd=nee−li /radicalbig nee−li=/radicalbig nee−li ( 4 ) thus , for a give neand amount of attenuation , the snr be proportional to the square root of the size of a detector , namely resolution .",
        "because of the inver se relation between resolution and k-space coverage , snr be inversely proportional to the radius of a k-space region .",
        "in order to compensate for the snr loss use projection data from low-dose ct , we can utilize a small center k-space region to achieve adequate snr , and the radius of ring 1 ( r1 ) can be derive from eq .",
        "5 : r1=nproj πrsnr ( 5 ) where rsnr be the relative snr of low dose ctp versus the full dose scan .",
        "the rest of k-space can be subsequentlydivided into ring that will be progressively average between neighbor time frame to increase snr .",
        "the radius of ring norr ncan be derive from eq .",
        "6 : rn=r1+ndetectors 2−r1 nrings−1 ( n−1 ) ( 6 ) where nrings be the total number of ring , ndetectors be the number of detector , and rnis the derived radius for the nth ring .",
        "in practice , the optimal number of ring and their respective size can be determine empirically .",
        "the more ring that be use , high the snr .",
        "however , the resultantimages could potentially be more susceptible to motion aswell as temporal smoothing ( of ﬁne structure ) between time frame .",
        "after apply kwia , the k-space data be regridded into cartesian space follow by 2d inverse fast ft ( fft ) to generate ct image .",
        "iii .",
        "m at erial and methods a. kwia algorithm implementation the kwia algorithm be implement in matlab ( the mathworks inc. , natick , ma , usa ) and include 5 steps:1 ) perform 1d fft of parallel beam projection along the detector row direction ; 2 ) multiplication with a kwia ﬁlter that separate and weigh projection into sub-apertures orrings ; 3 ) stacking of kwia ﬁltered projection into a radial k-space ; 4 ) compensating for the weighting of radial data use the voronoi algorithm ; 5 ) regridding of radial k-space into 2d cartesian k-space ; and ﬁnally 6 ) perform 2d inverse fft of the regridded k-space data into 2d image .",
        "in step 1 , the parallel beam ct projection be simulate from ctp image use the astra toolbox [ 26 ] , [ 27 ] for digital phan- tom and clinical data , while , for real scan of the phantom , fanbeam projection be acquire and then rebinned into parallel beam projection .",
        "the voronoi algorithm in step 4 be use as an efﬁcient and accurate estimation of the density com- pensation for radial sample k-space data [ 28 ] .",
        "even though the density weight along each radial projection in k-spaceis just a ramp function , the voronoi algorithm provide more ﬂexibility for potential implementation of kwia in more complicated ct geometry , such as 3d cone beam ct ( cbct ) .",
        "for the regridding algorithm of step 5 , we choose the kaiser-bessel kernel with β=16.25 , window width =7 , and oversampling rate =2 as the convolution kernel to achieve the optimal balance between side-lobe suppression and computa- tion time [ 29 ] .",
        "compiled matlab program and a sample ctpdataset can be download ( http : //loft-lab.org/index-5.html ) .",
        "b .",
        "digital dynamic phantom simulation a forbild digital phantom [ 30 ] with three time-varying vessel insert ( 10 , 5 and 2.5 mm in diameter respectively ) be create to simulate a dynamic ct scan .",
        "scanning para- meter of the simulation be show in table i , and ring size use for kwia reconstruction be list in table ii .",
        "a baseline poisson noise with an emit x-ray photon number of 4.8×106 , which be the same value estimate for clinical ctp data in section 3 .",
        "d , be add in the projection data to simulate full dose ctp scan .",
        "accordingly , 50 % and 25 % dose ctp scan be generate use 2 .4×10 6and 1.2×106 as the emit x-ray photon number , respect ively .",
        "in addition , the temporal variation of vessel signal follow a pre-deﬁnedgamma variate function [ 31 ] ( eq .",
        "7 ) , where c ( t ) be the vessel signal , c 0is a constant which be set to 1 , trefers to time andαis a parameter determine the signal changing rate ( α=11 ) .",
        "the digital phantom simulation use the same scan time ( 54 second ) and number of frame ( 27 frames ) as ourclinical data .",
        "the peak vessel signal be set to appear at the 10th time frame .",
        "c ( t ) =c 0tαeα ( 1−t ) ( 7 ) 3882 ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 table i imaging and reconstruction parameters table ii kwia r ingsize ( radius ) definition for the simulation of low dose ctp use digital phantom , we hypothesize that : ( 1 ) true compound poisson process can be well-estimated as poisson distribution ; ( 2 ) electronicnoise , which be gaussian distribute , can be ignore [ 32 ] – [ 34 ] .",
        "thus , the noise model can be simpliﬁed as that , on a detector , the detected number of photon follow the poisson distribu- tion of the number of received photon , which be attenuate from the number of e mitting photon while penetrate the body .",
        "the reduction of tube current will proportionally reduce the emitted photon .",
        "as a result , the detected number of photon by a detector under the reduce tube current can bedetermined by eq .",
        "8 [ 35 ] , where n dis the detected photon number , neis the emitted photon number , liis the line integral of attenuation coefﬁcients correspond to the detector i , α andβrepresent the full dose tube current and reduced tube current respectively .",
        "nd=poisson ( β αnee−li ) ( 8 ) ctp scan with full dose , 50 % dose , and 25 % dose be simulate accordingly .",
        "kwia with 2 and 3 ring be then apply to recover snr of 50 % dose ctp scan , while kwia with 3 and 4 ring be apply to recover snr of 25 % dose ctp scan .",
        "to evaluate the performance of kwia , the meansignal and standard deviation ( sd ) of noise be measure in a relatively uniform region to estimate snr ( blue circle in fig .",
        "2 ( a ) ) .",
        "contrast-to-noise ratio ( cnr ) be also estimate use two region ( blue circle and purple circle in fig .",
        "2 ( a ) ) with different mean value .",
        "the value of cnr be deﬁned as the ratio of the difference of mean signal between two region fig .",
        "2 .",
        "forbild ct phantom with 3 vessel of different size .",
        "( a ) and ( b ) contain the full dose , low dose simulation , and 4 kwia simulation result .",
        "two roi be enlarge to emphasize snr change.and subtraction image ( window level and window center be adjust for visual observation ) be make to show the structural change .",
        "to the square root of the sum of their variance .",
        "to evaluate the impact of different vessel size on the temporal ﬁdelityof kwia reconstruction , the region contain 3 time-varying vessel be select as an roi to measure the time course , as well as temporal parameter , include area-under-the-curve ( auc ) , full width at half maximum ( fwhm ) , and root mean square error ( rmse ) .",
        "to well demonstrate the snr change , subtraction image between a noiseless phantom image and simulate low dose ctp and kwia image be generate and present .",
        "c. physical ctp phantom scan the purpose of the physical phantom study be to verify the low dose simulation method , the snr dependency of perfusion metric , and the feasibility of kwia reconstruction on reallow dose ctp scan .",
        "a commercial ct perfusion phantom ( gammex , middleton , wi , usa ) be scan on a siemens somatom deﬁnition as scanner with a ﬁxed tube voltageof 100 kvp and 3 different tube current at 200 , 120 and 60 mas respectively .",
        "the gammex ctp phantom consist of a homogenous scan disk ( the image object show in fig .",
        "4 ) and 4 rod ( as indicate by the yellow arrow in fig .",
        "4 ) , include an “ artery ” , a “ vein ” and 2 identical “ brain tissue ” rod , that be make of several disc with variable density .",
        "when set in motion , the 4 rod can mimic the ﬂow of a contrast agent through a blood-tissue network over time .",
        "therefore , the phantom be capable of simulate blood ﬂow through an artery , a vein and two tissue region [ 36 ] .",
        "during the scan , three slice be image simultaneously in a total scanzhao et al .",
        ": low dose ct perfusion with kwia 3883 duration of 39 second with an interval of 1 second for each time frame .",
        "after the scan , fan b eam projection data collect from scanner be rebinned into parallel beam projection data for ofﬂine reconstruction with kwia .",
        "the scan with the high tube current of 200 mas be use as the full dose , while the scan with 120 and 60 mas be treat as 60 % and 30 % dose respectively .",
        "kwia with 2 and3 ring be apply on the 60 % dose scan , while kwia with 3 and 4 ring on the 30 % dose scan .",
        "for comparison , full and low dose image be also reconstruct with standard regridding reconstruction without kwia .",
        "detailed scan parameter be list in table i , and the size of ring use in kwia be list in table ii .",
        "snr be measure in a uniform region ( purple circle in fig .",
        "4 ( a ) ) in the scan disk of the ctp phantom , and cnr be measure between the scan disk region and a uniform region in brain tissue ( blue circle in fig .",
        "4 ( a ) ) .",
        "the arterial input function ( aif ) , venous outﬂow function ( vof ) and tissue signal curve be measure in rois of the artery , vein , and brain tissue , respectively .",
        "quantitative ctp analysis be perform use in-house matlab program for deconvolution base on the singular- value decomposition ( svd ) algorithm [ 37 ] .",
        "post-processingof ctp image yield cerebral blood ﬂow ( cbf ) map .",
        "cbf value in 2 brain tissue region of the phantom be measure for comparison across all the reconstruct perfusion map .",
        "d. clinical ctp data simulation six clinical ctp datasets , treat as full dose case in this study , be acquire on a toshiba aquilion ct scanner .",
        "detailed parameter of the ctp scan be list in table i .",
        "poisson distribute noise be add to simulate the 50 % and25 % low dose case .",
        "the kwia algorithm with 2 , 3 and 4 ring be implement and test on the simulated low dose ctp scan respectively use the same ring size as those for digital dynamic phantom simulation ( parameter list in table ii ) .",
        "there be a few difference in how noise be add between the clinical data and the digital phantom .",
        "in digital phantom , poisson noise be directly add on noiseless phan-tom image .",
        "given an emitted photon number n efor the full dose scan , the low dose scan can be simply simulate from noiseless phantom image usingβ αnein eq .",
        "8 .",
        "in clinical data , however , no noiseless image be available , which require include additional noise on top of the full dose imagesalready contain some level of noise .",
        "also , n eof the full dose image be an unknown parameter .",
        "the simulation process can be describe by eq .",
        "9 [ 38 ] : nβ d=β αnβ ee−li+poisson 0 ( αβ−β2 α2nα ee−li ) ( 9 ) where nβ dis the received x-ray photon number at dose β , nα eis the emitted photon number at dose α , a n d poisson 0 refers to the poisson distribution with zero mean .",
        "in this case , the generate data will have th e desire variance and mean of β αnα e.f o r ne , we estimate it as 4 .8×106by measure the change of resultant snr in reconstructed image .",
        "an accurate estimation of neshould allow the snr to decrease linearlywith the square root of tube current reduction , which have be validate by our physical phantom study .",
        "the mean signal and noise sd be measure in a uniform region ( blue circle in fig .",
        "8 ( a ) ) in grey matter to examine the impact of kwia on snr .",
        "cnr be also estimate between grey matter ( blue circle in fig .",
        "8 ( a ) ) and white matter ( purple circle in fig .",
        "8 ( a ) ) .",
        "the arterial input function ( aif ) , venous outﬂow function ( vof ) and tissue density signal curve be measure in rois of the anterior cerebral artery , posterior part of the superior sagittal sinus , and uniform grey matter region without visible vessel , respectively .",
        "quantitative ctp analysis be perform in the same way as the physical phantom study .",
        "the mean cbf value of the whole brain be measure for all 6 datasets for comparison across all the reconstruct perfusion map .",
        "e. comparison of kwia with other reconstruction algorithms a comparison of kwia with two other image reconstruc- tion method be perform on the clinical ctp data from the perspective of noise suppression and cbf bias reduction .",
        "the two method include ﬁltered back projection ( fbp ) with ramp ﬁlter , the standard algorithm for clinical ct , and simultaneous algebraic reconstruction regularize by total variation ( sart-tv ) [ 39 ] , a state-of-art technique for ctdenoising .",
        "the fbp be implement use astra toolbox [ 26 ] , [ 28 ] , and tigre toolbox [ 40 ] be use for sart-tv implementation .",
        "among the 3 commonly use fbp ﬁlter func-tions ( ram-lak , hann , shepp-logan ) , the ram-lak ﬁlter be apply in the comparison study since low-pass windowing function like hann and shepp- logan introduce trade-off between denoising and smooth .",
        "quantitative comparison include snr in gm ( blue circle in fig .",
        "12 ) a n dw m ( purple circle in fig .",
        "12 ) , cnr between gm and wm , and the whole brain cbf measurement across 6 clinical datasets be perform .",
        "to achieve performan ce-efﬁciency balance , default hyperparameter value recommend by the tigre toolbox be select , include 100 as the number of iteration , 1 as the step size , 15 as the value of the parameter for regularization strength , and 50 as the number of iteration in tv regularization step .",
        "iv .",
        "r esults a .",
        "digital dynamic phantom simulation figure 2 show the ct image ( 7th time frame ) of 7 experimental condition ( full dose , 50 % dose , 25 % dose , kwia 50 % 2 rings , kwia 50 % 3 rings , kwia 25 % 3 rings , kwia 25 % 4 rings ) , respectively .",
        "the inset show two zoom rois to highlight the snr change .",
        "in these two rois , it can be see that the snr be degrade in 50 % and25 % dose image compare to full dose image , which be recover by kwia reconstruction .",
        "in addition , the subtracted image between kwia reconstruct image and full doseimages illustrate that no structured noise pattern or texture change be induce by kwia reconstruction .",
        "table iii list the snr value of the seven experimental con- ditions respectively .",
        "the snr of 50 % and 25 % dose images3884 ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 table iii the digital phantom snr and cnr m easurement indifferent conditions fig .",
        "3 .",
        "the gamma variate dynamic time curve ( full dose and 4 kwia case ) of 3 vessel with different size in digital phantom .",
        "table iv rmse , auc , and fwhm m easurement for 3v essels with different sizecontained in forbild p hantom be about 73 % and 52 % of that in full dose image , which be consistent with theoretical prediction .",
        "kwia , however , wasable to recover the snr of 50 % and 25 % dose image to be comparable to that of the full dose image .",
        "consistent with our prediction , increase number of ring in kwia reconstruction lead to great snr .",
        "the cnr result of low dose simulation be consistent with our prediction as well , and kwia be ableto recover cnr to full dose level .",
        "temporal signal of the 3 vessel with different size ( 2.5 , 5 , and 10 mm in diameter ) be show in fig .",
        "3 .i n1 0m m fig .",
        "4 .",
        "scans of the ctp phantom .",
        "( a ) and ( b ) contain the full dose ( 200 mas ) , low dose ( 120 mas and 60 mas ) , and 4 kwia reconstructionresults .",
        "an roi be enlarge to emphasize snr change .",
        "and subtractionimages ( window level and window center be adjust for visual observation ) be make to show the structural change .",
        "( fig .",
        "3 ( a ) ) a n d5m m ( fig .",
        "3 ( b ) ) vessel , no apparent dif- ference between kwia and full dose curve can be observed.this show the capability of kwia to preserve high temporal resolution .",
        "however , slight reduction in the maximum peak can be observe in 2.5 mm ( fig .",
        "3 ( c ) ) vessel of kwia image , likely due to temporal blurring cause by the averaging of high frequency k-space data between neighboring time frame in kwia .",
        "to quantitatively estimate the effect of temporal blurring , temporal parameter include auc , fwhm , and rmse werecalculated and show in table iv .",
        "there be up to about 1 % difference in auc and 7 % difference in fwhm , respectively , for the small vessel .",
        "the rmse be generally small ( < 0.01 ) for 5 and 10 mm vessel , and increase up to 0.027 for the 2.5 mm vessel .",
        "the rmse be small with high dose and few ring use .",
        "b .",
        "physical ctp phantom experiment figure 4 show image ( 11th time frame ) of the ctp phantom scan at a single slice within the scan disk with 7 experimental condition , include full dose ( 200 mas ) ,60 % dose ( 120 mas ) , 30 % dose ( 60 mas ) , 60 % dose with kwia 2 and 3 rings , 30 % dose with kwia 3 and 4 rings , respectively .",
        "the zoomed inset illustrate snr change , whilezhao et al .",
        ": low dose ct perfusion with kwia 3885 table v thephysical phantom snr and cnr m easurement in different conditions fig .",
        "5 .",
        "aif , vof and brain tissue signal curve of full dose and low dose image reconstruct with k wia .",
        "no apparent difference can be observe all curve .",
        "the second peak in aif and vof represent the second-pass of contrast bolus .",
        "the subtracted image show residual noise pattern between the full dose and rest experimental condition respectively .",
        "similar to the simulated digital phantom study , a great level of noisecan be observe with real 60 % and 30 % dose scan , which be recover to be comparable to that of the full dose scan with kwia .",
        "there be residual edge signal in the subtractedimages between low dos and full dose image , due to slight displacement of the phantom be tween scan .",
        "nevertheless , the consistency of the residual noise pattern and edge signal across the low dose and kwia reconstruct image suggest that kwia do not introduce structured noise pattern ortexture change .",
        "table v list the snr and cnr measurement of the phan- tom image under seven experime ntal condition respectively .",
        "fig .",
        "6 .",
        "cbf map ( ml/100g/min ) of the ctp phantom .",
        "bias be introduce in the low dose cbf map , which be correct by kwia .",
        "fig .",
        "7 .",
        "bar plot of the mean cbf value for the physical phantom ( a ) and the clinical data ( b ) in full dose , low dose , and 4 kwia condition .",
        "for physical phantom , each condition include 2 measurement in 2tissue region .",
        "and for the clinical data , each condition contain 6 wholebrain measurement from 6 clinical dat asets .",
        "error bar indicate standard deviation .",
        "the measured snr and cnr value of low dose scan strictly follow the theoretical value pre dicted by eq .",
        "4 , which validate our low dose simulation perform in section 3 .",
        "b and 3 .",
        "d.it can be see that kwia be able to recover snr and cnr of low dose scan to be comparable with that of the full dose scan .",
        "the more ring use in kwia , the great snr and cnr recovery .",
        "figure 5 show aif , vof and brain tissue signal curve .",
        "no apparent difference can be observe between time curve of full dose and low dose image reconstruct with kwia suggest that that no temporal blurring be introduce bykwia .",
        "figure 6 show quantitative cbf map of the ctp phan- tom with seven different experimental condition .",
        "it can be observe that an increase bias be introduce in the cbf map with decrease radiation dose ( from full dose to 60 % and30 % dose ) .",
        "the bias be correct with kwia reconstruction ( see fig .",
        "7 ( a ) ) , and the resultant cbf map be visually similar to that of the full dose scan .",
        "c. clinical ctp data simulation figure 8 show a representative image ( 15th time frame ) of clinical ctp data , include simulate 50 % and 25 % dos and kwia reconstruct image .",
        "the inset show two zoom rois to well illustrate the snr difference .",
        "the snr reduction from full dose to 50 % and 25 % dose can be clearlyobserved , whereas this snr reduction can be successfully recover to be comparable to full dose level with kwia reconstruction .",
        "the subtraction image between kwia and3886 ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 fig .",
        "8 .",
        "clinical ct image , 25 % and 50 % dose simulation from original dose , and kwia reconstruction .",
        "( a ) and ( b ) contain the full dose , low dose simulation , and 4 kwia reconstruction result .",
        "two roi wereenlarged to emphasize snr change .",
        "and subtraction image ( windowlevel and window center be adjust for visual observation ) be make to show the structural change .",
        "visible snr and cnr reduction can be observe in 50 % and 25 % dose simulation case , and kwia ’ s ability ofsnr recovery can also be visually capture .",
        "in rois , the snr change can be see more clearly , the performance of noise reduction in roi 1 and contrast recovery in roi 2 can be demonstrate with kwia.no structural difference can be detect from subtraction image .",
        "full dose image show no structured noise pattern or texture change introduce by kwia reconstruction .",
        "due to possible motion occur between frame , some low-level ringing artifact can be observe in subtraction image .",
        "table vi show quantitative measurement of grey and white matter rois across the 7 experimental condition .",
        "the snr of simulated 50 % dose image be 75 % ( wm ) and71 % ( gm ) ( 70.7 % in theory ) of full dose snr , and 54 % ( wm ) and 50 % ( gm ) ( 50 % in theory ) for 25 % dose image .",
        "on 50 % dose image , kwia reconstruction with 2 and 3 ringsimproved snr to 92 % and 100 % of full dose level respectively for white matter , and 89 % and 95 % respectively for grey matter .",
        "on 25 % dose image , kwia reconstruction with 3 and 4 ring improve snr to 89 % and 95 % of full dose level respectively for white matter , and 74 % and 84 % for greymatter .",
        "as for noise sd , simulate 50 % dose image increase sd to 1.38 ( wm ) and 1.37 ( gm ) ( 1.41 in theory ) time of full dose level , and simulate 25 % dose image increase sdtable vi quantitative measurement of snr and cnr inclinical data fig .",
        "9 .",
        "dynamic contrast curve for venous ( a ) , a r t e r i a l ( b ) , tissue roi ( c ) , and an about 1 mm wide small vessel ( d ) of full dose case and kwia simulation case .",
        "no apparent difference can be observe in all 4 signal .",
        "in arterial , tissue , and the small vessel signal , kwia simulation with 25 % dose reduction tend to have a great difference than kwiasimulation with 50 % dose reduction .",
        "to 1.84 ( wm ) and 2.05 ( gm ) ( 2 in theory ) time of full dose level .",
        "kwia reconstruction also decrease noise sd to fulldose level .",
        "the cnr measure between wm and gm be 0.38 ( 0.39 in theory ) for 50 % dose and 0.28 ( 0.28 in theory ) for 25 % dose .",
        "kwia also show its ability to signiﬁcantly improve cnr .",
        "the vof , aif , and tissue signal curve of full dose and 4 kwia reconstruction be present in fig .",
        "9 ( a ) , ( b ) , and ( c ) , respectively .",
        "the signal curve of 4 kwia reconstruction closely follow those of the full dose image .",
        "to evaluate the potential impact of kwia on small ves- sels due to the averaging of high spatial frequency signal , fig .",
        "9 ( d ) show the dynamic signal curve of a small vessel with a width about 1 mm .",
        "no apparent temporal smoothing be observe for this small vessel with kwia reconstruction .",
        "quantitative cbf map of a clinical case be show in fig .",
        "10 .",
        "reduction of radiation dose to 50 % and 25 % intro- duced a substantial bias in the quantiﬁcation of cbf map , which be large at 25 % compare to 50 % dose .",
        "however , the cbf map of kwia reconstruction be able to sub- stantially correct the bias , especially in kwia 50 % 3 ringszhao et al .",
        ": low dose ct perfusion with kwia 3887 fig .",
        "10 .",
        "cbf map ( ml/100g/min ) of 2 clinical ctp case .",
        "from top to bottom be full dose , 50 % and 25 % dose with regridding reconstruction , as well as kwia 50 % with 2 and 3 rings , kwia 25 % with 3 and 4 ringsrespectively .",
        "and kwia 25 % 4 rings which be visually comparable with the full dose image and show improve contrast between grey and white matter .",
        "the quantitative cbf value of the 7 condition be display as bar plot in fig .",
        "7 ( b ) .",
        "finally , cbf value measure in whole brain between full dose and each low dose or kwia case be demonstrate by the bland- altman plot in fig .",
        "11 .",
        "cbf bias or mean difference be obvious in low dose condition ( 8.6 and 27.2ml/100g/min for 50 % and 25 % respectively ) , which be minimize or reduce in all kwia reconstruction .",
        "however , there be a small bias ( ∼7ml/100g/min ) between cbf value calculate with full dose and kwia 25 % 4 rings ctp data .",
        "low dose conditionsalso show wide limit of agreement or 95 % conﬁdence interval of cbf difference ( 10.4 and 13.7 ml/100g/min for 50 % and 25 % dose respectively ) compare with theircorresponding kwia reconstruction with the same dose ( 7.0 and 7.6 ml/100g/min for kwia 50 % with 2 and 3 ring , respectively , and 9.1 and 7.8 ml/100g/min for kwia 25 % with 3 and 4 rings , respectively ) .",
        "the variability of scatter be consistent across the graph , suggest that the change ofdifference do not depend on the average .",
        "d. comparison with other reconstruction algorithms figure 12 display the ctp image and cbf map of full dose fbp ( gold standard ) , 3 simulate 50 % dose ( fig .",
        "12 ( a ) ) fig .",
        "11 .",
        "bland-altman plot for comparison of whole brain cbf value measure between full dose and low dose condition as well as low dose with kwia reconstruction .",
        "and 3 simulate 25 % dose ( fig .",
        "12 ( b ) ) reconstruct by fbp , kwia and sart-tv respectively .",
        "the snr and cnr value for ctp image , and mean cbf value for cbf map be listedintable vii .",
        "the 50 % and 25 % dose fbp image exhibit large image degradation ( 26 % ( gm ) and 20 % ( wm ) snr reduction for 50 % dose , and 54 % ( gm ) and 60 % ( wm ) snr reductionfor 25 % dose ) and cbf overestimation ( 19 % increase for 50 % dose , and 48 % increase for 25 % dose ) , whereas kwia yield excellent reconstruction result comparable to the full dose fbp ( 92 % ( gm ) and 96 % ( wm ) of full dose fbp for 50 % dose , and 82 % ( gm ) and 88 % ( wm ) of full dose fbpfor 25 % dose ) without introduce smooth effect or loss of spatial resolution .",
        "the cbf bias due to 50 % and 25 % dose , which be 10.6 and 27.2 ml/100g/min respectively , be largely suppress by kwia to 2.3 and 9.1 ml/100g/min respectively .",
        "sart-tv show strong denoising effect than kwia with snr and cnr high than those of full dose fbp image .",
        "however , there be a slight over-correction of cbf bias use sart-tv ( -4.3 and -1.4ml/100g/min for 50 % and 25 % respectively ) and the reconstructed image appear smooth .",
        "it might be possible to achieve good performance of sart-tv by tune hyperparameters to balance denoisingpower and spatial smoothness .",
        "however , the tune process of sart-tv be constrain by the prolonged computation time , which far limit the use of sart-tv in clinical ctp scan .",
        "table vii also list the execution time ( et ) of reconstruct a 512-by-512 image from a 728-by-1152 sinogram use fbp , kwia , and sart-tv respectively .",
        "with the same imple- mentation environment ( matlab , intel i5-9400f ) , it take 11.2 second for kwia to reconstruct an image which wassimilar to the reconstruction time of 9.3 second require by fbp .",
        "in comparison , sart-tv take 265.8 second with a graphic processing unit ( matlab , gtx 1660 ti ) .3888 ieee transactions on medical imaging , vol .",
        "39 , no .",
        "12 , december 2020 fig .",
        "12 .",
        "reconstructed image ( top row of ( a ) and ( b ) ) and cbf map ( bottom row of ( a ) and ( b ) ) with full dose fbp , 50 % dose fbp , 25 % dose fbp , kwia 50 % 3 rings , kwia 25 % 4 rings , 50 % dose sart -tv , and25 % dose sart -tv .",
        "insets with magniﬁed region of image show snrand spatial smoothness of eac h reconstruction method .",
        "table vii q uantitative comparison among fbp , kwia , and sart-tv v. d iscussion projection image data such as ct can be relate to the spatial frequency domain ( e.g.",
        ", k-space in mri ) through the central-slice theorem by perform 1-d ft of each projection of an object , which be equivalent to a line through the center of the 2-d ft plane ( i.e.",
        ", k-space ) .",
        "by convert the ct sinogram into “ k-space ” data , we can adapt many innovativemri reconstruction algorithm to preserve high spatial and temporal resolution of undersampled ct data .",
        "in a previ- ous study , we introduce an innovative image reconstructionalgorithm base on k-space weight image contrast ( kwic ) [ 23 ] , [ 41 ] for radiation dose reduction of ctp [ 24 ] .",
        "our preliminary result show that kwic be able to reduce the radiation dose of exist ctp method by 50-75 % withoutcompromising image speed or quality .",
        "however , the original kwic algorithm require rapid-switching pulsed x-ray at pre- speciﬁed rotation angle – a hardware capability not availableon most commercial ct scanner .",
        "in order to address this limitation , here we introduce a novel algorithm term k-space weighted image average ( kwia ) that preserve image quality ( snr and cnr ) , spatial and temporal resolution , as well as quantiﬁcation accuracy of low-dose ctp data ( 50-75 % dose reduction ) to be comparable to those of standard ctp scan .",
        "unlike kwic which require a modiﬁed ct hardware , kwia can be implement by simplyreducing the tube current .",
        "in this work , we demonstrate the feasibility of kwia use both digital phantom and clinical ctp data with simulated low dos , as well as a physical ctp phantom with real low dose scan .",
        "compared to exist low dose ct technique such as iterative reconstruction , ourapproach be unique and have several advantage : 1 ) it be base on fourier base ct image reconstruction , do not make assumption of noise characteristic , and preserve the textureand resolution of ct image ; 2 ) it have a low computational overhead and doesn ’ t affect th e clinical workﬂow ; and 3 ) it do not require modiﬁcation of exist ct hardware , and therefore have a low barrier for c linical adoption .",
        "the k-space noise at different frequency be average when convertinginto image space through ft [ 42 ] , therefore kwia improve the snr of ctp image without affect the resolution , texture or other characteristic .",
        "previous study have shownthat the accuracy of ctp quantiﬁcation be highly dependent on the noise level of ct image [ 43 ] , [ 44 ] .",
        "overestimation of perfusion often occur in the presence of substantial noise use singular value decomposition ( svd ) base deconvolu- tion analysis .",
        "by recover the snr of low dose ctp image , kwia be able to correct the bias of perfusion quantiﬁcation with 50-75 % dose reduction .",
        "only the application of kwia on 2d parallel beam and fan beam ct be evaluate in this study .",
        "nevertheless , the theoretical principle of kwia be applicable to low dose 3d cone beam ct ( cbct ) .",
        "speciﬁcally , the central slice theorem for 3d cbct geometry state that 1d ft of any 1d radon data of a 3d object , which can be obtain indirectlywith grangeat ’ s method , be identical to the same radial line in the 3d k-space [ 45 ] .",
        "across different time frame , kwia will be able to partition , weight and average these radial line fromthe center of the 3d k-space to the periphery , if a complete 3d radon space can be obtain in cbct .",
        "previous study have also show the reliability and efﬁciency of fourierbased reconstruction for 3d cbct [ 46 ] .",
        "alternatively , for cbct with circular geometry , where only the middle plane deﬁned by the x-ray source trajectory have a complete set of radon data , approximate reconstruction [ 47 ] can be apply on the projection data of the off-middle plane which canbe convert to k-space for kwia processing ( with the caveat that the large the cone angle , the less accurate the approximation be ) .zhao et al .",
        ": low dose ct perfusion with kwia 3889 despite kwia ’ s potential to reduce ctp dose , it have a few limitation .",
        "kwia improve image snr by average high frequency k-space data with neighboring time frame , and be therefore potentially more sensitive to patient head motion thanstandard ctp scan .",
        "another potential drawback of kwia be the temporal blurring of dynamic signal change of ﬁne vessel and/or structure .",
        "as show in fig .",
        "3 , slight temporal blurring can be observe in 2.5 mm vessel of kwia image , but not in vessel with 5 and 10mm size .",
        "nevertheless , signiﬁcant tem- poral blurring of clinical ctp data with kwia reconstruction be not observe .",
        "the aif and vof curve reconstruct with kwia also match well with those of standard ctp data , and no apparent temporal signal deviation be observe for a vessel with ∼1mm size .",
        "the potential temporal blurring of kwia may depend on various parameter such as the rate ofsignal change and sample rate of ctp , which merit further evaluation .",
        "in addition , iterative reconstruction algorithm such as sart-tv may have strong denoising capability than kwia .",
        "nevertheless , kwia be more advantageous in term of the ease and robustness for implementation , computationalspeed , and retainment of texture and resolution .",
        "comparison of kwia with other iterative reconstruction and deep learning base denoising method should also be perform in futurestudies .",
        "lastly , the cbf bias reduction performance of kwia be only evaluate by the cbf map generate from standard svd ctp analysis in this study .",
        "alternative ctp analysis with denoising capability such as bayesian probabilistic method need to be test use kwia reconstruct ctp image [ 48 ] .",
        "in this work , kwia be apply to simulate low dose ctp data with reduced x-ray tube current which have a relatively straightforward relationship with snr .",
        "it be also possible toreduce tube voltage , the square of which be generally acknowl- edge to be proportional to the receive radiation dose [ 49 ] .",
        "the temporal window size or footprint of kwia be keep as short as possible to minimize potential temporal blurring in this study .",
        "nevertheless , the windowing function for averagingneighboring time frame as well as the number and size of ring in kwia could be far optimize base on trade-off between snr improvement and the loss of temporal resolu-tion .",
        "alternative function such as inverse nufft ( inufft ) may be apply for regridding reconstruction .",
        "in the future , deep learning base approach may be combine with kwia to far improve its robustness in the presence of patient head motion or other artifact ( e.g .",
        "streak due to photonstarvation ) .",
        "lastly , kwia may be directly apply on ctp data acquire with standard radi ation dose to reduce noise and enhance image contrast .",
        "vi .",
        "c onclusion in this research , we present a new low dose ctp tech- nique term kwia , with a constant reduce tube current and projection average in out k-space .",
        "the propose technique be evaluate use a digital phantom , a physical phantom and clinical ctp data , an d it can achieve considerable dose-savings ( 50-75 % ) without compromise the image qual-ity and perfusion metric .",
        "due to its robustness and simplicity , kwia may provide a promising method for reduce radiation exposure to patient undergo ctp exams.a cknowledgment the author be grateful to dr. hee kwon song for his help with the manuscript .",
        "disclosure tm and djw be inventor of a patent on low dose ctp , tm and djw hold share in hura imaging , inc ."
    ],
    "processed_text": "ieee transactions medical imaging vol 39 12 december 2020 3879 low dose ct perfusion kspace weighted image average kwia chenyang zhao thomas martin xingfeng shao jeffry r alger vinay duddalwar danny j j wang abstract ctp computed tomography perfusion widely use clinical practice evaluation cerebrovascular disorder however ctp involve high radiation dose 200mgy xray source remain continuously passage contrast medium thepurpose study present low dose ctp techniquetermed kspace weighted image average kwia usinga novel projection viewshared average algorithm withreduced tube current kwia take advantage kspace signal property image contrast primarily determinedby kspace center low spatial frequency oversampled projection kwia divide 2d fourier transform ft kspace ctp data multiple ring outerrings average neighboring time frame achieveadequatesignaltonoiseratio snr center regionof kspace remain unchanged preserve high temporalresolution reduced dose sinogram data simulate byadding poisson distribute noise zero mean digitalphantom clinical ctp scan physical ctp phantomstudy also perform different xray tube currentsthe sinogram data simulated real low dos werethen reconstruct kwia compare thosereconstructed standard filtered back projection fbp simultaneous algebraic reconstruction regularization total variation sarttv evaluation image qualityand perfusion metric use parameter include snr cnr contrasttonoise ratio auc areaunderthecurve cbf cerebral blood flow demonstrate kwia manuscript receive may 8 2020 revise june 26 2020 accept june 28 2020 date publication july 2 2020 date current version november 30 2020 work support nih grantr41eb024438 grant r01eb028297 corresponding author danny j j wang chenyang zhao xingfeng shao vinay duddalwar keck school medicine stevens neuroimaging informatics institute university southern california los angeles ca 90033 usa email czhao @ uscedu evanshaoxf @ gmailcom vinayduddalwar @ meduscedu thomas martin mays cancer center radiation oncology university texas health science center san antonio tx 78229 usa also hura imaging inc calabasas ca 91302 usa email thomasmartin @ aggiemailusuedu jeffry r alger department neurology university california los angeles los angeles ca 90095 usa also advanced imaging research center university texas southwesternmedical center dallas tx 75390 usa also hura imaging inc calabasas ca 91302 usa email jalger @ huraimagingcom danny j j wang keck school medicine stevens neuroimaging informatics institute university southerncalifornia los angeles ca 90033 usa also hura imaging inc calabasas ca 91302 usa email jwang71 @ gmailcom color version one figures article available online http //ieeexploreieeeorg digital object identifier 101109/tmi20203006461able preserve image quality spatial temporal resolution well accuracy perfusion quantification ctp scan considerable 5075 dosesavings index terms perfusion imaging xray imaging compute tomography brain image reconstruction analytical method image enhancement introduction computed tomography perfusion ctp brain widely use imaging technique provide assess ments regional blood supply hemodynamic information distinguish ischemic core penumbral tissue help decision making recanalization therapy cerebral ischemia 1 4 typical ctp scan dataset timeresolved ct image acquire scan duration 1 min track passage contrast bolus intracranial vasculature contrast enhancement tissue time depict time density curve tdc multiple perfusion parameter cerebral bloodflow cbf cerebral blood volume cbv mean transit time mtt derive tdc information 5 repeated ct scan perform brain region passage contrast bolus result high radiation dose patient example typicalclinical setting ctp scan acquisition parameter use tube voltage 80 kev tube current 150 mas temporal sample rate 1 image/2s acco rding alara low reasonably achievable principle resultant dose 200 mgy approximately 3 time high standard head ct 6 recently several technique apply radiation dose reduction ctp scan include reduction tubecurrent and/or tube voltage well use noise reduction technique iterative reconstruction ir 7 8 typical ir method include adaptive statisticaliterative reconstruction asir 9 modelbased iterative reconstruction mbir 10 however ir method often yield blotchy image appearance long computational time 11 although application ir standard ct scan improve due enhance computational power application ctp limited due high complexity significant computational overhead process dynamic ctp image series also possible lower radiation doseby reduce temporal sampling frequency ctp however work license creative commons attrib ution 40 license information see http //creativecommonso rg/licenses/by/40/3880 ieee transactions medical imaging vol 39 12 december 2020 approach yield insuffici ent temporal information accurate quantification hemodynamic parameter 12 past 3 year deep learning dl technique explore ct image reduce radiation dose 13 17 residual neural network 14 generative adversarial network gan 16 18 19 base denoising deep network expand incorporate iterativesteps 20 21 improve performance robustness denoising lowdose ct image recently dl method apply lowdose ctp use iterative residual artifact learning net irlnet 22 spatialtemporal image restoration net stirne 12 advantage dl technique compare exist ir method lowdose ct include short computation time nearly instantaneous train well retainment texture resolution ofct image however dl method highly dependent training datasets may specific ct scanner protocol use data collection kspace weighted image contrast kwic technique originally use 4d dynamic mri radial trajectoriesto shorten scan time use sparse sample 23 based central slice theorem ct sinogram data convert 2d fourier space equivalent kspace inmri make feasible adaptation kwic ct perfusion reduce dose sparse sampling projection follow viewsharing proofofconcept study specific sparse sample scheme employ achieve 75 dose reduction maintain bothhigh image quality quantification accuracy ctp scan 24 however implementation kwic algorithm require rapidswitching pulsed xray prespecified rotationanglesa hardware capability yet implement commercial ct vendor purpose study introduce variant kwic algorithm term kspace weighted image average kwia preserve high spatial temporalresolutions well image quality lowdose ctp data 5075 dose reduction ielding image comparable standard ctp scan three majoradvantages contribution kwia compare exist denoising method lowdose ctp 1 kwia require modification exist ct hardware use standard lowdose technique uch tube current reduction 2 kwia computationally simple fast noniterative therefore affect clini cal workflow 3 kwia preserve texture well spatial temporal resolution ctp image paper first present theoreticalframework kwia demonstrate feasibility use digital phantom physical phantom clinical data ii heory typical ct scan xray tube detector contin uously rotate around center point specific constant angular interval xray tube emit fan beam xray receive array detector process toform fan beam projection signal based central slice theorem 1d fourier transform ft perform along parallel beam projection obtain fromfan beam projection rebinning form kspace like ct data meet nyquist theory radial sampling sample rate periphery kspace less sample rat e projection avoid streak thus number projection ct scan n proj theory satisfy nproj 2ndetector 1 practice number projection use ct scan slightly low theoretical number since fieldofview fov ct image generally small width detector array assuming ris radius radial kspace region satisfies nyquist theory determine r=nproj 2 common practice low dose ct include reduction tube current and/or tube voltage without loss generality focus low dose ct reduced tube current paper tube voltage reduction discuss later direct proportional relationship betweenthe apply tube current square root snr reconstructed ct image 25 example reduce tube current 1 2will result snr ct image 2 2of original snr however effect snr reduction evenly distribute across 2d ft kspace show infig 1 center kspace ring 1 effectively high snr due average effect high sample density projection outer kspace however progressivelysparser projection lead deficient snr ctp image kspace property time resolved image acquisition exploit reduce radiation dose introduce new algorithm term kspace weighted image average kwia preserve highspatial temporal resolution well image quality lowdose ctp data 5075 dose reduction propose kwia method divide 2d ft kspace ctp datainto multiple ring central part kspace ring 1 directly use data single time frame eg 1in fig 1 kspace region progressively average neighbor time frame increase snr eg ring 2 average 2 time frame t1andt2 n ring 3 average 4 time frame t0tot3 since image contrast primarily determine central kspace region kwia preserve high eff ective temporal resolution low dose ctp maintain high snr spatial resolution viewsharing outer kspace region kwia reconstruct kspace data express following equation si k=\u0005m1 2\u0006/summationdisplay d=\u0005m1 2\u0006wd ksi+d k 3 ii image time frame kis distance kspace center mis average window size wd kis weighting function note averaging window shift atzhao et al low dose ct perfusion kwia 3881 fig 1 schematic diagram kwia four time frame ctp data t0t3 reduce radiation dose acquire 2d ft kspace divide multiple ring outer ring average betweenneighboring time frame improve snr beginning end ctp time series keep averaged image within range kspace divide discrete ringsand move average apply ring accordingly proofofconcept study use short averaging window size 1 2 4 ring 1 2 3 respectively base originalkwic algorithm minimize potential temporal blurring alternative window size weight function discuss since number received xray photon n na detector estimate poisson distribution thenumber incident photon see section 3 b detail number emitted photon n eafter attenuation snr derive follow snr=mean sd=neeli /radicalbig neeli=/radicalbig neeli 4 thus give neand amount attenuation snr proportional square root size detector namely resolution inver se relation resolution kspace coverage snr inversely proportional radius kspace region order compensate snr loss use projection data lowdose ct utilize small center kspace region achieve adequate snr radius ring 1 r1 derive eq 5 r1=nproj rsnr 5 rsnr relative snr low dose ctp versus full dose scan rest kspace subsequentlydivided ring progressively average neighbor time frame increase snr radius ring norr ncan derive eq 6 rn=r1+ndetectors 2r1 nrings1 n1 6 nrings total number ring ndetectors number detector rnis derived radius nth ring practice optimal number ring respective size determine empirically ring use high snr however resultantimages could potentially susceptible motion aswell temporal smoothing fine structure time frame apply kwia kspace data regridded cartesian space follow 2d inverse fast ft fft generate ct image iii erial methods kwia algorithm implementation kwia algorithm implement matlab mathworks inc natick usa include 5 steps1 perform 1d fft parallel beam projection along detector row direction 2 multiplication kwia filter separate weigh projection subapertures orrings 3 stacking kwia filtered projection radial kspace 4 compensating weighting radial data use voronoi algorithm 5 regridding radial kspace 2d cartesian kspace finally 6 perform 2d inverse fft regridded kspace data 2d image step 1 parallel beam ct projection simulate ctp image use astra toolbox 26 27 digital phan tom clinical data real scan phantom fanbeam projection acquire rebinned parallel beam projection voronoi algorithm step 4 use efficient accurate estimation density com pensation radial sample kspace data 28 even though density weight along radial projection kspaceis ramp function voronoi algorithm provide flexibility potential implementation kwia complicated ct geometry 3d cone beam ct cbct regridding algorithm step 5 choose kaiserbessel kernel =1625 window width =7 oversampling rate =2 convolution kernel achieve optimal balance sidelobe suppression computa tion time 29 compiled matlab program sample ctpdataset download http //loftlaborg/index5html b digital dynamic phantom simulation forbild digital phantom 30 three timevarying vessel insert 10 5 25 mm diameter respectively create simulate dynamic ct scan scanning para meter simulation show table ring size use kwia reconstruction list table ii baseline poisson noise emit xray photon number 48106 value estimate clinical ctp data section 3 add projection data simulate full dose ctp scan accordingly 50 25 dose ctp scan generate use 2 410 6and 12106 emit xray photon number respect ively addition temporal variation vessel signal follow predefinedgamma variate function 31 eq 7 c vessel signal c 0is constant set 1 trefers time andis parameter determine signal changing rate =11 digital phantom simulation use scan time 54 second number frame 27 frames ourclinical data peak vessel signal set appear 10th time frame c =c 0te 1t 7 3882 ieee transactions medical imaging vol 39 12 december 2020 table imaging reconstruction parameters table ii kwia r ingsize radius definition simulation low dose ctp use digital phantom hypothesize 1 true compound poisson process wellestimated poisson distribution 2 electronicnoise gaussian distribute ignore 32 34 thus noise model simplified detector detected number photon follow poisson distribu tion number received photon attenuate number e mitting photon penetrate body reduction tube current proportionally reduce emitted photon result detected number photon detector reduce tube current bedetermined eq 8 35 n dis detected photon number neis emitted photon number liis line integral attenuation coefficients correspond detector andrepresent full dose tube current reduced tube current respectively nd=poisson neeli 8 ctp scan full dose 50 dose 25 dose simulate accordingly kwia 2 3 ring apply recover snr 50 dose ctp scan kwia 3 4 ring apply recover snr 25 dose ctp scan evaluate performance kwia meansignal standard deviation sd noise measure relatively uniform region estimate snr blue circle fig 2 contrasttonoise ratio cnr also estimate use two region blue circle purple circle fig 2 different mean value value cnr defined ratio difference mean signal two region fig 2 forbild ct phantom 3 vessel different size b contain full dose low dose simulation 4 kwia simulation result two roi enlarge emphasize snr changeand subtraction image window level window center adjust visual observation make show structural change square root sum variance evaluate impact different vessel size temporal fidelityof kwia reconstruction region contain 3 timevarying vessel select roi measure time course well temporal parameter include areaunderthecurve auc full width half maximum fwhm root mean square error rmse well demonstrate snr change subtraction image noiseless phantom image simulate low dose ctp kwia image generate present c physical ctp phantom scan purpose physical phantom study verify low dose simulation method snr dependency perfusion metric feasibility kwia reconstruction reallow dose ctp scan commercial ct perfusion phantom gammex middleton wi usa scan siemens somatom definition scanner fixed tube voltageof 100 kvp 3 different tube current 200 120 60 mas respectively gammex ctp phantom consist homogenous scan disk image object show fig 4 4 rod indicate yellow arrow fig 4 include artery vein 2 identical brain tissue rod make several disc variable density set motion 4 rod mimic flow contrast agent bloodtissue network time therefore phantom capable simulate blood flow artery vein two tissue region 36 scan three slice image simultaneously total scanzhao et al low dose ct perfusion kwia 3883 duration 39 second interval 1 second time frame scan fan b eam projection data collect scanner rebinned parallel beam projection data offline reconstruction kwia scan high tube current 200 mas use full dose scan 120 60 mas treat 60 30 dose respectively kwia 2 and3 ring apply 60 dose scan kwia 3 4 ring 30 dose scan comparison full low dose image also reconstruct standard regridding reconstruction without kwia detailed scan parameter list table size ring use kwia list table ii snr measure uniform region purple circle fig 4 scan disk ctp phantom cnr measure scan disk region uniform region brain tissue blue circle fig 4 arterial input function aif venous outflow function vof tissue signal curve measure rois artery vein brain tissue respectively quantitative ctp analysis perform use inhouse matlab program deconvolution base singular value decomposition svd algorithm 37 postprocessingof ctp image yield cerebral blood flow cbf map cbf value 2 brain tissue region phantom measure comparison across reconstruct perfusion map clinical ctp data simulation six clinical ctp datasets treat full dose case study acquire toshiba aquilion ct scanner detailed parameter ctp scan list table poisson distribute noise add simulate 50 and25 low dose case kwia algorithm 2 3 4 ring implement test simulated low dose ctp scan respectively use ring size digital dynamic phantom simulation parameter list table ii difference noise add clinical data digital phantom digital phantom poisson noise directly add noiseless phantom image given emitted photon number n efor full dose scan low dose scan simply simulate noiseless phantom image using nein eq 8 clinical data however noiseless image available require include additional noise top full dose imagesalready contain level noise also n eof full dose image unknown parameter simulation process describe eq 9 38 n d= n eeli+poisson 0 2 2n eeli 9 n dis received xray photon number dose n eis emitted photon number dose n poisson 0 refers poisson distribution zero mean case generate data th e desire variance mean n ef r ne estimate 4 8106by measure change resultant snr reconstructed image accurate estimation neshould allow snr decrease linearlywith square root tube current reduction validate physical phantom study mean signal noise sd measure uniform region blue circle fig 8 grey matter examine impact kwia snr cnr also estimate grey matter blue circle fig 8 white matter purple circle fig 8 arterial input function aif venous outflow function vof tissue density signal curve measure rois anterior cerebral artery posterior part superior sagittal sinus uniform grey matter region without visible vessel respectively quantitative ctp analysis perform way physical phantom study mean cbf value whole brain measure 6 datasets comparison across reconstruct perfusion map e comparison kwia reconstruction algorithms comparison kwia two image reconstruc tion method perform clinical ctp data perspective noise suppression cbf bias reduction two method include filtered back projection fbp ramp filter standard algorithm clinical ct simultaneous algebraic reconstruction regularize total variation sarttv 39 stateofart technique ctdenoising fbp implement use astra toolbox 26 28 tigre toolbox 40 use sarttv implementation among 3 commonly use fbp filter functions ramlak hann shepplogan ramlak filter apply comparison study since lowpass windowing function like hann shepp logan introduce tradeoff denoising smooth quantitative comparison include snr gm blue circle fig 12 n dw purple circle fig 12 cnr gm wm whole brain cbf measurement across 6 clinical datasets perform achieve performan ceefficiency balance default hyperparameter value recommend tigre toolbox select include 100 number iteration 1 step size 15 value parameter regularization strength 50 number iteration tv regularization step iv r esults digital dynamic phantom simulation figure 2 show ct image 7th time frame 7 experimental condition full dose 50 dose 25 dose kwia 50 2 rings kwia 50 3 rings kwia 25 3 rings kwia 25 4 rings respectively inset show two zoom rois highlight snr change two rois see snr degrade 50 and25 dose image compare full dose image recover kwia reconstruction addition subtracted image kwia reconstruct image full doseimages illustrate structured noise pattern texture change induce kwia reconstruction table iii list snr value seven experimental con ditions respectively snr 50 25 dose images3884 ieee transactions medical imaging vol 39 12 december 2020 table iii digital phantom snr cnr easurement indifferent conditions fig 3 gamma variate dynamic time curve full dose 4 kwia case 3 vessel different size digital phantom table iv rmse auc fwhm easurement 3v essels different sizecontained forbild p hantom 73 52 full dose image consistent theoretical prediction kwia however wasable recover snr 50 25 dose image comparable full dose image consistent prediction increase number ring kwia reconstruction lead great snr cnr result low dose simulation consistent prediction well kwia ableto recover cnr full dose level temporal signal 3 vessel different size 25 5 10 mm diameter show fig 3 n1 0m fig 4 scans ctp phantom b contain full dose 200 mas low dose 120 mas 60 mas 4 kwia reconstructionresults roi enlarge emphasize snr change subtractionimages window level window center adjust visual observation make show structural change fig 3 n d5m fig 3 b vessel apparent dif ference kwia full dose curve observedthis show capability kwia preserve high temporal resolution however slight reduction maximum peak observe 25 mm fig 3 c vessel kwia image likely due temporal blurring cause averaging high frequency kspace data neighboring time frame kwia quantitatively estimate effect temporal blurring temporal parameter include auc fwhm rmse werecalculated show table iv 1 difference auc 7 difference fwhm respectively small vessel rmse generally small < 001 5 10 mm vessel increase 0027 25 mm vessel rmse small high dose ring use b physical ctp phantom experiment figure 4 show image 11th time frame ctp phantom scan single slice within scan disk 7 experimental condition include full dose 200 mas 60 dose 120 mas 30 dose 60 mas 60 dose kwia 2 3 rings 30 dose kwia 3 4 rings respectively zoomed inset illustrate snr change whilezhao et al low dose ct perfusion kwia 3885 table v thephysical phantom snr cnr easurement different conditions fig 5 aif vof brain tissue signal curve full dose low dose image reconstruct k wia apparent difference observe curve second peak aif vof represent secondpass contrast bolus subtracted image show residual noise pattern full dose rest experimental condition respectively similar simulated digital phantom study great level noisecan observe real 60 30 dose scan recover comparable full dose scan kwia residual edge signal subtractedimages low dos full dose image due slight displacement phantom tween scan nevertheless consistency residual noise pattern edge signal across low dose kwia reconstruct image suggest kwia introduce structured noise pattern ortexture change table v list snr cnr measurement phan tom image seven experime ntal condition respectively fig 6 cbf map ml/100g/min ctp phantom bias introduce low dose cbf map correct kwia fig 7 bar plot mean cbf value physical phantom clinical data b full dose low dose 4 kwia condition physical phantom condition include 2 measurement 2tissue region clinical data condition contain 6 wholebrain measurement 6 clinical dat asets error bar indicate standard deviation measured snr cnr value low dose scan strictly follow theoretical value pre dicted eq 4 validate low dose simulation perform section 3 b 3 dit see kwia able recover snr cnr low dose scan comparable full dose scan ring use kwia great snr cnr recovery figure 5 show aif vof brain tissue signal curve apparent difference observe time curve full dose low dose image reconstruct kwia suggest temporal blurring introduce bykwia figure 6 show quantitative cbf map ctp phan tom seven different experimental condition observe increase bias introduce cbf map decrease radiation dose full dose 60 and30 dose bias correct kwia reconstruction see fig 7 resultant cbf map visually similar full dose scan c clinical ctp data simulation figure 8 show representative image 15th time frame clinical ctp data include simulate 50 25 dos kwia reconstruct image inset show two zoom rois well illustrate snr difference snr reduction full dose 50 25 dose clearlyobserved whereas snr reduction successfully recover comparable full dose level kwia reconstruction subtraction image kwia and3886 ieee transactions medical imaging vol 39 12 december 2020 fig 8 clinical ct image 25 50 dose simulation original dose kwia reconstruction b contain full dose low dose simulation 4 kwia reconstruction result two roi wereenlarged emphasize snr change subtraction image windowlevel window center adjust visual observation make show structural change visible snr cnr reduction observe 50 25 dose simulation case kwia ability ofsnr recovery also visually capture rois snr change see clearly performance noise reduction roi 1 contrast recovery roi 2 demonstrate kwiano structural difference detect subtraction image full dose image show structured noise pattern texture change introduce kwia reconstruction due possible motion occur frame lowlevel ringing artifact observe subtraction image table vi show quantitative measurement grey white matter rois across 7 experimental condition snr simulated 50 dose image 75 wm and71 gm 707 theory full dose snr 54 wm 50 gm 50 theory 25 dose image 50 dose image kwia reconstruction 2 3 ringsimproved snr 92 100 full dose level respectively white matter 89 95 respectively grey matter 25 dose image kwia reconstruction 3 4 ring improve snr 89 95 full dose level respectively white matter 74 84 greymatter noise sd simulate 50 dose image increase sd 138 wm 137 gm 141 theory time full dose level simulate 25 dose image increase sdtable vi quantitative measurement snr cnr inclinical data fig 9 dynamic contrast curve venous r e r l b tissue roi c 1 mm wide small vessel full dose case kwia simulation case apparent difference observe 4 signal arterial tissue small vessel signal kwia simulation 25 dose reduction tend great difference kwiasimulation 50 dose reduction 184 wm 205 gm 2 theory time full dose level kwia reconstruction also decrease noise sd fulldose level cnr measure wm gm 038 039 theory 50 dose 028 028 theory 25 dose kwia also show ability significantly improve cnr vof aif tissue signal curve full dose 4 kwia reconstruction present fig 9 b c respectively signal curve 4 kwia reconstruction closely follow full dose image evaluate potential impact kwia small ves sels due averaging high spatial frequency signal fig 9 show dynamic signal curve small vessel width 1 mm apparent temporal smoothing observe small vessel kwia reconstruction quantitative cbf map clinical case show fig 10 reduction radiation dose 50 25 intro duced substantial bias quantification cbf map large 25 compare 50 dose however cbf map kwia reconstruction able sub stantially correct bias especially kwia 50 3 ringszhao et al low dose ct perfusion kwia 3887 fig 10 cbf map ml/100g/min 2 clinical ctp case top bottom full dose 50 25 dose regridding reconstruction well kwia 50 2 3 rings kwia 25 3 4 ringsrespectively kwia 25 4 rings visually comparable full dose image show improve contrast grey white matter quantitative cbf value 7 condition display bar plot fig 7 b finally cbf value measure whole brain full dose low dose kwia case demonstrate bland altman plot fig 11 cbf bias mean difference obvious low dose condition 86 272ml/100g/min 50 25 respectively minimize reduce kwia reconstruction however small bias 7ml/100g/min cbf value calculate full dose kwia 25 4 rings ctp data low dose conditionsalso show wide limit agreement 95 confidence interval cbf difference 104 137 ml/100g/min 50 25 dose respectively compare theircorresponding kwia reconstruction dose 70 76 ml/100g/min kwia 50 2 3 ring respectively 91 78 ml/100g/min kwia 25 3 4 rings respectively variability scatter consistent across graph suggest change ofdifference depend average comparison reconstruction algorithms figure 12 display ctp image cbf map full dose fbp gold standard 3 simulate 50 dose fig 12 fig 11 blandaltman plot comparison whole brain cbf value measure full dose low dose condition well low dose kwia reconstruction 3 simulate 25 dose fig 12 b reconstruct fbp kwia sarttv respectively snr cnr value ctp image mean cbf value cbf map listedintable vii 50 25 dose fbp image exhibit large image degradation 26 gm 20 wm snr reduction 50 dose 54 gm 60 wm snr reductionfor 25 dose cbf overestimation 19 increase 50 dose 48 increase 25 dose whereas kwia yield excellent reconstruction result comparable full dose fbp 92 gm 96 wm full dose fbp 50 dose 82 gm 88 wm full dose fbpfor 25 dose without introduce smooth effect loss spatial resolution cbf bias due 50 25 dose 106 272 ml/100g/min respectively largely suppress kwia 23 91 ml/100g/min respectively sarttv show strong denoising effect kwia snr cnr high full dose fbp image however slight overcorrection cbf bias use sarttv 43 14ml/100g/min 50 25 respectively reconstructed image appear smooth might possible achieve good performance sarttv tune hyperparameters balance denoisingpower spatial smoothness however tune process sarttv constrain prolonged computation time far limit use sarttv clinical ctp scan table vii also list execution time et reconstruct 512by512 image 728by1152 sinogram use fbp kwia sarttv respectively imple mentation environment matlab intel i59400f take 112 second kwia reconstruct image wassimilar reconstruction time 93 second require fbp comparison sarttv take 2658 second graphic processing unit matlab gtx 1660 ti 3888 ieee transactions medical imaging vol 39 12 december 2020 fig 12 reconstructed image top row b cbf map bottom row b full dose fbp 50 dose fbp 25 dose fbp kwia 50 3 rings kwia 25 4 rings 50 dose sart tv and25 dose sart tv insets magnified region image show snrand spatial smoothness eac h reconstruction method table vii q uantitative comparison among fbp kwia sarttv v iscussion projection image data ct relate spatial frequency domain eg kspace mri centralslice theorem perform 1d ft projection object equivalent line center 2d ft plane ie kspace convert ct sinogram kspace data adapt many innovativemri reconstruction algorithm preserve high spatial temporal resolution undersampled ct data previ ous study introduce innovative image reconstructionalgorithm base kspace weight image contrast kwic 23 41 radiation dose reduction ctp 24 preliminary result show kwic able reduce radiation dose exist ctp method 5075 withoutcompromising image speed quality however original kwic algorithm require rapidswitching pulsed xray pre specified rotation angle hardware capability availableon commercial ct scanner order address limitation introduce novel algorithm term kspace weighted image average kwia preserve image quality snr cnr spatial temporal resolution well quantification accuracy lowdose ctp data 5075 dose reduction comparable standard ctp scan unlike kwic require modified ct hardware kwia implement simplyreducing tube current work demonstrate feasibility kwia use digital phantom clinical ctp data simulated low dos well physical ctp phantom real low dose scan compared exist low dose ct technique iterative reconstruction ourapproach unique several advantage 1 base fourier base ct image reconstruction make assumption noise characteristic preserve textureand resolution ct image 2 low computational overhead affect th e clinical workflow 3 require modification exist ct hardware therefore low barrier c linical adoption kspace noise different frequency average convertinginto image space ft 42 therefore kwia improve snr ctp image without affect resolution texture characteristic previous study shownthat accuracy ctp quantification highly dependent noise level ct image 43 44 overestimation perfusion often occur presence substantial noise use singular value decomposition svd base deconvolu tion analysis recover snr low dose ctp image kwia able correct bias perfusion quantification 5075 dose reduction application kwia 2d parallel beam fan beam ct evaluate study nevertheless theoretical principle kwia applicable low dose 3d cone beam ct cbct specifically central slice theorem 3d cbct geometry state 1d ft 1d radon data 3d object obtain indirectlywith grangeat method identical radial line 3d kspace 45 across different time frame kwia able partition weight average radial line fromthe center 3d kspace periphery complete 3d radon space obtain cbct previous study also show reliability efficiency fourierbased reconstruction 3d cbct 46 alternatively cbct circular geometry middle plane defined xray source trajectory complete set radon data approximate reconstruction 47 apply projection data offmiddle plane canbe convert kspace kwia processing caveat large cone angle less accurate approximation zhao et al low dose ct perfusion kwia 3889 despite kwia potential reduce ctp dose limitation kwia improve image snr average high frequency kspace data neighboring time frame therefore potentially sensitive patient head motion thanstandard ctp scan another potential drawback kwia temporal blurring dynamic signal change fine vessel and/or structure show fig 3 slight temporal blurring observe 25 mm vessel kwia image vessel 5 10mm size nevertheless significant tem poral blurring clinical ctp data kwia reconstruction observe aif vof curve reconstruct kwia also match well standard ctp data apparent temporal signal deviation observe vessel 1mm size potential temporal blurring kwia may depend various parameter rate ofsignal change sample rate ctp merit evaluation addition iterative reconstruction algorithm sarttv may strong denoising capability kwia nevertheless kwia advantageous term ease robustness implementation computationalspeed retainment texture resolution comparison kwia iterative reconstruction deep learning base denoising method also perform futurestudies lastly cbf bias reduction performance kwia evaluate cbf map generate standard svd ctp analysis study alternative ctp analysis denoising capability bayesian probabilistic method need test use kwia reconstruct ctp image 48 work kwia apply simulate low dose ctp data reduced xray tube current relatively straightforward relationship snr also possible toreduce tube voltage square generally acknowl edge proportional receive radiation dose 49 temporal window size footprint kwia keep short possible minimize potential temporal blurring study nevertheless windowing function averagingneighboring time frame well number size ring kwia could far optimize base tradeoff snr improvement loss temporal resolution alternative function inverse nufft inufft may apply regridding reconstruction future deep learning base approach may combine kwia far improve robustness presence patient head motion artifact eg streak due photonstarvation lastly kwia may directly apply ctp data acquire standard radi ation dose reduce noise enhance image contrast vi c onclusion research present new low dose ctp tech nique term kwia constant reduce tube current projection average kspace propose technique evaluate use digital phantom physical phantom clinical ctp data achieve considerable dosesavings 5075 without compromise image quality perfusion metric due robustness simplicity kwia may provide promising method reduce radiation exposure patient undergo ctp examsa cknowledgment author grateful dr hee kwon song help manuscript disclosure tm djw inventor patent low dose ctp tm djw hold share hura imaging inc",
    "bag_of_words": {
        "ieee": 6,
        "transactions": 6,
        "medical": 6,
        "imaging": 15,
        "vol": 6,
        "december": 6,
        "low": 50,
        "dose": 169,
        "ct": 51,
        "perfusion": 20,
        "kspace": 48,
        "weighted": 6,
        "image": 106,
        "average": 20,
        "kwia": 139,
        "chenyang": 2,
        "zhao": 3,
        "thomas": 2,
        "martin": 2,
        "xingfeng": 2,
        "shao": 2,
        "jeffry": 2,
        "alger": 2,
        "vinay": 2,
        "duddalwar": 2,
        "danny": 3,
        "wang": 3,
        "abstract": 1,
        "ctp": 83,
        "computed": 2,
        "tomography": 3,
        "widely": 2,
        "use": 40,
        "clinical": 25,
        "practice": 4,
        "evaluation": 3,
        "cerebrovascular": 1,
        "disorder": 1,
        "however": 16,
        "involve": 1,
        "high": 19,
        "radiation": 14,
        "200mgy": 1,
        "xray": 14,
        "source": 2,
        "remain": 2,
        "continuously": 1,
        "passage": 3,
        "contrast": 14,
        "medium": 1,
        "thepurpose": 1,
        "study": 16,
        "present": 5,
        "techniquetermed": 1,
        "usinga": 1,
        "novel": 2,
        "projection": 28,
        "viewshared": 1,
        "algorithm": 18,
        "withreduced": 1,
        "tube": 26,
        "current": 18,
        "take": 3,
        "advantage": 3,
        "signal": 23,
        "property": 2,
        "primarily": 2,
        "determinedby": 1,
        "center": 15,
        "spatial": 12,
        "frequency": 7,
        "oversampled": 1,
        "divide": 4,
        "2d": 11,
        "fourier": 4,
        "transform": 2,
        "ft": 10,
        "data": 49,
        "multiple": 4,
        "ring": 31,
        "outerrings": 1,
        "neighboring": 3,
        "time": 40,
        "frame": 21,
        "achieveadequatesignaltonoiseratio": 1,
        "snr": 65,
        "regionof": 1,
        "unchanged": 1,
        "preserve": 10,
        "temporalresolution": 1,
        "reduced": 4,
        "sinogram": 5,
        "simulate": 15,
        "byadding": 1,
        "poisson": 10,
        "distribute": 4,
        "noise": 25,
        "zero": 2,
        "mean": 12,
        "digitalphantom": 1,
        "scan": 53,
        "physical": 11,
        "phantomstudy": 1,
        "also": 18,
        "perform": 12,
        "different": 12,
        "currentsthe": 1,
        "simulated": 5,
        "real": 4,
        "dos": 4,
        "werethen": 1,
        "reconstruct": 15,
        "compare": 6,
        "thosereconstructed": 1,
        "standard": 14,
        "filtered": 3,
        "back": 2,
        "fbp": 16,
        "simultaneous": 2,
        "algebraic": 2,
        "reconstruction": 45,
        "regularization": 3,
        "total": 4,
        "variation": 3,
        "sarttv": 13,
        "qualityand": 1,
        "metric": 3,
        "parameter": 13,
        "include": 16,
        "cnr": 21,
        "contrasttonoise": 2,
        "ratio": 3,
        "auc": 5,
        "areaunderthecurve": 2,
        "cbf": 32,
        "cerebral": 6,
        "blood": 5,
        "flow": 4,
        "demonstrate": 6,
        "manuscript": 2,
        "receive": 3,
        "may": 8,
        "revise": 1,
        "june": 2,
        "accept": 1,
        "date": 2,
        "publication": 1,
        "july": 1,
        "version": 2,
        "november": 1,
        "work": 4,
        "support": 1,
        "nih": 1,
        "grantr41eb024438": 1,
        "grant": 1,
        "r01eb028297": 1,
        "corresponding": 1,
        "author": 2,
        "keck": 2,
        "school": 2,
        "medicine": 2,
        "stevens": 2,
        "neuroimaging": 2,
        "informatics": 2,
        "institute": 2,
        "university": 5,
        "southern": 1,
        "california": 2,
        "los": 4,
        "angeles": 4,
        "ca": 6,
        "usa": 10,
        "email": 4,
        "czhao": 1,
        "uscedu": 1,
        "evanshaoxf": 1,
        "gmailcom": 2,
        "vinayduddalwar": 1,
        "meduscedu": 1,
        "mays": 1,
        "cancer": 1,
        "oncology": 1,
        "texas": 2,
        "health": 1,
        "science": 1,
        "san": 1,
        "antonio": 1,
        "tx": 2,
        "hura": 4,
        "inc": 5,
        "calabasas": 3,
        "thomasmartin": 1,
        "aggiemailusuedu": 1,
        "department": 1,
        "neurology": 1,
        "advanced": 1,
        "research": 2,
        "southwesternmedical": 1,
        "dallas": 1,
        "jalger": 1,
        "huraimagingcom": 1,
        "southerncalifornia": 1,
        "jwang71": 1,
        "color": 1,
        "one": 1,
        "figures": 1,
        "article": 1,
        "available": 2,
        "online": 1,
        "http": 3,
        "//ieeexploreieeeorg": 1,
        "digital": 16,
        "object": 4,
        "identifier": 1,
        "101109/tmi20203006461able": 1,
        "quality": 7,
        "temporal": 28,
        "resolution": 16,
        "well": 16,
        "accuracy": 4,
        "quantification": 7,
        "considerable": 2,
        "dosesavings": 2,
        "index": 1,
        "terms": 1,
        "compute": 1,
        "brain": 13,
        "analytical": 1,
        "method": 17,
        "enhancement": 2,
        "introduction": 1,
        "technique": 10,
        "provide": 3,
        "assess": 1,
        "ments": 1,
        "regional": 1,
        "supply": 1,
        "hemodynamic": 2,
        "information": 4,
        "distinguish": 1,
        "ischemic": 1,
        "core": 1,
        "penumbral": 1,
        "tissue": 14,
        "help": 2,
        "decision": 1,
        "making": 1,
        "recanalization": 1,
        "therapy": 1,
        "ischemia": 1,
        "typical": 3,
        "dataset": 1,
        "timeresolved": 1,
        "acquire": 5,
        "duration": 2,
        "min": 1,
        "track": 1,
        "bolus": 3,
        "intracranial": 1,
        "vasculature": 1,
        "depict": 1,
        "density": 6,
        "curve": 14,
        "tdc": 2,
        "bloodflow": 1,
        "volume": 1,
        "cbv": 1,
        "transit": 1,
        "mtt": 1,
        "derive": 4,
        "repeated": 1,
        "region": 20,
        "result": 8,
        "patient": 4,
        "example": 2,
        "typicalclinical": 1,
        "setting": 1,
        "acquisition": 2,
        "voltage": 5,
        "kev": 1,
        "mas": 10,
        "sample": 9,
        "rate": 6,
        "image/2s": 1,
        "acco": 1,
        "rding": 1,
        "alara": 1,
        "reasonably": 1,
        "achievable": 1,
        "principle": 2,
        "resultant": 3,
        "mgy": 1,
        "approximately": 1,
        "head": 3,
        "recently": 2,
        "several": 3,
        "apply": 13,
        "reduction": 26,
        "tubecurrent": 1,
        "and/or": 3,
        "iterative": 6,
        "ir": 5,
        "adaptive": 1,
        "statisticaliterative": 1,
        "asir": 1,
        "modelbased": 1,
        "mbir": 1,
        "often": 2,
        "yield": 4,
        "blotchy": 1,
        "appearance": 1,
        "long": 1,
        "computational": 4,
        "although": 1,
        "application": 3,
        "improve": 9,
        "due": 10,
        "enhance": 2,
        "power": 1,
        "limited": 1,
        "complexity": 1,
        "significant": 2,
        "overhead": 2,
        "process": 5,
        "dynamic": 10,
        "series": 2,
        "possible": 5,
        "lower": 1,
        "doseby": 1,
        "reduce": 14,
        "sampling": 3,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attrib": 1,
        "ution": 1,
        "see": 6,
        "//creativecommonso": 1,
        "rg/licenses/by/40/3880": 1,
        "approach": 2,
        "insuffici": 1,
        "ent": 1,
        "accurate": 4,
        "past": 1,
        "year": 1,
        "deep": 4,
        "learning": 4,
        "dl": 4,
        "explore": 1,
        "residual": 5,
        "neural": 1,
        "network": 4,
        "generative": 1,
        "adversarial": 1,
        "gan": 1,
        "base": 10,
        "denoising": 8,
        "expand": 1,
        "incorporate": 1,
        "iterativesteps": 1,
        "performance": 5,
        "robustness": 4,
        "lowdose": 9,
        "artifact": 3,
        "net": 2,
        "irlnet": 1,
        "spatialtemporal": 1,
        "restoration": 1,
        "stirne": 1,
        "exist": 6,
        "short": 3,
        "computation": 2,
        "nearly": 1,
        "instantaneous": 1,
        "train": 1,
        "retainment": 2,
        "texture": 6,
        "ofct": 1,
        "highly": 2,
        "dependent": 2,
        "training": 1,
        "datasets": 4,
        "specific": 3,
        "scanner": 5,
        "protocol": 1,
        "collection": 1,
        "kwic": 8,
        "originally": 1,
        "4d": 1,
        "mri": 2,
        "radial": 10,
        "trajectoriesto": 1,
        "shorten": 1,
        "sparse": 3,
        "based": 2,
        "central": 5,
        "slice": 5,
        "theorem": 4,
        "convert": 3,
        "space": 4,
        "equivalent": 2,
        "inmri": 1,
        "make": 6,
        "feasible": 1,
        "adaptation": 1,
        "follow": 7,
        "viewsharing": 2,
        "proofofconcept": 2,
        "scheme": 1,
        "employ": 1,
        "achieve": 6,
        "maintain": 2,
        "bothhigh": 1,
        "implementation": 5,
        "require": 7,
        "rapidswitching": 2,
        "pulsed": 2,
        "prespecified": 1,
        "rotationanglesa": 1,
        "hardware": 5,
        "capability": 5,
        "yet": 1,
        "implement": 5,
        "commercial": 3,
        "vendor": 1,
        "purpose": 2,
        "introduce": 11,
        "variant": 1,
        "term": 5,
        "temporalresolutions": 1,
        "ielding": 1,
        "comparable": 8,
        "three": 3,
        "majoradvantages": 1,
        "contribution": 1,
        "modification": 2,
        "uch": 1,
        "computationally": 1,
        "simple": 1,
        "fast": 2,
        "noniterative": 1,
        "therefore": 5,
        "affect": 3,
        "clini": 1,
        "cal": 1,
        "workflow": 2,
        "paper": 2,
        "first": 1,
        "theoreticalframework": 1,
        "feasibility": 3,
        "phantom": 39,
        "ii": 6,
        "heory": 1,
        "detector": 10,
        "contin": 1,
        "uously": 1,
        "rotate": 1,
        "around": 1,
        "point": 1,
        "constant": 3,
        "angular": 1,
        "interval": 3,
        "emit": 3,
        "fan": 4,
        "beam": 12,
        "array": 2,
        "toform": 1,
        "1d": 5,
        "along": 3,
        "parallel": 6,
        "obtain": 3,
        "fromfan": 1,
        "rebinning": 1,
        "form": 1,
        "like": 2,
        "meet": 1,
        "nyquist": 2,
        "theory": 9,
        "periphery": 2,
        "less": 2,
        "rat": 1,
        "avoid": 1,
        "streak": 2,
        "thus": 3,
        "number": 24,
        "proj": 1,
        "satisfy": 1,
        "nproj": 1,
        "2ndetector": 1,
        "slightly": 1,
        "theoretical": 4,
        "since": 4,
        "fieldofview": 1,
        "fov": 1,
        "generally": 3,
        "small": 11,
        "width": 4,
        "assuming": 1,
        "ris": 1,
        "radius": 6,
        "satisfies": 1,
        "determine": 4,
        "r=nproj": 1,
        "common": 1,
        "without": 6,
        "loss": 4,
        "generality": 1,
        "focus": 1,
        "discuss": 2,
        "later": 1,
        "direct": 1,
        "proportional": 4,
        "relationship": 2,
        "betweenthe": 1,
        "square": 6,
        "root": 5,
        "reconstructed": 4,
        "2will": 1,
        "2of": 1,
        "original": 3,
        "effect": 5,
        "evenly": 1,
        "across": 8,
        "show": 29,
        "infig": 1,
        "effectively": 1,
        "outer": 3,
        "progressivelysparser": 1,
        "lead": 2,
        "deficient": 1,
        "resolved": 1,
        "exploit": 1,
        "new": 2,
        "highspatial": 1,
        "propose": 2,
        "datainto": 1,
        "part": 2,
        "directly": 3,
        "single": 2,
        "eg": 4,
        "1in": 1,
        "fig": 37,
        "progressively": 2,
        "neighbor": 2,
        "increase": 9,
        "t1andt2": 1,
        "t0tot3": 1,
        "eff": 1,
        "ective": 1,
        "express": 1,
        "following": 1,
        "equation": 1,
        "si": 1,
        "k=\u0005m1": 1,
        "2\u0006/summationdisplay": 1,
        "d=\u0005m1": 1,
        "2\u0006wd": 1,
        "ksi+d": 1,
        "kis": 2,
        "distance": 1,
        "mis": 1,
        "window": 11,
        "size": 17,
        "wd": 1,
        "weighting": 2,
        "function": 11,
        "note": 1,
        "averaging": 4,
        "shift": 1,
        "atzhao": 1,
        "et": 6,
        "al": 5,
        "schematic": 1,
        "diagram": 1,
        "four": 1,
        "t0t3": 1,
        "betweenneighboring": 1,
        "beginning": 1,
        "end": 1,
        "keep": 2,
        "averaged": 1,
        "within": 2,
        "range": 1,
        "discrete": 1,
        "ringsand": 1,
        "move": 1,
        "accordingly": 3,
        "respectively": 27,
        "originalkwic": 1,
        "minimize": 3,
        "potential": 7,
        "blurring": 9,
        "alternative": 3,
        "weight": 4,
        "received": 3,
        "photon": 15,
        "na": 1,
        "estimate": 7,
        "distribution": 3,
        "thenumber": 1,
        "incident": 1,
        "section": 3,
        "detail": 1,
        "emitted": 5,
        "eafter": 1,
        "attenuation": 3,
        "snr=mean": 1,
        "sd=neeli": 1,
        "/radicalbig": 1,
        "neeli=/radicalbig": 1,
        "neeli": 2,
        "give": 1,
        "neand": 1,
        "amount": 1,
        "namely": 1,
        "inver": 1,
        "se": 1,
        "relation": 1,
        "coverage": 1,
        "inversely": 1,
        "order": 2,
        "compensate": 1,
        "utilize": 1,
        "adequate": 1,
        "r1": 1,
        "eq": 7,
        "r1=nproj": 1,
        "rsnr": 2,
        "relative": 1,
        "versus": 1,
        "full": 54,
        "rest": 2,
        "subsequentlydivided": 1,
        "norr": 1,
        "ncan": 1,
        "rn=r1+ndetectors": 1,
        "2r1": 1,
        "nrings1": 1,
        "n1": 2,
        "nrings": 1,
        "ndetectors": 1,
        "rnis": 1,
        "derived": 1,
        "nth": 1,
        "optimal": 2,
        "respective": 1,
        "empirically": 1,
        "resultantimages": 1,
        "could": 2,
        "potentially": 2,
        "susceptible": 1,
        "motion": 5,
        "aswell": 1,
        "smoothing": 2,
        "fine": 2,
        "structure": 2,
        "regridded": 2,
        "cartesian": 2,
        "inverse": 3,
        "fft": 3,
        "generate": 5,
        "iii": 3,
        "erial": 1,
        "methods": 1,
        "matlab": 5,
        "mathworks": 1,
        "natick": 1,
        "steps1": 1,
        "row": 3,
        "direction": 1,
        "multiplication": 1,
        "filter": 4,
        "separate": 1,
        "weigh": 1,
        "subapertures": 1,
        "orrings": 1,
        "stacking": 1,
        "compensating": 1,
        "voronoi": 3,
        "regridding": 5,
        "finally": 2,
        "step": 5,
        "astra": 2,
        "toolbox": 4,
        "phan": 3,
        "tom": 3,
        "fanbeam": 1,
        "rebinned": 2,
        "efficient": 1,
        "estimation": 2,
        "com": 1,
        "pensation": 1,
        "even": 1,
        "though": 1,
        "kspaceis": 1,
        "ramp": 2,
        "flexibility": 1,
        "complicated": 1,
        "geometry": 3,
        "3d": 8,
        "cone": 3,
        "cbct": 6,
        "choose": 1,
        "kaiserbessel": 1,
        "kernel": 2,
        "=1625": 1,
        "=7": 1,
        "oversampling": 1,
        "=2": 1,
        "convolution": 1,
        "balance": 3,
        "sidelobe": 1,
        "suppression": 2,
        "computa": 1,
        "tion": 4,
        "compiled": 1,
        "program": 2,
        "ctpdataset": 1,
        "download": 1,
        "//loftlaborg/index5html": 1,
        "simulation": 19,
        "forbild": 3,
        "timevarying": 2,
        "vessel": 23,
        "insert": 1,
        "mm": 8,
        "diameter": 2,
        "create": 1,
        "scanning": 1,
        "para": 1,
        "meter": 1,
        "table": 17,
        "list": 8,
        "baseline": 1,
        "value": 19,
        "add": 4,
        "6and": 1,
        "respect": 1,
        "ively": 1,
        "addition": 3,
        "predefinedgamma": 1,
        "variate": 2,
        "0is": 1,
        "set": 4,
        "trefers": 1,
        "andis": 1,
        "changing": 1,
        "=11": 1,
        "second": 7,
        "frames": 1,
        "ourclinical": 1,
        "peak": 3,
        "appear": 2,
        "10th": 1,
        "=c": 1,
        "0te": 1,
        "1t": 1,
        "parameters": 1,
        "ingsize": 1,
        "definition": 2,
        "hypothesize": 1,
        "true": 1,
        "compound": 1,
        "wellestimated": 1,
        "electronicnoise": 1,
        "gaussian": 1,
        "ignore": 1,
        "model": 1,
        "simplified": 1,
        "detected": 3,
        "distribu": 1,
        "attenuate": 1,
        "mitting": 1,
        "penetrate": 1,
        "body": 1,
        "proportionally": 1,
        "bedetermined": 1,
        "dis": 2,
        "neis": 1,
        "liis": 1,
        "line": 4,
        "integral": 1,
        "coefficients": 1,
        "correspond": 1,
        "andrepresent": 1,
        "nd=poisson": 1,
        "recover": 9,
        "evaluate": 6,
        "meansignal": 1,
        "deviation": 3,
        "sd": 5,
        "measure": 13,
        "relatively": 2,
        "uniform": 5,
        "blue": 6,
        "circle": 10,
        "two": 10,
        "purple": 4,
        "defined": 2,
        "difference": 12,
        "contain": 6,
        "roi": 7,
        "enlarge": 2,
        "emphasize": 3,
        "changeand": 1,
        "subtraction": 6,
        "level": 12,
        "adjust": 3,
        "visual": 3,
        "observation": 3,
        "structural": 4,
        "change": 16,
        "sum": 1,
        "variance": 2,
        "impact": 3,
        "fidelityof": 1,
        "select": 2,
        "course": 1,
        "half": 1,
        "maximum": 2,
        "fwhm": 4,
        "error": 2,
        "rmse": 5,
        "noiseless": 4,
        "verify": 1,
        "dependency": 1,
        "reallow": 1,
        "gammex": 2,
        "middleton": 1,
        "wi": 1,
        "siemens": 1,
        "somatom": 1,
        "fixed": 1,
        "voltageof": 1,
        "kvp": 1,
        "consist": 1,
        "homogenous": 1,
        "disk": 4,
        "rod": 3,
        "indicate": 2,
        "yellow": 1,
        "arrow": 1,
        "artery": 4,
        "vein": 3,
        "identical": 2,
        "disc": 1,
        "variable": 1,
        "mimic": 1,
        "agent": 1,
        "bloodtissue": 1,
        "capable": 1,
        "simultaneously": 1,
        "scanzhao": 1,
        "eam": 1,
        "collect": 1,
        "offline": 1,
        "treat": 2,
        "and3": 1,
        "comparison": 12,
        "detailed": 2,
        "arterial": 3,
        "input": 2,
        "aif": 7,
        "venous": 3,
        "outflow": 2,
        "vof": 7,
        "rois": 7,
        "quantitative": 8,
        "analysis": 5,
        "inhouse": 1,
        "deconvolution": 1,
        "singular": 2,
        "decomposition": 2,
        "svd": 3,
        "postprocessingof": 1,
        "map": 16,
        "six": 1,
        "case": 10,
        "toshiba": 1,
        "aquilion": 1,
        "and25": 3,
        "test": 2,
        "given": 1,
        "efor": 1,
        "simply": 1,
        "using": 1,
        "nein": 1,
        "additional": 1,
        "top": 3,
        "imagesalready": 1,
        "eof": 1,
        "unknown": 1,
        "describe": 1,
        "d=": 1,
        "eeli+poisson": 1,
        "2n": 1,
        "eeli": 1,
        "eis": 1,
        "refers": 1,
        "th": 2,
        "desire": 1,
        "ef": 1,
        "ne": 1,
        "8106by": 1,
        "neshould": 1,
        "allow": 1,
        "decrease": 3,
        "linearlywith": 1,
        "validate": 2,
        "grey": 6,
        "matter": 9,
        "examine": 1,
        "white": 5,
        "anterior": 1,
        "posterior": 1,
        "superior": 1,
        "sagittal": 1,
        "sinus": 1,
        "visible": 2,
        "way": 1,
        "whole": 4,
        "algorithms": 2,
        "reconstruc": 1,
        "perspective": 1,
        "bias": 12,
        "regularize": 1,
        "stateofart": 1,
        "ctdenoising": 1,
        "tigre": 2,
        "among": 2,
        "commonly": 1,
        "functions": 1,
        "ramlak": 2,
        "hann": 2,
        "shepplogan": 1,
        "lowpass": 1,
        "windowing": 2,
        "shepp": 1,
        "logan": 1,
        "tradeoff": 2,
        "smooth": 3,
        "gm": 11,
        "dw": 1,
        "wm": 10,
        "measurement": 6,
        "performan": 1,
        "ceefficiency": 1,
        "default": 1,
        "hyperparameter": 1,
        "recommend": 1,
        "iteration": 2,
        "strength": 1,
        "tv": 3,
        "iv": 3,
        "esults": 1,
        "figure": 6,
        "7th": 1,
        "experimental": 6,
        "condition": 12,
        "rings": 12,
        "inset": 3,
        "zoom": 2,
        "highlight": 1,
        "degrade": 1,
        "subtracted": 2,
        "doseimages": 1,
        "illustrate": 3,
        "structured": 3,
        "pattern": 5,
        "induce": 1,
        "seven": 3,
        "con": 1,
        "ditions": 1,
        "images3884": 1,
        "easurement": 3,
        "indifferent": 1,
        "conditions": 2,
        "gamma": 1,
        "3v": 1,
        "essels": 1,
        "sizecontained": 1,
        "hantom": 1,
        "consistent": 4,
        "prediction": 3,
        "wasable": 1,
        "great": 4,
        "ableto": 1,
        "0m": 1,
        "scans": 1,
        "reconstructionresults": 1,
        "subtractionimages": 1,
        "d5m": 1,
        "apparent": 6,
        "dif": 1,
        "ference": 1,
        "observedthis": 1,
        "slight": 4,
        "observe": 12,
        "likely": 1,
        "cause": 1,
        "quantitatively": 1,
        "werecalculated": 1,
        "experiment": 1,
        "11th": 1,
        "zoomed": 1,
        "whilezhao": 1,
        "thephysical": 1,
        "wia": 1,
        "represent": 1,
        "secondpass": 1,
        "similar": 2,
        "noisecan": 1,
        "edge": 3,
        "subtractedimages": 1,
        "displacement": 1,
        "tween": 1,
        "nevertheless": 5,
        "consistency": 1,
        "suggest": 3,
        "ortexture": 1,
        "experime": 1,
        "ntal": 1,
        "ml/100g/min": 7,
        "correct": 4,
        "bar": 3,
        "plot": 4,
        "2tissue": 1,
        "wholebrain": 1,
        "dat": 1,
        "asets": 1,
        "measured": 1,
        "strictly": 1,
        "pre": 2,
        "dicted": 1,
        "dit": 1,
        "able": 5,
        "recovery": 3,
        "bykwia": 1,
        "and30": 1,
        "visually": 3,
        "representative": 1,
        "15th": 1,
        "clearlyobserved": 1,
        "whereas": 2,
        "successfully": 1,
        "and3886": 1,
        "wereenlarged": 1,
        "windowlevel": 1,
        "ability": 2,
        "ofsnr": 1,
        "capture": 1,
        "clearly": 1,
        "kwiano": 1,
        "detect": 1,
        "occur": 2,
        "lowlevel": 1,
        "ringing": 1,
        "vi": 3,
        "and71": 1,
        "ringsimproved": 1,
        "greymatter": 1,
        "sdtable": 1,
        "inclinical": 1,
        "wide": 2,
        "tend": 1,
        "kwiasimulation": 1,
        "fulldose": 1,
        "significantly": 1,
        "closely": 1,
        "ves": 1,
        "sels": 1,
        "intro": 1,
        "duced": 1,
        "substantial": 2,
        "large": 3,
        "sub": 1,
        "stantially": 1,
        "especially": 1,
        "ringszhao": 1,
        "bottom": 2,
        "ringsrespectively": 1,
        "display": 2,
        "bland": 1,
        "altman": 1,
        "obvious": 1,
        "272ml/100g/min": 1,
        "7ml/100g/min": 1,
        "calculate": 1,
        "conditionsalso": 1,
        "limit": 2,
        "agreement": 1,
        "confidence": 1,
        "theircorresponding": 1,
        "variability": 1,
        "scatter": 1,
        "graph": 1,
        "ofdifference": 1,
        "depend": 2,
        "gold": 1,
        "blandaltman": 1,
        "listedintable": 1,
        "vii": 3,
        "exhibit": 1,
        "degradation": 1,
        "reductionfor": 1,
        "overestimation": 2,
        "excellent": 1,
        "fbpfor": 1,
        "largely": 1,
        "suppress": 1,
        "strong": 2,
        "overcorrection": 1,
        "14ml/100g/min": 1,
        "might": 1,
        "good": 1,
        "tune": 2,
        "hyperparameters": 1,
        "denoisingpower": 1,
        "smoothness": 2,
        "constrain": 1,
        "prolonged": 1,
        "far": 3,
        "execution": 1,
        "512by512": 1,
        "728by1152": 1,
        "imple": 1,
        "mentation": 1,
        "environment": 1,
        "intel": 1,
        "i59400f": 1,
        "wassimilar": 1,
        "graphic": 1,
        "processing": 2,
        "unit": 1,
        "gtx": 1,
        "ti": 1,
        "sart": 2,
        "insets": 1,
        "magnified": 1,
        "snrand": 1,
        "eac": 1,
        "uantitative": 1,
        "iscussion": 1,
        "relate": 1,
        "domain": 1,
        "centralslice": 1,
        "plane": 3,
        "ie": 1,
        "adapt": 1,
        "many": 1,
        "innovativemri": 1,
        "undersampled": 1,
        "previ": 1,
        "ous": 1,
        "innovative": 1,
        "reconstructionalgorithm": 1,
        "preliminary": 1,
        "withoutcompromising": 1,
        "speed": 1,
        "specified": 1,
        "rotation": 1,
        "angle": 2,
        "availableon": 1,
        "address": 1,
        "limitation": 2,
        "unlike": 1,
        "modified": 1,
        "simplyreducing": 1,
        "compared": 1,
        "ourapproach": 1,
        "unique": 1,
        "assumption": 1,
        "characteristic": 2,
        "textureand": 1,
        "barrier": 1,
        "linical": 1,
        "adoption": 1,
        "convertinginto": 1,
        "previous": 2,
        "shownthat": 1,
        "presence": 2,
        "deconvolu": 1,
        "applicable": 1,
        "specifically": 1,
        "state": 1,
        "radon": 3,
        "indirectlywith": 1,
        "grangeat": 1,
        "partition": 1,
        "fromthe": 1,
        "complete": 2,
        "reliability": 1,
        "efficiency": 1,
        "fourierbased": 1,
        "alternatively": 1,
        "circular": 1,
        "middle": 1,
        "trajectory": 1,
        "approximate": 1,
        "offmiddle": 1,
        "canbe": 1,
        "caveat": 1,
        "approximation": 1,
        "despite": 1,
        "sensitive": 1,
        "thanstandard": 1,
        "another": 1,
        "drawback": 1,
        "10mm": 1,
        "tem": 1,
        "poral": 1,
        "match": 1,
        "1mm": 1,
        "various": 1,
        "ofsignal": 1,
        "merit": 1,
        "advantageous": 1,
        "ease": 1,
        "computationalspeed": 1,
        "futurestudies": 1,
        "lastly": 2,
        "bayesian": 1,
        "probabilistic": 1,
        "need": 1,
        "straightforward": 1,
        "toreduce": 1,
        "acknowl": 1,
        "footprint": 1,
        "averagingneighboring": 1,
        "optimize": 1,
        "improvement": 1,
        "nufft": 1,
        "inufft": 1,
        "future": 1,
        "combine": 1,
        "photonstarvation": 1,
        "radi": 1,
        "ation": 1,
        "onclusion": 1,
        "tech": 1,
        "nique": 1,
        "compromise": 1,
        "simplicity": 1,
        "promising": 1,
        "exposure": 1,
        "undergo": 1,
        "examsa": 1,
        "cknowledgment": 1,
        "grateful": 1,
        "dr": 1,
        "hee": 1,
        "kwon": 1,
        "song": 1,
        "disclosure": 1,
        "tm": 2,
        "djw": 2,
        "inventor": 1,
        "patent": 1,
        "hold": 1,
        "share": 1
    },
    "objective": [
        "thepurpose of this study be to present a low dose ctp techniquetermed k-space weighted image average ( kwia ) usinga novel projection view-shared average algorithm withreduced tube current .",
        "the purpose of this study be to introduce a variant of the kwic algorithm term k-space weighted image average ( kwia ) that preserve high spatial and temporalresolutions as well as image quality of low-dose ctp data ( 50-75 % dose reduction ) , y ielding image comparable to those of standard ctp scan .",
        "in this paper , we ﬁrst present the theoreticalframework of kwia , and demonstrate its feasibility use a digital phantom , a physical phantom , and clinical data .",
        "the propose kwia method divide each 2d ft or k-space ctp datainto multiple ring ."
    ],
    "references": [
        "",
        "REFERENCES [1]W. J. Powers et al. , “2018 Guidelines for the early management of patients with acute ischemic stroke: A guideline for healthcare professionals from the American heart association/American strokeassociation,” Stroke , vol. 49, no. 3, pp. e46–e99, 2018. [2]M. Wintermark et al. , “Acute stroke imaging research roadmap II,” Stroke , vol. 44, no. 9, pp. 2628–2639, 2013. [3]B. C. V . Campbell et al. , “Endovascular therapy for ischemic stroke with perfusion-imaging selection,” New England J. Med. , vol. 372, no. 11, pp. 1009–1018, 2015. [4]J. L. Saver et al. , “Stent-retriever thrombectomy after intravenous t- PA vs. T-PA alone in stroke,” New England J. Med. , vol. 372, no. 24, pp. 2285–2295, Jun. 2015. [5]P. Krishnan, A. Murphy, and R. I. Aviv, “CT-based techniques for brain perfusion,” Topics Magn. Reson. Imag. , vol. 26, no. 3, pp. 113–119, 2017. [6]B. Abels, E. Klotz, B. F. Tomandl, J. P. Villablanca, S. P. Kloska, and M. M. Lell, “CT perfusion in acute ischemic stroke: A comparison of 2- second and 1-second temporal resolution,” Amer. J. Neuroradiol. , vol. 32, no. 9, pp. 1632–1639, Oct. 2011. [7]A. E. Othman et al. , “Radiation dose reduction in perfusion CT imaging of the brain: A review of the literature,” J. Neuroradiol. , vol. 43, no. 1, pp. 1–5, Feb. 2016. [8]T.-Y . Lee and R. K. Chhem, “Impact of new technologies on dose reduction in CT,” Eur. J. Radiol. , vol. 76, no. 1, pp. 28–35, Oct. 2010. [9]Z. Yu, J.-B. Thibault, C. A. Bouman, K. D. Sauer, and J. Hsieh, “Fast model-based X-ray CT reconstruction using spatially nonhomo-geneous ICD optimization,” IEEE Trans. Image Process. , vol. 20, no. 1, pp. 161–175, Jan. 2011. [10] M. Beister, D. Kolditz, and W. A. Kalender, “Iterative reconstruction methods in X-ray CT,” Phys. Medica , vol. 28, no. 2, pp. 94–108, Apr. 2012. [11] L. L. Geyer et al. , “State of the art: Iterative CT reconstruction techniques,” Radiology , vol. 276, no. 2, pp. 339–357, Aug. 2015. [12] Y. X i a o et al. , “STIR-Net: Deep spatial-temporal image restoration net for radiation reduction in CT perfusion,” Frontiers Neurol. , vol. 10, pp. 1–16, Jun. 2019. [13] E. Kang, J. Min, and J. C. Ye, “A deep convolutional neural network using directional wavelets for lo w-dose X-ray CT reconstruction,” Med. Phys. , vol. 44, no. 10, pp. e360–e375, Oct. 2017. [14] H. Chen et al. , “Low-dose CT with a residual encoder-decoder con- volutional neural network,” I E E ET r a n s .M e d .I m a g . , vol. 36, no. 12, pp. 2524–2535, Dec. 2017. [15] H. Chen et al. , “LEARN: Learned experts’ assessment-based reconstruc- tion network for sparse-data CT,” IEEE Trans. Med. Imag. , vol. 37, no. 6, pp. 1333–1347, Jun. 2018. [16] Q. Yang et al. , “Low-dose CT image denoising using a generative adversarial network with wasserstein distance and perceptual loss,” IEEE Trans. Med. Imag. , vol. 37, no. 6, pp. 1348–1357, Jun. 2018. [17] H. Chen et al. , “Low-dose CT via convolutional neural network,” Biomed. Opt. Express , vol. 8, no. 2, pp. 679–694, 2017. [18] J. M. Wolterink, T. Leiner, M. A. Viergever, and I. Išgum, “Generative adversarial networks for noise reduction in low-dose CT,” IEEE Trans. Med. Imag. , vol. 36, no. 12, pp. 2536–2545, Dec. 2017. [19] D. Wu, K. Kim, G. El Fakhri, and Q. Li, “Iterative low-dose CT reconstruction with priors traine d by artiﬁcial neural network,” IEEE Trans. Med. Imag. , vol. 36, no. 12, pp. 2479–2486, Dec. 2017. [20] E. Kang, W. Chang, J. Yoo, and J. C. Ye, “Deep convolutional framelet denosing for low-dose CT via wavelet residual network,” IEEE Trans. Med. Imag. , vol. 37, no. 6, pp. 1358–1369, Jun. 2018. [21] H. Gupta, K. H. Jin, H. Q. Nguyen, M. T. McCann, and M. Unser, “CNN-based projected gradient descent for consistent CT image recon- struction,” I E E ET r a n s .M e d .I m a g . , vol. 37, no. 6, pp. 1440–1453, Jun. 2018.3890 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 39, NO. 12, DECEMBER 2020 [22] Y. Wa n g et al. , “Iterative quality enhancement via residual-artifact learning networks for low-dose CT,” Phys. Med. Biol. , vol. 63, no. 21, Oct. 2018, Art. no. 215004. [23] H. K. Song and L. Dougherty, “Dynamic MRI with projection recon- struction and KWIC processing fo r simultaneous high spatial and temporal resolution,” Magn. Reson. Med. , vol. 52, no. 4, pp. 815–824, 2004. [24] T. Martin, J. Hoffman, J. R. Alger, M. McNitt-Gray, and D. J. Wang, “Low-dose CT perfusion with projection view sharing,” Med. Phys. , vol. 45, no. 1, pp. 101–113, Jan. 2018. [25] A. N. Primak, C. H. McCollough, M. R. Bruesewitz, J. Zhang, and J. G. Fletcher, “Relationship between noise, dose, and pitch in cardiacmulti–detector row CT,” Radiographics , vol. 26, no. 6, pp. 1785–1794, Nov. 2006. [26] W. van Aarle et al. , “Fast and ﬂexible X-ray tomography using the ASTRA toolbox,” Opt. Express , vol. 24, no. 22, pp. 25129–25147, 2016. [27] W. van Aarle et al. , “The ASTRA toolbox: A platform for advanced algorithm development in electron tomography,” Ultramicroscopy , vol. 157, pp. 35–47, Oct. 2015. [28] W. Q. Malik, H. A. Khan, D. J. Edwards, and C. J. Stevens, “A gridding algorithm for efﬁcient density compensation of arbitrarily sampled Fourier-domain data,” in Proc. IEEE/Sarnoff Symp. Adv. Wired Wireless Commun. , 2005, pp. 125–128. [29] J. I. Jackson, C. H. Meyer, D. G. Nishimura, and A. Macovski, “Selection of a convolution function f or Fourier inversion using grid- ding (computerised tomography application),” IEEE Trans. Med. Imag. , vol. 10, no. 3, pp. 473–478, Sep. 1991. [30] Z. Yu, F. Noo, F. Dennerlein, A. Wunderlich, G. Lauritsch, and J. Hornegger, “Simulation tool s for two-dimensional experi- ments in X-ray computed tomography using the FORBILD headphantom,” Phys. Med. Biol. , vol. 57, no. 13, pp. N237–N252, Jul. 2012. [31] T. Benner, S. Heiland, G. Erb, M. Forsting, and K. Sartor, “Accu- racy of gamma-variate ﬁts to concentration-time curves from dynamicsusceptibility-contrast enhanced MRI: Inﬂuence of time resolution, maximal signal drop and signal-to-noise,” Magn. Reson. Imag. , vol. 15, no. 3, pp. 307–317, Jan. 1997. [32] J. R. Mayo et al. , “Simulated dose reduction in conventional chest CT: Validation study,” Radiology , vol. 202, no. 2, pp. 453–457, Feb. 1997. [33] O. Amir, D. Braunstein, and A. Altman, “Dose optimization tool,” Proc. SPIE , vol. 5029, pp. 815–821, May 2003. [34] D. P. Frush et al. , “Computer-simulated radiation dose reduction for abdominal multidetector CT of pediatric patients,” Amer. J. Roentgenol. , vol. 179, no. 5, pp. 1107–1113, Nov. 2002. [35] S. Žabi´ c, Q. Wang, T. Morton, and K. M. Brown, “A low dose simulation tool for CT systems with energy integrating detectors,” Med. Phys. , vol. 40, no. 3, Feb. 2013, Art. no. 031102.[36] Sun Nuclear Corporation. CT Perfusion Phantom . Accessed: Mar. 18, 2020. [Online]. Available: https://www.sunnuclear.com/products/ct-perfusion-phantom [37] L. Østergaard, R. M. Weisskoff, D. A. Chesler, C. Gyldensted, and B. R. Rosen, “High resolution measurement of cerebral blood ﬂow usingintravascular tracer bolus passages. Part I: Mathematical approach andstatistical analysis,” Magn. Reson. Med. , vol. 36, no. 5, pp. 715–725, Nov. 1996. [38] T. M. Benson and B. K. B. De Man, “Synthetic CT noise emulation in the raw data domain,” in Proc. IEEE Nucl. Sci. Symp. Med. Imag. Conf. , Oct. 2010, pp. 3169–3171. [39] X. Jia, Y . Lou, R. Li, W. Y . Song, and S. B. Jiang, “GPU-based fast cone beam CT reconstruction from undersampled and noisy projectiondata via total variation,” Med. Phys. , vol. 37, no. 4, pp. 1757–1760, Mar. 2010. [40] A. Biguri, M. Dosanjh, S. Hancoc k, and M. Soleimani, “TIGRE: A MATLAB-GPU toolbox for CBCT image reconstruction,” Biomed. P h y s .E n g .E x p r e s s , vol. 2, no. 5, Sep. 2016, Art. no. 055010. [41] H. K. Song and L. Dougherty, “K-s pace weighted image contrast (KWIC) for contrast manipulation i n projection reconstruction MRI,” Magn. Reson. Med., Off. J. Int. Soc. Magn. Reson. Med. , vol. 44, no. 6, pp. 825–832, 2000. [42] R. W. Brown, Y .-C. N. Cheng, E. M. Haacke, M. R. Thompson, and R. Venkatesan, Magnetic Resonance Imaging: Physical Principles and Sequence Design . Hoboken, NJ, USA: Wiley, 2014. [43] R. Manniesing, M. T. H. Oei, B. van Ginneken, and M. Prokop, “Quantitative dose dependency analysis of whole-brain CT perfusionimaging,” Radiology , vol. 278, no. 1, pp. 190–197, Jan. 2016. [44] K. Li and G.-H. Chen, “Dependence of quantitative accuracy of CT perfusion imaging on system parameters,” Proc. SPIE , vol. 10132, Mar. 2017, Art. no. 101320D. [45] T. M. Buzug, Computed Tomography: From Photon Statistics to Modern Cone-Beam CT . Berlin, Germany: Springer, 2008. [46] S. Schaller, T. Flohr, and P. Steffe n, “An efﬁcient Fourier method for 3-D radon inversion in exact cone-beam CT reconstruction,” IEEE Trans. Med. Imag. , vol. 17, no. 2, pp. 244–250, Apr. 1998. [47] L. A. Feldkamp, L. C. Davis, and J. W. Kress, “Practical cone-beam algorithm,” J. Opt. Soc. Amer. A, Opt. Image Sci. , vol. 1, no. 6, pp. 612–619, 1984. [48] T. Boutelier, K. Kudo, F. Pautot, a nd M. Sasaki, “Bayesian hemo- dynamic parameter estimation by bolus tracking perfusion weightedimaging,” IEEE Trans. Med. Imag. , vol. 31, no. 7, pp. 1381–1395, Jul. 2012. [49] A. R. Seyal, A. Arslanoglu, S. F. A bboud, A. Sahin, J. M. Horowitz, and V . Yaghmai, “CT of the abdomen with reduced tube voltage in adults:A practical approach,” Radiographics , vol. 35, no. 7, pp. 1922–1939, Nov. 2015."
    ]
}{
    "name": null,
    "paragraphs": [
        "received july 12 , 2019 , accept july 18 , 2019 , date of publication july 29 , 2019 , date of current version august 12 , 2019 .",
        "digital object identifier 10.1 109/access.2019.2930650 model-based optoacoustic tomography image reconstruction with non-local and sparsity regularizations xipan li , li qi , shuangyang zhang , shixian huang , jian wu , lijun lu , yanqiu feng , qianjin feng , and wufan chen school of biomedical engineering , southern medical university , guangzhou 510515 , china guangdong provincial key laboratory of medial image processing , southern medical university , guangzhou 510515 , china corresponding author : li qi ( qili @ smu.edu.cn ) and wufan chen ( chenwf @ mmu.com ) this work be support in part by the china postdoctoral science foundation under grant 2017m610536 , in part by the national natural science foundation of china under grant 31700857 , grant 61471188 , and grant 81871437 , in part by the guangdong provincial natural science foundation under grant 2017a030310516 , in part by the guangzhou science and technology program under grant 201804010375 , and in part by the guangdong key area research and development program under grant 2018b030333001 .",
        "abstract optoacoustic tomography ( oat ) be an emerge imaging modality with ultrasonic image depth and optical contrast .",
        "the reconstruction of optoacoustic image be to recover the initial acoustic pressure distribution of the object from a set of ultrasound signal .",
        "the model-based optoacoustic tomography image reconstruction be an ill-conditioned inverse problem affect by factor such as limited detection angle , imperfect image model , and noise .",
        "accounting for this , appropriate penalty should be incorporate into the reconstruction process to improve image quality .",
        "in this paper , we present a new dual-constraint oat imaging model involve a combination of non-local mean ltering and sparse coding , with the former to preserve image detail by self-similarity and the latter to enforce sparsity .",
        "a two-step optimization algorithm and an iterative parameter tune method be propose to ensure accurate solution .",
        "by compare to other exist regularization approach in both numerical simulation and in vivo animal image study , the new method show improved image quality in term of signal to noise ratio and contrast enhancement .",
        "index terms model-based image reconstruction , non-local mean , optoacoustic tomography , sparsity .",
        "i .",
        "introduction optoacoustic tomography ( oat ) , also name photoacous- tic tomography ( pat ) , be a novel hybrid image modality that combine the high contrast of optical imaging and the deep imaging range of ultrasonic image [ 1 ] , [ 2 ] .",
        "the rich endogenous and exogenous contrast agent of oat enable noninvasive molecular image [ 3 ] \u0015 [ 5 ] .",
        "for this unique advantage , oat have a broad impact in preclinical medical and biological research [ 6 ] \u0015 [ 8 ] .",
        "generally , the oat signal be originate from optical absorption .",
        "the image process typically start with a short laser pulse red at biological tis- sue .",
        "as photon propagate through tissue , some be absorb and their energy be partially convert into heat , which be then far convert to mechanical pressure wave propagate in tissue as ultrasound wave .",
        "the ultrasound wave be detect the associate editor coordinate the review of this manuscript and approve it for publication be ahmet m. elbir.outside the tissue by an ultrasonic transducer or transducer array .",
        "an image that map the original optical energy depo- sition inside the tissue can be reconstruct from the signal through computational approach .",
        "image reconstruction be an essential step in optoacoustic imaging technology , and have a great in uence on the quality of the generated image .",
        "generally , the image reconstruction algorithm for oat can be classi ed into two main cate- gories : the analytical method [ 9 ] \u0015 [ 12 ] and the model-based ( mb ) method [ 13 ] \u0015 [ 16 ] .",
        "for the analytical method , lihong wang 's group rst propose a universal back-projection ( ubp ) algorithm for oat image reconstruction [ 9 ] .",
        "the ubp algorithm be simple and computationally fast , but this algorithm can not be easily generalize into realistic optoa- coustic illumination-detection model , since it be base on an ideal description of the acoustic wave propagation and detection as well as on speci c detection geometry .",
        "besides , the image reconstruct by this method suffer from artifact , 102136this work be license under a creative commons attribution 4.0 license .",
        "for more information , see http : //creativecommons.org/licenses/by/4.0/volume 7 , 2019x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations such as streak artifact and negative value artifacts [ 17 ] , which limit the application of the method for functional and molecular imaging [ 13 ] .",
        "on the contrary , the model-based method be not base on an analytical solution to the inverse problem .",
        "instead , the oat image be obtain by minimize the error between the measure acoustic signal and the signal pre- dicted by an imaging model , which be commonly depict as a linear operator .",
        "more importantly , because the mb method work by iteratively seek for a global-optimal solution to the inverse problem , it can suppress a variety of image arti- fact associate with the conventional ubp algorithm , such as incomplete projection data and the loss of low-frequency information .",
        "the other advantage of the mb method be that prior knowledge of the imaging scenario ( include both the imag- ing geometry and the target object ) could be incorporate into the reconstruction process as regularization term , and produce image with much good quality [ 13 ] , [ 15 ] .",
        "var- ious regularization approach have be propose for the oat image reconstruction problem , include the tikhonov method [ 18 ] , [ 19 ] , the total-variation method [ 20 ] , [ 21 ] , and sparsity-based method [ 22 ] \u0015 [ 26 ] .",
        "in these method , the major enforced prior knowledge be the smoothness of the imaged object , or the sparsity on the solution space .",
        "more recently , in clinical medical image system such as computed tomography ( ct ) , magnetic resonance imaging ( mri ) , and positron emission tomography ( pet ) , approach include the non-local mean ( nlm ) ltering [ 27 ] and block match with 3d ltering ( bm3d ) [ 28 ] , both of which exploit self-similarities within the image , have be use to improve image quality [ 27 ] \u0015 [ 31 ] .",
        "not like previous approach , these method be build on patch-based image operation , and therefore could better preserve local struc- tures .",
        "the patch-based nlm regularization approach have not yet be introduce to oat image reconstruction .",
        "in this paper , we propose a novel oat image model that combine two now classical regularization technique into a single framework : the non-local mean method to image reconstruction explicitly exploit self-similarities in oat image to average out the noise among similar patch , whereas sparse cod encodes optoacoustic image statistic by decompose the image into a linear combination of a few element from a basis set call a dictionary .",
        "we pro- pose to extend and combine these two approach by use a simple dual-constraint model , which can be ef ciently solve by a tailored two-step optimization method base on gradient descent and iterative shrinkage-thresholding .",
        "to effectively determine the regularization parameter , a trial- and-error method that learn the parameter from empirical ne-tuned sample be develop .",
        "to our best knowledge , this be the rst time that the corresponding model of image self-similarities be explicitly use in a common setting with sparse cod in oat imaging .",
        "numerical simulation and in vivo animal image experiment be carry out to verify the propose method , and the result show that ourmethod have a good performance compare to use only nlm or sparse coding as a single regularization term .",
        "the rest of the paper be organize as follow : in sec .",
        "2 , we review the model-based oat reconstruction framework and its regularization method , and then introduce the dual- constraint imaging strategy and a tailored optimization proce- dure for the inverse problem .",
        "section 3 describe the detail of numerical , phantom and animal experiment .",
        "the result of simulation and experiment be present in sec .",
        "4 .",
        "finally , discussion and conclusion be give in sec .",
        "5 and sec .",
        "6 , respectively .",
        "ii .",
        "theory a .",
        "the imaging model of oat in oat , the generation and propagation of the optoacoustic signal can be express as : @ 2p.er ; t/ @ t2\u0000c2r2p.er ; t/d0 @ h.er ; t/ @ t ; ( 1 ) where p.er ; t/denotes the acoustic pressure at position er and time t.cis sound speed .",
        "0is the grünesien parameter .",
        "h.er ; t/dhr.er/ht.t/is the heating function that describe the energy deposition by the laser in unit volume and unit time .",
        "for impulse heating , we assume ht.t/\u0019\u000e.t/ , then ( 1 ) can be solve by use the green function [ 7 ] : pd.erd ; t/d0 4\u0019c2 @ @ t\u00141 ctz vhr.er/\u000e\u0012 t\u0000jerd\u0000erj c\u0013 der\u0015 ; ( 2 ) whereerdrepresents the detector position , vis the illuminated volume of the target object , and ris one point inside v. for cross-sectional oat , the low limit of the integral in ( 2 ) be change from vtol , and ldjerd\u0000erjdctis a circular arc whose center be the detector location erdand radius be ct .",
        "the reconstruction of optoacoustic image be to recover the initial acoustic pressure distribution of the object from a set of measured signal pd.erd ; t/ .",
        "to do this , the ubp algorithm work by nding the analytical solution of ( 2 ) .",
        "the formulation of the ubp method in time domain writes : p0.er/d1 0z sd0\u00022\u0014 p.erd ; t/\u0000t @ p.erd ; t/ @ t\u0015 ctdjer\u0000erdj ; ( 3 ) where0is a solid angle of the whole detection geometry s ( 0is a circle for planar geometry and thus 0d2\u0019 ) .",
        "the term d0/0is a weighing factor for the contribution of the detection element , and it be characterize by the angular position of the transducer and the number of projection .",
        "on the other hand , the mb method for oat reconstruction work by treat the pressure signal measure by the ultra- sound sensor as a linear map from the energy deposition in a grid , which be locate in the eld of view of an oat system .",
        "such a linear map be refer to as a model matrix of the imaging system .",
        "this oat forward model can be express volume 7 , 2019 102137x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations as a discretized version of ( 2 ) : pdwx ; ( 4 ) where xis a rn\u00021column vector represent the imaged object , pis a rm\u00021column vector denote the projection data , wis a rm\u0002nforward model matrix .",
        "in this work , we use the interpolated model matrix inversion method in [ 13 ] to generate the model matrix .",
        "the inversion of ( 4 ) can be perform by solve the following minimization problem : xdarg min1 2kp\u0000wxk2 2 ; ( 5 ) wherek\u0001k2 2is the l2-norm .",
        "with this , the image recon- struction process be to minimize the difference between the actual measure signal and the signal predict by the model [ 13 ] , [ 14 ] , [ 32 ] .",
        "generally , the inverse problem of oat be ill-conditioned , and the solution to ( 5 ) may be incor- rect and numerically unstable [ 33 ] .",
        "therefore , appropriate prior or penalty be need to improve the reconstruc- tion result .",
        "this typically involve incorporate some prior knowledge in the form of a penalty function , which control some desired property of an unknown deterministic or the prior probability distribution of an unknown random variable .",
        "in this way , the objective function be modi ed as : xdarg min\u001a1 2kp\u0000wxk2 2c\u0015j.x/\u001b ; ( 6 ) where , \u0015\u00150 be the regularization parameter .",
        "j ( x ) be the regularization functional operator .",
        "in the context of conven- tional medical tomographic image reconstruction such as ct , mri and pet , penalty function be often choose to enforce smoothness [ 18 ] , preserve edge [ 20 ] , promote spar- sity [ 22 ] , [ 34 ] , or incorporate anatomical information [ 29 ] .",
        "b .",
        "the proposed regularization scheme 1 ) the non-local means regularization the non-local mean algorithm be rst present as an image denoising method [ 27 ] , it work by nding simi- lar patch across the non-local region within the image , and then performs weight average operation for those patch accord to their similarity .",
        "traditionally , in the nlm scheme , give a discrete noisy image xdfx.i/ji2ig , iis denote as a discrete grid of pixel , the restored value nl ( x ( i ) ) for each pixel iis compute as a weighted sum of a function of neighbor pixel in the image domain [ 30 ] : nl.x.i//dx j2si !",
        ".i ; j/'.x.i/\u0000x.j// ; ( 7 ) where , iis the coordinate index of the image x.siis a search window center at pixel i .",
        "'is generally describe as the potential function .",
        "the weight !",
        "( i , j ) quanti es the similarity between pixel iand pixel j ; it can be express as follow : !",
        ".i ; j/d1 z.i/expn \u0000 x.ei/\u0000x\u0000 ej\u0001 2 2 ; a. h2o ; ( 8 ) where , z.i/dp j2siexpn \u0000 x.ei/\u0000x\u0000 ej\u0001 2 2 ; a=h2o be the normalizing factor , eiandejare two similarity neighborhood ( patch ) center at pixel iandj , x ( ei ) and x ( ej ) be the vector of neighborhood pixel value in the patch-window ei andej , respectively .",
        "the notation k\u0001k2 2 ; adenotes a gaussian- weighted euclidean distance between two similarity patch , with abeing the standard deviation of gaussian function and hthe parameter that control the decay of the exponential function .",
        "the nlm method show very good performance in term of edge-preserving for image restoration , and therefore have later be successfully apply to tomographic image recon- struction problem , which usually possess the following form : xdarg min\u001a1 2kp\u0000wxk2 2c\u0015\u0001r ( x ) \u001b ; ( 9 ) in which , r ( x ) dp i2inl.x.i// .",
        "in this way , the nlm be incorporate as a regularization term .",
        "the solution to this optimization problem can be find by use steep descend algorithm , in which the gradient direction be the derivative of the potential function .",
        "inspired by [ 29 ] , in our work , we choose the potential function 'as : '.x.i/\u0000x.j//ds 1c\u0012.x.i/\u0000x.j// \u0011\u00132 \u00001 ; ( 10 ) where , \u0011was an empirical parameter .",
        "the derivative of this potential function be give by : @ '.x.i/\u0000x.j// @ x.i/dx.i/ \u00112r 1c\u0010 .x.i/\u0000x.j// \u0011\u00112 : ( 11 ) as show in [ 29 ] , the author have illustrate the preferable edge-preserving characteristic of this hyperbolic potential function .",
        "2 ) the sparsity based regularizaiton based on the assumption that the clean signal can be approx- imated by a sparse linear combination of element from a basis set ( dictionary ) , the sparse cod implies that when the image xis sparse in a basis/dictionary d , i.e.",
        ", xddu , thenuis a corresponding code with very few non-zero entry .",
        "a solution of the code ucan be find by solve the following l1-norm minimization problem : minkuk1s .",
        "t. pdwdu : ( 12 ) in a linear inverse problem such as the image reconstruc- tion problem in oat , the sparse cod mechanism can be incorporate as a sparsity regularization term : udarg min\u001a1 2kp\u0000wduk2 2c\u0015skuk1\u001b : ( 13 ) if we nd a basis dthat could sparsely represent x , and express win such a way that wd be a sparse matrix , then the image in that domain can be reconstruct by 102138 volume 7 , 2019x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations minimizing ( 13 ) .",
        "the optimization of ( 13 ) may be ef ciently solve by a variety of method , such as the iterative shrinkage-thresholding algorithm ( ista ) [ 35 ] .",
        "the nal reconstruction be transfer back to the image domain use xddu .",
        "3 ) the combined nlm and sparsity regularizaiton scheme the purpose of nlm-based regularization be to preserve the image smoothness use self-similarity .",
        "rather than averag- ing neighboring pixel within a local window , it utilize the non-local information across the image to perform denoising , so that the structure information , such as edge and texture , can be well preserve .",
        "on the other hand , for the sparse cod penalty , the major observation be that most signal be sparse under an appropriate basis .",
        "thus , the sparsity- base regularization scheme be to enforce sparsity through recover the clean signal via l1-norm-based minimization .",
        "based on the above observation , we present our regular- ization scheme involve a combination of non-local mean and l1-norm-based sparse cod penalty .",
        "the purpose of the dual-constraint scheme be to nd a method that could both suppress the streaking artifact and preserve tissue detail .",
        "the cost function we seek to minimize contained three parts\u0016the data- tting term , the nlm-based penalty term and the sparsity-based penalty term .",
        "the nal objective function be de ned as : xdarg min\u001a1 2kp\u0000wxk2 2c\u0015nlm\u0001r ( x ) c\u0015s d\u00001x 1\u001b ; ( 14 ) where , \u0015nlmand\u0015swere the regularization parameter .",
        "this simple dual-constraint model effectively connect the two classical regularization method , and be name nlmcs .",
        "for the sparse cod term , various type of wavelet [ 36 ] have be use as the dictionary dfor both natural and clinical tomographic image .",
        "in our work , we choose to stick to such wavelet-based dictionary for prove-of-concept pur- pose , and dwas choose to represent four level bior6.8 wavelet transform .",
        "however , alternative sparse decomposition base on learn , possibly over complete dictionary adapt to speci c image may provide good result , as prove by other application such as natural image processing [ 37 ] , [ 38 ] .",
        "c. the two-step iterative algorithm to solve the dual-constraint problem in ( 14 ) , a two-step iter- ative optimization method be develop .",
        "our algorithm to the optimization problem be base on gradient descent and iterative shrinkage-thresholding [ 35 ] .",
        "to start with , the rst step of the algorithm be to update the least-squares term and the nlm regularization term use gradient descent .",
        "a sub- objective function l ( x ) be de ned : l.x/d1 2kp\u0000wxk2 2c\u0015nlm\u0001r.x/ : ( 15 ) during each iteration , we update xkc1as : xkc1dx\u0000 \u0001\u0014 wt.wx\u0000p/c2\u0015nlm\u0001 @ r ( x ) @ x\u0015 dx\u0000 \u0001\u0010 wt.wx\u0000p/ c2\u0015 nlm\u0001x i2ix j2si !",
        ".i ; j/ @ f ' [ x.i/\u0000x.j/ ] g @ x.i/1 a : ( 16 ) the second step be to optimize the l1-norm-based sparse cod regularization term base on the rst step .",
        "an intermediate variable uis introduce , and by let xdduwe could obtain another objective function ofu : p.u/d\u0015skuk1c1 2 d\u00001xkc1\u0000u 2 2 : ( 17 ) by introduce the shrinkage-thresholding operator [ 35 ] : soft\u001ad8 > < > : x\u0000\u001a ; ifx > \u001a xc\u001a ; if x < \u001a 0 ; otherwise ; ( 18 ) where x2r and\u001a > 0 , then we could update ukc1as : ukc1dsoft\u0015s\u0010 d\u00001xkc1\u0011 : ( 19 ) finally , by transfer ukc1back to the image domain , we could obtain the updated image : xkc1ddukc1 : ( 20 ) the iteration stop when the total error errdjjp-wxkc1jj2 be less than a prede ned value `` , or when a maximum iteration number ki meet .",
        "the two-step iterative algorithm for our dual-constraint image reconstruction scheme be summarize inalgorithm 1 .",
        "algorithm 1 two-step iterative algorithm for nlmcs regularized oat image reconstruction input : x.0/ ubp or0 , k , itermax , '' .",
        "repeat 1 .",
        "update xkc1using : xkc1dx\u0000 \u0001\u0000 wt.wx\u0000p/ c2\u0015 nlm\u0001p i2ip j2si !",
        ".i ; j/ @ f ' [ x.i/\u0000x.j/ ] g @ x.i/ !",
        ": 2 .",
        "update ukc1using : ukc1dsoft\u0015s\u0000 d\u00001xkc1\u0001 : 3 .",
        "transfer the result back to the image domain : xkc1 dukc1 : 4 .",
        "calculate the error : err norm\u0000 p\u0000wxkc1\u0001 : 5 .",
        "update the iteration : k kc1 : until convergence where k > iter max or err < `` .",
        "output : x .",
        "volume 7 , 2019 102139x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations d. parameter setup 1 ) the trial-and-error method for choosing the regularization parameters in linear inverse problem , all regularization method for compute stable solution involve a trade-off between the regularization term j ( x ) and the data- tting term kp\u0000wxk2 2 .",
        "therefore , the regularization parameter should be choose carefully in order to avoid over- tting or under- tting .",
        "a common method use to determine a suitable value of \u0015 be the l-curve method [ 18 ] , [ 39 ] .",
        "the l-curve be a log-log plot of the norm of the regularization term and the norm of the data- tting term .",
        "with this , the possible selection of a suitable regularization parameter lie in the corner of the l-curve .",
        "however , when the reconstruction be very smooth ( such as in the case of oat ) , the l-curve method will fail to nd the optimal regularization parameter [ 39 ] .",
        "to address this , we herein propose a simple scheme , name the trial-and- error method , to determine the regularization parameter in our optimization problem .",
        "to explain our trial-and-error method in a common framework , we take the single regularization problem as an example .",
        "we de ne a simple model : \u0015d oc\u0016 1c\u001b2 2c\u0010 \u0016\u0001\u001b2\u0011 3 ; ( 21 ) where , \u0015is a regularization parameter , \u0016and\u001b2are the mean and variance of the initial image obtain by ( 5 ) without regularization , respectively .",
        "the purpose of the trial-and-error method be to learn the coef cients ( d [ 1 , 2 , 3 ] ) from a series of ne-tuned image reconstruction , such that when give a new image , the regularization parameter \u0015for this new image could be obtain by simply apply ( 21 ) .",
        "to estimate , rst , a series of image be acquire ; then , two kind of reconstruction be perform , one with empir- ically determine regularization parameter , and the other with no regularization ; after this , we would have a set of\u0015 ( use in the rst kind of reconstruction ) , and a set of \u0016and\u001b2estimated from the second kind of reconstruction , and then a linear system \u0015dx can be establish with xd [ one ( size ( \u0016 ) ; 1 ) ; \u0016 , \u001b2 ] ; nally , the coef cients be estimate from this linear system by multiple linear regres- sion analysis .",
        "to demonstrate this method , we have acquire a total of 30 in vivo cross-sectional image of a nude mouse at the head , the liver and the kidney section ( 10 frame for each section ) .",
        "after perform the multiple linear regression analysis , we could obtain the initial coef cients , where 0d 3:3957\u000210\u00005 , 1d\u00003:2573\u000210\u00007 , 2d\u00001:2376\u000210\u00007 , 3d1:4102\u000210\u00009 .",
        "the con dence interval of these estimate value be [ 1.9971\u000210\u00005 , 4.7943\u000210\u00005 ] , [ -4.6644\u000210\u00007 , -1.8502\u000210\u00007 ] , [ -1.7008\u000210\u00007 , -7.7443\u0002 10\u00008 ] , [ 9.9507\u000210\u000010 , 1.9052\u000210\u00009 ] , respectively .",
        "thus , our linear regression equation be write as : \u0015d3:3957\u000210\u00005-3.2573\u000210\u00007\u0016 \u00001:2376\u000210\u00007\u001b2c1:4102\u000210\u00009\u0016\u001b2 : ( 22 ) figure 1 .",
        "multiple linear regression result for the testing dataset , show good linear relationship among the mean and variance of the image and the regularization parameter .",
        "the result of the regression be show in fig .",
        "1 .",
        "the pvalue and the coef cient of determination r2of the regression be pd3:4762\u000210\u000014andr2d0:9325 , therefore the model present in ( 22 ) could be consider accurate .",
        "for the dual-constraint problem , a two-step strategy be employ to estimate the two regularization parameter \u0015nlm and\u0015s .",
        "the rst step be pre-estimation , where the trial-and- error method be use to obtain the reconstruction for only one regularization term include in the objective function ( by let other regularization parameter be zero ) .",
        "the result obtain by the rst step be use as an original image to calculate the mean and variance .",
        "the second step be correction , where the trial-and-error method be use again to nd the regularization parameter of the second penalty term .",
        "2 ) choosing the nlm parameter it be not a trivial task to determine the optimal nlm lter parameter .",
        "in this work , these parameter be empiri- cally determine through extensive experiment by quanti- tative measure and visual inspection .",
        "we have find that an 11\u000211 , search-window and a 7\u00027 patch size be adequate for suppress streak artifact while retain computational ef ciency .",
        "as for the parameter h , we let h2d2 \u001b2 0jnij , where\u001b2 0denotes the standard deviation of the reconstructed image , jnijdenotes the size of the search window , and be a scale parameter .",
        "for the selection of regularization parameter in the exper- iments of present study , we rst find the optimal regular- ization parameter of tikhonov , nlm and wavelet method , respectively .",
        "ideally , in the case of dual-constraint , the pre- vious obtain optimal parameter of each constraint should be rstly apply to reconstruct an initial image , and then far ne-tune to nd the best result .",
        "however , in our implementation , we have find that it be not necessary to adjust the regularization parameter of each single constraint because the initial result be already good enough .",
        "the actual value of the regularization parameter be present in table 1 .",
        "iii .",
        "experimental setups and methods a .",
        "the multi-spectral optoacoustic tomography system the simulation , phantom and in vivo animal image experiment be all base on a commercially available 102140 volume 7 , 2019x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations table 1 .",
        "regularization parameter of tikhonov prior , nlm prior , wavelet prior , and nlmcs prior .",
        "figure 2 .",
        "( a ) the image chamber have a 128-elecment transducer array and 10 fiber illumination port .",
        "( b ) the schematic of the detector position : the red point represent the ultrasound detector positons ; the transducer array cover a 270\u000espan of projection angle .",
        "td : transducer .",
        "optoacoustic tomography platform : the multi-spectral optoa- coustic tomography system ( msot invision128 ) by ithera medical , germany .",
        "the msot system be base on the design present in [ 40 ] \u0015 [ 43 ] .",
        "figure 2 ( a ) show a photo of the imaging chamber where the transducer array and the ber illumination port be visible .",
        "the laser be separate into 10 bundle of bers such that the laser energy be uniformly distribute on the surface of the imaged object .",
        "the pulse duration of laser be around 5 n and the repetition rate be 10 hz .",
        "during experiment , the image chamber be lled with water , and the imaged object be submerge in the water with a horizontal position in an animal holder .",
        "figure 2 ( b ) show the schematic of the ultrasound detection system geometry .",
        "the ring-shape transducer array be consist of 128 element and cover a 270\u000espan of projection angle with a radius of 40.5 mm .",
        "the transducer element have a central frequency of 5 mhz and a 6-db bandwidth of 100 % .",
        "the signal of the transducer be acquire at a sampling frequency of 40 mhz .",
        "the laser wavelength be tunable from 680 nm to 980 nm .",
        "in our experiment , all the data be acquire with a laser wavelength of 760 nm and each slice be average 10 time .",
        "b. simulation setup simulation experiment be perform to validate the pro- posed dual-constraint approach .",
        "the detector geometry in the simulation be exactly the same as the msot experimental system describe above .",
        "a numerical 2d phantom have be use as the reference image , as show in fig .",
        "3 ( a ) .",
        "the size of the phantom image be 300\u0002300 pixel .",
        "the perfor- mance of the dual-constraint scheme be compare with figure 3 .",
        "simulation result : ( a ) the original image .",
        "the reconstructed image with ( b ) no prior , ( c ) the tikhonov prior , ( d ) the nlm prior , ( e ) the wavelet prior , and ( f ) the nlmcs prior .",
        "reconstruction obtain use no prior , the tikhonov prior [ 18 ] , the nlm prior , and the wavelet prior .",
        "to avoid inverse crime [ 44 ] , the projection data be simulate with a 75 mhz sample rate , and then resampled to 40 mhz .",
        "after add a 10db gaussian noise to the original data , the nal simulated pressure signal consist of 1131 time point , equivalent to a 30mm\u000230mm eld of view at 1500m/s sound speed .",
        "for all the algorithm use in the simulation experiment , the stop criterion be `` d1\u000210\u000012 anditermaxd500 .",
        "all the algorithm be implement in matlab , on a desktop pc with a quad-core cpu and 8gb of memory .",
        "c. experiments setup 1 ) phantom experiments phantom experiment have be carry out to evaluate our method with the msot system .",
        "we employ a cylindrical- shape phantom with a diameter of 2 cm .",
        "the phantom be create by 1.5 % agar , 1 % intra-lipid .",
        "inside the phantom there be three cylindrical cavity of different diameter .",
        "these cavity be lled with light absorb black chinese ink to provide optoacoustic contrast .",
        "for the reconstruction , the speed of sound be set to 1500m/s , and all the 128 pro- jections be use , each contain 1131 time-samples .",
        "the reconstruction image be consist of 300\u0002300 pixel .",
        "2 ) in vivo animal experiments animal experiment be approve by southern medical university and carry out in accordance with institutional guideline .",
        "in our study , we choose 8 week nude mouse as experimental subject .",
        "the subject be anesthetize use a mixture of 3 % iso urane and 100 % oxygen during image .",
        "the anesthesia port be connect to the animal holder , as well as the scanner .",
        "the anesthetized nude mouse be place in the animal holder with a thin layer of ultrasound gel around the circumference of the desired imaging region , and then the mouse be wrap up use a plastic foil mem- brane .",
        "in the in vivo experiment , we choose the position of volume 7 , 2019 102141x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations the head , the kidney , and the liver to acquire the experimental data .",
        "for image reconstruction in these experiment , each projection contain 1105 temporal sample , and the speed of sound in the medium be set to 1536 m/s .",
        "the reconstruction image be also consist of 300\u0002300 pixel .",
        "d. the performance metrics the quantitative performance metric use to evaluate the reconstruction result be the root mean square difference ( rmsd ) , the signal-to-noise ratio ( snr ) and the contrast- to-noise ratio ( cnr ) .",
        "the rmsd be calculate between the theoretical image and the reconstructed image for different method during numerical simulation .",
        "it be de ned as : rmsddvuut1 nnx nd1 xn 1\u0000xn 2 2 ; ( 23 ) where xn 1andxn 2are the n-th pixel value of the two image x1andx2 , and nis the total pixel number of the image .",
        "the snr be calculate as the ratio of the root mean square ampli- tudes of the target and background region and the unit of snr value be db .",
        "it be de ned as : snrd20 log10\u0012at sdb\u0013 ; ( 24 ) where atis the root-mean-square amplitude value of the tar- get region and sdbis the standard variance of the background region .",
        "the cnr be calculate as the mean value difference between the target region and the background region divide by the standard deviation of the background region , give by : cnrdjxt\u0000xbj \u001bb ; ( 25 ) wherenxtandnxbare the mean value of the target region and the background region , respectively , and \u001bbis the variance of the background region .",
        "the structural similarity ( ssim ) index between image x1andx2is de ned as [ 45 ] : ssimd\u0000 2\u0016x1\u0016x2cc1\u0001\u0000 2\u001bx1\u0001x2cc2\u0001 \u0000 \u00162x1c\u00162x2cc1\u0001\u0000 \u001b2x1c\u001b2x2cc2\u0001 ; ( 26 ) where , \u0016x1and\u0016x2are the mean of x1andx2 , respectively .",
        "\u001bx1and\u001bx2are the variance of x1andx2 , respectively .",
        "\u001bx1\u0001x2 be the covariance of image x1andx2 .",
        "the small constant c1 , c2andc3are give by : c1d.k1l/2 ; c2d.k2l/2 ; andc3dc2=2 ; ( 27 ) where , lis the dynamic range of the pixel value ( l d255 for 8 bits/pixel gray scale image ) , k 1and k2are set as k1d0:01 and k2d0:03 , respectively .",
        "iv .",
        "results a. simulation results in simulation study , the test oat image be reconstruct with the nlmcs method and four other com- par method .",
        "the compare method include the non- regularized model , the tikhonov model , the nlm model , figure 4 .",
        "the residual image between the original image and the reconstructed image ( a ) no prior , ( b ) the tikhonov prior , ( c ) the nlm prior , ( d ) the wavelet prior , and ( e ) the nlmcs prior .",
        "( f ) enlarged region enclose in the solid red box in ( a ) .",
        "table 2 .",
        "the rmsd of simulation study .",
        "and the wavelet-based sparse cod model .",
        "the reconstruc- tion result obtain from numerical simulation be show in fig .",
        "3 .",
        "figure 3 ( a ) be the original image use in the simulation .",
        "figure 3 ( b ) be the image obtain without any regularization .",
        "figure 3 ( c ) to fig .",
        "3 ( f ) be the image reconstruct by use the tikhonov , the nlm , the wavelet , and the nlmcs regularization , respectively .",
        "figure 3 ( f ) clearly show that the contrast of the image enhance with the dual-constraint method .",
        "after subtract the original image , the residual image be show in fig .",
        "4 .",
        "the region correspond to the red box in fig .",
        "4 ( a ) be enlarge and show in fig .",
        "4 ( f ) .",
        "it could be see that the residual image of the sparsity-based prior and the nlmcs prior have similar error level , but the other image show much high difference .",
        "the rmsd value for all ve method be list in table 2 .",
        "the dual-constraint image have the small error among all method .",
        "figure 5 ( a ) show the intensity pro le in the reconstructed image obtain by different method .",
        "the location of the pro le be mark by a yellow dashed line in fig .",
        "3 ( b ) .",
        "as can be see , our method have the low noise platform ; and the pro le of the nlmcs method conform to the reference pro le .",
        "figure 5 ( b ) show the rmsd value with respect to different iteration number .",
        "we can conclude that the dual-constraint method have a bet- ter convergence performance than all the other compare method .",
        "102142 volume 7 , 2019x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations figure 5 .",
        "( a ) intensity profile extract from the reconstruct image with different method .",
        "the profile position be mark by the yellow dashed line in fig .",
        "3 ( b ) .",
        "( b ) convergence performance of different method .",
        "table 3 .",
        "the snr and cnr of phantom image .",
        "b .",
        "experimental results 1 ) phantom the oat reconstruction result of the tissue-mimicking phantom be show in fig .",
        "6 .",
        "as can be see , the image obtain use the dual-constraint method show sharp boundary of the phantom and two inner cavity .",
        "smooth and uniform pixel intensity be find inside the phantom and the cavity .",
        "for other method , the streak artifact in the image be prominent in both outside and inside the phantom .",
        "next , the snr and cnr value for all the image be calculate and list in table 3 .",
        "the region label in the cyan dash box and the yellow dash box in fig .",
        "6 ( b ) represent the target and background region respectively for obtain the snr and cnr .",
        "our method have the high snr and cnr value compare to the other method .",
        "an additional phantom experiment be perform to val- idate the stability of our algorithm .",
        "we design a phantom with two insertion : indocyanine green ( icg ) and chinese ink .",
        "the absorption coef cient of icg be 1.9 cm\u00001at 800 nm .",
        "we obtain oat image of the phantom at 800 nm use different method .",
        "the reconstruction result be display in figure 7 .",
        "because the oat image be in arbitrary unit , to perform quantitative comparison , the signal of icg be chose as a reference to quantify the signal of ink by use the following equation : \u0016inkdpink\u0016icg picg ; ( 28 ) where , pinkandpicgare the pixel intensity of ink and icg , respectively , which can be obtain by average the intensity within the corresponding region of interest ( roi ) in the reconstructed image .",
        "\u0016icgis the absorption coef cient of icg whose value be 1.9 cm\u00001 .",
        "the\u0016inkis the absorption coef cient of ink of which the unit be cm\u00001 .",
        "five pair of rois be select to calculate \u0016ink .",
        "the position of the figure 6 .",
        "phantom : the reconstructed image with ( a ) no prior , ( b ) the tikhonov prior , ( c ) the nlm prior , ( d ) the wavelet prior , and ( e ) the nlmcs prior .",
        "the region label in the cyan dash box and yellow dash box in ( b ) be serve as target and background region respectively for calculate snr and cnr .",
        "( f ) zoomed-in image of the region in the red solid box in ( a ) .",
        "our method can suppress streak artifact more effectively .",
        "rois be show in fig .",
        "7 ( b ) .",
        "the \u0016inkvalues obtain from six compare method and ve rois be show in table 4 .",
        "these result be analyzed use one-way anov a ( analysis of variance ) implement on spss ( sta- tistical product and service solutions ) to determine whether the value of different method be signi cantly different .",
        "the anov a table be present as table 5 .",
        "and we can see that the f value of different rois calculate by spss be 0.423 .",
        "since fd0.423 < f0:01 ( 5,24 ) d3.90 , there be no signi cant difference in the quantitative \u0016inkvalues of different method .",
        "we can conclude that our method do not change the pixel intensity of the oa signal .",
        "2 ) animal the image reconstruction and quantitative analysis of in vivo image study of the mouse head , kidney and liver region be carry out .",
        "figure 8 show the reconstructed volume 7 , 2019 102143x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations figure 7 .",
        "additional phantom result : the reconstructed image with ( a ) ubp , ( b ) no prior , ( c ) the tikhonov prior , ( d ) the nlm prior , ( e ) the wavelet prior , and ( f ) the nlmcs prior .",
        "table 4 .",
        "\u0016inkobtained by use different method .",
        "table 5 .",
        "anova of the data in table 4 .",
        "oat image of the mouse head use different method .",
        "the ubp reconstruction be also carry out for fair com- parison .",
        "the region enclose by the red box and the blue box in fig .",
        "8 ( a ) be show as enlarged view in fig .",
        "8 ( g ) .",
        "comparing these enlarge view , we could see that the image obtain use the dual-constraint method show smooth head structure , and generate few streak artifact in both the head and background region .",
        "also , it could be see that our method preserve sharp edge of the head surface , and produce a high contrast .",
        "figure 9 show the result of the kidney oat image .",
        "the region enclose by the red box and the blue box in fig .",
        "9 ( a ) be show as zoomed-in view in fig .",
        "9 ( g ) .",
        "the image obtain by the dual-constraint method show well de ned contour of different organ .",
        "the image be smooth and the detailed information be well preserve .",
        "when compare the zoomed-in view enclose figure 8 .",
        "head : the reconstructed image with ( a ) ubp ( b ) no prior , ( c ) the tikhonov prior , ( d ) the nlm prior , ( e ) the wavelet prior , and ( f ) the nlmcs prior .",
        "( g ) the zoomed-in view of region label the red box and blue box in ( a ) .",
        "the enlarged area show that our method performs best among all the method mention in the paper .",
        "by the red box in fig .",
        "9 ( g ) , there be hardly any noticeable streaking artifact in the image reconstruct by the dual- constraint method .",
        "however , the image obtain by the other method show obvious streak artifact that blur out the detail .",
        "figure 10 show the image pro le of the kidney area .",
        "the location of the pro le be mark by a yellow dashed line in fig .",
        "9 ( b ) .",
        "as can be see , our method provide accurate boundary information without lose too much detail , and generate more accurate image than use the nlm or the wavelet regularization alone .",
        "moreover , the reconstruct oat image of the liver posi- tion be show in fig .",
        "11 .",
        "the region enclose by the red box and the blue box in fig .",
        "11 ( a ) be show as zoomed-in view in fig .",
        "11 ( g ) .",
        "as illustrated , the image obtain use the dual-constraint method provide signi cantly improve image quality .",
        "however , for the image obtain use the other method , the noise and streaking artifact be obvious both inside and outside the liver region .",
        "as a quantitative comparison , figure 12 show the result of the snr and cnr calculate in the in vivo study .",
        "the region label in the cyan dash box and the yellow dash box in fig .",
        "12 ( a-c ) represent the target and background region for calculate the snr and cnr respectively .",
        "the comparison result be present in fig .",
        "12 ( d ) and fig .",
        "12 ( e ) .",
        "our method generate high snr and cnr value than all the other compare method , suggest more superior performance of the dual-constraint scheme .",
        "finally , the mean 102144 volume 7 , 2019x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations figure 9 .",
        "kidney : the reconstructed image with ( a ) ubp ( b ) no prior , ( c ) the tikhonov prior , ( d ) the nlm prior , ( e ) the wavelet prior , and ( f ) the nlmcs prior .",
        "( g ) the zoomed-in view of region label in the red box and the blue box in ( a ) .",
        "the yellow arrows 1 to 7 indicate the tissue , the renal cortex ( arrow 1 ) , the spleen ( arrow 2 ) , the intestine ( arrow 3 ) , the spinal cord ( arrow 4 ) , the mouse body ( arrow 5 ) , and some tiny blood vessel ( arrow 6 and 7 ) .",
        "figure 10 .",
        "profiles of the five image along the yellow dashed line in fig .",
        "9 ( b ) .",
        "value of ssim ( mssim ) be list in table 6 .",
        "our method score the high mssim value in all three animal study .",
        "v. discussion in optoacoustic tomography , properly design regulariza- tion method to the original computed image reconstruction problem be desirable because it be inherently ill-conditioned .",
        "this work seek to resolve this problem by introduce a new figure 11 .",
        "liver : the reconstructed image with ( a ) ubp ( b ) no prior , ( c ) the tikhonov prior , ( d ) the nlm prior , ( e ) the wavelet prior , and ( f ) the nlmcs prior .",
        "( g ) the zoomed-in view of region label in the red box and the blue box .",
        "the dual-constraint method perform best in suppress the noise and streak artifact .",
        "table 6 .",
        "the mssim value of different method .",
        "dual-constraint framework , our main contribution be : 1 ) we propose , for the rst time , a novel regularize oat image reconstruction model by combine the non-local mean and sparse coding algorithm .",
        "these two algorithm be couple into the oat inverse problem as two separate regularization term , such that the overall goal of the optimization process be to nd a solution that simultaneously preserve data delity , non-local self-similarities and structural sparsity ; 2 ) to ensure stability and accuracy of the solution , a two- step iterative algorithm for the dual-constraint model , along with a trial-and-error method that ef ciently determine the two regularization parameter , be develop ; 3 ) numerical simulation study , as well as experimental image phan- tom and extensive in vivo small animal study demonstrate the effectiveness of our method : comparing to the image obtain by apply single constraint , our approach achieve volume 7 , 2019 102145x .",
        "li et al .",
        ": model-based oat image reconstruction with non-local and sparsity regularizations figure 12 .",
        "the reconstructed image of the kidney ( a ) , the head ( b ) , and the liver ( c ) region : the cyan and yellow box represent the target area and background area , respectively , for calculate snr and cnr .",
        "snr ( d ) and cnr ( e ) calculate for all in vivo experiment .",
        "k-kidney , h-head , l-liver .",
        "table 7 .",
        "the inversion time of different method at different position .",
        "( unit : s ) .",
        "superior performance in term of artifact removal , noise sup- pression and contrast enhancement , both qualitatively and quantitatively .",
        "our method can be seamlessly extend to other preclinical and translational oat imaging application , and the superior performance of our approach offer great potential for image quality improvement on current oat imaging system .",
        "the major limitation of our current implementation of the dual-constraint method be its computational complexity : the average reconstruction time require for each method be list in table 7 .",
        "the reconstruction time of the nlmcs method be long than all other method , but be close to the nlm method , indicate that the long reconstruc- tion time be mostly cause by the nlm regularization .",
        "to address this problem , previous study [ 46 ] , [ 47 ] have show that such patch-based image processing algorithmcould be largely accelerated via various measure .",
        "moreover , although not show in our work , the nlm regularization have other unique advantage , include improve sparse angle image [ 48 ] and allow for the incorporation of additional prior knowledge [ 29 ] .",
        "even though these previous work be on other image modality , the idea behind them be directly applicable to our oat imaging problem .",
        "finally , fur- ther improvement to our current method could be potentially achieve by correct for light in uence [ 49 ] or sound speed heterogeneity [ 50 ] .",
        "vi .",
        "conclusion this work try to solve the regularized image reconstruction problem in optoacoustic tomography by propose a new dual-constraint imaging framework .",
        "the two complemen- tary constraint , namely the non-local mean ltering and sparse coding , simultaneously preserve the detail and sparse structure in the oat image .",
        "experimental result show that the propose method outperform other previous single constraint scheme , thus provide an alternative imaging strategy for image quality improvement in pre-clinical and clinical oat application ."
    ],
    "processed_text": "received july 12 2019 accept july 18 2019 date publication july 29 2019 date current version august 12 2019 digital object identifier 101 109/access20192930650 modelbased optoacoustic tomography image reconstruction nonlocal sparsity regularizations xipan li li qi shuangyang zhang shixian huang jian wu lijun lu yanqiu feng qianjin feng wufan chen school biomedical engineering southern medical university guangzhou 510515 china guangdong provincial key laboratory medial image processing southern medical university guangzhou 510515 china corresponding author li qi qili @ smueducn wufan chen chenwf @ mmucom work support part china postdoctoral science foundation grant 2017m610536 part national natural science foundation china grant 31700857 grant 61471188 grant 81871437 part guangdong provincial natural science foundation grant 2017a030310516 part guangzhou science technology program grant 201804010375 part guangdong key area research development program grant 2018b030333001 abstract optoacoustic tomography oat emerge imaging modality ultrasonic image depth optical contrast reconstruction optoacoustic image recover initial acoustic pressure distribution object set ultrasound signal modelbased optoacoustic tomography image reconstruction illconditioned inverse problem affect factor limited detection angle imperfect image model noise accounting appropriate penalty incorporate reconstruction process improve image quality paper present new dualconstraint oat imaging model involve combination nonlocal mean ltering sparse coding former preserve image detail selfsimilarity latter enforce sparsity twostep optimization algorithm iterative parameter tune method propose ensure accurate solution compare exist regularization approach numerical simulation vivo animal image study new method show improved image quality term signal noise ratio contrast enhancement index terms modelbased image reconstruction nonlocal mean optoacoustic tomography sparsity introduction optoacoustic tomography oat also name photoacous tic tomography pat novel hybrid image modality combine high contrast optical imaging deep imaging range ultrasonic image 1 2 rich endogenous exogenous contrast agent oat enable noninvasive molecular image 3 \u0015 5 unique advantage oat broad impact preclinical medical biological research 6 \u0015 8 generally oat signal originate optical absorption image process typically start short laser pulse red biological tis sue photon propagate tissue absorb energy partially convert heat far convert mechanical pressure wave propagate tissue ultrasound wave ultrasound wave detect associate editor coordinate review manuscript approve publication ahmet elbiroutside tissue ultrasonic transducer transducer array image map original optical energy depo sition inside tissue reconstruct signal computational approach image reconstruction essential step optoacoustic imaging technology great uence quality generated image generally image reconstruction algorithm oat classi ed two main cate gories analytical method 9 \u0015 12 modelbased mb method 13 \u0015 16 analytical method lihong wang 's group rst propose universal backprojection ubp algorithm oat image reconstruction 9 ubp algorithm simple computationally fast algorithm easily generalize realistic optoa coustic illuminationdetection model since base ideal description acoustic wave propagation detection well speci c detection geometry besides image reconstruct method suffer artifact 102136this work license creative commons attribution 40 license information see http //creativecommonsorg/licenses/by/40/volume 7 2019x li et al modelbased oat image reconstruction nonlocal sparsity regularizations streak artifact negative value artifacts 17 limit application method functional molecular imaging 13 contrary modelbased method base analytical solution inverse problem instead oat image obtain minimize error measure acoustic signal signal pre dicted imaging model commonly depict linear operator importantly mb method work iteratively seek globaloptimal solution inverse problem suppress variety image arti fact associate conventional ubp algorithm incomplete projection data loss lowfrequency information advantage mb method prior knowledge imaging scenario include imag ing geometry target object could incorporate reconstruction process regularization term produce image much good quality 13 15 var ious regularization approach propose oat image reconstruction problem include tikhonov method 18 19 totalvariation method 20 21 sparsitybased method 22 \u0015 26 method major enforced prior knowledge smoothness imaged object sparsity solution space recently clinical medical image system computed tomography ct magnetic resonance imaging mri positron emission tomography pet approach include nonlocal mean nlm ltering 27 block match 3d ltering bm3d 28 exploit selfsimilarities within image use improve image quality 27 \u0015 31 like previous approach method build patchbased image operation therefore could better preserve local struc tures patchbased nlm regularization approach yet introduce oat image reconstruction paper propose novel oat image model combine two classical regularization technique single framework nonlocal mean method image reconstruction explicitly exploit selfsimilarities oat image average noise among similar patch whereas sparse cod encodes optoacoustic image statistic decompose image linear combination element basis set call dictionary pro pose extend combine two approach use simple dualconstraint model ef ciently solve tailored twostep optimization method base gradient descent iterative shrinkagethresholding effectively determine regularization parameter trial anderror method learn parameter empirical netuned sample develop best knowledge rst time corresponding model image selfsimilarities explicitly use common setting sparse cod oat imaging numerical simulation vivo animal image experiment carry verify propose method result show ourmethod good performance compare use nlm sparse coding single regularization term rest paper organize follow sec 2 review modelbased oat reconstruction framework regularization method introduce dual constraint imaging strategy tailored optimization proce dure inverse problem section 3 describe detail numerical phantom animal experiment result simulation experiment present sec 4 finally discussion conclusion give sec 5 sec 6 respectively ii theory imaging model oat oat generation propagation optoacoustic signal express @ 2per t/ @ t2\u0000c2r2per t/d0 @ t/ @ 1 per t/denotes acoustic pressure position er time tcis sound speed 0is grunesien parameter t/dhrer/htt/is heating function describe energy deposition laser unit volume unit time impulse heating assume htt/\u0019\u000et/ 1 solve use green function 7 pderd t/d0 4\u0019c2 @ @ t\u00141 ctz vhrer/\u000e\u0012 t\u0000jerd\u0000erj c\u0013 der\u0015 2 whereerdrepresents detector position vis illuminated volume target object ris one point inside v crosssectional oat low limit integral 2 change vtol ldjerd\u0000erjdctis circular arc whose center detector location erdand radius ct reconstruction optoacoustic image recover initial acoustic pressure distribution object set measured signal pderd t/ ubp algorithm work nding analytical solution 2 formulation ubp method time domain writes p0er/d1 0z sd0\u00022\u0014 perd t/\u0000t @ perd t/ @ t\u0015 ctdjer\u0000erdj 3 where0is solid angle whole detection geometry 0is circle planar geometry thus 0d2\u0019 term d0/0is weighing factor contribution detection element characterize angular position transducer number projection hand mb method oat reconstruction work treat pressure signal measure ultra sound sensor linear map energy deposition grid locate eld view oat system linear map refer model matrix imaging system oat forward model express volume 7 2019 102137x li et al modelbased oat image reconstruction nonlocal sparsity regularizations discretized version 2 pdwx 4 xis rn\u00021column vector represent imaged object pis rm\u00021column vector denote projection data wis rm\u0002nforward model matrix work use interpolated model matrix inversion method 13 generate model matrix inversion 4 perform solve following minimization problem xdarg min1 2kp\u0000wxk2 2 5 wherek\u0001k2 2is l2norm image recon struction process minimize difference actual measure signal signal predict model 13 14 32 generally inverse problem oat illconditioned solution 5 may incor rect numerically unstable 33 therefore appropriate prior penalty need improve reconstruc tion result typically involve incorporate prior knowledge form penalty function control desired property unknown deterministic prior probability distribution unknown random variable way objective function modi ed xdarg min\u001a1 2kp\u0000wxk2 2c\u0015jx/\u001b 6 \u0015\u00150 regularization parameter j x regularization functional operator context conven tional medical tomographic image reconstruction ct mri pet penalty function often choose enforce smoothness 18 preserve edge 20 promote spar sity 22 34 incorporate anatomical information 29 b proposed regularization scheme 1 nonlocal means regularization nonlocal mean algorithm rst present image denoising method 27 work nding simi lar patch across nonlocal region within image performs weight average operation patch accord similarity traditionally nlm scheme give discrete noisy image xdfxi/ji2ig iis denote discrete grid pixel restored value nl x pixel iis compute weighted sum function neighbor pixel image domain 30 nlxi//dx j2si j/'xi/\u0000xj// 7 iis coordinate index image xsiis search window center pixel 'is generally describe potential function weight j quanti es similarity pixel iand pixel j express follow j/d1 zi/expn \u0000 xei/\u0000x\u0000 ej\u0001 2 2 h2o 8 zi/dp j2siexpn \u0000 xei/\u0000x\u0000 ej\u0001 2 2 a=h2o normalizing factor eiandejare two similarity neighborhood patch center pixel iandj x ei x ej vector neighborhood pixel value patchwindow ei andej respectively notation k\u0001k2 2 adenotes gaussian weighted euclidean distance two similarity patch abeing standard deviation gaussian function hthe parameter control decay exponential function nlm method show good performance term edgepreserving image restoration therefore later successfully apply tomographic image recon struction problem usually possess following form xdarg min\u001a1 2kp\u0000wxk2 2c\u0015\u0001r x \u001b 9 r x dp i2inlxi// way nlm incorporate regularization term solution optimization problem find use steep descend algorithm gradient direction derivative potential function inspired 29 work choose potential function 'as 'xi/\u0000xj//ds 1c\u0012xi/\u0000xj// \u0011\u00132 \u00001 10 \u0011was empirical parameter derivative potential function give @ 'xi/\u0000xj// @ xi/dxi/ \u00112r 1c\u0010 xi/\u0000xj// \u0011\u00112 11 show 29 author illustrate preferable edgepreserving characteristic hyperbolic potential function 2 sparsity based regularizaiton based assumption clean signal approx imated sparse linear combination element basis set dictionary sparse cod implies image xis sparse basis/dictionary ie xddu thenuis corresponding code nonzero entry solution code ucan find solve following l1norm minimization problem minkuk1s pdwdu 12 linear inverse problem image reconstruc tion problem oat sparse cod mechanism incorporate sparsity regularization term udarg min\u001a1 2kp\u0000wduk2 2c\u0015skuk1\u001b 13 nd basis dthat could sparsely represent x express win way wd sparse matrix image domain reconstruct 102138 volume 7 2019x li et al modelbased oat image reconstruction nonlocal sparsity regularizations minimizing 13 optimization 13 may ef ciently solve variety method iterative shrinkagethresholding algorithm ista 35 nal reconstruction transfer back image domain use xddu 3 combined nlm sparsity regularizaiton scheme purpose nlmbased regularization preserve image smoothness use selfsimilarity rather averag ing neighboring pixel within local window utilize nonlocal information across image perform denoising structure information edge texture well preserve hand sparse cod penalty major observation signal sparse appropriate basis thus sparsity base regularization scheme enforce sparsity recover clean signal via l1normbased minimization based observation present regular ization scheme involve combination nonlocal mean l1normbased sparse cod penalty purpose dualconstraint scheme nd method could suppress streaking artifact preserve tissue detail cost function seek minimize contained three parts\u0016the data tting term nlmbased penalty term sparsitybased penalty term nal objective function de ned xdarg min\u001a1 2kp\u0000wxk2 2c\u0015nlm\u0001r x c\u0015s d\u00001x 1\u001b 14 \u0015nlmand\u0015swere regularization parameter simple dualconstraint model effectively connect two classical regularization method name nlmcs sparse cod term various type wavelet 36 use dictionary dfor natural clinical tomographic image work choose stick waveletbased dictionary proveofconcept pur pose dwas choose represent four level bior68 wavelet transform however alternative sparse decomposition base learn possibly complete dictionary adapt speci c image may provide good result prove application natural image processing 37 38 c twostep iterative algorithm solve dualconstraint problem 14 twostep iter ative optimization method develop algorithm optimization problem base gradient descent iterative shrinkagethresholding 35 start rst step algorithm update leastsquares term nlm regularization term use gradient descent sub objective function l x de ned lx/d1 2kp\u0000wxk2 2c\u0015nlm\u0001rx/ 15 iteration update xkc1as xkc1dx\u0000 \u0001\u0014 wtwx\u0000p/c2\u0015nlm\u0001 @ r x @ x\u0015 dx\u0000 \u0001\u0010 wtwx\u0000p/ c2\u0015 nlm\u0001x i2ix j2si j/ @ f ' xi/\u0000xj/ g @ xi/1 16 second step optimize l1normbased sparse cod regularization term base rst step intermediate variable uis introduce let xdduwe could obtain another objective function ofu pu/d\u0015skuk1c1 2 d\u00001xkc1\u0000u 2 2 17 introduce shrinkagethresholding operator 35 soft\u001ad8 > < > x\u0000\u001a ifx > \u001a xc\u001a x < \u001a 0 otherwise 18 x2r and\u001a > 0 could update ukc1as ukc1dsoft\u0015s\u0010 d\u00001xkc1\u0011 19 finally transfer ukc1back image domain could obtain updated image xkc1ddukc1 20 iteration stop total error errdjjpwxkc1jj2 less prede ned value maximum iteration number ki meet twostep iterative algorithm dualconstraint image reconstruction scheme summarize inalgorithm 1 algorithm 1 twostep iterative algorithm nlmcs regularized oat image reconstruction input x0/ ubp or0 k itermax repeat 1 update xkc1using xkc1dx\u0000 \u0001\u0000 wtwx\u0000p/ c2\u0015 nlm\u0001p i2ip j2si j/ @ f ' xi/\u0000xj/ g @ xi/ 2 update ukc1using ukc1dsoft\u0015s\u0000 d\u00001xkc1\u0001 3 transfer result back image domain xkc1 dukc1 4 calculate error err norm\u0000 p\u0000wxkc1\u0001 5 update iteration k kc1 convergence k > iter max err < output x volume 7 2019 102139x li et al modelbased oat image reconstruction nonlocal sparsity regularizations parameter setup 1 trialanderror method choosing regularization parameters linear inverse problem regularization method compute stable solution involve tradeoff regularization term j x data tting term kp\u0000wxk2 2 therefore regularization parameter choose carefully order avoid tting tting common method use determine suitable value \u0015 lcurve method 18 39 lcurve loglog plot norm regularization term norm data tting term possible selection suitable regularization parameter lie corner lcurve however reconstruction smooth case oat lcurve method fail nd optimal regularization parameter 39 address herein propose simple scheme name trialand error method determine regularization parameter optimization problem explain trialanderror method common framework take single regularization problem example de ne simple model \u0015d oc\u0016 1c\u001b2 2c\u0010 \u0016\u0001\u001b2\u0011 3 21 \u0015is regularization parameter \u0016and\u001b2are mean variance initial image obtain 5 without regularization respectively purpose trialanderror method learn coef cients 1 2 3 series netuned image reconstruction give new image regularization parameter \u0015for new image could obtain simply apply 21 estimate rst series image acquire two kind reconstruction perform one empir ically determine regularization parameter regularization would set of\u0015 use rst kind reconstruction set \u0016and\u001b2estimated second kind reconstruction linear system \u0015dx establish xd one size \u0016 1 \u0016 \u001b2 nally coef cients estimate linear system multiple linear regres sion analysis demonstrate method acquire total 30 vivo crosssectional image nude mouse head liver kidney section 10 frame section perform multiple linear regression analysis could obtain initial coef cients 0d 33957\u000210\u00005 1d\u000032573\u000210\u00007 2d\u000012376\u000210\u00007 3d14102\u000210\u00009 con dence interval estimate value 19971\u000210\u00005 47943\u000210\u00005 46644\u000210\u00007 18502\u000210\u00007 17008\u000210\u00007 77443\u0002 10\u00008 99507\u000210\u000010 19052\u000210\u00009 respectively thus linear regression equation write \u0015d33957\u000210\u0000532573\u000210\u00007\u0016 \u000012376\u000210\u00007\u001b2c14102\u000210\u00009\u0016\u001b2 22 figure 1 multiple linear regression result testing dataset show good linear relationship among mean variance image regularization parameter result regression show fig 1 pvalue coef cient determination r2of regression pd34762\u000210\u000014andr2d09325 therefore model present 22 could consider accurate dualconstraint problem twostep strategy employ estimate two regularization parameter \u0015nlm and\u0015s rst step preestimation trialand error method use obtain reconstruction one regularization term include objective function let regularization parameter zero result obtain rst step use original image calculate mean variance second step correction trialanderror method use nd regularization parameter second penalty term 2 choosing nlm parameter trivial task determine optimal nlm lter parameter work parameter empiri cally determine extensive experiment quanti tative measure visual inspection find 11\u000211 searchwindow 7\u00027 patch size adequate suppress streak artifact retain computational ef ciency parameter h let h2d2 \u001b2 0jnij where\u001b2 0denotes standard deviation reconstructed image jnijdenotes size search window scale parameter selection regularization parameter exper iments present study rst find optimal regular ization parameter tikhonov nlm wavelet method respectively ideally case dualconstraint pre vious obtain optimal parameter constraint rstly apply reconstruct initial image far netune nd best result however implementation find necessary adjust regularization parameter single constraint initial result already good enough actual value regularization parameter present table 1 iii experimental setups methods multispectral optoacoustic tomography system simulation phantom vivo animal image experiment base commercially available 102140 volume 7 2019x li et al modelbased oat image reconstruction nonlocal sparsity regularizations table 1 regularization parameter tikhonov prior nlm prior wavelet prior nlmcs prior figure 2 image chamber 128elecment transducer array 10 fiber illumination port b schematic detector position red point represent ultrasound detector positons transducer array cover 270\u000espan projection angle td transducer optoacoustic tomography platform multispectral optoa coustic tomography system msot invision128 ithera medical germany msot system base design present 40 \u0015 43 figure 2 show photo imaging chamber transducer array ber illumination port visible laser separate 10 bundle bers laser energy uniformly distribute surface imaged object pulse duration laser around 5 n repetition rate 10 hz experiment image chamber lled water imaged object submerge water horizontal position animal holder figure 2 b show schematic ultrasound detection system geometry ringshape transducer array consist 128 element cover 270\u000espan projection angle radius 405 mm transducer element central frequency 5 mhz 6db bandwidth 100 signal transducer acquire sampling frequency 40 mhz laser wavelength tunable 680 nm 980 nm experiment data acquire laser wavelength 760 nm slice average 10 time b simulation setup simulation experiment perform validate pro posed dualconstraint approach detector geometry simulation exactly msot experimental system describe numerical 2d phantom use reference image show fig 3 size phantom image 300\u0002300 pixel perfor mance dualconstraint scheme compare figure 3 simulation result original image reconstructed image b prior c tikhonov prior nlm prior e wavelet prior f nlmcs prior reconstruction obtain use prior tikhonov prior 18 nlm prior wavelet prior avoid inverse crime 44 projection data simulate 75 mhz sample rate resampled 40 mhz add 10db gaussian noise original data nal simulated pressure signal consist 1131 time point equivalent 30mm\u000230mm eld view 1500m/s sound speed algorithm use simulation experiment stop criterion d1\u000210\u000012 anditermaxd500 algorithm implement matlab desktop pc quadcore cpu 8gb memory c experiments setup 1 phantom experiments phantom experiment carry evaluate method msot system employ cylindrical shape phantom diameter 2 cm phantom create 15 agar 1 intralipid inside phantom three cylindrical cavity different diameter cavity lled light absorb black chinese ink provide optoacoustic contrast reconstruction speed sound set 1500m/s 128 pro jections use contain 1131 timesamples reconstruction image consist 300\u0002300 pixel 2 vivo animal experiments animal experiment approve southern medical university carry accordance institutional guideline study choose 8 week nude mouse experimental subject subject anesthetize use mixture 3 iso urane 100 oxygen image anesthesia port connect animal holder well scanner anesthetized nude mouse place animal holder thin layer ultrasound gel around circumference desired imaging region mouse wrap use plastic foil mem brane vivo experiment choose position volume 7 2019 102141x li et al modelbased oat image reconstruction nonlocal sparsity regularizations head kidney liver acquire experimental data image reconstruction experiment projection contain 1105 temporal sample speed sound medium set 1536 m/s reconstruction image also consist 300\u0002300 pixel performance metrics quantitative performance metric use evaluate reconstruction result root mean square difference rmsd signaltonoise ratio snr contrast tonoise ratio cnr rmsd calculate theoretical image reconstructed image different method numerical simulation de ned rmsddvuut1 nnx nd1 xn 1\u0000xn 2 2 23 xn 1andxn 2are nth pixel value two image x1andx2 nis total pixel number image snr calculate ratio root mean square ampli tudes target background region unit snr value db de ned snrd20 log10\u0012at sdb\u0013 24 atis rootmeansquare amplitude value tar get region sdbis standard variance background region cnr calculate mean value difference target region background region divide standard deviation background region give cnrdjxt\u0000xbj \u001bb 25 wherenxtandnxbare mean value target region background region respectively \u001bbis variance background region structural similarity ssim index image x1andx2is de ned 45 ssimd\u0000 2\u0016x1\u0016x2cc1\u0001\u0000 2\u001bx1\u0001x2cc2\u0001 \u0000 \u00162x1c\u00162x2cc1\u0001\u0000 \u001b2x1c\u001b2x2cc2\u0001 26 \u0016x1and\u0016x2are mean x1andx2 respectively \u001bx1and\u001bx2are variance x1andx2 respectively \u001bx1\u0001x2 covariance image x1andx2 small constant c1 c2andc3are give c1dk1l/2 c2dk2l/2 andc3dc2=2 27 lis dynamic range pixel value l d255 8 bits/pixel gray scale image k 1and k2are set k1d001 k2d003 respectively iv results simulation results simulation study test oat image reconstruct nlmcs method four com par method compare method include non regularized model tikhonov model nlm model figure 4 residual image original image reconstructed image prior b tikhonov prior c nlm prior wavelet prior e nlmcs prior f enlarged region enclose solid red box table 2 rmsd simulation study waveletbased sparse cod model reconstruc tion result obtain numerical simulation show fig 3 figure 3 original image use simulation figure 3 b image obtain without regularization figure 3 c fig 3 f image reconstruct use tikhonov nlm wavelet nlmcs regularization respectively figure 3 f clearly show contrast image enhance dualconstraint method subtract original image residual image show fig 4 region correspond red box fig 4 enlarge show fig 4 f could see residual image sparsitybased prior nlmcs prior similar error level image show much high difference rmsd value method list table 2 dualconstraint image small error among method figure 5 show intensity pro le reconstructed image obtain different method location pro le mark yellow dashed line fig 3 b see method low noise platform pro le nlmcs method conform reference pro le figure 5 b show rmsd value respect different iteration number conclude dualconstraint method bet ter convergence performance compare method 102142 volume 7 2019x li et al modelbased oat image reconstruction nonlocal sparsity regularizations figure 5 intensity profile extract reconstruct image different method profile position mark yellow dashed line fig 3 b b convergence performance different method table 3 snr cnr phantom image b experimental results 1 phantom oat reconstruction result tissuemimicking phantom show fig 6 see image obtain use dualconstraint method show sharp boundary phantom two inner cavity smooth uniform pixel intensity find inside phantom cavity method streak artifact image prominent outside inside phantom next snr cnr value image calculate list table 3 region label cyan dash box yellow dash box fig 6 b represent target background region respectively obtain snr cnr method high snr cnr value compare method additional phantom experiment perform val idate stability algorithm design phantom two insertion indocyanine green icg chinese ink absorption coef cient icg 19 cm\u00001at 800 nm obtain oat image phantom 800 nm use different method reconstruction result display figure 7 oat image arbitrary unit perform quantitative comparison signal icg chose reference quantify signal ink use following equation \u0016inkdpink\u0016icg picg 28 pinkandpicgare pixel intensity ink icg respectively obtain average intensity within corresponding region interest roi reconstructed image \u0016icgis absorption coef cient icg whose value 19 cm\u00001 the\u0016inkis absorption coef cient ink unit cm\u00001 five pair rois select calculate \u0016ink position figure 6 phantom reconstructed image prior b tikhonov prior c nlm prior wavelet prior e nlmcs prior region label cyan dash box yellow dash box b serve target background region respectively calculate snr cnr f zoomedin image region red solid box method suppress streak artifact effectively rois show fig 7 b \u0016inkvalues obtain six compare method rois show table 4 result analyzed use oneway anov analysis variance implement spss sta tistical product service solutions determine whether value different method signi cantly different anov table present table 5 see f value different rois calculate spss 0423 since fd0423 < f001 524 d390 signi cant difference quantitative \u0016inkvalues different method conclude method change pixel intensity oa signal 2 animal image reconstruction quantitative analysis vivo image study mouse head kidney liver region carry figure 8 show reconstructed volume 7 2019 102143x li et al modelbased oat image reconstruction nonlocal sparsity regularizations figure 7 additional phantom result reconstructed image ubp b prior c tikhonov prior nlm prior e wavelet prior f nlmcs prior table 4 \u0016inkobtained use different method table 5 anova data table 4 oat image mouse head use different method ubp reconstruction also carry fair com parison region enclose red box blue box fig 8 show enlarged view fig 8 g comparing enlarge view could see image obtain use dualconstraint method show smooth head structure generate streak artifact head background region also could see method preserve sharp edge head surface produce high contrast figure 9 show result kidney oat image region enclose red box blue box fig 9 show zoomedin view fig 9 g image obtain dualconstraint method show well de ned contour different organ image smooth detailed information well preserve compare zoomedin view enclose figure 8 head reconstructed image ubp b prior c tikhonov prior nlm prior e wavelet prior f nlmcs prior g zoomedin view region label red box blue box enlarged area show method performs best among method mention paper red box fig 9 g hardly noticeable streaking artifact image reconstruct dual constraint method however image obtain method show obvious streak artifact blur detail figure 10 show image pro le kidney area location pro le mark yellow dashed line fig 9 b see method provide accurate boundary information without lose much detail generate accurate image use nlm wavelet regularization alone moreover reconstruct oat image liver posi tion show fig 11 region enclose red box blue box fig 11 show zoomedin view fig 11 g illustrated image obtain use dualconstraint method provide signi cantly improve image quality however image obtain use method noise streaking artifact obvious inside outside liver region quantitative comparison figure 12 show result snr cnr calculate vivo study region label cyan dash box yellow dash box fig 12 ac represent target background region calculate snr cnr respectively comparison result present fig 12 fig 12 e method generate high snr cnr value compare method suggest superior performance dualconstraint scheme finally mean 102144 volume 7 2019x li et al modelbased oat image reconstruction nonlocal sparsity regularizations figure 9 kidney reconstructed image ubp b prior c tikhonov prior nlm prior e wavelet prior f nlmcs prior g zoomedin view region label red box blue box yellow arrows 1 7 indicate tissue renal cortex arrow 1 spleen arrow 2 intestine arrow 3 spinal cord arrow 4 mouse body arrow 5 tiny blood vessel arrow 6 7 figure 10 profiles five image along yellow dashed line fig 9 b value ssim mssim list table 6 method score high mssim value three animal study v discussion optoacoustic tomography properly design regulariza tion method original computed image reconstruction problem desirable inherently illconditioned work seek resolve problem introduce new figure 11 liver reconstructed image ubp b prior c tikhonov prior nlm prior e wavelet prior f nlmcs prior g zoomedin view region label red box blue box dualconstraint method perform best suppress noise streak artifact table 6 mssim value different method dualconstraint framework main contribution 1 propose rst time novel regularize oat image reconstruction model combine nonlocal mean sparse coding algorithm two algorithm couple oat inverse problem two separate regularization term overall goal optimization process nd solution simultaneously preserve data delity nonlocal selfsimilarities structural sparsity 2 ensure stability accuracy solution two step iterative algorithm dualconstraint model along trialanderror method ef ciently determine two regularization parameter develop 3 numerical simulation study well experimental image phan tom extensive vivo small animal study demonstrate effectiveness method comparing image obtain apply single constraint approach achieve volume 7 2019 102145x li et al modelbased oat image reconstruction nonlocal sparsity regularizations figure 12 reconstructed image kidney head b liver c region cyan yellow box represent target area background area respectively calculate snr cnr snr cnr e calculate vivo experiment kkidney hhead lliver table 7 inversion time different method different position unit superior performance term artifact removal noise sup pression contrast enhancement qualitatively quantitatively method seamlessly extend preclinical translational oat imaging application superior performance approach offer great potential image quality improvement current oat imaging system major limitation current implementation dualconstraint method computational complexity average reconstruction time require method list table 7 reconstruction time nlmcs method long method close nlm method indicate long reconstruc tion time mostly cause nlm regularization address problem previous study 46 47 show patchbased image processing algorithmcould largely accelerated via various measure moreover although show work nlm regularization unique advantage include improve sparse angle image 48 allow incorporation additional prior knowledge 29 even though previous work image modality idea behind directly applicable oat imaging problem finally fur ther improvement current method could potentially achieve correct light uence 49 sound speed heterogeneity 50 vi conclusion work try solve regularized image reconstruction problem optoacoustic tomography propose new dualconstraint imaging framework two complemen tary constraint namely nonlocal mean ltering sparse coding simultaneously preserve detail sparse structure oat image experimental result show propose method outperform previous single constraint scheme thus provide alternative imaging strategy image quality improvement preclinical clinical oat application",
    "bag_of_words": {
        "received": 1,
        "july": 3,
        "accept": 1,
        "date": 2,
        "publication": 2,
        "current": 4,
        "version": 2,
        "august": 1,
        "digital": 1,
        "object": 9,
        "identifier": 1,
        "109/access20192930650": 1,
        "modelbased": 16,
        "optoacoustic": 15,
        "tomography": 13,
        "image": 155,
        "reconstruction": 50,
        "nonlocal": 23,
        "sparsity": 20,
        "regularizations": 11,
        "xipan": 1,
        "li": 13,
        "qi": 2,
        "shuangyang": 1,
        "zhang": 1,
        "shixian": 1,
        "huang": 1,
        "jian": 1,
        "wu": 1,
        "lijun": 1,
        "lu": 1,
        "yanqiu": 1,
        "feng": 2,
        "qianjin": 1,
        "wufan": 2,
        "chen": 2,
        "school": 1,
        "biomedical": 1,
        "engineering": 1,
        "southern": 3,
        "medical": 7,
        "university": 3,
        "guangzhou": 3,
        "china": 4,
        "guangdong": 3,
        "provincial": 2,
        "key": 2,
        "laboratory": 1,
        "medial": 1,
        "processing": 3,
        "corresponding": 4,
        "author": 2,
        "qili": 1,
        "smueducn": 1,
        "chenwf": 1,
        "mmucom": 1,
        "work": 14,
        "support": 1,
        "part": 5,
        "postdoctoral": 1,
        "science": 4,
        "foundation": 3,
        "grant": 7,
        "2017m610536": 1,
        "national": 1,
        "natural": 4,
        "2017a030310516": 1,
        "technology": 2,
        "program": 2,
        "area": 5,
        "research": 2,
        "development": 1,
        "2018b030333001": 1,
        "abstract": 1,
        "oat": 49,
        "emerge": 1,
        "imaging": 20,
        "modality": 3,
        "ultrasonic": 3,
        "depth": 1,
        "optical": 4,
        "contrast": 9,
        "recover": 3,
        "initial": 6,
        "acoustic": 5,
        "pressure": 6,
        "distribution": 3,
        "set": 9,
        "ultrasound": 6,
        "signal": 19,
        "illconditioned": 3,
        "inverse": 9,
        "problem": 24,
        "affect": 1,
        "factor": 3,
        "limited": 1,
        "detection": 6,
        "angle": 5,
        "imperfect": 1,
        "model": 23,
        "noise": 8,
        "accounting": 1,
        "appropriate": 3,
        "penalty": 9,
        "incorporate": 6,
        "process": 5,
        "improve": 5,
        "quality": 8,
        "paper": 4,
        "present": 10,
        "new": 6,
        "dualconstraint": 23,
        "involve": 4,
        "combination": 4,
        "mean": 17,
        "ltering": 4,
        "sparse": 20,
        "coding": 4,
        "former": 1,
        "preserve": 10,
        "detail": 6,
        "selfsimilarity": 2,
        "latter": 1,
        "enforce": 3,
        "twostep": 7,
        "optimization": 9,
        "algorithm": 22,
        "iterative": 8,
        "parameter": 32,
        "tune": 1,
        "method": 95,
        "propose": 9,
        "ensure": 2,
        "accurate": 4,
        "solution": 11,
        "compare": 9,
        "exist": 1,
        "regularization": 50,
        "approach": 10,
        "numerical": 7,
        "simulation": 16,
        "vivo": 10,
        "animal": 12,
        "study": 11,
        "show": 35,
        "improved": 1,
        "term": 22,
        "ratio": 4,
        "enhancement": 2,
        "index": 3,
        "terms": 1,
        "introduction": 1,
        "also": 4,
        "name": 3,
        "photoacous": 1,
        "tic": 1,
        "pat": 1,
        "novel": 3,
        "hybrid": 1,
        "combine": 4,
        "high": 6,
        "deep": 1,
        "range": 2,
        "rich": 1,
        "endogenous": 1,
        "exogenous": 1,
        "agent": 1,
        "enable": 1,
        "noninvasive": 1,
        "molecular": 2,
        "unique": 2,
        "advantage": 3,
        "broad": 1,
        "impact": 1,
        "preclinical": 3,
        "biological": 2,
        "generally": 4,
        "originate": 1,
        "absorption": 4,
        "typically": 2,
        "start": 2,
        "short": 1,
        "laser": 7,
        "pulse": 2,
        "red": 12,
        "tis": 1,
        "sue": 1,
        "photon": 1,
        "propagate": 2,
        "tissue": 6,
        "absorb": 2,
        "energy": 5,
        "partially": 1,
        "convert": 2,
        "heat": 1,
        "far": 2,
        "mechanical": 1,
        "wave": 4,
        "detect": 1,
        "associate": 2,
        "editor": 1,
        "coordinate": 2,
        "review": 2,
        "manuscript": 1,
        "approve": 2,
        "ahmet": 1,
        "elbiroutside": 1,
        "transducer": 10,
        "array": 5,
        "map": 3,
        "original": 8,
        "depo": 1,
        "sition": 1,
        "inside": 6,
        "reconstruct": 9,
        "computational": 3,
        "essential": 1,
        "step": 8,
        "great": 2,
        "uence": 2,
        "generated": 1,
        "classi": 1,
        "ed": 2,
        "two": 16,
        "main": 2,
        "cate": 1,
        "gories": 1,
        "analytical": 4,
        "mb": 4,
        "lihong": 1,
        "wang": 1,
        "group": 1,
        "rst": 11,
        "universal": 1,
        "backprojection": 1,
        "ubp": 11,
        "simple": 5,
        "computationally": 1,
        "fast": 1,
        "easily": 1,
        "generalize": 1,
        "realistic": 1,
        "optoa": 2,
        "coustic": 2,
        "illuminationdetection": 1,
        "since": 2,
        "base": 9,
        "ideal": 1,
        "description": 1,
        "propagation": 2,
        "well": 6,
        "speci": 2,
        "geometry": 6,
        "besides": 1,
        "suffer": 1,
        "artifact": 12,
        "102136this": 1,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "information": 7,
        "see": 8,
        "http": 1,
        "//creativecommonsorg/licenses/by/40/volume": 1,
        "2019x": 5,
        "et": 10,
        "al": 10,
        "streak": 7,
        "negative": 1,
        "value": 24,
        "artifacts": 1,
        "limit": 2,
        "application": 4,
        "functional": 2,
        "contrary": 1,
        "instead": 1,
        "obtain": 24,
        "minimize": 3,
        "error": 7,
        "measure": 5,
        "pre": 2,
        "dicted": 1,
        "commonly": 1,
        "depict": 1,
        "linear": 14,
        "operator": 3,
        "importantly": 1,
        "iteratively": 1,
        "seek": 3,
        "globaloptimal": 1,
        "suppress": 5,
        "variety": 2,
        "arti": 1,
        "fact": 1,
        "conventional": 1,
        "incomplete": 1,
        "projection": 7,
        "data": 11,
        "loss": 1,
        "lowfrequency": 1,
        "prior": 51,
        "knowledge": 5,
        "scenario": 1,
        "include": 6,
        "imag": 1,
        "ing": 2,
        "target": 9,
        "could": 14,
        "produce": 2,
        "much": 3,
        "good": 6,
        "var": 1,
        "ious": 1,
        "tikhonov": 13,
        "totalvariation": 1,
        "sparsitybased": 3,
        "major": 3,
        "enforced": 1,
        "smoothness": 3,
        "imaged": 4,
        "space": 1,
        "recently": 1,
        "clinical": 3,
        "system": 12,
        "computed": 2,
        "ct": 3,
        "magnetic": 1,
        "resonance": 1,
        "mri": 2,
        "positron": 1,
        "emission": 1,
        "pet": 2,
        "nlm": 26,
        "block": 1,
        "match": 1,
        "3d": 1,
        "bm3d": 1,
        "exploit": 2,
        "selfsimilarities": 4,
        "within": 4,
        "use": 35,
        "like": 1,
        "previous": 4,
        "build": 1,
        "patchbased": 3,
        "operation": 2,
        "therefore": 5,
        "better": 1,
        "local": 2,
        "struc": 1,
        "tures": 1,
        "yet": 1,
        "introduce": 5,
        "classical": 2,
        "technique": 1,
        "single": 6,
        "framework": 5,
        "explicitly": 2,
        "average": 5,
        "among": 4,
        "similar": 2,
        "patch": 6,
        "whereas": 1,
        "cod": 9,
        "encodes": 1,
        "statistic": 1,
        "decompose": 1,
        "element": 5,
        "basis": 4,
        "call": 1,
        "dictionary": 5,
        "pro": 9,
        "pose": 2,
        "extend": 2,
        "ef": 4,
        "ciently": 3,
        "solve": 7,
        "tailored": 2,
        "gradient": 4,
        "descent": 3,
        "shrinkagethresholding": 4,
        "effectively": 3,
        "determine": 8,
        "trial": 1,
        "anderror": 1,
        "learn": 3,
        "empirical": 2,
        "netuned": 2,
        "sample": 3,
        "develop": 3,
        "best": 4,
        "time": 11,
        "common": 3,
        "setting": 1,
        "experiment": 15,
        "carry": 5,
        "verify": 1,
        "result": 21,
        "ourmethod": 1,
        "performance": 9,
        "rest": 1,
        "organize": 1,
        "follow": 2,
        "sec": 4,
        "dual": 2,
        "constraint": 7,
        "strategy": 3,
        "proce": 1,
        "dure": 1,
        "section": 3,
        "describe": 4,
        "phantom": 20,
        "finally": 4,
        "discussion": 2,
        "conclusion": 2,
        "give": 6,
        "respectively": 15,
        "ii": 1,
        "theory": 1,
        "generation": 1,
        "express": 4,
        "2per": 1,
        "t/": 4,
        "t2\u0000c2r2per": 1,
        "t/d0": 2,
        "per": 1,
        "t/denotes": 1,
        "position": 9,
        "er": 1,
        "tcis": 1,
        "sound": 6,
        "speed": 5,
        "0is": 1,
        "grunesien": 1,
        "t/dhrer/htt/is": 1,
        "heating": 2,
        "function": 18,
        "deposition": 2,
        "unit": 6,
        "volume": 11,
        "impulse": 1,
        "assume": 1,
        "htt/\u0019\u000et/": 1,
        "green": 2,
        "pderd": 2,
        "4\u0019c2": 1,
        "t\u00141": 1,
        "ctz": 1,
        "vhrer/\u000e\u0012": 1,
        "t\u0000jerd\u0000erj": 1,
        "c\u0013": 1,
        "der\u0015": 1,
        "whereerdrepresents": 1,
        "detector": 5,
        "vis": 1,
        "illuminated": 1,
        "ris": 1,
        "one": 4,
        "point": 3,
        "crosssectional": 2,
        "low": 2,
        "integral": 1,
        "change": 2,
        "vtol": 1,
        "ldjerd\u0000erjdctis": 1,
        "circular": 1,
        "arc": 1,
        "whose": 2,
        "center": 3,
        "location": 3,
        "erdand": 1,
        "radius": 2,
        "measured": 1,
        "nding": 2,
        "formulation": 1,
        "domain": 6,
        "writes": 1,
        "p0er/d1": 1,
        "0z": 1,
        "sd0\u00022\u0014": 1,
        "perd": 2,
        "t/\u0000t": 1,
        "t\u0015": 1,
        "ctdjer\u0000erdj": 1,
        "where0is": 1,
        "solid": 3,
        "whole": 1,
        "0is": 1,
        "circle": 1,
        "planar": 1,
        "thus": 4,
        "0d2\u0019": 1,
        "d0/0is": 1,
        "weighing": 1,
        "contribution": 2,
        "characterize": 1,
        "angular": 1,
        "number": 4,
        "hand": 2,
        "treat": 1,
        "ultra": 1,
        "sensor": 1,
        "grid": 2,
        "locate": 1,
        "eld": 2,
        "view": 10,
        "refer": 1,
        "matrix": 5,
        "forward": 1,
        "102137x": 1,
        "discretized": 1,
        "pdwx": 1,
        "xis": 2,
        "rn\u00021column": 1,
        "vector": 3,
        "represent": 7,
        "pis": 1,
        "rm\u00021column": 1,
        "denote": 2,
        "wis": 1,
        "rm\u0002nforward": 1,
        "interpolated": 1,
        "inversion": 3,
        "generate": 4,
        "perform": 8,
        "following": 4,
        "minimization": 3,
        "xdarg": 4,
        "min1": 1,
        "2kp\u0000wxk2": 5,
        "wherek\u0001k2": 1,
        "2is": 1,
        "l2norm": 1,
        "recon": 2,
        "struction": 2,
        "difference": 5,
        "actual": 2,
        "predict": 1,
        "may": 3,
        "incor": 1,
        "rect": 1,
        "numerically": 1,
        "unstable": 1,
        "need": 1,
        "reconstruc": 4,
        "tion": 6,
        "form": 2,
        "control": 2,
        "desired": 2,
        "property": 1,
        "unknown": 2,
        "deterministic": 1,
        "probability": 1,
        "random": 1,
        "variable": 2,
        "way": 3,
        "objective": 5,
        "modi": 1,
        "min\u001a1": 4,
        "2c\u0015jx/\u001b": 1,
        "\u0015\u00150": 1,
        "context": 1,
        "conven": 1,
        "tional": 1,
        "tomographic": 3,
        "often": 1,
        "choose": 7,
        "edge": 3,
        "promote": 1,
        "spar": 1,
        "sity": 1,
        "anatomical": 1,
        "proposed": 1,
        "scheme": 11,
        "means": 1,
        "denoising": 2,
        "simi": 1,
        "lar": 1,
        "across": 2,
        "region": 31,
        "performs": 2,
        "weight": 2,
        "accord": 1,
        "similarity": 5,
        "traditionally": 1,
        "discrete": 2,
        "noisy": 1,
        "xdfxi/ji2ig": 1,
        "iis": 3,
        "pixel": 18,
        "restored": 1,
        "nl": 1,
        "compute": 2,
        "weighted": 2,
        "sum": 1,
        "neighbor": 1,
        "nlxi//dx": 1,
        "j2si": 3,
        "j/'xi/\u0000xj//": 1,
        "xsiis": 1,
        "search": 2,
        "window": 3,
        "'is": 1,
        "potential": 6,
        "quanti": 2,
        "es": 1,
        "iand": 1,
        "j/d1": 1,
        "zi/expn": 1,
        "xei/\u0000x\u0000": 2,
        "ej\u0001": 2,
        "h2o": 1,
        "zi/dp": 1,
        "j2siexpn": 1,
        "a=h2o": 1,
        "normalizing": 1,
        "eiandejare": 1,
        "neighborhood": 2,
        "iandj": 1,
        "ei": 2,
        "ej": 1,
        "patchwindow": 1,
        "andej": 1,
        "notation": 1,
        "k\u0001k2": 1,
        "adenotes": 1,
        "gaussian": 3,
        "euclidean": 1,
        "distance": 1,
        "abeing": 1,
        "standard": 4,
        "deviation": 3,
        "hthe": 1,
        "decay": 1,
        "exponential": 1,
        "edgepreserving": 2,
        "restoration": 1,
        "later": 1,
        "successfully": 1,
        "apply": 4,
        "usually": 1,
        "possess": 1,
        "2c\u0015\u0001r": 1,
        "dp": 1,
        "i2inlxi//": 1,
        "find": 6,
        "steep": 1,
        "descend": 1,
        "direction": 1,
        "derivative": 2,
        "inspired": 1,
        "'as": 1,
        "'xi/\u0000xj//ds": 1,
        "1c\u0012xi/\u0000xj//": 1,
        "\u0011\u00132": 1,
        "\u00001": 1,
        "\u0011was": 1,
        "'xi/\u0000xj//": 1,
        "xi/dxi/": 1,
        "\u00112r": 1,
        "1c\u0010": 1,
        "xi/\u0000xj//": 1,
        "\u0011\u00112": 1,
        "illustrate": 1,
        "preferable": 1,
        "characteristic": 1,
        "hyperbolic": 1,
        "based": 3,
        "regularizaiton": 2,
        "assumption": 1,
        "clean": 2,
        "approx": 1,
        "imated": 1,
        "implies": 1,
        "basis/dictionary": 1,
        "ie": 1,
        "xddu": 2,
        "thenuis": 1,
        "code": 2,
        "nonzero": 1,
        "entry": 1,
        "ucan": 1,
        "l1norm": 1,
        "minkuk1s": 1,
        "pdwdu": 1,
        "mechanism": 1,
        "udarg": 1,
        "2kp\u0000wduk2": 1,
        "2c\u0015skuk1\u001b": 1,
        "nd": 6,
        "dthat": 1,
        "sparsely": 1,
        "win": 1,
        "wd": 1,
        "minimizing": 1,
        "ista": 1,
        "nal": 3,
        "transfer": 3,
        "back": 2,
        "combined": 1,
        "purpose": 3,
        "nlmbased": 2,
        "rather": 1,
        "averag": 1,
        "neighboring": 1,
        "utilize": 1,
        "structure": 3,
        "texture": 1,
        "observation": 2,
        "via": 2,
        "l1normbased": 3,
        "regular": 2,
        "ization": 2,
        "streaking": 3,
        "cost": 1,
        "contained": 1,
        "three": 3,
        "parts\u0016the": 1,
        "tting": 5,
        "de": 7,
        "ned": 7,
        "2c\u0015nlm\u0001r": 1,
        "c\u0015s": 1,
        "d\u00001x": 1,
        "1\u001b": 1,
        "\u0015nlmand\u0015swere": 1,
        "connect": 2,
        "nlmcs": 15,
        "various": 2,
        "type": 1,
        "wavelet": 14,
        "dfor": 1,
        "stick": 1,
        "waveletbased": 2,
        "proveofconcept": 1,
        "pur": 1,
        "dwas": 1,
        "four": 2,
        "level": 2,
        "bior68": 1,
        "transform": 1,
        "however": 5,
        "alternative": 2,
        "decomposition": 1,
        "possibly": 1,
        "complete": 1,
        "adapt": 1,
        "provide": 5,
        "prove": 1,
        "iter": 2,
        "ative": 1,
        "update": 6,
        "leastsquares": 1,
        "sub": 1,
        "lx/d1": 1,
        "2c\u0015nlm\u0001rx/": 1,
        "iteration": 5,
        "xkc1as": 1,
        "xkc1dx\u0000": 2,
        "\u0001\u0014": 1,
        "wtwx\u0000p/c2\u0015nlm\u0001": 1,
        "x\u0015": 1,
        "dx\u0000": 1,
        "\u0001\u0010": 1,
        "wtwx\u0000p/": 2,
        "c2\u0015": 2,
        "nlm\u0001x": 1,
        "i2ix": 1,
        "j/": 2,
        "xi/\u0000xj/": 2,
        "xi/1": 1,
        "second": 4,
        "optimize": 1,
        "intermediate": 1,
        "uis": 1,
        "let": 3,
        "xdduwe": 1,
        "another": 1,
        "ofu": 1,
        "pu/d\u0015skuk1c1": 1,
        "d\u00001xkc1\u0000u": 1,
        "soft\u001ad8": 1,
        "x\u0000\u001a": 1,
        "ifx": 1,
        "xc\u001a": 1,
        "otherwise": 1,
        "x2r": 1,
        "and\u001a": 1,
        "ukc1as": 1,
        "ukc1dsoft\u0015s\u0010": 1,
        "d\u00001xkc1\u0011": 1,
        "ukc1back": 1,
        "updated": 1,
        "xkc1ddukc1": 1,
        "stop": 2,
        "total": 3,
        "errdjjpwxkc1jj2": 1,
        "less": 1,
        "prede": 1,
        "maximum": 1,
        "ki": 1,
        "meet": 1,
        "summarize": 1,
        "inalgorithm": 1,
        "regularized": 3,
        "input": 1,
        "x0/": 1,
        "or0": 1,
        "itermax": 1,
        "repeat": 1,
        "xkc1using": 1,
        "\u0001\u0000": 1,
        "nlm\u0001p": 1,
        "i2ip": 1,
        "xi/": 1,
        "ukc1using": 1,
        "ukc1dsoft\u0015s\u0000": 1,
        "d\u00001xkc1\u0001": 1,
        "xkc1": 1,
        "dukc1": 1,
        "calculate": 13,
        "err": 2,
        "norm\u0000": 1,
        "p\u0000wxkc1\u0001": 1,
        "kc1": 1,
        "convergence": 3,
        "max": 1,
        "output": 1,
        "102139x": 1,
        "setup": 3,
        "trialanderror": 5,
        "choosing": 2,
        "parameters": 1,
        "stable": 1,
        "tradeoff": 1,
        "kp\u0000wxk2": 1,
        "carefully": 1,
        "order": 1,
        "avoid": 2,
        "suitable": 2,
        "lcurve": 4,
        "loglog": 1,
        "plot": 1,
        "norm": 2,
        "possible": 1,
        "selection": 2,
        "lie": 1,
        "corner": 1,
        "smooth": 4,
        "case": 2,
        "fail": 1,
        "optimal": 4,
        "address": 2,
        "herein": 1,
        "trialand": 2,
        "explain": 1,
        "take": 1,
        "example": 1,
        "ne": 1,
        "\u0015d": 1,
        "oc\u0016": 1,
        "1c\u001b2": 1,
        "2c\u0010": 1,
        "\u0016\u0001\u001b2\u0011": 1,
        "\u0015is": 1,
        "\u0016and\u001b2are": 1,
        "variance": 7,
        "without": 3,
        "coef": 7,
        "cients": 3,
        "series": 2,
        "\u0015for": 1,
        "simply": 1,
        "estimate": 4,
        "acquire": 5,
        "kind": 3,
        "empir": 1,
        "ically": 1,
        "would": 1,
        "of\u0015": 1,
        "\u0016and\u001b2estimated": 1,
        "\u0015dx": 1,
        "establish": 1,
        "xd": 1,
        "size": 4,
        "\u001b2": 2,
        "nally": 1,
        "multiple": 3,
        "regres": 1,
        "sion": 1,
        "analysis": 4,
        "demonstrate": 2,
        "nude": 3,
        "mouse": 7,
        "head": 9,
        "liver": 7,
        "kidney": 7,
        "frame": 1,
        "regression": 5,
        "0d": 1,
        "33957\u000210\u00005": 1,
        "1d\u000032573\u000210\u00007": 1,
        "2d\u000012376\u000210\u00007": 1,
        "3d14102\u000210\u00009": 1,
        "con": 1,
        "dence": 1,
        "interval": 1,
        "19971\u000210\u00005": 1,
        "47943\u000210\u00005": 1,
        "46644\u000210\u00007": 1,
        "18502\u000210\u00007": 1,
        "17008\u000210\u00007": 1,
        "77443\u0002": 1,
        "10\u00008": 1,
        "99507\u000210\u000010": 1,
        "19052\u000210\u00009": 1,
        "equation": 2,
        "write": 1,
        "\u0015d33957\u000210\u0000532573\u000210\u00007\u0016": 1,
        "\u000012376\u000210\u00007\u001b2c14102\u000210\u00009\u0016\u001b2": 1,
        "figure": 25,
        "testing": 1,
        "dataset": 1,
        "relationship": 1,
        "fig": 25,
        "pvalue": 1,
        "cient": 4,
        "determination": 1,
        "r2of": 1,
        "pd34762\u000210\u000014andr2d09325": 1,
        "consider": 1,
        "employ": 2,
        "\u0015nlm": 1,
        "and\u0015s": 1,
        "preestimation": 1,
        "zero": 1,
        "correction": 1,
        "trivial": 1,
        "task": 1,
        "lter": 1,
        "empiri": 1,
        "cally": 1,
        "extensive": 2,
        "tative": 1,
        "visual": 1,
        "inspection": 1,
        "11\u000211": 1,
        "searchwindow": 1,
        "7\u00027": 1,
        "adequate": 1,
        "retain": 1,
        "ciency": 1,
        "h2d2": 1,
        "0jnij": 1,
        "where\u001b2": 1,
        "0denotes": 1,
        "reconstructed": 13,
        "jnijdenotes": 1,
        "scale": 2,
        "exper": 1,
        "iments": 1,
        "ideally": 1,
        "vious": 1,
        "rstly": 1,
        "netune": 1,
        "implementation": 2,
        "necessary": 1,
        "adjust": 1,
        "already": 1,
        "enough": 1,
        "table": 16,
        "iii": 1,
        "experimental": 7,
        "setups": 1,
        "methods": 1,
        "multispectral": 2,
        "commercially": 1,
        "available": 1,
        "chamber": 3,
        "128elecment": 1,
        "fiber": 1,
        "illumination": 2,
        "port": 3,
        "schematic": 2,
        "positons": 1,
        "cover": 2,
        "270\u000espan": 2,
        "td": 1,
        "platform": 2,
        "msot": 4,
        "invision128": 1,
        "ithera": 1,
        "germany": 1,
        "design": 3,
        "photo": 1,
        "ber": 1,
        "visible": 1,
        "separate": 2,
        "bundle": 1,
        "bers": 1,
        "uniformly": 1,
        "distribute": 1,
        "surface": 2,
        "duration": 1,
        "around": 2,
        "repetition": 1,
        "rate": 2,
        "hz": 1,
        "lled": 2,
        "water": 2,
        "submerge": 1,
        "horizontal": 1,
        "holder": 3,
        "ringshape": 1,
        "consist": 4,
        "mm": 1,
        "central": 1,
        "frequency": 2,
        "mhz": 4,
        "6db": 1,
        "bandwidth": 1,
        "sampling": 1,
        "wavelength": 2,
        "tunable": 1,
        "nm": 5,
        "slice": 1,
        "validate": 1,
        "posed": 1,
        "exactly": 1,
        "2d": 1,
        "reference": 3,
        "300\u0002300": 3,
        "perfor": 1,
        "mance": 1,
        "crime": 1,
        "simulate": 1,
        "resampled": 1,
        "add": 1,
        "10db": 1,
        "simulated": 1,
        "equivalent": 1,
        "30mm\u000230mm": 1,
        "1500m/s": 2,
        "criterion": 1,
        "d1\u000210\u000012": 1,
        "anditermaxd500": 1,
        "implement": 2,
        "matlab": 1,
        "desktop": 1,
        "pc": 1,
        "quadcore": 1,
        "cpu": 1,
        "8gb": 1,
        "memory": 1,
        "experiments": 3,
        "evaluate": 2,
        "cylindrical": 2,
        "shape": 1,
        "diameter": 2,
        "cm": 1,
        "create": 1,
        "agar": 1,
        "intralipid": 1,
        "cavity": 4,
        "different": 17,
        "light": 2,
        "black": 1,
        "chinese": 2,
        "ink": 5,
        "jections": 1,
        "contain": 2,
        "timesamples": 1,
        "accordance": 1,
        "institutional": 1,
        "guideline": 1,
        "week": 1,
        "subject": 2,
        "anesthetize": 1,
        "mixture": 1,
        "iso": 1,
        "urane": 1,
        "oxygen": 1,
        "anesthesia": 1,
        "scanner": 1,
        "anesthetized": 1,
        "place": 1,
        "thin": 1,
        "layer": 1,
        "gel": 1,
        "circumference": 1,
        "wrap": 1,
        "plastic": 1,
        "foil": 1,
        "mem": 1,
        "brane": 1,
        "102141x": 1,
        "temporal": 1,
        "medium": 1,
        "m/s": 1,
        "metrics": 1,
        "quantitative": 5,
        "metric": 1,
        "root": 2,
        "square": 2,
        "rmsd": 5,
        "signaltonoise": 1,
        "snr": 13,
        "tonoise": 1,
        "cnr": 12,
        "theoretical": 1,
        "rmsddvuut1": 1,
        "nnx": 1,
        "nd1": 1,
        "xn": 2,
        "1\u0000xn": 1,
        "1andxn": 1,
        "2are": 1,
        "nth": 1,
        "x1andx2": 4,
        "nis": 1,
        "ampli": 1,
        "tudes": 1,
        "background": 11,
        "db": 1,
        "snrd20": 1,
        "log10\u0012at": 1,
        "sdb\u0013": 1,
        "atis": 1,
        "rootmeansquare": 1,
        "amplitude": 1,
        "tar": 1,
        "get": 1,
        "sdbis": 1,
        "divide": 1,
        "cnrdjxt\u0000xbj": 1,
        "\u001bb": 1,
        "wherenxtandnxbare": 1,
        "\u001bbis": 1,
        "structural": 2,
        "ssim": 2,
        "x1andx2is": 1,
        "ssimd\u0000": 1,
        "2\u0016x1\u0016x2cc1\u0001\u0000": 1,
        "2\u001bx1\u0001x2cc2\u0001": 1,
        "\u00162x1c\u00162x2cc1\u0001\u0000": 1,
        "\u001b2x1c\u001b2x2cc2\u0001": 1,
        "\u0016x1and\u0016x2are": 1,
        "\u001bx1and\u001bx2are": 1,
        "\u001bx1\u0001x2": 1,
        "covariance": 1,
        "small": 3,
        "constant": 1,
        "c1": 1,
        "c2andc3are": 1,
        "c1dk1l/2": 1,
        "c2dk2l/2": 1,
        "andc3dc2=2": 1,
        "lis": 1,
        "dynamic": 1,
        "d255": 1,
        "bits/pixel": 1,
        "gray": 1,
        "1and": 1,
        "k2are": 1,
        "k1d001": 1,
        "k2d003": 1,
        "iv": 1,
        "results": 3,
        "test": 1,
        "com": 2,
        "par": 1,
        "non": 1,
        "residual": 3,
        "enlarged": 3,
        "enclose": 5,
        "box": 23,
        "clearly": 1,
        "enhance": 1,
        "subtract": 1,
        "correspond": 1,
        "enlarge": 2,
        "list": 4,
        "intensity": 6,
        "le": 6,
        "mark": 3,
        "yellow": 9,
        "dashed": 4,
        "line": 4,
        "conform": 1,
        "respect": 1,
        "conclude": 2,
        "bet": 1,
        "ter": 1,
        "profile": 2,
        "extract": 1,
        "tissuemimicking": 1,
        "sharp": 2,
        "boundary": 2,
        "inner": 1,
        "uniform": 1,
        "prominent": 1,
        "outside": 2,
        "next": 1,
        "label": 6,
        "cyan": 4,
        "dash": 6,
        "additional": 3,
        "val": 1,
        "idate": 1,
        "stability": 2,
        "insertion": 1,
        "indocyanine": 1,
        "icg": 5,
        "cm\u00001at": 1,
        "display": 1,
        "arbitrary": 1,
        "comparison": 3,
        "chose": 1,
        "quantify": 1,
        "\u0016inkdpink\u0016icg": 1,
        "picg": 1,
        "pinkandpicgare": 1,
        "interest": 1,
        "roi": 1,
        "\u0016icgis": 1,
        "cm\u00001": 2,
        "the\u0016inkis": 1,
        "five": 2,
        "pair": 1,
        "rois": 4,
        "select": 1,
        "\u0016ink": 1,
        "serve": 1,
        "zoomedin": 7,
        "\u0016inkvalues": 2,
        "six": 1,
        "analyzed": 1,
        "oneway": 1,
        "anov": 2,
        "spss": 2,
        "sta": 1,
        "tistical": 1,
        "product": 1,
        "service": 1,
        "solutions": 1,
        "whether": 1,
        "signi": 3,
        "cantly": 2,
        "fd0423": 1,
        "f001": 1,
        "d390": 1,
        "cant": 1,
        "oa": 1,
        "102143x": 1,
        "\u0016inkobtained": 1,
        "anova": 1,
        "fair": 1,
        "parison": 1,
        "blue": 6,
        "comparing": 2,
        "contour": 1,
        "organ": 1,
        "detailed": 1,
        "mention": 1,
        "hardly": 1,
        "noticeable": 1,
        "obvious": 2,
        "blur": 1,
        "lose": 1,
        "alone": 1,
        "moreover": 2,
        "posi": 1,
        "illustrated": 1,
        "ac": 1,
        "suggest": 1,
        "superior": 3,
        "arrows": 1,
        "indicate": 2,
        "renal": 1,
        "cortex": 1,
        "arrow": 6,
        "spleen": 1,
        "intestine": 1,
        "spinal": 1,
        "cord": 1,
        "body": 1,
        "tiny": 1,
        "blood": 1,
        "vessel": 1,
        "profiles": 1,
        "along": 2,
        "mssim": 3,
        "score": 1,
        "properly": 1,
        "regulariza": 1,
        "desirable": 1,
        "inherently": 1,
        "resolve": 1,
        "regularize": 1,
        "couple": 1,
        "overall": 1,
        "goal": 1,
        "simultaneously": 2,
        "delity": 1,
        "accuracy": 1,
        "phan": 1,
        "tom": 1,
        "effectiveness": 1,
        "achieve": 2,
        "102145x": 1,
        "kkidney": 1,
        "hhead": 1,
        "lliver": 1,
        "removal": 1,
        "sup": 1,
        "pression": 1,
        "qualitatively": 1,
        "quantitatively": 1,
        "seamlessly": 1,
        "translational": 1,
        "offer": 1,
        "improvement": 3,
        "limitation": 1,
        "complexity": 1,
        "require": 1,
        "long": 2,
        "close": 1,
        "mostly": 1,
        "cause": 1,
        "algorithmcould": 1,
        "largely": 1,
        "accelerated": 1,
        "although": 1,
        "allow": 1,
        "incorporation": 1,
        "even": 1,
        "though": 1,
        "idea": 1,
        "behind": 1,
        "directly": 1,
        "applicable": 1,
        "fur": 1,
        "ther": 1,
        "potentially": 1,
        "correct": 1,
        "heterogeneity": 1,
        "vi": 1,
        "try": 1,
        "complemen": 1,
        "tary": 1,
        "namely": 1,
        "outperform": 1
    },
    "objective": [
        "in this paper , we present a new dual-constraint oat imaging model involve a combination of non-local mean ltering and sparse coding , with the former to preserve image detail by self-similarity and the latter to enforce sparsity .",
        "a two-step optimization algorithm and an iterative parameter tune method be propose to ensure accurate solution .",
        "var- ious regularization approach have be propose for the oat image reconstruction problem , include the tikhonov method [ 18 ] , [ 19 ] , the total-variation method [ 20 ] , [ 21 ] , and sparsity-based method [ 22 ] \u0015 [ 26 ] .",
        "in this paper , we propose a novel oat image model that combine two now classical regularization technique into a single framework : the non-local mean method to image reconstruction explicitly exploit self-similarities in oat image to average out the noise among similar patch , whereas sparse cod encodes optoacoustic image statistic by decompose the image into a linear combination of a few element from a basis set call a dictionary .",
        "numerical simulation and in vivo animal image experiment be carry out to verify the propose method , and the result show that ourmethod have a good performance compare to use only nlm or sparse coding as a single regularization term .",
        "the proposed regularization scheme 1 ) the non-local means regularization the non-local mean algorithm be rst present as an image denoising method [ 27 ] , it work by nding simi- lar patch across the non-local region within the image , and then performs weight average operation for those patch accord to their similarity .",
        "experimental result show that the propose method outperform other previous single constraint scheme , thus provide an alternative imaging strategy for image quality improvement in pre-clinical and clinical oat application ."
    ],
    "references": [
        "",
        "REFERENCES [1] J. Xia, J. Yao, and L. V. Wang, ``Photoacoustic tomography: Principles and advances,'' Prog. Electromagn. Res., vol. 147, pp. 1\u001522, May 2014. [2] L. V. Wang and J. Yao, ``A practical guide to photoacoustic tomography in the life sciences,'' Nat. Methods, vol. 13, no. 8, pp. 627\u0015638, Jul. 2016. [3] J. Xia and L. V. Wang, ``Small-animal whole-body photoacoustic tomogra- phy: A review,'' IEEE Trans. Biomed. Eng., vol. 61, no. 5, pp. 1380\u00151389, May 2014. 102146 VOLUME 7, 2019X. Li et al.: Model-Based OAT Image Reconstruction With Non-Local and Sparsity Regularizations [4] L. V. Wang and S. Hu, ``Photoacoustic tomography: In vivo imaging from organelles to organs,'' Science, vol. 335, no. 6075, pp. 1458\u00151462, Mar. 2012. [5] J. Chen, R. Lin, H. Wang, J. Meng, H. Zheng, and L. Song, ``Blind- deconvolution optical-resolution photoacoustic microscopy in vivo,'' Opt. Express, vol. 21, no. 6, pp. 7316\u00157327, 2013. [6] J. Yao, J. Xia, and L. V. Wang, ``Multiscale functional and molecular photoacoustic tomography,'' Ultrason. Imag., vol. 38, no. 1, pp. 44\u001562, Jan. 2016. [7] C. Li and L. V. Wang, ``Photoacoustic tomography and sensing in biomedicine,'' Phys. Med. Biol., vol. 54, no. 19, p. R59, Oct. 2009. [8] A. Dima and V. Ntziachristos, ``Non-invasive carotid imaging using optoa- coustic tomography,'' Opt. Express, vol. 20, pp. 25044\u001525057, Oct. 2012. [9] M. Xu and L. V. Wang, ``Universal back-projection algorithm for photoa- coustic computed tomography,'' Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., vol. 71, no. 1, 2005, Art. no. 016706. [10] M. Xu, Y. Xu, and L. V. Wang, ``Time-domain reconstruction algorithms and numerical simulations for thermoacoustic tomography in various geometries,'' IEEE Trans. Biomed. Eng., vol. 50, no. 9, pp. 1086\u00151099, Sep. 2003. [11] M. Xu and L. V. Wang, ``Time-domain reconstruction for thermoacoustic tomography in a spherical geometry,'' IEEE Trans. Med. Imag., vol. 21, no. 7, pp. 814\u0015822, Jul. 2002. [12] L. Liu, C. Tao, X. Liu, M. Deng, S. Wang, and J. Liu, ``Photoacous- tic tomography from weak and noisy signals by using a pulse decom- position algorithm in the time-domain,'' Opt. Express, vol. 23, no. 21, pp. 26969\u001526977, 2015. [13] A. Rosenthal, D. Razansky, and V. Ntziachristos, ``Fast semi-analytical model-based acoustic inversion for quantitative optoacoustic tomography,'' IEEE Trans. Med. Imag., vol. 29, no. 6, pp. 1275\u00151285, Jun. 2010. [14] H. Liu, K. Wang, D. Peng, H. Li, Y. Zhu, S. Zhang, M. Liu, and J. Tian, ``Curve-driven-based acoustic inversion for photoacoustic tomography,'' IEEE Trans. Med. Imag., vol. 35, no. 12, pp. 2546\u00152557, Dec. 2016. [15] K. Wang, S. A. Ermilov, R. Su, H.-P. Brecht, A. A. Oraevsky, and M. A. Anastasio, ``An imaging model incorporating ultrasonic transducer properties for three-dimensional optoacoustic tomography,'' IEEE Trans. Med. Imag., vol. 30, no. 2, pp. 203\u0015214, Feb. 2011. [16] C. Tao and X. Liu, ``Reconstruction of high quality photoacoustic tomog- raphy with a limited-view scanning,'' Opt. Express, vol. 18, no. 3, pp. 2760\u00152766, 2010. [17] J. Prakash, S. Mandal, D. Razansky, and V. Ntziachristos, ``Maximum entropy based non-negative optoacoustic tomographic image reconstruc- tion,'' IEEE Trans. Biomed. Eng., to be published. [18] D. Calvetti, S. Morigi, L. Reichel, and F. Sgallari, ``Tikhonov regulariza- tion and the L-curve for large discrete ill-posed problems,'' J. Comput. Appl. Math., vol. 123, nos. 1\u00152, pp. 423\u0015446, Nov. 2000. [19] C. B. Shaw, J. Prakash, M. Pramanik, and P. K. Yalavarthy, ``Least squares QR-based decomposition provides an ef\u001ccient way of computing optimal regularization parameter in photoacoustic tomography,'' J. Biomed. Opt., vol. 18, no. 8, Aug. 2013, Art. no. 080501. [20] J. Wang and Y. Wang, ``Photoacoustic imaging reconstruction using com- bined nonlocal patch and total-variation regularization for straight-line scanning,'' Biomed. Eng. Online, vol. 17, no. 1, p. 105, Aug. 2018. [21] Y. Zhang, Y. Wang, and C. Zhang, ``Total variation based gradient descent algorithm for sparse-view photoacoustic image reconstruction,'' Ultrason- ics, vol. 52, no. 8, pp. 1046\u00151055, Dec. 2012. [22] Z. Guo, C. Li, L. Song, and L. V. Wang, ``Compressed sensing in pho- toacoustic tomography in vivo,'' J. Biomed. Opt., vol. 15, Mar. 2010, Art. no. 021311. [23] H. Moradi, S. Tang, and S. E. Salcudean, ``Deconvolution based photoa- coustic reconstruction with sparsity regularization,'' Opt. Express, vol. 25, no. 3, pp. 2771\u00152789, Feb. 2017. [24] Y. Han, L. Ding, X. L. D. Ben, D. Razansky, J. Prakash, and V. Ntziachristos, ``Three-dimensional optoacoustic reconstruction using fast sparse representation,'' Opt. Lett., vol. 42, no. 5, pp. 979\u0015982, 2017. [25] J. Meng, L. V. Wang, D. Liang, and L. Song, ``In vivo optical-resolution photoacoustic computed tomography with compressed sensing,'' Opt. Lett., vol. 37, no. 22, pp. 4573\u00154575, 2012. [26] J. Meng, L. V. Wang, L. Ying, D. Liang, L. J. M. Song, and B. Imaging, ``Compressed-sensing photoacoustic computed tomography in vivo with partially known support,'' Opt. Express, vol. 20, no. 15, pp. 16510\u001516523, 2012.[27] A. Buades, B. Coll, and J.-M. Morel, ``A non-local algorithm for image denoising,'' in Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recog- nit. (CVPR), vol. 2, Jun. 2005, pp. 60\u001565. [28] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, ``Image denoising by sparse 3-D transform-domain collaborative \u001cltering,'' IEEE Trans. Image Process., vol. 16, no. 8, pp. 2080\u00152095, Aug. 2007. [29] L. Lu, J. Ma, Q. Feng, W. Chen, and A. Rahmim, ``Anatomy-guided brain PET imaging incorporating a joint prior model,'' Phys. Med. Biol., vol. 60, no. 6, pp. 2145\u00152166, Mar. 2015. [30] Z. Yang and M. Jacob, ``Nonlocal regularization of inverse problems: A uni\u001ced variational framework,'' IEEE Trans. Image. Process., vol. 22, no. 8, pp. 3192\u00153203, Aug. 2013. [31] H. Zhang, D. Zeng, J. Lin, H. Zhang, Z. Bian, J. Huang, Y. Gao, S. Zhang, H. Zhang, Q. Feng, Z. Liang, W. Chen, and J. Ma, ``Iterative reconstruction for dual energy CT with an average image-induced nonlocal means regu- larization,'' Phys. Med. Biol., vol. 62, no. 13, pp. 5556\u00155574, Jul. 2017. [32] X. L. Dean-Ben, A. Buehler, V. Ntziachristos, and D. Razansky, ``Accurate model-based reconstruction algorithm for three-dimensional optoacoustic tomography,'' IEEE Trans. Med. Imag., vol. 31, no. 10, pp. 1922\u00151928, Oct. 2012. [33] J. Dutta, S. Ahn, C. Li, S. R. Cherry, and R. M. Leahy, ``Joint L1 and total variation regularization for \u001duorescence molecular tomography,'' Phys. Med. Biol., vol. 57, no. 6, pp. 1459\u00151476, Mar. 2012. [34] Z. Chen, L. Xia, F. Liu, Q. Wang, Y. Li, X. Zhu, and F. Huang, ``An improved non-Cartesian partially parallel imaging by exploiting arti- \u001ccial sparsity,'' Magn. Reson. Med., vol. 78, no. 1, pp. 271\u0015279, 2016. [35] A. Beck and M. Teboulle, ``A fast Iterative Shrinkage-Thresholding Algo- rithm with application to wavelet-based image deblurring,'' in Proc. IEEE Int. Conf. Acoust., Apr. 2009, pp. 693\u0015696. [36] S. Mallat, A Wavelet Tour of Signal Processing, 2nd ed. San Diego, CA, USA: Academic, 1999. [37] M. Elad, ``Image denoising via sparse and redundant representations over learned dictionaries,'' IEEE Trans. Image Process., vol. 54, no. 12, pp. 3736\u00153745, Dec. 2006. [38] J. Mairal, M. Elad, and G. Sapiro, ``Sparse representation for color image restoration,'' IEEE Trans. Image Process., vol. 17, no. 1, pp. 53\u001569, Jan. 2008. [39] P. C. Hansen, ``The L-curve and its use in the numerical treatment of inverse problem,'' in InviteComputational Inverse Problems in Electrocardiology. Southampton, U.K.: WIT Press, 2000. [40] D. Razansky, M. Distel, C. Vinegoni, R. Ma, N. Perrimon, R. W. Köster, and V. Ntziachristos, ``Multispectral opto-acoustic tomography of deep- seated \u001duorescent proteins in vivo,'' Nature Photon., vol. 3, no. 7, pp. 412\u0015417, 2009. [41] D. Razansky, A. Buehler, and V. Ntziachristos, `` Volumetric real-time multispectral optoacoustic tomography of biomarkers,'' Nat. Protocols, vol. 6, no. 8, pp. 1121\u00151129, Jul. 2011. [42] X. L. Dean-Ben, V. Ntziachristos, and D. Razansky, ``Acceleration of optoacoustic model-based reconstruction using angular image discretiza- tion,'' IEEE Trans. Med. Imag., vol. 31, no. 5, pp. 1154\u00151162, May 2012. [43] T. Jetzfellner, A. Rosenthal, K.-H. Englmeier, A. Dima, M. Á. A. Caballero, D. Razansky, and V. Ntziachristos, ``Interpolated model-matrix optoacoustic tomography of the mouse brain,'' Appl. Phys. Lett., vol. 98, no. 16, 2011, Art. no. 163701. [44] J. Kaipio and E. Somersalo, ``Statistical inverse problems: Discretization, model reduction and inverse crimes,'' J. Comput. Appl. Math., vol. 198, pp. 493\u0015504, 2007. [45] A. Kazakeviciute, C. J. H. Ho, and M. Olivo, ``Multispectral photoa- coustic imaging artifact removal and denoising using time series model- based spectral noise estimation,'' IEEE Trans. Med. Imag., vol. 35, no. 9, pp. 2151\u00152163, Sep. 2016. [46] J. Froment, ``Parameter-free fast pixelwise non-local means denoising,'' Image Process. Line, vol. 4, pp. 300\u0015326, Nov. 2014. [47] J. Wang, Y. Guo, Y. Ying, Y. Liu, and Q. Peng, ``Fast non-local algorithm for image denoising,'' in Proc. IEEE Int. Conf. Image Process., Oct. 2007, pp. 1429\u00151432. [48] J. Ma, J. Huang, Q. Feng, H. Zhang, H. Lu, Z. Liang, and W. Chen, ``Low- dose computed tomography image restoration using previous normal-dose scan,'' Med. Phys., vol. 38, no. 10, pp. 5713\u00155731, Oct. 2011. [49] F. M. Brochu, J. Brunker, J. Joseph, M. R. Tomaszewski, S. Morscher, and S. E. Bohndiek, ``Towards quantitative evaluation of tissue absorption coef\u001ccients using light \u001duence correction in optoacoustic tomography,'' IEEE Trans. Med. Imag., vol. 36, no. 1, pp. 322\u0015331, Jan. 2017. VOLUME 7, 2019 102147X. Li et al.: Model-Based OAT Image Reconstruction With Non-Local and Sparsity Regularizations [50] S. Mandal, X. L. Deán-Ben, and D. Razansky, ``Visual quality enhance- ment in optoacoustic tomography using active contour segmentation pri- ors,'' IEEE Trans. Med. Imag., vol. 35, no. 10, pp. 2209\u00152217, Oct. 2016. XIPAN LI received the B.S. degree in biomed- ical engineering from Southern Medical Univer- sity, in 2016, where she is currently pursuing the Ph.D. degree with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomedical Engineering. Her research inter- est includes preclinical and clinical photoacoustic imaging for diagnostics and therapy guidance. LI QI received the Ph.D. degree in optical engineering from Nanjing University, in 2016. He is currently a Lecturer with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China. His research interests include photoacoustic imag- ing and optical coherence tomography. SHUANGYANG ZHANG received the B.Eng. degree from Southern Medical University, in 2017, where he is currently pursuing the master's degree in engineering with the School of Biomedical Engineering. His research interests include multi- modal image registration and information fusion. SHIXIAN HUANG received the B.S. degree in biomedical engineering from the School of Biomedical Engineering, Southern Medical Uni- versity, in 2018, where she is currently pursuing the master's degree with the Institute of Medical Information. Her research interests include \u001duo- rescence microscopy. JIAN WU received the B.Eng. degree from Guangzhou Medical University, in 2018. He is currently pursuing the master's degree in biomedi- cal engineering with Southern Medical University. His current research subject is image restoration methods for photoacoustic imaging. LIJUN LU received the Ph.D. degree in biomedi- cal engineering from Southern Medical University, in 2012, where he is currently an Associate Pro- fessor with the Guangdong Provincial Key Lab- oratory of Medial Image Processing, School of Biomedical Engineering. His research interests include medical image processing and PET imag- ing methods. YANQIU FENG received the M.Sc. and Ph.D. degrees in biomedical engineering from Southern Medical University, in 2003 and 2005, respec- tively, where he is currently a Full Professor with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomedical Engineering. His current research interests include MRI imaging and image processing. QIANJIN FENG received the B.S., M.Sc., and Ph.D. degrees in biomedical engineering from Southern Medical University, in 1996, 2000, and 2003, respectively, where he is currently a Full Professor with the Guangdong Provincial Key Laboratory of Medial Image Processing, School of Biomedical Engineering. His current research interest includes biomedical image analysis. WUFAN CHEN received the B.S. and M.Sc. degrees from Beihang University, in 1975 and 1981, respectively. He is currently a Full Pro- fessor with the Guangdong Provincial Key Lab- oratory of Medial Image Processing, School of Biomedical Engineering. His research interests include biomedical imaging principle and image processing. 102148 VOLUME 7, 2019"
    ]
}{
    "name": "PET Reconstruction With an Anatomical MRI Prior Using Parallel Level Sets",
    "paragraphs": [
        "ieeetransactions on medicalimaging , vol.35 , no.9 , september 2016 2189 pet reconstruction with an anatomical mri prior using parallel level sets matthias j. ehrhardt * , pawel markiewicz , maria liljeroth , anna barnes , ville kolehmainen , john s. duncan , luis pizarro , david atkinson , brian f. hutton , senior member , ieee , sébastien ourselin , kris thielemans , senior member , ieee , and simon r. arridge abstract— the combination of positron emission tomography ( pet ) and magnetic resonance imaging ( mri ) offer unique pos- sibilities.inthispaperweaimtoexploitthehighspatialresolutionof mri to enhance the reconstruct ion of simultaneously acquire pet data .",
        "we propose a new prior to incorporate structural side information into a maximum a posteriori reconstruction .",
        "the new priorcombinesthestrengthsofpreviouslyproposedpriorsforthe same problem : it be very efﬁcient in guide the reconstruction at edge available from the side information and it reduce locallyto edge-preserving total variation in the degenerate case when no structural information be available .",
        "in addition , this prior be segmentation-free , convex and no ap r i o r iassumptions be make on the correlation of edge direction of the pet and mri image .",
        "we present result for a simulated brain phantom and for real data acquire by the siemens biograph mmr for a hardwarephantom and a clinical scan .",
        "the result from simulation show that the new prior have a good trade-off between enhance common anatomical boundary and preserve unique featuresthan several other prior .",
        "more over , it have a good mean absolute bias-to-mean standard deviation trade-off and yield reconstruc- tions with superior relative -error and structural similarity index .",
        "these ﬁndings be underpin by the real data result from a hardware phantom and a clinical patient conﬁrming that the new prior be capable of promote well-deﬁned anatomicalboundaries .",
        "index terms— anatomica l prior , magnetic resonance imaging , parallel level set , positron emission tomography , totalvariation .",
        "manuscript receive december 17 , 20 15 ; revise march 11 , 2016 ; accept march 29 , 2016 .",
        "date of current version august 30 , 2016 .",
        "this research wasfunded by the epsrc ( ep/k005278/1 ) and ep/h046410/1 and support bythe national institute for health research university college london hos pi- talsbiomedicalresearchcentre.m.j.ehrhardtwassupportedbyanimpactstudentshipfundedjointlybysiemensandtheuclfacultyofengineerings ci- ences .",
        "k. thielemans and d. atkinson be partially support by the epsrcgrant ep/m022587/1 .",
        "asterisk indicate correspond author .",
        "* m. j. ehrhardt be with the centre for medical image computing , wc1e 6bt london , u.k .",
        "he be now with the department for applied mathematicsandtheoreticalphysics , university ofcambridge , cb30wacambridge , u.k .",
        "( e-mail : m.j.ehrhardt @ damtp.cam.ac.uk ) .",
        "p.markiewicz , l.pizarro , s.ourselin , ands.r.arridgearewiththecentr e for medical image computing , wc1e 6bt london , u.k. m.liljeroth , a.barnes , andk.thielemansarewiththeinstitutefornucle ar medicine , university college london , nw1 2bu london , u.k. v. kolehmainen be with the department of applied physics , university of eastern finland , 70211 kuopio , finland .",
        "j. s. duncan be with the institute of neurology , university college london , wc1n 3bg london , u.k. d. atkinson be with the centre for medical imaging , university college london , nw1 2pg london , u.k. b. f. hutton be with the institute for nuclear medicine , university colleg e london , nw1 2bu london , u.k. and the centre for medical radiationphysics , university of wollongong , nsw , australia .",
        "colorversionsofoneormoreoftheﬁguresinthispaperareavailableonlin e at http : //ieeexplore.ieee.org .",
        "digital object identiﬁer 10.1109/tmi.2016.2549601i .",
        "introduction positron emission tomography ( pet ) allow mon- itoring with high sensitivity the distribution of a bio- logically important molecule and therefore to provide unique information for clin ical application ; h owever , pet intrin- sically suffers from low spatial resolution which , due to thepartial volume effect , may prevent it from be quantitative [ 1 ] – [ 5 ] .",
        "high spatial resolution be one of the key strength of magneticresonanceimaging ( mri ) andisoftenavailableeitherfrom a separate scan with the hel p of registration [ 1 ] – [ 3 ] , [ 6 ] or from a combine pet-mri scan ner that can simultaneously image function and structure [ 7 ] – [ 11 ] .",
        "the anatomical mri information can be use to correct for the partial volume effect either po st reconstruction [ 1 ] – [ 3 ] , [ 5 ] orwithinthereconstruction [ 12 ] – [ 14 ] .overthelasttwodecades manypriorshavebeenproposedtoutilizeanatomicalsideinfor- mationintothereconstructionofalowresolutionmodality [ 6 ] , [ 15 ] – [ 30 ] .",
        "the propose method for this task often rely on asegmentation of the anatomical image [ 6 ] , [ 15 ] , be a heuristic modiﬁcation of a minimization p rocedure [ 16 ] , [ 17 ] , [ 20 ] or minimize a non-convex functional [ 18 ] , [ 21 ] – [ 24 ] , [ 29 ] , [ 30 ] .inallcasesthereisacompromise onstability , robustnessand/or theoretical justiﬁcation .",
        "there have be prior propose that do not rely on a seg- mentation and be convex [ 25 ] , [ 26 ] , [ 28 ] , but these lack other desirableproperties.itisimportantthatapriorthatincorporates anatomical information respect the information content in thefunctional image .",
        "as such , it be desirable that the prior reduces locally to an edge-preserved denoising scheme , such as total variation , if no ap r i o r iedge information be available ; which isnotthecasefor [ 26 ] , [ 28 ] .moreover , functionalandanatom- ical image from pet and mri m ight share many edge , but in general we can not expect that the intensity change in thesameway : attheedgeofananatomicalregionthemricontrast might increase while the tracer uptake in pet might decrease orviceversa.thisfeature , alth oughveryimportanttocombine imagesofarbitraryintensities , isnotpartofthemodelproposed in [ 25 ] .inthispaperwecombinethestrengthsof [ 25 ] , [ 26 ] and proposeapriorthatdoesnotrelyonasegmentation , isconvex , preservestheedgesofuniquefeaturesanddoesnotrelyonany assumption on the intensity of the two image .",
        "a .",
        "contributions the contribution in this paper be threefold .",
        "first , we pro- pose a new prior to incorporate structural information into the reconstruction that have all the desired property we outline aboveandweproveitsconvexity.second , weapplyotherpriors this work be license under a creative commons attribution 3.0 license .",
        "fo r more information , see http : //creativecommons.org/licenses/by/3.0/2190 ieee transactions on medicalimaging , vol .",
        "35 , no .",
        "9 , september 2016 thathavebeenusedforotherap plicationstothesettingofpet- mri .",
        "finally , we compare ﬁve different prior in the setting of pet-mri on synthetic phantom data , real phantom data and clinical patient data .",
        "b. set-up we consider pet data as a random variable model as a poisson process [ 31 ] with expectation ( 1 ) where denote the pet image , denote the pet forward operator that includ es scanner geometry , detector normalizationandattenuation , and denotesabackgroundterm need to correct for scatter and randoms .",
        "based on this model , we perform image reconstruction via minimization of an objective function [ 32 ] ( 2 ) where ( 3 ) measure the distance of the estimate data to the ac- quired data .t h ed a t aﬁ t be ( up to an additive constant in- dependent of ) the negative logarithm of the poisson distribu- tionwhichnaturallycallsforanon-negativityconstraintontheimage value for .",
        "the prior introduces ap r i o r iknowledge of the solution we seek .",
        "the regularization parameter allow the balance ofinformationthatcomesfromthedatawithour ap r i o r ibelief aboutthesolution .apopularprioristhe ( smooth ) totalvari- ation [ 33 ] ( 4 ) asitleadstoedge-preserveddenoising.here be introducedto render ( 4 ) differentiable ; it be sometimes consider a scale pa- rameteronthevaluesof belowwhichedgesareconsid- eredtobenoise.wewillreturntoadiscussionofth isparameter later .",
        "inthecontextofpet-mri , wehavestructuralknowledgeon thesolutiongivenbyananatomicalmriimage ; we seek an extension of ( 4 ) which allow us to incorporatethis ap r i o r iedgeinformation.wewillde notearegularizationterm that depend on an associate image by .m oreover , we call the extra information about the structure side information whichprovidespriorinformationaboutthepetimageweseek aside the actual acquire data .",
        "ii .",
        "methods a. asymmetric parallel level sets to simplify the notation , we introduce the spatially varying gradient ﬁeld ( 5 ) with the regularized norm , .t h e parameter playsasimilarroleto in ( 4 ) inthatitscalesdown theinﬂuenceof whenedgesmerelyrepresentnoise.atany location , the vector ﬁeld point in the direction of the gradient but it be normalize such that ( 6 ) where the low bound be obtain if and the upper bound be obtain asymptotically as .",
        "motivated by the ﬁndings in [ 34 ] – [ 37 ] we can measure how structurally similar an image islocally to anotherimage by compare to the gradient ﬁeld by ( 7 ) where denote the euclidean inner product .",
        "the upper bound be obtain when there be no structural sideinformation , i.e.",
        ", , and the low bound ( asymptoti- callyfor ) when isalignedto inthesense thatthereexistsa suchthat .note thatforthecasewhen , thegradientvectorisalignedto any other vector by allow the parameter to be zero .",
        "we derive a global prior by integrate this local measure of similarity over the entire domain ( 8 ) from the local property it follow directly that this prior be non-negative and zero if and only if be align to almost everywhere .",
        "as the gradient be perpendicular to the level setsof , andisperpendiculartothelevelsetsof , wereferto thismeasureofsimilarityofstructuresasthemethodof parallel level set .",
        "thispriorhasallthedesiredproperties : itisconvexin , cf.",
        ", [ 37 ] or proposition 1 in the appendix , it do not depend on asegmentedmriimageandinthedegeneratecasewhenthemriimage be ﬂat , i.e.",
        ", , it reduce to the total variation of the pet image .",
        "moreover , it be independent of the sign andscale of and therefore can be apply to image of arbitrary intensity .",
        "similar to the case of total variation above , we introduce a smoothing parameter ( 9 ) that allow us to employ smooth minimization method .",
        "the extensiontothenon-smoothcase , i.e.",
        ", , willbethesubject of future work .",
        "b .",
        "other methods to incorporate anatomical information we will benchmark our prior against previously propose convexandsegmentation-freepr iors [ 19 ] , [ 25 ] , [ 26 ] , [ 28 ] , [ 38 ] , [ 39 ] .",
        "while some of these have be propose for the verysameapplication [ 19 ] , [ 25 ] , [ 28 ] , othershavebeenproposedforsimilar task in other application such as geophysics [ 38 ] andcolour image [ 39 ] , other modal itieslikeelectricalimpedance tomography ( eit ) combine w ith computer assist tomog- raphy [ 26 ] or joint pet-mri reconstruction [ 35 ] .ehrhardt et al .",
        ": petreconstructionwith ananatomical mri prior using parallel levelset s 2191 1 ) kaipio et al .",
        ": kaipio et al.proposedtoincorporate ap r i o r i knowledge by the prior ( 10 ) whereis deﬁned as in ( 5 ) [ 26 ] .",
        "the original formulation be a littledifferentbutitisequivalentto ( 10 ) withaslightlydifferentnormalization , cf.",
        ", [ 37 ] for detail .",
        "this prior have most of the desired property but , as can be readily see , it reduce to aquadratic functional in the degenerate case , r a t h e rt h a n tototalvariation.thispriorhasbeenproposedoriginallyintheeitcontextandweapplyittothepet-mrisettingfortheﬁrsttime .",
        "2 ) kazantsev et al .",
        ": motivated by the lot model [ 40 ] and the bregman distance for total variation [ 41 ] , it have be pro-posed [ 25 ] to formulate the prior knowledge as ( 11 ) whereagainasmoothingparameterisusedtomaketheproblem differentiable.thismodelﬁxestheproblemofkaipio et al.that featuresin thatarenotpresentin arepenalizedquadratically , andthereforeallowsedgesintheseareas.however , itpenalizesthedeviationof andinawaysothatvectorswithopposite orientation arepenalized even more than orthogonal vector .",
        "3 ) bowsher ’ s prior : ithas be propose by bowsher et al .",
        "to deﬁne a prior on neighbour voxels by ( 12 ) the weight be choose such that the most similar neighbour in the anatomical image have a positiv e weight de- pending on the spatial distance of voxel to voxeland zero otherwise.asitmighthappenthat isweighteddif- ferently than w eu s ea y m m e t r i z e dv e rsion where the weight and be average .",
        "4 ) joint total variation : thelastpriorweben chmarkagainst be joint total variation ( 13 ) whereaparameter isusedtoadjustthescaleofthesidein- formation.ithasbeenﬁrstproposedasanextensionoftotalvari-ation to rgb colour image [ 39 ] and have subsequently beenusedforjointreconstructioning eophysics [ 38 ] andjointrecon- structionofpet-mri [ 35 ] .incontrastto , and , jointtotal variationonlymakesuseofthemagnitudeofthegradientofthesideinformation thereby neglectingpossiblyvaluableinforma-tion .",
        "recently a similar prior ha s be propose to incorporate anatomical information into pet reconstruction [ 19 ] .",
        "an overview of the different method with some key prop- erties be give in table i .",
        "not all of the method reduce to totalvariation in the degenerated case when no side information isavailable.whileallofthemethodsdependonthelocationoftheedges , only , anddepend on the edge orientation .",
        "how- ever , do not allow edge to be negatively correlate .",
        "this mean for example that if there be a “ jump up ” in the side in-formation , thena “ jumpdown ” intheimagetobereconstructedtable i summary of anatomical priors.thelastcategory onlyapplies for methodsthat are orientation dependent .is theonlypriorthat fulfilsall of the fourcriteria.proposed be strongly penalize .",
        "be the only prior that fulﬁls all of the desired criterion .",
        "iii .",
        "numerical set-up algorithm , projections and parameters algorithm : inordertofairlycompareallthedifferentpriors , we use the same method to minimize ( 2 ) with the differentchoicesofpriorsdiscussed inthelastsections.tobemorepre-cise , we use l-bfgs-b [ 42 ] , [ 43 ] where the non-negativityconstraint be implement by pro jecting the iterates onto the non-negative quadrant .",
        "l-bfg s-b be a quasi-newton method thatapproximatestheinverseofthehessianwithﬁrstorderin-formation .",
        "in all case , we run l-bfgs-b for 2000 iterations.implementation be in matlab® .",
        "asthispaperfocusesonpriorsratherthanoptimizationalgo- rithms we do not compare or investigate other algorithm .",
        "weplan to investigate optimization algorithm for this applicationmoreclosely , particularlyforthenon-smoothcasewhen .",
        "1 ) projections : all the data in this paper correspond to the geometryofonedirectplaneofthesiemensbiographmmr® , cf.",
        ", [ 44 ] forscannerspeciﬁcatio n , ﬁxedatagivenaxialposition andformedbysummingsixorﬁve ( dependingontheaxialpo-sition ) direct and cross sinogram s in the scanner 's native axial compression of span-11 .",
        "the pet forward and adjoint opera-tors for this geometry be take from stir ( software for to-mographicimagereconstruction ) [ 45 ] thathasbeeninterfacedto matlab® .",
        "in all case we model the loss of resolution bya gaussian blur of full width at half maximum ( fwhm ) of 4mm 4 mm in image space prior to projection and after back- projection .",
        "2 ) parameters : we test several regularization parameter for all method and show a few of these result , cf.",
        ", the model ( 2 ) .theparameter for , andhasbeenchosenin whichisaround0.1 % -1 % ofthemaximalgradient magnitude of the side information .",
        "the similar parameter for have be choose in [ 1 , 5 ] which lead to gradient of similar magnitude in both ima ge .",
        "for the tv-like prior , we smooth the norm by which be approximately 0.01 % of the expect maximal gradient intensity of the petimage .",
        "for , 4 neighbour from a 3 3 neighbourhood be choose .",
        "for comparison , we a lso ran maximum likelihood expectation maximization ( mlem ) [ 46 ] for up to 500 itera- tions and smooth the ﬁnal iterate with a gaussian ﬁlter withfwhm of 4 mm 4m m .",
        "a. phantoms 1 ) software phantom : the ﬁrst test case be a software phantom , cf.",
        ", fig .",
        "1 ( a ) , which be base on an mri image2192 ieee transactions on medicalimaging , vol .",
        "35 , no .",
        "9 , september 2016 fig.1 .",
        "mrisideinformationandpetdatafor ( a ) softwarephantom , ( b ) hard - ware phantom and ( c ) clinical patient data .",
        "for the software phantom also t he petgroundtruth ( highresolution , lowresolution ) andregionsofinteres t ( grey matter , white matter , lesion ) be show .",
        "obtain from brainweb [ 47 ] and convert into a continuous spline phantom [ 48 ] .",
        "different region in the brain such asgrey matter , white matter , cerebrospinal ﬂuid , cold lesion andhot lesion be then assign a con stant intensity reﬂecting an expect fdg uptake .",
        "the constant uptake in the region hasbeen model as 0.44 , 0.11 , 0.06 , 0.28 , 1 , respectively .",
        "wesampled the continuous phantom on a resolution of 1140 1140 ( 0.25 mm 0.25 mm ) .",
        "to simulate ﬁnite voxel size , the imagesarethenaveragedover4 4regionstogetgroundtruth image of size 285 2 8 5 ( 1m m 1 mm ) .",
        "the noise level be set to 500 k count with another 500 k count contributingto the background .",
        "the randoms have be model spatiallyconstant and the scatter smoothly vary , resemble theshape of the x-ray transform of the ground truth .",
        "in addition , know attenuation from a simulated ct be model as well.the region of interest be set to be all pixel which contain at least 50 % of a certain type ( e.g.",
        ", grey matter ) .",
        "2 ) hardware phantom : for the second test case , show in fig .",
        "1 b ) , a 6.4 litre cylindrical phantom be use for pet andmridataacquisitions.thediameterandheightofthephantomwere 20.4 cm and 18.6 cm , respectively , with additional sixinserts of the same size and diameter of 2.5 cm .",
        "one of theinserts be solid ( make of teﬂon ) .",
        "in order to obtain a goodquality mri signal , a solution of copper sulphate and sodiumchloride be use in ratio of 4 g and 1 g , respectively , perone litre of water .",
        "this solution be far mixed with petradiotracer , 18f-fdg , with var ying radioactivity concentra- tions between the background and the insert .",
        "the data wasacquired on a siemens biogr a p hm m r ®h y b r i dp e t - m r i scanner .",
        "for computational efﬁciency only the event detectedin one direct compress sinogram in span-11 be use .",
        "thesinogram correspond to an axial position of 6.6 cm from thescanner 's isocentre , directly cover the phantom 's inserts.the sinogram plane be form by sum six cross anduncompressed sinograms .",
        "the scatter and random event wereestimated use the off-line version of the siemens healthcarereconstruction software.3 ) clinical data : the clinical data be from a 34 year old , maleepilepsypatient.thedatasetiscomposedofa -weighted mri , a ute-based -map and list mode fdg-pet data .",
        "the -weightedmri ( 3.0t , te:2.63ms , tr:1700ms , ti900ms , ﬂip angle : 9 , voxel size : 0.53 0.531.1 mm ) , ute-based -maps ( voxelsize:1.56 1.561.56mm ) andpetlistmode data ( radiopharmaceutical : fdg ) be acquire on a siemens biograph mmr® hybrid pet-mri scanner ; 250 mbq of fdgwere administer half an hour before the 15 min pet acqui- sition .",
        "the mri be co-registered to the pet image and thenresampled use vinci software [ 49 ] to account for motion be-tweenthemrandpetacquisitions.asliceofthemriandthepetdataacquiredinonecompressedsinograminspan-11cor-responding to onedirect detection plane areshown in fig.1c ) .",
        "iv .",
        "r esults a .",
        "results for software phantom 1 ) choice of regularization parameter : wewillﬁrstinves- tigate the choice of the re gularization parameter for the dif- ferentmethods.formlemthenumberofiterationscanbeseenas a regularization parameter .",
        "f or noisy data the iteration ex- hibit a semi-convergence property such that we yield well re-sults by early termination of the procedure [ 50 ] .",
        "to ﬁnd a suit-able choice we vary the regulari zation parameter and evaluate the result in term of relative -error and structural similarity ( s si m ) i n dex [ 5 1 ] , cf .",
        ", fi g.2 .th eop t imalcho i ceb asedonth erelative -error over the whole phantom be mark in all four plots.wecanseethatforthischoiceofregularizationparameter andperform bestover thewholephantomforbothquality measure ( toprow ) andforgreymatter ( bottomleft ) .however , this choice of regularization yield for a suboptimal solution in the right hot lesion in term of the relative -error , cf.",
        ", right handsideoffig.2.thiscanalsobeseeninfig.3andclose-upsin fig .",
        "4 showing image for “ optimal ” regularization .",
        "2 ) perfect versus imperfect side information : next , we comparereconstructionswithper fectsideinformation ( namely thepet groundtruthimage ) versusimperfectsideinformationwhichisareconstructedmriimagefromnoisymeasurements , cf.",
        ", fig .",
        "5 .",
        "first of all , it should be note that for perfect sideinformation andresult in large error compare to , and .",
        "when the side information be change to the more realistic mri image , it can be see that , i nc o n t r a s t to the other four method , be not able to reconstruct the greymatter-to-white matter boundary as the side information isfalsely inform that the activ ity should increase while in fact the activity decrease .",
        "3 ) bias-versus-standard deviation trade-off : for , we reconstruct pet image , and estimate with the mean , the biasandstandard deviation ( sd ) as ( 14 ) heredenotes the pet ground truth that have be use for this simulation , cf.",
        ", fig .",
        "1 .",
        "the mean absolute value of theseestimates over four region of interest be show in fig .",
        "6 as aehrhardt et al .",
        ": petreconstructionwith ananatomical mri prior using parallel levelset s 2193 fig .",
        "2 .",
        "quantitative result for the software phantom with the amount of re gularization ( number of iteration for mlem ) on the horizontal axis .",
        "the o ptimal parameter be choose base on the relative -error over the whole phantom ( far leave ) and the result for this choice be mark solid in all four plot and show in fig .",
        "3.also show ( second left ) the ssim ( structural similarity index ) for thewhole phantom .",
        "“ too low ” and “ too high ” regularization , cf.",
        ", fig.3 , be mark with light shading .",
        "andperform best for the whole phantom and grey matter .",
        "moreover , for this choi ce of regularization andperform worse for the right hot lesion than the other method which all perform similarly .",
        "propose method .",
        "fig .",
        "3 .",
        "effect of regularization parameter ( number of iteration for mlem ) on the result for the software phantom with mri as side information .",
        "the c hoice be “ optimal ” with respect to the -norm between the reconstruction and the ground truth .",
        "the image corresp o n dt ot h ema r k er si nf i g .2 .f o rt h e “ o p t i ma l ” c h o ic e of regularization , both andresult in well-deﬁned anatomical boundary .",
        "propose method .",
        "curvewithrespecttotheregular izationparameter/numberofit- erations.asitcanbeclearlyseen , closelyfollowedby have the best bias-versus-standard deviation trade-off for the wholephantom , greymatterandwhitematter.inthelesions , whicharenotpresentinmri , allmethodsperformequallywell.the “ op-timal ” regularization paramet er in term of the expected mean squarederroroverthewholephantomismarkedinallfourplots.it can be see that all method have roughly the same stan-dard deviation for the whole phantom , grey matter and whitematterbut hasalwaysthesmallestbias.inaddition , whilethe method that reduce to total variation ( ) h a v ea similar bias and standard deviation in the right hot lesion , thetwomethodsthatreducetoaquadraticfunctional ( ) havea slightlysmallerstandarddevia tionbutlargerbiasinthisregion .",
        "thebiasandstandarddeviationf ortheregularizationparam- eter with the small expected mean square error be plottedasimagesinfig.7withalineproﬁleinfig.8.asitcanbeseen , andboth have a small bias than the other ﬁve method .",
        "in addition , we can clearly see again the bias of at the grey matter-to-whitematterinterface.moreover , themethodsthatre-ducetototalvariationinabsenceofstructuralpriorinformation , ,andhave a more spatially localized standard deviation.incontrast , thestandarddeviationof appearsmore spatially constant .",
        "furthermore , we observe that the two smallregions of high activity at the right of the pet image be re-constructedwiththeleastbiasfor buthaveahigherstandard deviation when compare for instance to .",
        "this effect be re- lated to bregman iteration that have be show to decrease the systematic bias of total variation regularize reconstruction [ 41 ] .",
        "b .",
        "results for hardware phantom theresultsforthehardwarephantomareshowninfig.9with close-ups in fig .",
        "10 and line proﬁles in fig .",
        "11 .",
        "fig .",
        "9 showstheresultsforallmethods witha level of regularizationchosento balance data ﬁttingaccuracy an d noisepropagation.inorder to minimize subjectivity , we also show image with low andhigher level of regularization .",
        "we would like to highlight threeaspectsthatalsocorrespondtotheclose-upsinfig.10.firstofall , thehotinsertthatisnotvisibleinthesideinformationis , asexpected , reconstructedwellbythemethodsthatreducetototal2194 ieee transactions on medicalimaging , vol .",
        "35 , no .",
        "9 , september 2016 fig .",
        "4 .",
        "close-up of the lesion of the result with “ optimal ” chosen regula rization parameter from fig .",
        "3 .",
        "it can be see that both andresult in well-deﬁned anatomical boundary .",
        "moreover , show clearly deﬁned lesion .",
        "fig.5 .",
        "resultsforsoftwarephantom with groundtruth of petassideinform ationat the top andreconstructedmri at the bottom.top : , andreconstruct the phantom almost perfectly with the pet ground truth give as side inform ation .",
        "bottom : fails to reconstruct the grey matter-to-white matter interface as the gradientsinpetandmriarenegativel ycorrelated.thesameobservationc anbemadefromthelineproﬁlesontherightwherescaledandtranslatedlin eproﬁles of the pet ground truth and the mri serve as a reference .",
        "propose method .",
        "variationwhiletheothermethodstendtoover-smooth thisfea- ture.second , atthehotinsertatthebottomrightwecanseethesameeffectasatthegreymatter-to-whitematterinterfaceofthesoftwarephantom : theprior disfavoursnegativelycorrelated edge which result in a wide corona around the insert .",
        "third , at the left edge of the phantom we can see that the intensity ofthe mri phantom fade away .",
        "while it change the smoothingbehaviour of , and , it do not signiﬁcantly affect and .",
        "finally , the line plot in fig .",
        "11 show that especially result in clear , well-deﬁned edge .",
        "noteinfig.9 , thespherethatappearsinthepetreconstruc- tions that be reconstruct with the mri side information isnotanartefact.itisclearlyvisi bleinthemlemreconstruction withsixtimesthenumberofcounts.thus , thissphereisnotanartefact but show that by use a natomicalpriors itis possible to detect an object with a very low contrast .",
        "c. results for clinical data the result from the clinical patient data be show in fig .",
        "12 with close-ups in fig .",
        "13 .",
        "although , we can not saywhich result be the “ best ” we can make two observations.first , the resulting image for both andhave well-deﬁned anatomical boundary with superior in the level of detail .",
        "second , as in the software phantom , struggle to reconstruct the grey matter-to-white matter interface which appear verydifferent compare to all other method .",
        "the line proﬁles , show in fig .",
        "14 , conﬁrm these observation .",
        "in addition , itehrhardt et al .",
        ": petreconstructionwith ananatomical mri prior using parallel levelset s 2195 fig.6 .",
        "meanabsolutebias-versus-m eanstandarddeviationtrade-offind ifferentregionsofinterest .",
        "andhavethebesttrade-offforthewholephantom , grey matterandwhitematterastheircurveslie “ underneath ” theothercurvesb utallmethodshavesimilarcurvesforthelesions ( farright ) .moreover , t hesolutionthat have the small expected mean square error for the whole phantom ( distan ce from the origin in the far left plot ) be mark in all four graph .",
        "it can be see that these solutionshaveallroughly the same standarddeviationforthe whole phantom , grey matterandwhite matterbut have always the small bias.inaddition , the “ optimal ” solution for have a large bias for the hot lesion .",
        "fig.7 .",
        "biasandstandarddeviationforsoftwarephantomfortheregulariz ationparameterthatminimizesth eexpectedmeansquarederror .",
        "andvisuallyhave the small bias with all method appear to have a similar standard deviat ion.shows a large bias at the grey matter-to-white matter interface .",
        "fig .",
        "8 .",
        "line proﬁles of bias and standard deviation for the software phanto m , cf.",
        ", fig.7.thelinesegmentismarkedintheimageatthetoprightandascal ed versionofthemriservesasareferenceaboutanatomicalstructure.allme thods have spatially vary bias and standard deviation .",
        "while the method tha tr e - ducetoaquadraticprior , i.e.",
        ", and , havearelativelyﬂatstandarddeviation , the standard deviation of the other three method ( which reduce to total va ria- tion in the absence of anatomical information ) be relatively peaked .",
        "can be see that result in a sharp hot spot than all other method .",
        "however , no ground truth be available for this data .",
        "v. discussion in this section we discuss prospect and limitation of anatomical prior .",
        "a .",
        "side information the result of this paper conﬁrm that incorporate anatom- ical information can be very beneﬁcial , for instance for recov-ering very low contrast featur e as in fig .",
        "9 .",
        "however , to be useful , the reconstructed pet image have to be robust to er-rors in the anatomical information .",
        "most prior ( include the propose ) be insensitive to inhomogeneity in the mri im- a g e s , c f .",
        ", f i g .9 .",
        "the methodology relies on the registration of the two data set which be intrinsically the case in the simultaneouspet-mri set-up .",
        "however , ev en in this scenario we may encounter a slight misregistration—e.g.",
        ", due to motion anddistortions—which might introduce artefact into the recon-struction .",
        "the sensitivity of anatomical prior in general , andthe propose method in particular , to such misregistration isout of the scope of this work but might be address in futureresearch .",
        "b. parameters this method have three important parameter that have to be choose : the regularization parameter , the edge parameter andthesmoothingparameter .whileweonlyshowresultsfor the selection of the regularization parameter we brieﬂy dis- cuss our experience with the selection of the other two .",
        "first , thesmoothing parameter isrelated to thegradientmagnitude thatshallbepreservedandcanbechoseneitherfromanunregu-larizedmlem reconstructionorbasedonpreviousreconstruc-tions.wehavefoundthatthereconstructedimagesarenotverysensitive to change in this par ameter up to at least a factor of ten .",
        "the edge parameter should depend on the edge strength distribution of the anatomical image and deﬁnes which edgesshall or shall not be encourage in the pet image .",
        "the sensi-tivitytothisparameterdependsonthequalityoftheanatomical2196 ieee transactions on medicalimaging , vol .",
        "35 , no .",
        "9 , september 2016 fig .",
        "9 .",
        "reconstructionsof hardware phantom with mri asside information f or a varying amount of regularization .",
        "see caption of fig .",
        "10 for detail .",
        "fig .",
        "10 .",
        "close-ups on insert of the result for medium regularization ( mi ddle row ) show in fig .",
        "9 .",
        "as it can be see from the top row , , anddo not smearoutthehotinsertthatisnotpresentinthesideinformation.method doesnotallownegativeg radientcorrelationand thereforeintroducesac oronaaround the insert , cf.",
        ", middle and bottom row .",
        "both andreconstruct the left hand side of the phantom well despite the smooth varia tion in the side information ( bottom row ) .",
        "fig .",
        "11 .",
        "line segment of hardware phantom reconstruction for medium reg ularization show in cf.",
        ", fig .",
        "9 over s everal insert and the edge of the pha ntom .",
        "the line segment be mark in the image at the right hand side .",
        "andyield the sharp result without over-smoothing the insert not present in the side information ( second left ) .",
        "image as a small can also encourage edge that be due to noise or other artefact .",
        "therefore , the scale of be expect to be more important for image with less well-deﬁned edge .",
        "aswithallmethodsoralgorithms weneedtochoosevaluesofpa- rameters that will inﬂuence the reconstructed image quality .",
        "inthis paper we have choose to optimize the parameter with re- specttoanobjectiveandeasilycomputablequalitymeasurebutit be important to note that “ optimality ” be very much applica-tion dependent and might need to involve human that analysetheimages.therefore , allresults shouldbeinterpretedwithcareehrhardt et al .",
        ": petreconstructionwith ananatomical mri prior using parallel levelset s 2197 fig .",
        "12 .",
        "reconstructions of clinical patient data for a varying amount of r egularization .",
        "it can be see that both andresult in image with well-deﬁned anatomical boundary .",
        "moreover , fail to reconstruct the grey matter-to-white matter boundary due to the n egative correlation of the edge in pet and mri .",
        "propose method .",
        "fig .",
        "13 .",
        "close-ups of result in fig .",
        "12 for medium regularization .",
        "both andlead to well-deﬁned structure .",
        "while show a high level of detail in the grey matter , show a slightly sharp hot spot ( see also fig .",
        "14 for the latter observati on ) .",
        "and a different parameter selec tion might be need depend on the task .",
        "c .",
        "e x t e n s i o nt o3 d allexperimentsinthispaperhavebeencarriedoutintwodi- mensions to save computation time .",
        "the extension to the threedimensional case might need more efﬁcient algorithm that ex-ploitallthestructureoftheproblem.however , themathematicalbasisisvalidinarbitrarydimen sionsandthereisnoreasonwhy thismethodologyshouldnottranslatetothreedimensions.thiswill be the subject of future work .",
        "vi .",
        "c onclusion inthispaperweproposedanewpriortoincorporatestructural sideinformationintoreconstructionandshoweditsapplicationfor the case of anatomical information from mri incorporatedintothereconstructionofpet.theproposedpriorcombinesthe strengthofotherpreviouslypublishedpriorsandhastheadvan-tagethatitisconvex , segmentation-freeandedge-preservinginthe degenerated case .",
        "the prior ma kes use of directional infor- mation from the anatomical side image and encourages image withalignedgradientsorparallellevelsets.moreover , weintro-duced another prior that encour age parallel level sets—which reduce to a quadratic prior—to this particular application .",
        "re-sults from a simulated phantom , a hardware phantom and clin-ical data show that encourage p arallel level set be very suit- able for this application as it p romotes well-deﬁned edge and allowsnegativeedgecorrelation.theproposedmodiﬁcationtocombine the idea of parallel level set with total variation al-lows one to reconstruct distinct object that be not present inthe anatomical side information .",
        "the result for the softwarephantom show that the propose prior be superior to the othertested prior in term of several quality measures.2198 ieee transactions on medicalimaging , vol .",
        "35 , no .",
        "9 , september 2016 fig .",
        "14 .",
        "line segment of clinical data reconstruction for medium regula rization , cf.",
        ", fig .",
        "12 .",
        "the line segment be mark in the image on the righ t. both andyield similar result with sharp edge .",
        "in addition , result in a well-deﬁned hot spot ( far leave ) .",
        "the proﬁles of do not match the proﬁles of the other method apart from the edge of the brain ( far right ) .",
        "appendix theconvexityoftheproposedpriorfollowsfromarguments in [ 37 ] .",
        "we will state the proof for this special case here for completeness .",
        "proposition 1 : the prior deﬁned in ( 9 ) be convex .",
        "proof : we will prove that at any location it hold ( 15 ) with beingamatrixwhichisindependentof .therefore , the prior can be write as the convexity of then follow from the convexity of with a matrix independent of .",
        "to prove ( 15 ) , let with , where the spatial dependence on have be omit for readability .",
        "the latter be well-deﬁned as .",
        "we notice that solve such that"
    ],
    "processed_text": "ieeetransactions medicalimaging vol35 no9 september 2016 2189 pet reconstruction anatomical mri prior using parallel level sets matthias j ehrhardt pawel markiewicz maria liljeroth anna barnes ville kolehmainen john duncan luis pizarro david atkinson brian f hutton senior member ieee sebastien ourselin kris thielemans senior member ieee simon r arridge abstract combination positron emission tomography pet magnetic resonance imaging mri offer unique pos sibilitiesinthispaperweaimtoexploitthehighspatialresolutionof mri enhance reconstruct ion simultaneously acquire pet data propose new prior incorporate structural side information maximum posteriori reconstruction new priorcombinesthestrengthsofpreviouslyproposedpriorsforthe problem efficient guide reconstruction edge available side information reduce locallyto edgepreserving total variation degenerate case structural information available addition prior segmentationfree convex ap r r iassumptions make correlation edge direction pet mri image present result simulated brain phantom real data acquire siemens biograph mmr hardwarephantom clinical scan result simulation show new prior good tradeoff enhance common anatomical boundary preserve unique featuresthan several prior good mean absolute biastomean standard deviation tradeoff yield reconstruc tions superior relative error structural similarity index findings underpin real data result hardware phantom clinical patient confirming new prior capable promote welldefined anatomicalboundaries index terms anatomica l prior magnetic resonance imaging parallel level set positron emission tomography totalvariation manuscript receive december 17 20 15 revise march 11 2016 accept march 29 2016 date current version august 30 2016 research wasfunded epsrc ep/k005278/1 ep/h046410/1 support bythe national institute health research university college london hos pi talsbiomedicalresearchcentremjehrhardtwassupportedbyanimpactstudentshipfundedjointlybysiemensandtheuclfacultyofengineerings ci ences k thielemans atkinson partially support epsrcgrant ep/m022587/1 asterisk indicate correspond author j ehrhardt centre medical image computing wc1e 6bt london uk department applied mathematicsandtheoreticalphysics university ofcambridge cb30wacambridge uk email mjehrhardt @ damtpcamacuk pmarkiewicz lpizarro sourselin andsrarridgearewiththecentr e medical image computing wc1e 6bt london uk mliljeroth abarnes andkthielemansarewiththeinstitutefornucle ar medicine university college london nw1 2bu london uk v kolehmainen department applied physics university eastern finland 70211 kuopio finland j duncan institute neurology university college london wc1n 3bg london uk atkinson centre medical imaging university college london nw1 2pg london uk b f hutton institute nuclear medicine university colleg e london nw1 2bu london uk centre medical radiationphysics university wollongong nsw australia colorversionsofoneormoreofthefiguresinthispaperareavailableonlin e http //ieeexploreieeeorg digital object identifier 101109/tmi20162549601i introduction positron emission tomography pet allow mon itoring high sensitivity distribution bio logically important molecule therefore provide unique information clin ical application h owever pet intrin sically suffers low spatial resolution due thepartial volume effect may prevent quantitative 1 5 high spatial resolution one key strength magneticresonanceimaging mri andisoftenavailableeitherfrom separate scan hel p registration 1 3 6 combine petmri scan ner simultaneously image function structure 7 11 anatomical mri information use correct partial volume effect either po st reconstruction 1 3 5 orwithinthereconstruction 12 14 overthelasttwodecades manypriorshavebeenproposedtoutilizeanatomicalsideinfor mationintothereconstructionofalowresolutionmodality 6 15 30 propose method task often rely asegmentation anatomical image 6 15 heuristic modification minimization p rocedure 16 17 20 minimize nonconvex functional 18 21 24 29 30 inallcasesthereisacompromise onstability robustnessand/or theoretical justification prior propose rely seg mentation convex 25 26 28 lack desirablepropertiesitisimportantthatapriorthatincorporates anatomical information respect information content thefunctional image desirable prior reduces locally edgepreserved denoising scheme total variation ap r r iedge information available isnotthecasefor 26 28 moreover functionalandanatom ical image pet mri ight share many edge general expect intensity change thesameway attheedgeofananatomicalregionthemricontrast might increase tracer uptake pet might decrease orviceversathisfeature alth oughveryimportanttocombine imagesofarbitraryintensities isnotpartofthemodelproposed 25 inthispaperwecombinethestrengthsof 25 26 proposeapriorthatdoesnotrelyonasegmentation isconvex preservestheedgesofuniquefeaturesanddoesnotrelyonany assumption intensity two image contributions contribution paper threefold first pro pose new prior incorporate structural information reconstruction desired property outline aboveandweproveitsconvexitysecond weapplyotherpriors work license creative commons attribution 30 license fo r information see http //creativecommonsorg/licenses/by/30/2190 ieee transactions medicalimaging vol 35 9 september 2016 thathavebeenusedforotherap plicationstothesettingofpet mri finally compare five different prior setting petmri synthetic phantom data real phantom data clinical patient data b setup consider pet data random variable model poisson process 31 expectation 1 denote pet image denote pet forward operator includ es scanner geometry detector normalizationandattenuation denotesabackgroundterm need correct scatter randoms based model perform image reconstruction via minimization objective function 32 2 3 measure distance estimate data ac quired data h ed afi additive constant dependent negative logarithm poisson distribu tionwhichnaturallycallsforanonnegativityconstraintontheimage value prior introduces ap r r iknowledge solution seek regularization parameter allow balance ofinformationthatcomesfromthedatawithour ap r r ibelief aboutthesolution apopularprioristhe smooth totalvari ation 33 4 asitleadstoedgepreserveddenoisinghere introducedto render 4 differentiable sometimes consider scale pa rameteronthevaluesof belowwhichedgesareconsid eredtobenoisewewillreturntoadiscussionofth isparameter later inthecontextofpetmri wehavestructuralknowledgeon thesolutiongivenbyananatomicalmriimage seek extension 4 allow us incorporatethis ap r r iedgeinformationwewillde notearegularizationterm depend associate image oreover call extra information structure side information whichprovidespriorinformationaboutthepetimageweseek aside actual acquire data ii methods asymmetric parallel level sets simplify notation introduce spatially varying gradient field 5 regularized norm h e parameter playsasimilarroleto 4 inthatitscalesdown theinfluenceof whenedgesmerelyrepresentnoiseatany location vector field point direction gradient normalize 6 low bound obtain upper bound obtain asymptotically motivated findings 34 37 measure structurally similar image islocally anotherimage compare gradient field 7 denote euclidean inner product upper bound obtain structural sideinformation ie low bound asymptoti callyfor isalignedto inthesense thatthereexistsa suchthat note thatforthecasewhen thegradientvectorisalignedto vector allow parameter zero derive global prior integrate local measure similarity entire domain 8 local property follow directly prior nonnegative zero align almost everywhere gradient perpendicular level setsof andisperpendiculartothelevelsetsof wereferto thismeasureofsimilarityofstructuresasthemethodof parallel level set thispriorhasallthedesiredproperties itisconvexin cf 37 proposition 1 appendix depend asegmentedmriimageandinthedegeneratecasewhenthemriimage flat ie reduce total variation pet image moreover independent sign andscale therefore apply image arbitrary intensity similar case total variation introduce smoothing parameter 9 allow us employ smooth minimization method extensiontothenonsmoothcase ie willbethesubject future work b methods incorporate anatomical information benchmark prior previously propose convexandsegmentationfreepr iors 19 25 26 28 38 39 propose verysameapplication 19 25 28 othershavebeenproposedforsimilar task application geophysics 38 andcolour image 39 modal itieslikeelectricalimpedance tomography eit combine w ith computer assist tomog raphy 26 joint petmri reconstruction 35 ehrhardt et al petreconstructionwith ananatomical mri prior using parallel levelset 2191 1 kaipio et al kaipio et alproposedtoincorporate ap r r knowledge prior 10 whereis defined 5 26 original formulation littledifferentbutitisequivalentto 10 withaslightlydifferentnormalization cf 37 detail prior desired property readily see reduce aquadratic functional degenerate case r h e rt h n tototalvariationthispriorhasbeenproposedoriginallyintheeitcontextandweapplyittothepetmrisettingforthefirsttime 2 kazantsev et al motivated lot model 40 bregman distance total variation 41 proposed 25 formulate prior knowledge 11 whereagainasmoothingparameterisusedtomaketheproblem differentiablethismodelfixestheproblemofkaipio et althat featuresin thatarenotpresentin arepenalizedquadratically andthereforeallowsedgesintheseareashowever itpenalizesthedeviationof andinawaysothatvectorswithopposite orientation arepenalized even orthogonal vector 3 bowsher prior ithas propose bowsher et al define prior neighbour voxels 12 weight choose similar neighbour anatomical image positiv e weight de pending spatial distance voxel voxeland zero otherwiseasitmighthappenthat isweighteddif ferently w eu ea e r z e dv e rsion weight average 4 joint total variation thelastpriorweben chmarkagainst joint total variation 13 whereaparameter isusedtoadjustthescaleofthesidein formationithasbeenfirstproposedasanextensionoftotalvariation rgb colour image 39 subsequently beenusedforjointreconstructioning eophysics 38 andjointrecon structionofpetmri 35 incontrastto jointtotal variationonlymakesuseofthemagnitudeofthegradientofthesideinformation thereby neglectingpossiblyvaluableinformation recently similar prior ha propose incorporate anatomical information pet reconstruction 19 overview different method key prop erties give table method reduce totalvariation degenerated case side information isavailablewhileallofthemethodsdependonthelocationoftheedges anddepend edge orientation ever allow edge negatively correlate mean example jump side information thena jumpdown intheimagetobereconstructedtable summary anatomical priorsthelastcategory onlyapplies methodsthat orientation dependent theonlypriorthat fulfilsall fourcriteriaproposed strongly penalize prior fulfils desired criterion iii numerical setup algorithm projections parameters algorithm inordertofairlycompareallthedifferentpriors use method minimize 2 differentchoicesofpriorsdiscussed inthelastsectionstobemoreprecise use lbfgsb 42 43 nonnegativityconstraint implement pro jecting iterates onto nonnegative quadrant lbfg sb quasinewton method thatapproximatestheinverseofthehessianwithfirstorderinformation case run lbfgsb 2000 iterationsimplementation matlab asthispaperfocusesonpriorsratherthanoptimizationalgo rithms compare investigate algorithm weplan investigate optimization algorithm applicationmoreclosely particularlyforthenonsmoothcasewhen 1 projections data paper correspond geometryofonedirectplaneofthesiemensbiographmmr cf 44 forscannerspecificatio n fixedatagivenaxialposition andformedbysummingsixorfive dependingontheaxialposition direct cross sinogram scanner 's native axial compression span11 pet forward adjoint operators geometry take stir software tomographicimagereconstruction 45 thathasbeeninterfacedto matlab case model loss resolution bya gaussian blur full width half maximum fwhm 4mm 4 mm image space prior projection back projection 2 parameters test several regularization parameter method show result cf model 2 theparameter andhasbeenchosenin whichisaround01 1 ofthemaximalgradient magnitude side information similar parameter choose 1 5 lead gradient similar magnitude ima ge tvlike prior smooth norm approximately 001 expect maximal gradient intensity petimage 4 neighbour 3 3 neighbourhood choose comparison lso ran maximum likelihood expectation maximization mlem 46 500 itera tions smooth final iterate gaussian filter withfwhm 4 mm 4m phantoms 1 software phantom first test case software phantom cf fig 1 base mri image2192 ieee transactions medicalimaging vol 35 9 september 2016 fig1 mrisideinformationandpetdatafor softwarephantom b hard ware phantom c clinical patient data software phantom also petgroundtruth highresolution lowresolution andregionsofinteres grey matter white matter lesion show obtain brainweb 47 convert continuous spline phantom 48 different region brain asgrey matter white matter cerebrospinal fluid cold lesion andhot lesion assign con stant intensity reflecting expect fdg uptake constant uptake region hasbeen model 044 011 006 028 1 respectively wesampled continuous phantom resolution 1140 1140 025 mm 025 mm simulate finite voxel size imagesarethenaveragedover4 4regionstogetgroundtruth image size 285 2 8 5 1m 1 mm noise level set 500 k count another 500 k count contributingto background randoms model spatiallyconstant scatter smoothly vary resemble theshape xray transform ground truth addition know attenuation simulated ct model wellthe region interest set pixel contain least 50 certain type eg grey matter 2 hardware phantom second test case show fig 1 b 64 litre cylindrical phantom use pet andmridataacquisitionsthediameterandheightofthephantomwere 204 cm 186 cm respectively additional sixinserts size diameter 25 cm one theinserts solid make teflon order obtain goodquality mri signal solution copper sulphate sodiumchloride use ratio 4 g 1 g respectively perone litre water solution far mixed petradiotracer 18ffdg var ying radioactivity concentra tions background insert data wasacquired siemens biogr p hm r h b r dp e r scanner computational efficiency event detectedin one direct compress sinogram span11 use thesinogram correspond axial position 66 cm thescanner 's isocentre directly cover phantom 's insertsthe sinogram plane form sum six cross anduncompressed sinograms scatter random event wereestimated use offline version siemens healthcarereconstruction software3 clinical data clinical data 34 year old maleepilepsypatientthedatasetiscomposedofa weighted mri utebased map list mode fdgpet data weightedmri 30t te263ms tr1700ms ti900ms flip angle 9 voxel size 053 05311 mm utebased maps voxelsize156 156156mm andpetlistmode data radiopharmaceutical fdg acquire siemens biograph mmr hybrid petmri scanner 250 mbq fdgwere administer half hour 15 min pet acqui sition mri coregistered pet image thenresampled use vinci software 49 account motion betweenthemrandpetacquisitionsasliceofthemriandthepetdataacquiredinonecompressedsinograminspan11corresponding onedirect detection plane areshown fig1c iv r esults results software phantom 1 choice regularization parameter wewillfirstinves tigate choice gularization parameter dif ferentmethodsformlemthenumberofiterationscanbeseenas regularization parameter f noisy data iteration ex hibit semiconvergence property yield well results early termination procedure 50 find suitable choice vary regulari zation parameter evaluate result term relative error structural similarity si n dex 5 1 cf fi g2 th eop imalcho ceb asedonth erelative error whole phantom mark four plotswecanseethatforthischoiceofregularizationparameter andperform bestover thewholephantomforbothquality measure toprow andforgreymatter bottomleft however choice regularization yield suboptimal solution right hot lesion term relative error cf right handsideoffig2thiscanalsobeseeninfig3andcloseupsin fig 4 showing image optimal regularization 2 perfect versus imperfect side information next comparereconstructionswithper fectsideinformation namely thepet groundtruthimage versusimperfectsideinformationwhichisareconstructedmriimagefromnoisymeasurements cf fig 5 first note perfect sideinformation andresult large error compare side information change realistic mri image see nc n r four method able reconstruct greymattertowhite matter boundary side information isfalsely inform activ ity increase fact activity decrease 3 biasversusstandard deviation tradeoff reconstruct pet image estimate mean biasandstandard deviation sd 14 heredenotes pet ground truth use simulation cf fig 1 mean absolute value theseestimates four region interest show fig 6 aehrhardt et al petreconstructionwith ananatomical mri prior using parallel levelset 2193 fig 2 quantitative result software phantom amount gularization number iteration mlem horizontal axis ptimal parameter choose base relative error whole phantom far leave result choice mark solid four plot show fig 3also show second left ssim structural similarity index thewhole phantom low high regularization cf fig3 mark light shading andperform best whole phantom grey matter moreover choi ce regularization andperform worse right hot lesion method perform similarly propose method fig 3 effect regularization parameter number iteration mlem result software phantom mri side information c hoice optimal respect norm reconstruction ground truth image corresp n dt ot h ema r k er si nf g 2 f rt h e p l c h ic e regularization andresult welldefined anatomical boundary propose method curvewithrespecttotheregular izationparameter/numberofit erationsasitcanbeclearlyseen closelyfollowedby best biasversusstandard deviation tradeoff wholephantom greymatterandwhitematterinthelesions whicharenotpresentinmri allmethodsperformequallywellthe optimal regularization paramet er term expected mean squarederroroverthewholephantomismarkedinallfourplotsit see method roughly standard deviation whole phantom grey matter whitematterbut hasalwaysthesmallestbiasinaddition whilethe method reduce total variation h v ea similar bias standard deviation right hot lesion thetwomethodsthatreducetoaquadraticfunctional havea slightlysmallerstandarddevia tionbutlargerbiasinthisregion thebiasandstandarddeviationf ortheregularizationparam eter small expected mean square error plottedasimagesinfig7withalineprofileinfig8asitcanbeseen andboth small bias five method addition clearly see bias grey mattertowhitematterinterfacemoreover themethodsthatreducetototalvariationinabsenceofstructuralpriorinformation andhave spatially localized standard deviationincontrast thestandarddeviationof appearsmore spatially constant furthermore observe two smallregions high activity right pet image reconstructedwiththeleastbiasfor buthaveahigherstandard deviation compare instance effect lated bregman iteration show decrease systematic bias total variation regularize reconstruction 41 b results hardware phantom theresultsforthehardwarephantomareshowninfig9with closeups fig 10 line profiles fig 11 fig 9 showstheresultsforallmethods witha level regularizationchosento balance data fittingaccuracy noisepropagationinorder minimize subjectivity also show image low andhigher level regularization would like highlight threeaspectsthatalsocorrespondtothecloseupsinfig10firstofall thehotinsertthatisnotvisibleinthesideinformationis asexpected reconstructedwellbythemethodsthatreducetototal2194 ieee transactions medicalimaging vol 35 9 september 2016 fig 4 closeup lesion result optimal chosen regula rization parameter fig 3 see andresult welldefined anatomical boundary moreover show clearly defined lesion fig5 resultsforsoftwarephantom groundtruth petassideinform ationat top andreconstructedmri bottomtop andreconstruct phantom almost perfectly pet ground truth give side inform ation bottom fails reconstruct grey mattertowhite matter interface gradientsinpetandmriarenegativel ycorrelatedthesameobservationc anbemadefromthelineprofilesontherightwherescaledandtranslatedlin eprofiles pet ground truth mri serve reference propose method variationwhiletheothermethodstendtooversmooth thisfea turesecond atthehotinsertatthebottomrightwecanseethesameeffectasatthegreymattertowhitematterinterfaceofthesoftwarephantom theprior disfavoursnegativelycorrelated edge result wide corona around insert third left edge phantom see intensity ofthe mri phantom fade away change smoothingbehaviour significantly affect finally line plot fig 11 show especially result clear welldefined edge noteinfig9 thespherethatappearsinthepetreconstruc tions reconstruct mri side information isnotanartefactitisclearlyvisi bleinthemlemreconstruction withsixtimesthenumberofcountsthus thissphereisnotanartefact show use natomicalpriors itis possible detect object low contrast c results clinical data result clinical patient data show fig 12 closeups fig 13 although saywhich result best make two observationsfirst resulting image andhave welldefined anatomical boundary superior level detail second software phantom struggle reconstruct grey mattertowhite matter interface appear verydifferent compare method line profiles show fig 14 confirm observation addition itehrhardt et al petreconstructionwith ananatomical mri prior using parallel levelset 2195 fig6 meanabsolutebiasversusm eanstandarddeviationtradeoffind ifferentregionsofinterest andhavethebesttradeoffforthewholephantom grey matterandwhitematterastheircurveslie underneath theothercurvesb utallmethodshavesimilarcurvesforthelesions farright moreover hesolutionthat small expected mean square error whole phantom distan ce origin far left plot mark four graph see solutionshaveallroughly standarddeviationforthe whole phantom grey matterandwhite matterbut always small biasinaddition optimal solution large bias hot lesion fig7 biasandstandarddeviationforsoftwarephantomfortheregulariz ationparameterthatminimizesth eexpectedmeansquarederror andvisuallyhave small bias method appear similar standard deviat ionshows large bias grey mattertowhite matter interface fig 8 line profiles bias standard deviation software phanto cf fig7thelinesegmentismarkedintheimageatthetoprightandascal ed versionofthemriservesasareferenceaboutanatomicalstructureallme thods spatially vary bias standard deviation method tha tr e ducetoaquadraticprior ie havearelativelyflatstandarddeviation standard deviation three method reduce total va ria tion absence anatomical information relatively peaked see result sharp hot spot method however ground truth available data v discussion section discuss prospect limitation anatomical prior side information result paper confirm incorporate anatom ical information beneficial instance recovering low contrast featur e fig 9 however useful reconstructed pet image robust errors anatomical information prior include propose insensitive inhomogeneity mri im g e c f f g 9 methodology relies registration two data set intrinsically case simultaneouspetmri setup however ev en scenario may encounter slight misregistrationeg due motion anddistortionswhich might introduce artefact reconstruction sensitivity anatomical prior general andthe propose method particular misregistration isout scope work might address futureresearch b parameters method three important parameter choose regularization parameter edge parameter andthesmoothingparameter whileweonlyshowresultsfor selection regularization parameter briefly dis cuss experience selection two first thesmoothing parameter isrelated thegradientmagnitude thatshallbepreservedandcanbechoseneitherfromanunregularizedmlem reconstructionorbasedonpreviousreconstructionswehavefoundthatthereconstructedimagesarenotverysensitive change par ameter least factor ten edge parameter depend edge strength distribution anatomical image defines edgesshall shall encourage pet image sensitivitytothisparameterdependsonthequalityoftheanatomical2196 ieee transactions medicalimaging vol 35 9 september 2016 fig 9 reconstructionsof hardware phantom mri asside information f varying amount regularization see caption fig 10 detail fig 10 closeups insert result medium regularization mi ddle row show fig 9 see top row anddo smearoutthehotinsertthatisnotpresentinthesideinformationmethod doesnotallownegativeg radientcorrelationand thereforeintroducesac oronaaround insert cf middle bottom row andreconstruct left hand side phantom well despite smooth varia tion side information bottom row fig 11 line segment hardware phantom reconstruction medium reg ularization show cf fig 9 everal insert edge pha ntom line segment mark image right hand side andyield sharp result without oversmoothing insert present side information second left image small also encourage edge due noise artefact therefore scale expect important image less welldefined edge aswithallmethodsoralgorithms weneedtochoosevaluesofpa rameters influence reconstructed image quality inthis paper choose optimize parameter specttoanobjectiveandeasilycomputablequalitymeasurebutit important note optimality much application dependent might need involve human analysetheimagestherefore allresults shouldbeinterpretedwithcareehrhardt et al petreconstructionwith ananatomical mri prior using parallel levelset 2197 fig 12 reconstructions clinical patient data varying amount r egularization see andresult image welldefined anatomical boundary moreover fail reconstruct grey mattertowhite matter boundary due n egative correlation edge pet mri propose method fig 13 closeups result fig 12 medium regularization andlead welldefined structure show high level detail grey matter show slightly sharp hot spot see also fig 14 latter observati different parameter selec tion might need depend task c e x e n nt o3 allexperimentsinthispaperhavebeencarriedoutintwodi mensions save computation time extension threedimensional case might need efficient algorithm exploitallthestructureoftheproblemhowever themathematicalbasisisvalidinarbitrarydimen sionsandthereisnoreasonwhy thismethodologyshouldnottranslatetothreedimensionsthiswill subject future work vi c onclusion inthispaperweproposedanewpriortoincorporatestructural sideinformationintoreconstructionandshoweditsapplicationfor case anatomical information mri incorporatedintothereconstructionofpettheproposedpriorcombinesthe strengthofotherpreviouslypublishedpriorsandhastheadvantagethatitisconvex segmentationfreeandedgepreservinginthe degenerated case prior kes use directional infor mation anatomical side image encourages image withalignedgradientsorparallellevelsetsmoreover weintroduced another prior encour age parallel level setswhich reduce quadratic priorto particular application results simulated phantom hardware phantom clinical data show encourage p arallel level set suit able application p romotes welldefined edge allowsnegativeedgecorrelationtheproposedmodificationtocombine idea parallel level set total variation allows one reconstruct distinct object present inthe anatomical side information result softwarephantom show propose prior superior othertested prior term several quality measures2198 ieee transactions medicalimaging vol 35 9 september 2016 fig 14 line segment clinical data reconstruction medium regula rization cf fig 12 line segment mark image righ andyield similar result sharp edge addition result welldefined hot spot far leave profiles match profiles method apart edge brain far right appendix theconvexityoftheproposedpriorfollowsfromarguments 37 state proof special case completeness proposition 1 prior defined 9 convex proof prove location hold 15 beingamatrixwhichisindependentof therefore prior write convexity follow convexity matrix independent prove 15 let spatial dependence omit readability latter welldefined notice solve",
    "bag_of_words": {
        "ieeetransactions": 1,
        "medicalimaging": 6,
        "vol35": 1,
        "no9": 1,
        "september": 6,
        "pet": 25,
        "reconstruction": 13,
        "anatomical": 21,
        "mri": 25,
        "prior": 37,
        "using": 5,
        "parallel": 10,
        "level": 13,
        "sets": 2,
        "matthias": 1,
        "ehrhardt": 3,
        "pawel": 1,
        "markiewicz": 1,
        "maria": 1,
        "liljeroth": 1,
        "anna": 1,
        "barnes": 1,
        "ville": 1,
        "kolehmainen": 2,
        "john": 1,
        "duncan": 2,
        "luis": 1,
        "pizarro": 1,
        "david": 1,
        "atkinson": 3,
        "brian": 1,
        "hutton": 2,
        "senior": 2,
        "member": 2,
        "ieee": 7,
        "sebastien": 1,
        "ourselin": 1,
        "kris": 1,
        "thielemans": 2,
        "simon": 1,
        "arridge": 1,
        "abstract": 1,
        "combination": 1,
        "positron": 3,
        "emission": 3,
        "tomography": 4,
        "magnetic": 2,
        "resonance": 2,
        "imaging": 3,
        "offer": 1,
        "unique": 3,
        "pos": 1,
        "sibilitiesinthispaperweaimtoexploitthehighspatialresolutionof": 1,
        "enhance": 2,
        "reconstruct": 8,
        "ion": 1,
        "simultaneously": 2,
        "acquire": 4,
        "data": 26,
        "propose": 14,
        "new": 5,
        "incorporate": 5,
        "structural": 7,
        "side": 19,
        "information": 31,
        "maximum": 3,
        "posteriori": 1,
        "priorcombinesthestrengthsofpreviouslyproposedpriorsforthe": 1,
        "problem": 1,
        "efficient": 2,
        "guide": 1,
        "edge": 18,
        "available": 4,
        "reduce": 7,
        "locallyto": 1,
        "edgepreserving": 1,
        "total": 11,
        "variation": 10,
        "degenerate": 2,
        "case": 13,
        "addition": 5,
        "segmentationfree": 1,
        "convex": 3,
        "ap": 6,
        "iassumptions": 1,
        "make": 3,
        "correlation": 2,
        "direction": 2,
        "image": 38,
        "present": 3,
        "result": 21,
        "simulated": 3,
        "brain": 3,
        "phantom": 33,
        "real": 3,
        "siemens": 4,
        "biograph": 2,
        "mmr": 2,
        "hardwarephantom": 1,
        "clinical": 11,
        "scan": 3,
        "simulation": 2,
        "show": 20,
        "good": 2,
        "tradeoff": 4,
        "common": 1,
        "boundary": 7,
        "preserve": 1,
        "featuresthan": 1,
        "several": 3,
        "mean": 7,
        "absolute": 2,
        "biastomean": 1,
        "standard": 8,
        "deviation": 10,
        "yield": 3,
        "reconstruc": 1,
        "tions": 4,
        "superior": 3,
        "relative": 4,
        "error": 8,
        "similarity": 4,
        "index": 3,
        "findings": 2,
        "underpin": 1,
        "hardware": 6,
        "patient": 5,
        "confirming": 1,
        "capable": 1,
        "promote": 1,
        "welldefined": 11,
        "anatomicalboundaries": 1,
        "terms": 1,
        "anatomica": 1,
        "set": 7,
        "totalvariation": 2,
        "manuscript": 1,
        "receive": 1,
        "december": 1,
        "revise": 1,
        "march": 2,
        "accept": 1,
        "date": 1,
        "current": 1,
        "version": 2,
        "august": 1,
        "research": 2,
        "wasfunded": 1,
        "epsrc": 1,
        "ep/k005278/1": 1,
        "ep/h046410/1": 1,
        "support": 2,
        "bythe": 1,
        "national": 1,
        "institute": 3,
        "health": 1,
        "university": 8,
        "college": 4,
        "london": 11,
        "hos": 1,
        "pi": 1,
        "talsbiomedicalresearchcentremjehrhardtwassupportedbyanimpactstudentshipfundedjointlybysiemensandtheuclfacultyofengineerings": 1,
        "ci": 1,
        "ences": 1,
        "partially": 1,
        "epsrcgrant": 1,
        "ep/m022587/1": 1,
        "asterisk": 1,
        "indicate": 1,
        "correspond": 3,
        "author": 1,
        "centre": 3,
        "medical": 4,
        "computing": 2,
        "wc1e": 2,
        "6bt": 2,
        "uk": 7,
        "department": 2,
        "applied": 2,
        "mathematicsandtheoreticalphysics": 1,
        "ofcambridge": 1,
        "cb30wacambridge": 1,
        "email": 1,
        "mjehrhardt": 1,
        "damtpcamacuk": 1,
        "pmarkiewicz": 1,
        "lpizarro": 1,
        "sourselin": 1,
        "andsrarridgearewiththecentr": 1,
        "mliljeroth": 1,
        "abarnes": 1,
        "andkthielemansarewiththeinstitutefornucle": 1,
        "ar": 1,
        "medicine": 2,
        "nw1": 3,
        "2bu": 2,
        "physics": 1,
        "eastern": 1,
        "finland": 2,
        "kuopio": 1,
        "neurology": 1,
        "wc1n": 1,
        "3bg": 1,
        "2pg": 1,
        "nuclear": 1,
        "colleg": 1,
        "radiationphysics": 1,
        "wollongong": 1,
        "nsw": 1,
        "australia": 1,
        "colorversionsofoneormoreofthefiguresinthispaperareavailableonlin": 1,
        "http": 2,
        "//ieeexploreieeeorg": 1,
        "digital": 1,
        "object": 3,
        "identifier": 1,
        "101109/tmi20162549601i": 1,
        "introduction": 1,
        "allow": 6,
        "mon": 1,
        "itoring": 1,
        "high": 5,
        "sensitivity": 2,
        "distribution": 2,
        "bio": 1,
        "logically": 1,
        "important": 4,
        "molecule": 1,
        "therefore": 4,
        "provide": 1,
        "clin": 1,
        "ical": 3,
        "application": 5,
        "owever": 1,
        "intrin": 1,
        "sically": 1,
        "suffers": 1,
        "low": 7,
        "spatial": 4,
        "resolution": 4,
        "due": 4,
        "thepartial": 1,
        "volume": 2,
        "effect": 4,
        "may": 2,
        "prevent": 1,
        "quantitative": 2,
        "one": 4,
        "key": 2,
        "strength": 2,
        "magneticresonanceimaging": 1,
        "andisoftenavailableeitherfrom": 1,
        "separate": 1,
        "hel": 1,
        "registration": 2,
        "combine": 2,
        "petmri": 4,
        "ner": 1,
        "function": 2,
        "structure": 3,
        "use": 11,
        "correct": 2,
        "partial": 1,
        "either": 1,
        "po": 1,
        "st": 1,
        "orwithinthereconstruction": 1,
        "overthelasttwodecades": 1,
        "manypriorshavebeenproposedtoutilizeanatomicalsideinfor": 1,
        "mationintothereconstructionofalowresolutionmodality": 1,
        "method": 24,
        "task": 3,
        "often": 1,
        "rely": 2,
        "asegmentation": 1,
        "heuristic": 1,
        "modification": 1,
        "minimization": 3,
        "rocedure": 1,
        "minimize": 3,
        "nonconvex": 1,
        "functional": 2,
        "inallcasesthereisacompromise": 1,
        "onstability": 1,
        "robustnessand/or": 1,
        "theoretical": 1,
        "justification": 1,
        "seg": 1,
        "mentation": 1,
        "lack": 1,
        "desirablepropertiesitisimportantthatapriorthatincorporates": 1,
        "respect": 2,
        "content": 1,
        "thefunctional": 1,
        "desirable": 1,
        "reduces": 1,
        "locally": 1,
        "edgepreserved": 1,
        "denoising": 1,
        "scheme": 1,
        "iedge": 1,
        "isnotthecasefor": 1,
        "moreover": 6,
        "functionalandanatom": 1,
        "ight": 1,
        "share": 1,
        "many": 1,
        "general": 2,
        "expect": 4,
        "intensity": 6,
        "change": 4,
        "thesameway": 1,
        "attheedgeofananatomicalregionthemricontrast": 1,
        "might": 7,
        "increase": 2,
        "tracer": 1,
        "uptake": 3,
        "decrease": 3,
        "orviceversathisfeature": 1,
        "alth": 1,
        "oughveryimportanttocombine": 1,
        "imagesofarbitraryintensities": 1,
        "isnotpartofthemodelproposed": 1,
        "inthispaperwecombinethestrengthsof": 1,
        "proposeapriorthatdoesnotrelyonasegmentation": 1,
        "isconvex": 1,
        "preservestheedgesofuniquefeaturesanddoesnotrelyonany": 1,
        "assumption": 1,
        "two": 5,
        "contributions": 1,
        "contribution": 1,
        "paper": 4,
        "threefold": 1,
        "first": 4,
        "pro": 2,
        "pose": 1,
        "desired": 3,
        "property": 4,
        "outline": 1,
        "aboveandweproveitsconvexitysecond": 1,
        "weapplyotherpriors": 1,
        "work": 4,
        "license": 2,
        "creative": 1,
        "commons": 1,
        "attribution": 1,
        "fo": 1,
        "see": 13,
        "//creativecommonsorg/licenses/by/30/2190": 1,
        "transactions": 5,
        "vol": 5,
        "thathavebeenusedforotherap": 1,
        "plicationstothesettingofpet": 1,
        "finally": 2,
        "compare": 6,
        "five": 2,
        "different": 4,
        "setting": 1,
        "synthetic": 1,
        "setup": 3,
        "consider": 2,
        "random": 2,
        "variable": 1,
        "model": 8,
        "poisson": 2,
        "process": 1,
        "expectation": 2,
        "denote": 3,
        "forward": 2,
        "operator": 1,
        "includ": 1,
        "es": 1,
        "scanner": 4,
        "geometry": 2,
        "detector": 1,
        "normalizationandattenuation": 1,
        "denotesabackgroundterm": 1,
        "need": 4,
        "scatter": 3,
        "randoms": 2,
        "based": 1,
        "perform": 2,
        "via": 1,
        "objective": 1,
        "measure": 4,
        "distance": 3,
        "estimate": 2,
        "ac": 1,
        "quired": 1,
        "ed": 2,
        "afi": 1,
        "additive": 1,
        "constant": 3,
        "dependent": 3,
        "negative": 1,
        "logarithm": 1,
        "distribu": 1,
        "tionwhichnaturallycallsforanonnegativityconstraintontheimage": 1,
        "value": 2,
        "introduces": 1,
        "iknowledge": 1,
        "solution": 5,
        "seek": 2,
        "regularization": 17,
        "parameter": 21,
        "balance": 2,
        "ofinformationthatcomesfromthedatawithour": 1,
        "ibelief": 1,
        "aboutthesolution": 1,
        "apopularprioristhe": 1,
        "smooth": 5,
        "totalvari": 1,
        "ation": 2,
        "asitleadstoedgepreserveddenoisinghere": 1,
        "introducedto": 1,
        "render": 1,
        "differentiable": 1,
        "sometimes": 1,
        "scale": 2,
        "pa": 1,
        "rameteronthevaluesof": 1,
        "belowwhichedgesareconsid": 1,
        "eredtobenoisewewillreturntoadiscussionofth": 1,
        "isparameter": 1,
        "later": 1,
        "inthecontextofpetmri": 1,
        "wehavestructuralknowledgeon": 1,
        "thesolutiongivenbyananatomicalmriimage": 1,
        "extension": 2,
        "us": 2,
        "incorporatethis": 1,
        "iedgeinformationwewillde": 1,
        "notearegularizationterm": 1,
        "depend": 4,
        "associate": 1,
        "oreover": 1,
        "call": 1,
        "extra": 1,
        "whichprovidespriorinformationaboutthepetimageweseek": 1,
        "aside": 1,
        "actual": 1,
        "ii": 1,
        "methods": 2,
        "asymmetric": 1,
        "simplify": 1,
        "notation": 1,
        "introduce": 3,
        "spatially": 4,
        "varying": 3,
        "gradient": 6,
        "field": 3,
        "regularized": 1,
        "norm": 3,
        "playsasimilarroleto": 1,
        "inthatitscalesdown": 1,
        "theinfluenceof": 1,
        "whenedgesmerelyrepresentnoiseatany": 1,
        "location": 2,
        "vector": 3,
        "point": 1,
        "normalize": 1,
        "bound": 4,
        "obtain": 5,
        "upper": 2,
        "asymptotically": 1,
        "motivated": 2,
        "structurally": 1,
        "similar": 9,
        "islocally": 1,
        "anotherimage": 1,
        "euclidean": 1,
        "inner": 1,
        "product": 1,
        "sideinformation": 2,
        "ie": 4,
        "asymptoti": 1,
        "callyfor": 1,
        "isalignedto": 1,
        "inthesense": 1,
        "thatthereexistsa": 1,
        "suchthat": 1,
        "note": 3,
        "thatforthecasewhen": 1,
        "thegradientvectorisalignedto": 1,
        "zero": 3,
        "derive": 1,
        "global": 1,
        "integrate": 1,
        "local": 2,
        "entire": 1,
        "domain": 1,
        "follow": 2,
        "directly": 2,
        "nonnegative": 2,
        "align": 1,
        "almost": 2,
        "everywhere": 1,
        "perpendicular": 1,
        "setsof": 1,
        "andisperpendiculartothelevelsetsof": 1,
        "wereferto": 1,
        "thismeasureofsimilarityofstructuresasthemethodof": 1,
        "thispriorhasallthedesiredproperties": 1,
        "itisconvexin": 1,
        "cf": 14,
        "proposition": 2,
        "appendix": 2,
        "asegmentedmriimageandinthedegeneratecasewhenthemriimage": 1,
        "flat": 1,
        "independent": 2,
        "sign": 1,
        "andscale": 1,
        "apply": 1,
        "arbitrary": 1,
        "smoothing": 1,
        "employ": 1,
        "extensiontothenonsmoothcase": 1,
        "willbethesubject": 1,
        "future": 2,
        "benchmark": 1,
        "previously": 1,
        "convexandsegmentationfreepr": 1,
        "iors": 1,
        "verysameapplication": 1,
        "othershavebeenproposedforsimilar": 1,
        "geophysics": 1,
        "andcolour": 1,
        "modal": 1,
        "itieslikeelectricalimpedance": 1,
        "eit": 1,
        "ith": 1,
        "computer": 1,
        "assist": 1,
        "tomog": 1,
        "raphy": 1,
        "joint": 3,
        "et": 9,
        "al": 7,
        "petreconstructionwith": 4,
        "ananatomical": 4,
        "levelset": 4,
        "kaipio": 2,
        "alproposedtoincorporate": 1,
        "knowledge": 2,
        "whereis": 1,
        "defined": 3,
        "original": 1,
        "formulation": 1,
        "littledifferentbutitisequivalentto": 1,
        "withaslightlydifferentnormalization": 1,
        "detail": 4,
        "readily": 1,
        "aquadratic": 1,
        "rt": 2,
        "tototalvariationthispriorhasbeenproposedoriginallyintheeitcontextandweapplyittothepetmrisettingforthefirsttime": 1,
        "kazantsev": 1,
        "lot": 1,
        "bregman": 2,
        "proposed": 1,
        "formulate": 1,
        "whereagainasmoothingparameterisusedtomaketheproblem": 1,
        "differentiablethismodelfixestheproblemofkaipio": 1,
        "althat": 1,
        "featuresin": 1,
        "thatarenotpresentin": 1,
        "arepenalizedquadratically": 1,
        "andthereforeallowsedgesintheseareashowever": 1,
        "itpenalizesthedeviationof": 1,
        "andinawaysothatvectorswithopposite": 1,
        "orientation": 3,
        "arepenalized": 1,
        "even": 1,
        "orthogonal": 1,
        "bowsher": 2,
        "ithas": 1,
        "define": 1,
        "neighbour": 3,
        "voxels": 1,
        "weight": 3,
        "choose": 6,
        "positiv": 1,
        "de": 1,
        "pending": 1,
        "voxel": 3,
        "voxeland": 1,
        "otherwiseasitmighthappenthat": 1,
        "isweighteddif": 1,
        "ferently": 1,
        "eu": 1,
        "ea": 2,
        "dv": 1,
        "rsion": 1,
        "average": 1,
        "thelastpriorweben": 1,
        "chmarkagainst": 1,
        "whereaparameter": 1,
        "isusedtoadjustthescaleofthesidein": 1,
        "formationithasbeenfirstproposedasanextensionoftotalvariation": 1,
        "rgb": 1,
        "colour": 1,
        "subsequently": 1,
        "beenusedforjointreconstructioning": 1,
        "eophysics": 1,
        "andjointrecon": 1,
        "structionofpetmri": 1,
        "incontrastto": 1,
        "jointtotal": 1,
        "variationonlymakesuseofthemagnitudeofthegradientofthesideinformation": 1,
        "thereby": 1,
        "neglectingpossiblyvaluableinformation": 1,
        "recently": 1,
        "ha": 1,
        "overview": 1,
        "prop": 1,
        "erties": 1,
        "give": 2,
        "table": 1,
        "degenerated": 2,
        "isavailablewhileallofthemethodsdependonthelocationoftheedges": 1,
        "anddepend": 1,
        "ever": 1,
        "negatively": 1,
        "correlate": 1,
        "example": 1,
        "jump": 1,
        "thena": 1,
        "jumpdown": 1,
        "intheimagetobereconstructedtable": 1,
        "summary": 1,
        "priorsthelastcategory": 1,
        "onlyapplies": 1,
        "methodsthat": 1,
        "theonlypriorthat": 1,
        "fulfilsall": 1,
        "fourcriteriaproposed": 1,
        "strongly": 1,
        "penalize": 1,
        "fulfils": 1,
        "criterion": 1,
        "iii": 1,
        "numerical": 1,
        "algorithm": 5,
        "projections": 2,
        "parameters": 3,
        "inordertofairlycompareallthedifferentpriors": 1,
        "differentchoicesofpriorsdiscussed": 1,
        "inthelastsectionstobemoreprecise": 1,
        "lbfgsb": 2,
        "nonnegativityconstraint": 1,
        "implement": 1,
        "jecting": 1,
        "iterates": 1,
        "onto": 1,
        "quadrant": 1,
        "lbfg": 1,
        "sb": 1,
        "quasinewton": 1,
        "thatapproximatestheinverseofthehessianwithfirstorderinformation": 1,
        "run": 1,
        "iterationsimplementation": 1,
        "matlab": 2,
        "asthispaperfocusesonpriorsratherthanoptimizationalgo": 1,
        "rithms": 1,
        "investigate": 2,
        "weplan": 1,
        "optimization": 1,
        "applicationmoreclosely": 1,
        "particularlyforthenonsmoothcasewhen": 1,
        "geometryofonedirectplaneofthesiemensbiographmmr": 1,
        "forscannerspecificatio": 1,
        "fixedatagivenaxialposition": 1,
        "andformedbysummingsixorfive": 1,
        "dependingontheaxialposition": 1,
        "direct": 2,
        "cross": 2,
        "sinogram": 3,
        "native": 1,
        "axial": 2,
        "compression": 1,
        "span11": 2,
        "adjoint": 1,
        "operators": 1,
        "take": 1,
        "stir": 1,
        "software": 10,
        "tomographicimagereconstruction": 1,
        "thathasbeeninterfacedto": 1,
        "loss": 1,
        "bya": 1,
        "gaussian": 2,
        "blur": 1,
        "full": 1,
        "width": 1,
        "half": 2,
        "fwhm": 1,
        "4mm": 1,
        "mm": 6,
        "space": 1,
        "projection": 2,
        "back": 1,
        "test": 3,
        "theparameter": 1,
        "andhasbeenchosenin": 1,
        "whichisaround01": 1,
        "ofthemaximalgradient": 1,
        "magnitude": 2,
        "lead": 1,
        "ima": 1,
        "ge": 1,
        "tvlike": 1,
        "approximately": 1,
        "maximal": 1,
        "petimage": 1,
        "neighbourhood": 1,
        "comparison": 1,
        "lso": 1,
        "ran": 1,
        "likelihood": 1,
        "maximization": 1,
        "mlem": 3,
        "itera": 1,
        "final": 1,
        "iterate": 1,
        "filter": 1,
        "withfwhm": 1,
        "4m": 1,
        "phantoms": 1,
        "fig": 32,
        "base": 2,
        "image2192": 1,
        "fig1": 1,
        "mrisideinformationandpetdatafor": 1,
        "softwarephantom": 2,
        "hard": 1,
        "ware": 1,
        "also": 4,
        "petgroundtruth": 1,
        "highresolution": 1,
        "lowresolution": 1,
        "andregionsofinteres": 1,
        "grey": 12,
        "matter": 13,
        "white": 2,
        "lesion": 9,
        "brainweb": 1,
        "convert": 1,
        "continuous": 2,
        "spline": 1,
        "region": 4,
        "asgrey": 1,
        "cerebrospinal": 1,
        "fluid": 1,
        "cold": 1,
        "andhot": 1,
        "assign": 1,
        "con": 1,
        "stant": 1,
        "reflecting": 1,
        "fdg": 2,
        "hasbeen": 1,
        "respectively": 3,
        "wesampled": 1,
        "simulate": 1,
        "finite": 1,
        "size": 4,
        "imagesarethenaveragedover4": 1,
        "4regionstogetgroundtruth": 1,
        "1m": 1,
        "noise": 2,
        "count": 2,
        "another": 2,
        "contributingto": 1,
        "background": 2,
        "spatiallyconstant": 1,
        "smoothly": 1,
        "vary": 3,
        "resemble": 1,
        "theshape": 1,
        "xray": 1,
        "transform": 1,
        "ground": 6,
        "truth": 6,
        "know": 1,
        "attenuation": 1,
        "ct": 1,
        "wellthe": 1,
        "interest": 2,
        "pixel": 1,
        "contain": 1,
        "least": 2,
        "certain": 1,
        "type": 1,
        "eg": 1,
        "second": 4,
        "litre": 2,
        "cylindrical": 1,
        "andmridataacquisitionsthediameterandheightofthephantomwere": 1,
        "cm": 4,
        "additional": 1,
        "sixinserts": 1,
        "diameter": 1,
        "theinserts": 1,
        "solid": 2,
        "teflon": 1,
        "order": 1,
        "goodquality": 1,
        "signal": 1,
        "copper": 1,
        "sulphate": 1,
        "sodiumchloride": 1,
        "ratio": 1,
        "perone": 1,
        "water": 1,
        "far": 5,
        "mixed": 1,
        "petradiotracer": 1,
        "18ffdg": 1,
        "var": 1,
        "ying": 1,
        "radioactivity": 1,
        "concentra": 1,
        "insert": 6,
        "wasacquired": 1,
        "biogr": 1,
        "hm": 1,
        "dp": 1,
        "computational": 1,
        "efficiency": 1,
        "event": 2,
        "detectedin": 1,
        "compress": 1,
        "thesinogram": 1,
        "position": 1,
        "thescanner": 1,
        "isocentre": 1,
        "cover": 1,
        "insertsthe": 1,
        "plane": 2,
        "form": 1,
        "sum": 1,
        "six": 1,
        "anduncompressed": 1,
        "sinograms": 1,
        "wereestimated": 1,
        "offline": 1,
        "healthcarereconstruction": 1,
        "software3": 1,
        "year": 1,
        "old": 1,
        "maleepilepsypatientthedatasetiscomposedofa": 1,
        "weighted": 1,
        "utebased": 2,
        "map": 1,
        "list": 1,
        "mode": 1,
        "fdgpet": 1,
        "weightedmri": 1,
        "30t": 1,
        "te263ms": 1,
        "tr1700ms": 1,
        "ti900ms": 1,
        "flip": 1,
        "angle": 1,
        "maps": 1,
        "voxelsize156": 1,
        "156156mm": 1,
        "andpetlistmode": 1,
        "radiopharmaceutical": 1,
        "hybrid": 1,
        "mbq": 1,
        "fdgwere": 1,
        "administer": 1,
        "hour": 1,
        "min": 1,
        "acqui": 1,
        "sition": 1,
        "coregistered": 1,
        "thenresampled": 1,
        "vinci": 1,
        "account": 1,
        "motion": 2,
        "betweenthemrandpetacquisitionsasliceofthemriandthepetdataacquiredinonecompressedsinograminspan11corresponding": 1,
        "onedirect": 1,
        "detection": 1,
        "areshown": 1,
        "fig1c": 1,
        "iv": 1,
        "esults": 1,
        "results": 5,
        "choice": 5,
        "wewillfirstinves": 1,
        "tigate": 1,
        "gularization": 2,
        "dif": 1,
        "ferentmethodsformlemthenumberofiterationscanbeseenas": 1,
        "noisy": 1,
        "iteration": 4,
        "ex": 1,
        "hibit": 1,
        "semiconvergence": 1,
        "well": 2,
        "early": 1,
        "termination": 1,
        "procedure": 1,
        "find": 1,
        "suitable": 1,
        "regulari": 1,
        "zation": 1,
        "evaluate": 1,
        "term": 4,
        "si": 2,
        "dex": 1,
        "fi": 1,
        "g2": 1,
        "th": 1,
        "eop": 1,
        "imalcho": 1,
        "ceb": 1,
        "asedonth": 1,
        "erelative": 1,
        "whole": 6,
        "mark": 6,
        "four": 5,
        "plotswecanseethatforthischoiceofregularizationparameter": 1,
        "andperform": 3,
        "bestover": 1,
        "thewholephantomforbothquality": 1,
        "toprow": 1,
        "andforgreymatter": 1,
        "bottomleft": 1,
        "however": 4,
        "suboptimal": 1,
        "right": 7,
        "hot": 7,
        "handsideoffig2thiscanalsobeseeninfig3andcloseupsin": 1,
        "showing": 1,
        "optimal": 5,
        "perfect": 2,
        "versus": 1,
        "imperfect": 1,
        "next": 1,
        "comparereconstructionswithper": 1,
        "fectsideinformation": 1,
        "namely": 1,
        "thepet": 1,
        "groundtruthimage": 1,
        "versusimperfectsideinformationwhichisareconstructedmriimagefromnoisymeasurements": 1,
        "andresult": 4,
        "large": 3,
        "realistic": 1,
        "nc": 1,
        "able": 2,
        "greymattertowhite": 1,
        "isfalsely": 1,
        "inform": 2,
        "activ": 1,
        "ity": 1,
        "fact": 1,
        "activity": 2,
        "biasversusstandard": 2,
        "biasandstandard": 1,
        "sd": 1,
        "heredenotes": 1,
        "theseestimates": 1,
        "aehrhardt": 1,
        "amount": 3,
        "number": 2,
        "horizontal": 1,
        "axis": 1,
        "ptimal": 1,
        "leave": 2,
        "plot": 3,
        "3also": 1,
        "left": 5,
        "ssim": 1,
        "thewhole": 1,
        "fig3": 1,
        "light": 1,
        "shading": 1,
        "best": 3,
        "choi": 1,
        "ce": 2,
        "worse": 1,
        "similarly": 1,
        "hoice": 1,
        "corresp": 1,
        "dt": 1,
        "ot": 1,
        "ema": 1,
        "er": 2,
        "nf": 1,
        "ic": 1,
        "curvewithrespecttotheregular": 1,
        "izationparameter/numberofit": 1,
        "erationsasitcanbeclearlyseen": 1,
        "closelyfollowedby": 1,
        "wholephantom": 1,
        "greymatterandwhitematterinthelesions": 1,
        "whicharenotpresentinmri": 1,
        "allmethodsperformequallywellthe": 1,
        "paramet": 1,
        "expected": 3,
        "squarederroroverthewholephantomismarkedinallfourplotsit": 1,
        "roughly": 1,
        "whitematterbut": 1,
        "hasalwaysthesmallestbiasinaddition": 1,
        "whilethe": 1,
        "bias": 9,
        "thetwomethodsthatreducetoaquadraticfunctional": 1,
        "havea": 1,
        "slightlysmallerstandarddevia": 1,
        "tionbutlargerbiasinthisregion": 1,
        "thebiasandstandarddeviationf": 1,
        "ortheregularizationparam": 1,
        "eter": 1,
        "small": 6,
        "square": 2,
        "plottedasimagesinfig7withalineprofileinfig8asitcanbeseen": 1,
        "andboth": 1,
        "clearly": 2,
        "mattertowhitematterinterfacemoreover": 1,
        "themethodsthatreducetototalvariationinabsenceofstructuralpriorinformation": 1,
        "andhave": 2,
        "localized": 1,
        "deviationincontrast": 1,
        "thestandarddeviationof": 1,
        "appearsmore": 1,
        "furthermore": 1,
        "observe": 1,
        "smallregions": 1,
        "reconstructedwiththeleastbiasfor": 1,
        "buthaveahigherstandard": 1,
        "instance": 2,
        "lated": 1,
        "systematic": 1,
        "regularize": 1,
        "theresultsforthehardwarephantomareshowninfig9with": 1,
        "closeups": 4,
        "line": 8,
        "profiles": 5,
        "showstheresultsforallmethods": 1,
        "witha": 1,
        "regularizationchosento": 1,
        "fittingaccuracy": 1,
        "noisepropagationinorder": 1,
        "subjectivity": 1,
        "andhigher": 1,
        "would": 1,
        "like": 1,
        "highlight": 1,
        "threeaspectsthatalsocorrespondtothecloseupsinfig10firstofall": 1,
        "thehotinsertthatisnotvisibleinthesideinformationis": 1,
        "asexpected": 1,
        "reconstructedwellbythemethodsthatreducetototal2194": 1,
        "closeup": 1,
        "chosen": 1,
        "regula": 2,
        "rization": 2,
        "fig5": 1,
        "resultsforsoftwarephantom": 1,
        "groundtruth": 1,
        "petassideinform": 1,
        "ationat": 1,
        "top": 2,
        "andreconstructedmri": 1,
        "bottomtop": 1,
        "andreconstruct": 2,
        "perfectly": 1,
        "bottom": 3,
        "fails": 1,
        "mattertowhite": 4,
        "interface": 3,
        "gradientsinpetandmriarenegativel": 1,
        "ycorrelatedthesameobservationc": 1,
        "anbemadefromthelineprofilesontherightwherescaledandtranslatedlin": 1,
        "eprofiles": 1,
        "serve": 1,
        "reference": 1,
        "variationwhiletheothermethodstendtooversmooth": 1,
        "thisfea": 1,
        "turesecond": 1,
        "atthehotinsertatthebottomrightwecanseethesameeffectasatthegreymattertowhitematterinterfaceofthesoftwarephantom": 1,
        "theprior": 1,
        "disfavoursnegativelycorrelated": 1,
        "wide": 1,
        "corona": 1,
        "around": 1,
        "third": 1,
        "ofthe": 1,
        "fade": 1,
        "away": 1,
        "smoothingbehaviour": 1,
        "significantly": 1,
        "affect": 1,
        "especially": 1,
        "clear": 1,
        "noteinfig9": 1,
        "thespherethatappearsinthepetreconstruc": 1,
        "isnotanartefactitisclearlyvisi": 1,
        "bleinthemlemreconstruction": 1,
        "withsixtimesthenumberofcountsthus": 1,
        "thissphereisnotanartefact": 1,
        "natomicalpriors": 1,
        "itis": 1,
        "possible": 1,
        "detect": 1,
        "contrast": 2,
        "although": 1,
        "saywhich": 1,
        "observationsfirst": 1,
        "resulting": 1,
        "struggle": 1,
        "appear": 2,
        "verydifferent": 1,
        "confirm": 2,
        "observation": 1,
        "itehrhardt": 1,
        "fig6": 1,
        "meanabsolutebiasversusm": 1,
        "eanstandarddeviationtradeoffind": 1,
        "ifferentregionsofinterest": 1,
        "andhavethebesttradeoffforthewholephantom": 1,
        "matterandwhitematterastheircurveslie": 1,
        "underneath": 1,
        "theothercurvesb": 1,
        "utallmethodshavesimilarcurvesforthelesions": 1,
        "farright": 1,
        "hesolutionthat": 1,
        "distan": 1,
        "origin": 1,
        "graph": 1,
        "solutionshaveallroughly": 1,
        "standarddeviationforthe": 1,
        "matterandwhite": 1,
        "matterbut": 1,
        "always": 1,
        "biasinaddition": 1,
        "fig7": 1,
        "biasandstandarddeviationforsoftwarephantomfortheregulariz": 1,
        "ationparameterthatminimizesth": 1,
        "eexpectedmeansquarederror": 1,
        "andvisuallyhave": 1,
        "deviat": 1,
        "ionshows": 1,
        "phanto": 1,
        "fig7thelinesegmentismarkedintheimageatthetoprightandascal": 1,
        "versionofthemriservesasareferenceaboutanatomicalstructureallme": 1,
        "thods": 1,
        "tha": 1,
        "tr": 1,
        "ducetoaquadraticprior": 1,
        "havearelativelyflatstandarddeviation": 1,
        "three": 2,
        "va": 1,
        "ria": 1,
        "tion": 3,
        "absence": 1,
        "relatively": 1,
        "peaked": 1,
        "sharp": 4,
        "spot": 3,
        "discussion": 1,
        "section": 1,
        "discuss": 1,
        "prospect": 1,
        "limitation": 1,
        "anatom": 1,
        "beneficial": 1,
        "recovering": 1,
        "featur": 1,
        "useful": 1,
        "reconstructed": 2,
        "robust": 1,
        "errors": 1,
        "include": 1,
        "insensitive": 1,
        "inhomogeneity": 1,
        "im": 1,
        "methodology": 1,
        "relies": 1,
        "intrinsically": 1,
        "simultaneouspetmri": 1,
        "ev": 1,
        "en": 1,
        "scenario": 1,
        "encounter": 1,
        "slight": 1,
        "misregistrationeg": 1,
        "anddistortionswhich": 1,
        "artefact": 2,
        "andthe": 1,
        "particular": 2,
        "misregistration": 1,
        "isout": 1,
        "scope": 1,
        "address": 1,
        "futureresearch": 1,
        "andthesmoothingparameter": 1,
        "whileweonlyshowresultsfor": 1,
        "selection": 2,
        "briefly": 1,
        "dis": 1,
        "cuss": 1,
        "experience": 1,
        "thesmoothing": 1,
        "isrelated": 1,
        "thegradientmagnitude": 1,
        "thatshallbepreservedandcanbechoseneitherfromanunregularizedmlem": 1,
        "reconstructionorbasedonpreviousreconstructionswehavefoundthatthereconstructedimagesarenotverysensitive": 1,
        "par": 1,
        "ameter": 1,
        "factor": 1,
        "ten": 1,
        "defines": 1,
        "edgesshall": 1,
        "shall": 1,
        "encourage": 3,
        "sensitivitytothisparameterdependsonthequalityoftheanatomical2196": 1,
        "reconstructionsof": 1,
        "asside": 1,
        "caption": 1,
        "medium": 4,
        "mi": 1,
        "ddle": 1,
        "row": 4,
        "anddo": 1,
        "smearoutthehotinsertthatisnotpresentinthesideinformationmethod": 1,
        "doesnotallownegativeg": 1,
        "radientcorrelationand": 1,
        "thereforeintroducesac": 1,
        "oronaaround": 1,
        "middle": 1,
        "hand": 2,
        "despite": 1,
        "varia": 1,
        "segment": 4,
        "reg": 1,
        "ularization": 1,
        "everal": 1,
        "pha": 1,
        "ntom": 1,
        "andyield": 2,
        "without": 1,
        "oversmoothing": 1,
        "less": 1,
        "aswithallmethodsoralgorithms": 1,
        "weneedtochoosevaluesofpa": 1,
        "rameters": 1,
        "influence": 1,
        "quality": 2,
        "inthis": 1,
        "optimize": 1,
        "specttoanobjectiveandeasilycomputablequalitymeasurebutit": 1,
        "optimality": 1,
        "much": 1,
        "involve": 1,
        "human": 1,
        "analysetheimagestherefore": 1,
        "allresults": 1,
        "shouldbeinterpretedwithcareehrhardt": 1,
        "reconstructions": 1,
        "egularization": 1,
        "fail": 1,
        "egative": 1,
        "andlead": 1,
        "slightly": 1,
        "latter": 2,
        "observati": 1,
        "selec": 1,
        "nt": 1,
        "o3": 1,
        "allexperimentsinthispaperhavebeencarriedoutintwodi": 1,
        "mensions": 1,
        "save": 1,
        "computation": 1,
        "time": 1,
        "threedimensional": 1,
        "exploitallthestructureoftheproblemhowever": 1,
        "themathematicalbasisisvalidinarbitrarydimen": 1,
        "sionsandthereisnoreasonwhy": 1,
        "thismethodologyshouldnottranslatetothreedimensionsthiswill": 1,
        "subject": 1,
        "vi": 1,
        "onclusion": 1,
        "inthispaperweproposedanewpriortoincorporatestructural": 1,
        "sideinformationintoreconstructionandshoweditsapplicationfor": 1,
        "incorporatedintothereconstructionofpettheproposedpriorcombinesthe": 1,
        "strengthofotherpreviouslypublishedpriorsandhastheadvantagethatitisconvex": 1,
        "segmentationfreeandedgepreservinginthe": 1,
        "kes": 1,
        "directional": 1,
        "infor": 1,
        "mation": 1,
        "encourages": 1,
        "withalignedgradientsorparallellevelsetsmoreover": 1,
        "weintroduced": 1,
        "encour": 1,
        "age": 1,
        "setswhich": 1,
        "quadratic": 1,
        "priorto": 1,
        "arallel": 1,
        "suit": 1,
        "romotes": 1,
        "allowsnegativeedgecorrelationtheproposedmodificationtocombine": 1,
        "idea": 1,
        "allows": 1,
        "distinct": 1,
        "inthe": 1,
        "othertested": 1,
        "measures2198": 1,
        "righ": 1,
        "match": 1,
        "apart": 1,
        "theconvexityoftheproposedpriorfollowsfromarguments": 1,
        "state": 1,
        "proof": 2,
        "special": 1,
        "completeness": 1,
        "prove": 2,
        "hold": 1,
        "beingamatrixwhichisindependentof": 1,
        "write": 1,
        "convexity": 2,
        "matrix": 1,
        "let": 1,
        "dependence": 1,
        "omit": 1,
        "readability": 1,
        "notice": 1,
        "solve": 1
    },
    "objective": [
        "the propose method for this task often rely on asegmentation of the anatomical image [ 6 ] , [ 15 ] , be a heuristic modiﬁcation of a minimization p rocedure [ 16 ] , [ 17 ] , [ 20 ] or minimize a non-convex functional [ 18 ] , [ 21 ] – [ 24 ] , [ 29 ] , [ 30 ] .inallcasesthereisacompromise onstability , robustnessand/or theoretical justiﬁcation .",
        "the sensitivity of anatomical prior in general , andthe propose method in particular , to such misregistration isout of the scope of this work but might be address in futureresearch .",
        "inthis paper we have choose to optimize the parameter with re- specttoanobjectiveandeasilycomputablequalitymeasurebutit be important to note that “ optimality ” be very much applica-tion dependent and might need to involve human that analysetheimages.therefore , allresults shouldbeinterpretedwithcareehrhardt et al ."
    ],
    "references": [
        "",
        "REFERENCES [ 1 ]H .W .M ü l l e r - G ä r t n e r et al., “Measurement of radiotracer concentra- tion in brain gray matter using positron emission tomography: MRI-basedcorrectionforpartialvolumeeffects,” J. Cerbr. Blood Flow Me- tabolism, vol. 12, no. 4, pp. 571–583, 1992. [2] O.G.Rousset,Y.Ma,andA.C.Evans,“Correctionforpartialvolume effect in PET: Principle and validation,” J. Nucl. Med. ,v o l .3 9 ,n o .5 , 1998. [3] C. C. Meltzer et al., “Comparative evaluation of MR-based partial- volume correction schemes for PET,” J. Nucl. Med. , vol. 40, no. 12, pp. 2053–2065, 1999. [4] M.Soret,S.L.Bacharach,andI.Buvat,“Partial-volumeef fectinPET tumor imaging,” J. Nucl. Med. , vol. 48, no. 6, pp. 932–945, 2007. [5] K. Erlandsson, I. Buvat, P. H. Pretorius, B. A. Thomas, and B. F. Hutton, “A review of partial volume correction techniques for emis-sion tomography and their applications in neurology, cardiology andoncology,” P h y s .M e d .B i o l . ,vol.57,no.21,pp.R119–59,Nov.2012. [ 6 ]K .B a e t e ,J .N u y t s ,W .V a nP a e s s c h e n ,P .S u e t e n s ,a n dP .D u p o n t , “Anatomical-basedFDG-PETreconst ructionforthedetectionofhypo- metabolic regions in epilepsy,” IEEE Trans. Med. Imag. , vol. 23, no. 4, pp. 510–519, Apr. 2004.[7] S. R. Cherry, “Multimodality in vivo imaging systems: Twice the power or double the trouble?,” Annu. Rev. Biomed. Eng. ,v o l .8 ,p p . 35–62, 2006. [8] D. W. Townsend, “Multimodality imaging of structure and function,” Phys. Med. Biol. , vol. 53, no. 4, pp. R1–R39, 2008. [9] M.S.Judenhofer et al.,“SimultaneousPET-MRI:Anewapproachfor functional and morphological imaging,” Nat. Med. , vol. 14, no. 4, pp. 459–65, Apr. 2008. [10] B. J. Pichler, H. F. Wehrl, A. Kolb, and M. S. Judenhofer, “Positron emission tomography/magnetic res onance imaging: T he next genera- tionofmultimodalityimaging?,” Semin. Nucl. Med. ,vol.38,no.3,pp. 199–208, May 2008. [11] C.Catana,A.R.Guimaraes,and B.R.Rosen,“PETandMRimaging: The odd couple or a match made in heaven?,” J. Nucl. Med. , vol. 54, no. 5, pp. 815–24, May 2013. [12] K.Vunckx et al.,“EvaluationofthreeMRI-basedanatomicalpriorsfor quantitativePETbrainimaging,” IEEE Trans. Med. Imag. ,vol.31,no. 3, pp. 599–612, Mar. 2012. [13] B. F. Hutton et al., “What approach to brain p artial volume correction is best for PET/MRI?,” Nucl. Instrum. Meth. A. , vol. 702, pp. 29–33, Feb. 2013. [14] B. Bai, Q. Li, and R. M. Leahy, “Magnetic resonance-guided positron emission tomography image reconstruction,” Semin. Nucl. Med. , vol. 43, pp. 30–44, 2013. [15] R. M. Leahy and X. Yan, “Incorporation of anatomical MR data for improvedfunctionalimagingwithPET,”in Information Processing in Medical Imaging . New York: Springer, 1991, LNCS, pp. 105–120. [16] C.Chan,R.Fulton,D.D.Feng,andS.Meikle,“Regularizedimagere- constructionwithananatomicallyadaptivepriorforpositronemissiontomography,” Phys. Med. Biol. , vol. 54,no. 24, pp. 7379–400, 2009. [17] D. Kazantsev et al., “An anatomically driven anisotropic diffusion ﬁl- tering method for 3D SPECT reconstruction,” Phys. Med. Biol. , vol. 57, no. 12, pp. 3793–3810, 2012. [18] S.Pedemonte,A.Bousse,B.F.Hutton,S.R.Arridge,andS.Ourselin, “ProbabilisticgraphicalmodelofSPECT/MRI,”in Machine Learning in Medical Imaging . NewYork:Springer,2011,LNCS,pp.167–174. [19] L. Lu, J. Ma, Q. Feng, W. Chen, and A. Rahmim, “Anatomy-guided brainPETimagingincorporatingajointpriormodel,” P h y s .M e d .B i o l . , vol. 60, no. 6, pp. 2145–2166, 2015. [20] K. Vunckx and J. Nuyts, “Heuristic modiﬁcation of an anatomical Markov prior improves its performance,” in Proc. IEEE NSS-MIC , 2010, pp. 3262–3266. [21] J.Nuyts,“Theuseofmutualinformationandjointentropyforanatom- icalpriorsinemissiontomography,”in Proc. IEEE NSS-MIC ,2007,pp. 4149–4154. [22] S. Somayajula, E. Asma, and R. M. Leahy, “PET image reconstruc- tion using anatomical information through mutual information basedpriors,” in Proc. IEEE NSS-MIC , 2005, pp. 2722–2726. [23] S.Somayajula et al.,“Petimagereconstructionusinginformationthe- oretic anatomical priors,” IEEE Trans. Med. Imag. ,v o l .3 0 ,n o .3 ,p p . 537–549, Mar. 2011. [24] J. Tang and A. Rahmim, “Bayesian PET image reconstruction incor- poratinganato-functional jointentropy,” Phys. Med. Biol. ,vol.54,no. 23, pp. 7063–75, 2009. [25] D. Kazantsev, W. R. B. Lionheart,P. J. Withers, and P. D. Lee, “Mul- timodalimage reconstructionusingsupplementarystructural informa-tion in total variation regularization,” Sensing Imag. , vol. 15, no. 1, p. 97, Jan. 2014.EHRHARDT et al.:PETRECONSTRUCTIONWITH ANANATOMICAL MRI PRIOR USING PARALLEL LEVELSET S 2199 [26] J. P. Kaipio, V. Kolehmainen, M. Vauhkonen, and E. Somersalo, “In- verse problemswith structural prior information,” Inverse Probl. , vol. 15, no. 3, pp. 713–729, 1999. [ 2 7 ]D .K a z a n t s e v ,A .B o u s s e ,S .P e d e m o n t e ,S .R .A r r i d g e ,a n dB .F . Hutton, “Edge preserving bowsher prior with nonlocal weightingfor 3D SPECT reconstruction,” in Proc. IEEE NSS-MIC , 2011, pp. 1158–1161. [28] J.E.Bowsher et al.,“UtilizingMRIinformationtoestimateF18-FDG distributions in rat ﬂank tumors,” in Proc. IEEE NSS-MIC , 2004, pp. 2488–2492. [29] J. Cheng-Liao and J. Qi, “PET im age reconstruction with anatomical edgeguidedlevelsetprior,” Phys. Med. Biol. ,vol.56,pp.6899–6918, 2011. [30] J.TangandA.Rahmim,“Anatomy assistedPETimagereconstruction incorporatingmulti-resolutionjointentropy,” P h y s .M e d .B i o l . ,vol.60, no. 1, pp. 31–48, 2015. [31] J.M.OllingerandJ.A.Fessler,“Positron-emissontomography,” IEEE Signal Process. Mag. , vol. 14, no. 1, pp. 43–55, Jan. 1997. [32] J. Qi and R. M. Leahy, “Iterative reconstruction techniques in emis- sion computed tomography,” Phys. Med. Biol. , vol. 51, no. 15, pp. R541–R578, 2006. [33] L. I. Rudin, S. Osher, and E. Fatem i, “Nonlinear total variation based noise removal algorithms,” Physica D , vol. 60, no. 1, pp. 259–268, 1992. [34] M.J.Ehrhardt et al.,“JointreconstructionofPET-MRIbyparallellevel sets,” in Proc. IEEE NSS-MIC , 2014, pp. 1–6. [35] M. J. Ehrhardt et al., “Joint reconstruction of PET-MRI by exploiting structural similarity,” Inverse Probl. , vol. 31, p. 015001, Jan. 2015. [36] M.J.EhrhardtandS.R.Arridge,“Vector-valuedimageprocessingby parallel level sets,” IEEE Trans. Image Process. , vol. 23, no. 1, pp. 9–18, Jan. 2014. [37] M. J. Ehrhardt, “Joint reconstruction for multi-modality imaging with common structure,” Ph.D. dissertation, Univ. College London,London, U.K., 2015. [38] E.HaberandM.Holtzman-Gazit,“Modelfusionandjointinversion,” Surv. Geophys. , no. 34, pp. 675–695, Aug. 2013.[39] G.SapiroandD.L.Ringach,“Anisotropicdiffusionofmultivaluedim - ageswithapplicationstocolorﬁltering,” IEEE Trans. Image Process. , vol. 5, no. 11, pp. 1582–6, Nov. 1996. [40] M. Lysaker, S. Osher, and X.-C. Tai, “Noise removal using smoothed normalsand surfaceﬁtting,” IEEE Trans. Image Process. , vol.13,no. 10, pp. 1345–1357, Oct. 2004. [41] S.Osher,M.Burger,D.Goldfarb,J.Xu,andW.Yin,“Aniterativereg- ularizationmethodfortotalvariation-basedimagerestoration,” Multi- scale Model. Sim. , vol. 4, no. 2, pp. 460–489, 2005. [42] R. H. Byrd, P. Lu, J. Nocedal, and C. Zhu, “A limited memory algo- rithmforboundconstrainedoptimization,” SIAM J. Sci. Comput. ,vol. 16, no. 5, pp. 1190–1208, 1995. [43] J. Nocedal and S. J. Wright , Numerical Optimization .N e w Y o r k : Springer, 2000. [44] G. Delso et al., “Performance measurements of the siemens mMR in- tegratedwhole-bodyPET/MRscanner,” J. Nucl. Med. ,vol.52,no.12, pp. 1914–1922, 2011. [45] K. Thielemans et al., “STIR: Software for tomographic image recon- struction release 2,” P h y s .M e d .B i o l . , vol. 57, pp. 867–883, 2012. [46] L. A. Shepp and Y. Vardi, “Maximum likelihood reconstruction for emission tomography,” IEEE Trans. Med. Imag. , vol. 1, no. 2, pp. 113–22, Oct. 1982. [47] C. A. Cocosco, V. Kollokian, R. K.-S. Kwan, G. B. Pike, and A. C. Evans,“Brainweb:Onlineinterfacetoa3DMRIsimulatedbraindata-base,” NeuroImage ,v o l .5 ,p .4 2 5 ,1 9 9 7 . [48] M.Guerquin-Kern,L.Lejeune,K.P.Pruessmann,andM.Unser,“Re- alistic analytical phantoms for parallel magnetic resonance imaging,”IEEE Trans. Med. Imag. , vol. 31, no. 3, pp. 626–636, Mar. 2012. [49] S. Vollmar et al., “Vinci: Volume imaging in neurological research, co-registration and ROIs included,” Res. Sci. Comput. , pp. 115–131, 2003. [50] D.L.Bailey ,D.W.T ownsend,P.E.V alk,andM.N.Maisey , Positron Emission Tomography – Basic Sciences . NewYork: Springer,2005. [51] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image qualityassessment:Fromerrorvisibilitytostructuralsimilarity,” IEEE Trans. Image Process. , vol. 13, no. 4, pp. 600–12, Apr. 2004."
    ]
}{
    "name": "Super-Resolution Axial Localization of Ultrasound Scatter Using Multi-Focal Imaging",
    "paragraphs": [
        "1840 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 super-resolution axial localization of ultrasound scatter using multi-focal imaging konstantinos diamantis , alan h. greenaway , tom anderson , jørgen arendt jensen , fellow , ieee , paul a. dalgarno , and vassilis sboros abstract —objective : this paper aim to develop a method for achieve micrometre axial scatterer local- ization for medical ultrasound , surpass the inherent , pulse length dependence limit ultrasound imaging .",
        "methods : the method , directly translate from cellular microscopy , be base on multi-focal imaging and the simple , aberration-dependent , image sharpness metric of a single point scatterer .",
        "the localization of a point scatterer relies on the generation of multiple overlap sharpness curve , create by deploy three focus during receive processing , and by assess the sharpness value after each acquisition as a function of depth .",
        "each derive curve peak around the receive focus and the unique position of the scatterer be identiﬁed by combine the data from all curve use a maximum likelihood algorithm with a calibration standard .",
        "results : simulated and experimental ultrasound point scatter data show that the sharpness method can provide scatterer axial localization with an average accuracy down to 10.21 μm ( ≈λ/21 ) and with up to 11.4 time increased precision compare to conventional localization .",
        "the improvement depend on the rate of change of sharpness use each focus , and the signal to noise ratio in each image .",
        "conclusion : super-resolution axial imaging from optical microscopy have be suc- cessfully translate into ultrasound imaging by use raw ultrasound data and standard beamforming .",
        "signiﬁcance : the normalized sharpness method have the potential to be use in scatterer localization application and contribute in current super-resolution ultrasound image technique .",
        "index terms —axial localization , beamforming , multiple focusing , normalized sharpness , ultrasound image .",
        "manuscript receive august 23 , 2017 ; accept october 17 , 2017 .",
        "date of publication december 6 , 2017 ; date of current version july 17 , 2018 .",
        "this work be support in part by the science and tech- nology facilities council ( stfc-st/m007804/1 ) , in part by the danish advanced technology foundation under grant 82-2012-4 , and in part by b-k ultrasound aps .",
        "( corresponding author : paul a. dalgarno and vassilis sboros . )",
        "k. diamantis be with the institute of biological chemistry , biophysics and bioengineering , heriot-watt university .",
        "a. h. greenaway , retire , be with the institute of biological chemistry , biophysics and bioengineering , heriot-watt university .",
        "t. anderson be with the school of clinical sciences , centre of cardio- vascular science , university of edinburgh .",
        "j .",
        "a. jensen be with the department of electrical engineering , center for fast ultrasound imaging , technical university of denmark .",
        "p .",
        "a. dalgarno and v .",
        "sboros be with the institute of biological chem- istry , biophysics and bioengineering , heriot-watt university , edinburgh eh14 4as , u.k. ( e-mail : p .a.dalgarno @ hw.ac.uk ; v .sboros @ hw.ac.uk ) .",
        "digital object identiﬁer 10.1109/tbme.2017.2769164i .",
        "introduction in ultrasound imaging , the interference of emit- ted wavefront determine the focusing capability of an aperture [ 1 ] .",
        "the image resolution in the lateral direction be limit by diffraction as in all other wavefront base image method , and may vary greatly depend on the beam width and the depth of image .",
        "on the other hand , the axial resolution be ﬁxed as it only depend on the duration of the transmitted pulse .",
        "therefore , small object with dimension in the micrometre range will appear to have a size of the point spread function ( psf ) , which be comparable to the wavelength ( λ ) of the apply sound wave [ 2 ] , [ 3 ] .",
        "it be feasible to reduce the psf size by us- ing shorter pulse or transducer with high central frequency , as well as large array .",
        "in practice however , as the frequency be relate to attenuation , it be inversely relate to penetration depth [ 1 ] , [ 4 ] .",
        "as a consequence , there be a trade-off between psf dimension and penetration depth .",
        "for example , in the axial dimension tissue can be image use a transmission of a few mhz , achieve visualization over several centimetre depth , but limit the axial psf size to around the millimetre range [ 4 ] .",
        "conversely , use several hundred of mhz can provide psf size in the micrometre range , but with penetration of less than 1 mm [ 5 ] , [ 6 ] .",
        "super-resolution imaging method be base in the precise localization of single scatterers .",
        "not only do these meth- od offer improved image quality for great penetration depth but also , by provide access to exact scatterer positioning and thus velocity , they enable scatter density and dynamic mea- surements that directly relate to blood volume and blood ﬂow quantiﬁcation respectively .",
        "this lead directly to additional ben- eﬁts across ultrasound imaging in diagnostic application [ 7 ] .",
        "super-resolution imaging be well-established in other ﬁelds of sense [ 8 ] such as radar [ 9 ] – [ 11 ] , astronomy [ 12 ] , and optical microscopy [ 13 ] – [ 15 ] , however in ultrasound image it remain in its infancy .",
        "in general super-resolution ultrasound be connect to contrast enhanced ultrasound ( ceus ) , which be base on the use of contrast microbubbles ( mbs ) .",
        "it have be establish that despite the small size of the mbs ( 1–10 μm diameter ) , it be possible to distinguish single scatter event due to their high scatter cross-section [ 16 ] .",
        "ceus method therefore have a direct analogy with single molecule microscopy modality , where single scattering event be replace with single point emission event .",
        "modern imaging and signal processing enable the visualization of mb signal as they ﬂow through the vascular bed [ 17 ] .",
        "however , the requirement 0018-9294 © 2017 ieee .",
        "translations and content mining be permit for academic research only .",
        "personal use be also permit , but republication/ redistribution require ieee permission .",
        "see http : //www.ieee.org/publications standards/publications/rights/index.html for more information.diamantis et al .",
        ": super-resolution axial localization of ultrasound scatter using multi-focal imaging 1841 to use high concentration of mbs produce image that , for clinical application , allow only the vary brightness to provide a qualitative assessment of vascular kinetics .",
        "ceus be therefore , not only diffraction limit , but generally qualitative with limited potential to advance into robust quantitative measurement of the blood ﬂow dynamic .",
        "positron emission tomography ( pet ) , magnetic resonance imaging ( mri ) and contrast computed tomography ( ct ) , all provide an improved quantitative assessment of perfusion and thus be often the technology of choice in the clinic when deem cost effective .",
        "however , ultrasound be fast , safe , easy to use and generally , highly cost effective .",
        "ceus provide the foundation for super- resolution ultrasound image which , to a large extent , be base on the utilization of contrast mbs .",
        "techniques have focus on the resolution improvement achievable by image single mbs rely on ap r i o r i knowledge of the mb as a point scatter .",
        "such method provide localization base super-resolution , comparable to photoactivated localization microscopy ( palm ) and stochastic optical reconstruction microscopy ( storm ) technique , and show that more detailed and robust measurement of blood ﬂow dynamic may be obtain .",
        "by use this knowledge , o ’ reilly and hynynen have be able to obtain high resolution transcranial image of vascu- lar structure [ 18 ] , [ 19 ] that be of similar quality to those acquire by micro-ct. further , in-vivo imaging of the mouse ear microvasculature with 5-fold resolution gain have be demonstrate by christensen-jeffries et al .",
        "with the additional feature of a super-resolution velocity map [ 20 ] .",
        "couture et al .",
        "demonstrate the ultrasound equivalent of optical localization microscopy , microbubble ultrasound super-localization imag- ing ( musli ) , which can achieve individual mb lateral localiza- tion with up to λ/38 accuracy [ 21 ] , [ 22 ] .",
        "similarly , desailly et al .",
        "present the analog of ﬂuorescence palm ( f-palm ) in ultra- sound imaging , ultrafast ultrasound localization microscopy ( uulm ) [ 23 ] , [ 24 ] .",
        "by use uulm , errico et al .",
        "be able to achieve in-vivo imaging and haemodynamic quantiﬁcation of≤10μm-diameter rodent cerebral microvessels [ 7 ] .",
        "finally , ackermann and schmitz estimate single microbubble position by apply foreground detection and a modiﬁed markov chain monte carlo data association ( mcmcda ) algorithm [ 25 ] .",
        "this allow the reconstruction of vessel beyond the conventional resolution limit .",
        "these attempt demonstrate the potential for super-resolution ultrasound imaging .",
        "however , the image formation use in ul- trasound equipment be design for structural/anatomical imag- ing .",
        "the ultrasound super-resolution technique above , with the exception of uulm [ 7 ] , [ 23 ] , [ 24 ] , be apply to already beam- formed image , which be vulnerable to image quality variation , include the highly variable psf , the noise , and a number of artefact encounter in the ultrasound image .",
        "a more ro- bust approach to improve quality and spatial resolution involve wavefront modiﬁcation and adaptive array beamforming .",
        "for example , the re-emission of the received transducer element re- sponses can compensate for the wavefront distortion , cause by the change impedance mismatch between the transducer face and the target material [ 26 ] – [ 28 ] .",
        "alternatively , various adap- tive beamforming approach have show that up to λ/12 lateral resolution in the localization of isolated point scatterers can beachieved [ 29 ] , [ 30 ] , and there be an early demonstration use raw ultrasound data from in-vivo measurement [ 31 ] .",
        "the result show that particularly minimum v ariance ( mv ) beamforming could be suit to the detection of vessel stenosis [ 32 ] , and to real-time cardiac ultrasound image [ 33 ] , provide improve lateral resolution .",
        "the above approach demonstrate signiﬁcant research effort to generate ultrasound image method for improve the lat- eral resolution , which due to its dependence to focusing be sub- ject to improvement beyond the conventional limit .",
        "however , there be very little work on improvement in the axial dimension in the localization of a single point reﬂector .",
        "inherently this be more challenging due to the strict dependence of the axial psf size on the spatial pulse length ( spl ) which be constant .",
        "the spl be give by ncy×λ , where ncyis the number of cycle in the ultrasound pulse .",
        "thus , axial super-resolution be currently only dealt by the few image analysis approach describe above [ 7 ] , [ 18 ] – [ 25 ] .",
        "in this work , a new signal-based method for precise axial ultrasound point scatter localization be introduce .",
        "the method , base on simultaneous image use multiple focus , originate from optical microscopy , which also suffer from the complex nature of the psf .",
        "beamforming be use to acquire mul- tiple axially displace image of single point source emitter , and image sharpness be use to convert these image into a high precision axial localization co-ordinate .",
        "image sharpness , the integrate square intensity over the emitter , have be show to be a viable method to expand the lateral super-resolution [ 34 ] – [ 36 ] to the axial dimension [ 37 ] , [ 38 ] , in the optical analogy .",
        "it be a simple metric that represent any deviation from an in-focus image [ 39 ] – [ 41 ] , and when combine with a multi-focal imag- ing system [ 42 ] and a maximum likelihood estimation ( mle ) , have be use in optical system to extract axial localization precision below 10 nm , or λ/50 [ 43 ] , [ 44 ] .",
        "in this paper , these technique be translate into ultrasound imaging .",
        "the feasibil- ity of the method be investigate use a simple point reﬂector experimental setup .",
        "ii .",
        "m ethods a general overview of the propose method which be use for axial localization of isolated ultrasound point scatterers be depict in fig .",
        "1 .",
        "the ultrasound transmission [ see fig .",
        "1 ( a ) ] provide the point scatter data at different depth .",
        "these data be process in multiple way in receive as show in fig .",
        "1 ( b ) .t h e normalized sharpness be calculate for all scatterer position and receive focus , create multiple ( equal to the number of receive focus ) sharpness reference for each axial position .",
        "these sharp- ness value be then translate into axial position estimate , with micrometre deviation from the true scatterer position as show in in fig .",
        "1 ( c ) .",
        "a .",
        "image sharpness the metric of image sharpness can be see as a single descriptor of total psf aberration .",
        "as it be the high order aberration , sharpness be dominate by defocus , with out of focus image present low sharpness value .",
        "lower order aberration present a small perturbation to the defocus change , and can thus be ignore .",
        "sharpness thus provide a single1842 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 fig .",
        "1 .",
        "description of the propose sharpness-based axial localization method .",
        "( a ) the ultrasound reﬂection of a scatterer at a speciﬁc depth in the ﬁeld be acquire .",
        "this be repeat at several depth .",
        "( b ) the data be then beamformed ofﬂine with three receive focus .",
        "( c ) the calculation of sharpness us data from a small region of interest ( roi ) .",
        "the calcu- lation be repeat for all scatterer image , lead to high precision axial localization .",
        "quantiﬁable metric link to particle defocus position .",
        "there be no unique mathematical deﬁnition of image sharpness , but generally it involve the integration under the square of the modulation transfer function .",
        "in practice this simpliﬁes to the sum of the square of the pixel intensity , with the exact formulation tailor or optimize to the application [ 39 ] – [ 41 ] .",
        "a similar to image sharpness concept be early employ in ultrasound image relate speckle brightness to optimum focus [ 45 ] .",
        "in the previous optical work [ 44 ] a normalized version of image sharpness , sopt , be use and deﬁned as : sopt=k/summationdisplay k=1 ( n2 k−nk ) //parenleftbiggk/summationdisplay k=1nk/parenrightbigg2 , ( 1 ) for an image within a window consisting of kpixels where nkis the recorded intensity of the k-th pixel of the window .",
        "the subtraction in the numerator be to eliminate photon bias in the low-ﬂux regime , where intensity be express in photon count , and have negligible effect at modest to high-ﬂux .",
        "the cal- culation of sharpness be similar for an ultrasound image contain- ing a single point target , but the subtraction be neglect , since data be not ﬂux-dependent .",
        "in ultrasound image it be possible to access the raw radio frequency ( rf ) data from which the ﬁnal image be create and avoid distortion associate to the image formation stage ( i.e .",
        "interpolation , logarithmic compres- sion ) .",
        "upon signal acquisition the hilbert transform provide the signal envelope and the subsequent rectiﬁcation generate a pre-image signal , free from image processing bias .",
        "as a resultthe pixel intensity , which be proportional to the square of the signal amplitude , may also be substitute with the latter quan- tity , for an alternative ultrasound sharpness derivation , give by : s=q/summationdisplay q=1|eq|4/⎛ ⎝q/summationdisplay q=1|eq|2⎞ ⎠2 , ( 2 ) where sis the normalized ultrasound sharpness and |eq|2is the squared amplitude value of the q-th sample .",
        "the amplitude be derive use envelope detect data .",
        "however , there be no practical difference between the raw and envelope detect data due to the use of only even power of |eq|in ( 2 ) .",
        "the metric be calculate over qsamples in total , include a single point scatterer .",
        "the region of interest ( roi ) be deﬁned as a square box around the psf centre and of a size adequate to encompass the psf main lobe at all defocus condition .",
        "larger rois enclose the whole psf be not necessary for the sharpness calculation , while they be also likely to include undesired overlap information in the presence of multiple scatterers .",
        "b. beamforming indalgarno et al .",
        "[ 43 ] and dalgarno et al .",
        "[ 44 ] image sharp- ness be use as an adjunct to multi-plane ( multi-focal ) mi- croscopy , to demonstrate axial super-resolution potential for live cell axial imaging .",
        "as sharpness peak at focus and fall , approximately symmetrically either side of focus , a single plane give an ambiguous dissemination of position with one sharp- ness value correspond to two axial position [ 44 ] .",
        "fur- thermore , there be zero dependence around focus , where the sharpness peak have poor correlation with position .",
        "multi-plane microscopy , where distinct focal plane be image simultane- ously , remove the ambiguity by provide multiple reference to translate sharpness to an absolute axial position .",
        "to achieve this optically , a distorted diffraction grate [ 42 ] be pair with a relay lens and use as an attachment to a standard optical microscope .",
        "the same principle can be directly apply to ultra- sound imaging , however multiple focusing can be achieve by conventional beamforming without require additional hard- ware , and be therefore considerably simpler to implement than the optical equivalent .",
        "in the ultrasonic case the receive focus provide high ﬂexibility compare to transmit focus , as the element signal can be store after the transmission and beamformed ofﬂine , or even in real time , in multiple way .",
        "the conventional method to process the received transducer element signal be the delay-and-sum ( das ) beamformer [ 46 ] .",
        "the sig- nals be time-delayed , weighted , and subsequently sum to form the maximized beamformer output , b ( t ) .",
        "for a transducer array with mactive element in receive b ( t ) can be extract by : b ( t ) =m−1/summationdisplay m=0wm ( t ) xm ( t−τm ) = w ( t ) hx ( t ) , ( 3 ) where tis the time index , w ( t ) = [ w0 ( t ) , w 1 ( t ) , ... , w m−1 ( t ) ] h be the vector of the apodization weight , x ( t ) = [ x0 ( t− τ0 ) , x1 ( t−τ1 ) , ... , xm−1 ( t−τm−1 ) ] his the array of the trans- ducer element signal , and τmis the time delay apply to thediamantis et al .",
        ": super-resolution axial localization of ultrasound scatter using multi-focal imaging 1843 m-th receive element , depend on its distance from the select focus point .",
        "therefore , b ( t ) can be calculate for different focus point simply by change the time delay , and in this way the requirement for simultaneous axially displaced image in [ 43 ] , [ 44 ] can be easily meet .",
        "in this work , three different receive focus will be select , with each of the three beamformer output produce a different , but axially displace , image of the same object .",
        "c. maximum likelihood estimation the mle be an established statistical method to estimate the parameter of a dataset to a know model .",
        "it be employ in the optic approach [ 44 ] to extract the axial location of a single point scatterer use know calibration data .",
        "applied to the multi- focal imaging method , the estimate be unique , since each position be characterize by three , or more , distinct sharpness value dependent on the number of image plane employ .",
        "the calibration data can be obtain from repetitive measurement of point scatterers move in depth under equivalent experimental condition .",
        "this enable the calculation of the standard deviation of the measured mean sharpness at each position .",
        "the mean sharpness plot over the point scatterer axial distance typically form a lorentzian-like sharpness curve ( s-curve ) that peak around the best focus position .",
        "although the standard deviation do not follow any speciﬁc trend , high value be present around the peak of an s-curve and low at the edge .",
        "both statistical measure be interpolate by a factor i , to provide sub- resolution sampling and reduce inaccuracy due to quantization .",
        "the interpolated data be then use for the estimation of the probability density function ( pdf ) , p ( sj|z ) .",
        "this be the probability that a speciﬁc normalize sharpness value , sj , will be measure from the raw scatter data of a point scatterer locate at depth z , where jdenotes the focus in receive .",
        "since the sharpness calculation for each receive focus do not depend on each other and with the calibration zknown , the probability for the set of nsharpness measurement for all receive focus , when a point scatterer be locate at z , can be express as : l ( s1 , s2 , ... , sn|z ) =n/productdisplay j=1p ( sj|z ) , ( 4 ) where lis the likelihood for the set of sharpness measurement s1 , s2 , ... , snand nis the number of the receive focus .",
        "the max- imum likelihood estimator of the point depth , z , i st h ev a l u eo f z for which lis maximize give an actual dataset s1 , s2 , ... , sn and the calibration pdfs , p ( sj|z ) .",
        "for the pdf a gamma dis- tribution be select as it ﬁts best with the lorentzian shape s-curves and their variance , and be give by : p ( sj|z ) =e¯s2 j¯sα−1 j ( z ) β−α /gamma1 ( α ) , ( 5 ) where α=¯s2 j ( z ) /¯σ2 j , β=¯σ2 j/¯s2 j ( z ) , ¯sj ( z ) represent the in- terpolated s-curve , ¯ σ2 jthe interpolated variance , and /gamma1is the gamma function .",
        "the mle solution , by substitute ( 5 ) into ( 4 ) , be the point scatterer zdepth for which the product of the n gamma distribution be maximized.d .",
        "data analysis a set of three sharpness value as measure from a single data acquisition of an isolated point scatterer provide the input to the algorithm and the output be a depth position estimate , cor- responding to the pdf maximum .",
        "the method do not result in a separate psf and the pdf can be use to assess its perfor- mance .",
        "first , the accuracy of the normalized sharpness method be indicate by the depth deviation of the method ’ s z-estimate to the actual scatterer position , ddev .",
        "the true scatterer position be know for all simulation and be establish from a high pre- cision translation stage during the experimental measurement .",
        "depth estimate for all acquire datasets be calculate and com- par with the actual position .",
        "for vrepetitive measurement , ddevresults from the root mean square error ( rmse ) from allvcases .",
        "the average ddevis calculate for the total scatterer displacement and several small depth range , as in the op- tic equivalent [ 44 ] .",
        "second , the full-width-at-half-maximum ( fwhm ) of the pdf be calculate in each depth position and similar to the ddevanalysis , average pdf fwhm value be also extract .",
        "they be compare with the corresponding axial fwhm measure by the psfs of the das beamformed re- sponses [ see fig .",
        "1 ( b ) ] , provide a comparable metric with the conventional localization limit .",
        "third , the standard deviation dsd , of the average ddev , and the standard deviation ( fwhm sd ) , of the average pdf fwhm be calculate as extra indicator of the measurement ’ uncertainty .",
        "fig .",
        "2 show an example of how a single pdf lead to individual ddevand fwhm estima- tions , for a scatterer locate at a depth of 40 mm .",
        "the das axial fwhm assessment by the signal envelope be also include in the top right part of the ﬁgure .",
        "e. simulation of point scatter the ultrasound ﬁeld simulation package field ii [ 47 ] , [ 48 ] be use to model the multiple focusing requirement .",
        "a phan- tom consisting of a single point scatterer at a depth of 40 mm , be create and use as a target to replicate the optical setup .",
        "the phantom be scan by single plane wave ( pw ) emis- sion , make by a 7 mhz , 192 element , linear array simulate transducer with λspacing .",
        "the central transducer element be locate above the point target .",
        "the speed of sound , cwas set to 1540 m/s and all the parameter , for both simulation and experimental data discuss below , be give in table i .",
        "raw data from a single unfocused emission be acquire from all 192 channel individually in receive .",
        "the data be store , and the process be then repeat for 151 axial dis- placement step of 100 μm from position 32.5 mm to 47.5 mm .",
        "for the initial investigation , noise-free sharpness data be use .",
        "to introduce the uncertainty necessary for the pdf calculation , white gaussian noise be later add to the raw simulate sig- nals .",
        "ten sharpness datasets be create with a signal-to-noise ratio ( snr ) equal to 10 db .",
        "for each acquisition the data be beamformed with three different focus in receive .",
        "the central receive focus be select at a depth of 40 mm , the target ’ s initial position , and then the two other value be at −2m m and+2 mm of the start depth .",
        "the sharpness value be calculate from an area with dimension 1.3 mm ×1.3 mm1844 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 fig .",
        "2 .",
        "an exemplary pdf of the normalized sharpness method plot over depth for a simulated scatterer locate at 40 mm depth .",
        "the ddevand pdf fwhm measure use for the performance evaluation be show .",
        "the psf of the scatterer be display in the 6 mm ×6 mm image on the right , and a 60 db dynamic range display be use .",
        "on top right the signal envelope from the psf centre be plot over depth and the das axial fwhm be indicate .",
        "the pdf be scale to the maximum envelope amplitude and be also include for comparison .",
        "table i simulation and experimental scan parameters parameter name simulation experiment transducer type linear array transducer element pitch 208 μm transducer element kerf 35 μm transducer element height 4 .5m m centre frequency , f0 7m h z sampling frequency , fs 100 mhz 70 mhz bandwidth 60 % fractional speed of sound , c 1540 m/s 1484 m/s wavelength , λ=c/f0 220μm 212 μm excitation pulse two-cycle sinusoid at f0 transmit apodization hanning receive apodization hanning receive focal depth 38 mm/40 mm/42 mm number of transmit element 192 number of receive element , m 192 number of emission 1 highest scatterer position ( x , z ) = ( 0,32.5 ) mm lowest scatterer position ( x , z ) = ( 0,47.5 ) mm total distance cover 15 mm ( axially only ) z-step between 2 emission 100 μm 108 .7μm region of interest ( roi ) 1.3 mm ×1.3 mm 2.3 mm ×2.3 mm around the scatterer centre to fully enclose the defocused psf main-lobe , but minimize unnecessary background signal .",
        "f .",
        "wire-target experiment for the experimental veriﬁcation the setup depict in fig .",
        "3 be use .",
        "a wire with 0 .07 mm diameter be attach to a holder rod and be initially position at ( x , z ) = ( 0 , 40 ) mm , inside a water tank .",
        "the custom phantom position be kept ﬁxed in the two dimension ( x−and y−axis ) .",
        "after each emission the wire be move to the next zposition in the axial direction use the aims iii position setup ( onda corporation , sun- nyvale , ca ) , which be control use a matlab interface .",
        "fig .",
        "3 .",
        "illustration of the measurement setup : a wire target be in- serted into a water tank , which have the onda aims iii position sys- tem attach .",
        "the wire be move from an initial position across the z-dimension and be image for every displacement .",
        "the sarus scan- ner be use for all acquisition .",
        "the accuracy of the setup be at bad equal to the minimum movement step , which be 1 /92 mm =10.87μm as state in the equipment manual .",
        "the ratio 1 /92 be attribute to the stepper motor system .",
        "to avoid potential mechanical inaccuracy with the minimal stepper mode increment , z-steps of 108 .7μmw e r e use .",
        "consequently the total distance of 15 mm be cover in 139 step .",
        "the speed of sound be calculate to c=1484 m/s base on the water temperature [ 49 ] .",
        "the measurement be perform by the 1024 channel experimental ultrasound scan- ner sarus ( synthetic aperture real-time ultrasound system ) diamantis et al .",
        ": super-resolution axial localization of ultrasound scatter using multi-focal imaging 1845 fig .",
        "4 .",
        "point target image at different axial displacement generate by use different receive focus .",
        "columns ( a ) to ( i ) represent different depth location from 36 mm to 44 mm respectively with 1 mm gap between them .",
        "each image cover a 10 mm ×10 mm area .",
        "the noise-free simulated dataset be beamformed with three different receive ( rx ) focus position at 38 mm , 40 mm and 42 mm , show in the 1st,2nd and 3rd row respectively .",
        "a 60 db dynamic range display be use .",
        "the normalized sharpness be calculate by the envelope detect data sample or the image pixel that be include in the white box with dimension 1.3 mm ×1.3 mm show in ( a ) , ﬁ r s tr o w .",
        "fig .",
        "5 .",
        "normalized sharpness as a function of axial displacement .",
        "image derive sharpness be display in ( a ) for the middle row of the noise-free field ii image show in fig .",
        "4 use pixel value for the sharpness calculation .",
        "the corresponding signal-derived sharpness be display in ( b ) by use the envelope detect data and ( 2 ) .",
        "in ( c ) an equivalent result from optical microscopy be show for comparison .",
        "[ 50 ] and a bk ultrasound ( herlev , denmark ) linear array be use to scan the custom single-wire phantom .",
        "data be ini- tially sample at 70 mhz as the sarus scanner require , and then the sampling frequency , fswas decimate by a factor of 2 to 35 mhz .",
        "all the scan parameter can be find in table i .",
        "both simulation and measurement be conduct in a sim- ilar manner use similar parameter as indicate in table i .",
        "transmission of ultrasound be again perform through single plane wave , use all the transducer element as the transmit- ting aperture .",
        "rf data from one unfocused emission be ac- quired from all 192 channel individually in receive .",
        "ten frame be acquire per axial position .",
        "for each acquisition the data be beamformed in three different focus in receive with the use of an in-house programmed beamformation toolbox bft iii [ 51 ] .",
        "the receive focus be select to be at 38 mm , 40 mm , and 42 mm .",
        "data be produce across 15 mm , between 32.5 mm and 47.5 mm from the transducer face .",
        "after each set of 10 emission the data be store and the wire target be move to the next location in the axial direction .",
        "the roi be deﬁned , as in the previous subsection , as the small area enclose the psf main-lobe .",
        "this be 2.3 mm ×2.3 mm around the wire centre during the measurement.iii .",
        "r esults a. simulation from the ﬁrst , noise-free simulation , the result psfs of a single point scatterer move in the axial direction be show in fig .",
        "4 as a function of point displacement .",
        "similar to [ 43 ] , fig .",
        "4 demonstrate the effect of different receive focusing on the psf appearance .",
        "exemplary s-curves be form for the ultrasound data correspond to the central receive focus ( 40 mm ) .",
        "sharp- ness be calculate at each displacement , use ( 1 ) without the bias term −nkinfig .",
        "5 ( a ) , and use ( 2 ) in fig .",
        "5 ( b ) .",
        "for interest , the curve in fig .",
        "5 be display alongside an s-curve derived from optical confocal microscopy data in fig .",
        "5 ( c ) .",
        "this be generate by a setup that include a spatial pinhole with a diam- eter of 1 airy unit [ 52 ] that be position at the confocal plane of the lens use to image a red ﬂuorosphere with a diameter of 100 nm move through an axial defocus range by equivalent z-stage scanning .",
        "the optical wavelength be equal to 650 nm and the total displacement 8 μm for the ﬂuorescent particle .",
        "the pinhole addition result into the elimination of out-of-focus light and provide a close approximation to the focus ultrasound upon receive which be use here as show in fig .",
        "1 ( b ) .1846 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 fig .",
        "6 .",
        "( a ) a set of three normalized s-curves and their lorentzian ﬁts be display .",
        "these be generate use a simulated ultrasound point target that be move in the depth direction , and an unfocused pw ultrasound transmission that be beamformed use three different focus in receive ( at 38 mm , 40 mm and 42 mm respectively ) .",
        "the mean sharpness value for a single axial position at 38.4 mm be measure from the 3 psfs show on the left , as an example ( see text for sharpness value ) .",
        "each beamformed response corresponds to each receive focus and to that speciﬁc depth position .",
        "the ddevand the pdf fwhm achieve by the normalized sharpness method be show in ( b ) for image-derived sharpness and in ( c ) for signal-derived sharpness , for each depth position .",
        "the dark gray line in ( b ) and ( c ) indicate the das axial fwhm .",
        "the general shape of all s-curves show in fig .",
        "5 be simi- lar , maximize at a single peak around the focus , and fall rapidly , and roughly symmetrically with defocus .",
        "this provide conﬁdence that the establish multi-focal sharpness method be translatable from optical to ultrasound imaging .",
        "the signal- derived s-curve [ see fig .",
        "5 ( b ) ] be fall more rapidly than the image-derived s-curve [ see fig .",
        "5 ( a ) ] , and the high rate of change notice in fig .",
        "5 ( b ) increase the sensitivity when usingthe mle .",
        "for the calculation of each of the ultrasound signal- derive sharpness value , 12 ×169 envelope detect data sam- ples be process correspond to the 1.3 mm ×1.3 mm roi .",
        "the same region be represent by 45 ×45 square pixel of image data .",
        "the introduction of noise to the rf signal allow the gener- ation of a calibration standard base on the calculation of mean sharpness value and their standard deviation , for use with thediamantis et al .",
        ": super-resolution axial localization of ultrasound scatter using multi-focal imaging 1847 mle analysis .",
        "in fig .",
        "6 ( a ) the mean sharpness be plot over axial displacement for the three receive focus ( 38 mm , 40 mm , 42 mm ) .",
        "the best lorentzian ﬁts of the 3 sharpness datasets be also include in fig .",
        "6 ( a ) .",
        "the ﬁts be not mean as ac- curate representation of the sharpness function , however , they return correlation coefﬁcient , rvalues , high than 0.97 for all 3 case between ﬁtted and s-curves , allow , in this example , for a good approximation .",
        "the error bar represent the sharpness standard deviation in each depth .",
        "the displayed data result from ten field ii simulation in each z-position as explain in section ii-e. each curve ’ s peak be locate around the posi- tion of each receive focus .",
        "as an example , a set of 3 psfs from each focal plane for a single axial position at 38.4 mm , be also show .",
        "each image be 6 mm ×6 mm and a 60 db dynamic range display be use .",
        "mean sharpness value be calcu- lated from the displayed psfs , to 6 .548×10−3 ( ±6×10−6 ) , 4.197×10−3 ( ±6×10−6 ) and 2 .972×10−3 ( ±2×10−6 ) f o r the 1st , 2nd and 3rd receive focus respectively .",
        "fig .",
        "6 ( b ) and ( c ) show the theoretical accuracy in the scatterer axial localization base on the image- and signal-derived sharp- ness value respectively , the mle method and the metric de- scribed in section ii-d .",
        "the image-derived sharpness processing result in an average depth deviation to actual scatterer position ( ddev ) equal to 47 .43μm ( ≈λ/5 ) for the whole depth range be- tween 32.5 mm and 47.5 mm .",
        "the standard deviation of the ddev ( dsd ) be equal to 79 .66μm ( ≈λ/3 ) .",
        "this be because several low-precision depth estimate ( ddev∼=λ ) be include in the calculation .",
        "the calculated pdf fwhm be on average equal to 78.67μm ( ≈λ/3 ) which be 2.2 time low than the das axial fwhm ( 170 .35μm ) that be always constant regardless of scatterer or receive focus position .",
        "the corresponding stan- dard deviation of the pdf fwhm ( fwhm sd ) be 63 .37μm ( ≈λ/3.5 ) .",
        "these metric improve signiﬁcantly for the signal- derived sharpness processing [ see fig .",
        "6 ( c ) ] .",
        "for the same range the average ddevwas calculate to 29 .4μm ( ≈λ/7.5 ) , and the dsdto 91.47μm ( ≈λ/2.5 ) .",
        "in a similar manner , the average pdf fwhm be calculate to 32 .56μm ( ≈λ/7 ) which be 6.8 time low than the das axial fwhm , and the fwhm sdto 103.42μm ( ≈λ/2 ) .",
        "in general , the high standard deviation val- ues be due to the increase ddevand pdf fwhm value at region of reduced rate of sharpness change such as the dis- placement edge or the s-curve peak [ see fig .",
        "6 ( a ) ] .",
        "this be a feature in common with the optical equivalent and it be worth compare two small range in the ultrasound analogue .",
        "for instance , the 1 mm range between 37.5 mm and 38.5 mm be far from both displacement end and include the peak of the ﬁrst s-curve around the 38 mm receive focus and the low part of the other two s-curves ’ slope .",
        "for this range the average ddevwas equal to 3 .48μm , the dsdwas 2.72μm , the average pdf fwhm be 9 .1μm and the fwhm sdwas 6.91μm .",
        "the 1 mm range between 38.5 mm and 39.5 mm include the max- imum rate of sharpness change for the s-curves correspond to the ﬁrst two receive focus ( 38 mm and 40 mm ) and the low part of the s-curve slope correspond to the long receive focus ( 42 mm ) .",
        "for the second small range , the average ddev w a sa sl o wa s1 .25μm , the dsdwas 0.67μm , the average pdf fwhm be 4 .5μm and the fwhm sdwas 1.26μm .",
        "these fig .",
        "7 .",
        "five psfs correspond to maximum , middle and zero dis- placement for both end , during the wire-target experiment .",
        "the re- ceive focus be set to 40 mm .",
        "each image include an area of 6 mm ×6 mm and a 60 db dynamic range display be use .",
        "the normalized sharpness be calculate by the rf sample include in the white box with dimension 2.3 mm ×2.3 mm show in ( a ) .",
        "result show that by avoid the s-curve edge and focus on the slope the performance of the method improve greatly , while the inclusion of a peak slightly compromise the accu- racy of the localization , and this be consistent with other such sub-ranges across the entire displacement investigate here .",
        "b. wire-target experiment five experimentally acquire psfs of a wire-target moving in the axial direction from a single plane ( receive focus =40 mm ) be show in fig .",
        "7 in different axial displacement .",
        "the ﬁgure be equivalent to fig .",
        "4 ( 2nd row ) and the receive beamforming be expand to two far receive focus ( 38 mm and 42 mm ) , as in the simulation .",
        "in fig .",
        "8 ( a ) , the measure mean sharpness be plot over axial displacement and the best lorentzian s-curve ﬁts ( r > 0.98 ) be also add .",
        "the error bar rep- resent the sharpness standard deviation for each depth .",
        "the displayed sharpness data result from 10 experimentally ac- quired frame in each z-position .",
        "each curve ’ s peak be locate around the position of each receive focus .",
        "the set of 3 psfs from z=38.37 mm be also show as an example .",
        "each image be 6 mm ×6 mm and a 60 db dynamic range display be use .",
        "the mean sharpness value be calculate to 8 .491×10−3 ( ±1.4×10−5 ) , 5.938×10−3 ( ±9×10−6 ) and 4 .053×10−3 ( ±6×10−6 ) for the 1st , 2nd and 3rd receive focus respectively .",
        "fig .",
        "8 ( b ) and ( c ) show the accuracy in the wire axial localization base on the sharpness processing for image- and signal-derived sharpness respectively .",
        "as in the simulation study , the use of the envelope detect data for the sharpness calculation outperform the image sharpness processing .",
        "the latter result in an average ddevequal to 63 .67μm ( o r≈λ/3 ) .",
        "the dsdwas equal to 102.35 ( or ≈λ/2 ) due to several ddev value higher than the wavelength ( 212 μm ) , locate at the dis- placement edge .",
        "the calculated pdf fwhm be on average equal to 83 .91μm ( ≈λ/2.5 ) which be 3.4 time low than the das axial fwhm , which be measure to 287 .31μm from the signal envelope that pass through the centre of the psf as show in fig .",
        "2 .",
        "the corresponding fwhm sdwas 83 .86μm ( ≈λ/2.5 ) .",
        "for the signal-derived sharpness the average ddev be calculate to 10 .21μm ( o r≈λ/21 ) .",
        "the dsdfor the entire depth range be calculate to 16 .11μm ( o r≈λ/13 ) , indicate small variation between the ddevvalues compare to the simulation study .",
        "the average pdf fwhm be calculate to1848 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 fig .",
        "8 .",
        "( a ) a set of three normalized s-curves and their lorentzian ﬁts be display .",
        "these be generate use a wire-target that be move in the depth direction , and an unfocused pw ultrasound transmission that be beamformed use three different focus in receive ( at 38 mm , 40 mm and 42 mm respectively ) .",
        "the mean sharpness value for a single axial position at 38.37 mm be measure from the 3 psfs show on the left , as an example ( see text for sharpness value ) .",
        "each beamformed response corresponds to each receive focus and to that speciﬁc depth position .",
        "the ddevand the pdf fwhm achieve by the normalized sharpness method be show in ( b ) for image-derived sharpness and in ( c ) for signal-derived sharpness , for each depth position .",
        "the dark gray line in ( b ) and ( c ) indicate the das axial fwhm .",
        "25.15μm ( ≈λ/8.5 ) which be 11.4 time low than the das axial fwhm , and the fwhm sdwas 35 .09μm ( ≈λ/6 ) .",
        "the two 1 mm range be also investigate as in the sim- ulation study .",
        "for the 1 mm depth range between 37.5 mm and 38.5 mm , the average ddevwas equal to 3 .22μm , the dsd be 2.07μm , the average pdf fwhm be 9 .06μm and the fwhm sdwas 2.93μm .",
        "the 1 mm range between 38.5 mm and 39.5 mm result in slightly low value for the same metric , conﬁrming the beneﬁts of examine area where the sharpness change rapidly .",
        "an average ddevequal to 1 .52μm be cal-culated , the dsdwas 0.90μm , the average pdf fwhm be 7.53μm and the fwhm sdwas 2.66μm .",
        "iv .",
        "d iscussion the principle of multi-focal axial ultrasound localization have be demonstrate through the use of the sharpness metric ap- ply to simulate and experimental point scatter data .",
        "while a large number of beamforming method [ 30 ] , [ 53 ] , [ 54 ] have show signiﬁcant localization gain in the lateral ultrasound ar-diamantis et al .",
        ": super-resolution axial localization of ultrasound scatter using multi-focal imaging 1849 ray dimension , this be the ﬁrst beamforming technique to show signiﬁcant gain in the axial direction .",
        "the propose method exploit the effect of defocus on the diffraction-limited lateral resolution to achieve high precision localization in the axial di- mension , and be base on a previously present method for super-resolution optical microscopy [ 43 ] , [ 44 ] .",
        "in optic , in the absence of other aberration , sharpness be purely dependent on defocus .",
        "the inﬂuence of defocus aberration on the psf shape be similar for optic and ultrasonics , which enable the trans- lation of the technique .",
        "the only difference be in the wave- length ( ∼500 nm for optic compare to ∼200μm for ultra- sonics ) , which result in nanometre ( ≈10 nm ) and micrometre ( ≈10μm ) depth localization precision , respectively .",
        "a 25 % low depth deviation ( ddev ) to actual scatterer po- sition be acquire in simulation ( 47 .43μm ) compare to ex- periment ( 63 .67μm ) for the image-derived sharpness analysis .",
        "however , the processing that utilize image data be less reliable as describe in section iii-a , and overall result in limited localization improvement for both simulation and experiment .",
        "the signal-derived sharpness analysis show improved per- formance by a factor of ≈3 for the wire-target measurement ( 10.21μm ) compare to the simulated scatterer ( 29 .4μm ) , with both ddevvalues signiﬁcantly low than those obtain from the image data .",
        "the difference between simulation and experimen- tal study be attribute to the nature and amplitude of the noise add to the simulate data .",
        "the noise be assume gaussian as common practice for most noise process and high than in the experimental case , provide increase ddevnear to the displacement edge , and subsequently a high dsd .",
        "similar conclusion be draw from the introduction of the average pdf fwhm and its standard deviation as performance metric , which also enable a comparison with the das-derived axial localization ( das axial fwhm ) .",
        "this be an indirect com- parison since the propose method do not result in a psf .",
        "however it be show in fig .",
        "2 that the pdf generate by the sharpness processing can be use to limit the depth position range as this be calculate by the axial psf size .",
        "in simula- tion the image-derived sharpness analysis provide 7 % low average pdf fwhm ( 78 .67μm ) , compare to the experiment ( 81.93μm ) .",
        "however this be translate in 2.2- and 3.4-fold im- provements compare to the das localization , since the das axial fwhm be 287 .31μm for the wire-target and 170 .35μm for the simulated point scatterer .",
        "the signal-derived sharpness analysis result in similar average pdf fwhm value for the simulated scatterer ( 32 .56μm ) and the wire-target measure- ments ( 25 .15μm ) far increase the axial localization gain to 6.8- and 11.4-fold respectively .",
        "in the experimental case , the fwhm sdwas also calculate low by a factor of ≈3 than the one obtain from the simulate data .",
        "in addition , the method do not perform uniformly for the whole displacement range .",
        "the data analysis of small sub-regions show that away from the displacement edge and in area dominate by at least two of thes-curve slop the technique perform best , achieve axial localization with low than 3 .5μm precision and an average pdf fwhm up to 38 time low than the das axial fwhm for both simulation and measurement .",
        "however , this result be not conclusive and the method need to develop far in or-der to identify whether such axial localization accuracy can be achieve consistently for a large range of depth .",
        "in general , the ability of the propose method to control the sharpness value by alter the time delay could potentially allow its usage for optimum focusing deﬁnition or aberration correction application in ultrasound imaging [ 45 ] .",
        "however , the obvious application in ultrasound be the depth detection of contrast microbubbles .",
        "current microbubble visualization have enable the use of localization algorithm on image data .",
        "this have typically be accomplish by identify the psf centre of mass of spatially isolated bubble [ 20 ] , [ 55 ] or by ﬁtting three dimensional gaussians to approximate the psf and thus estimate the position of the bubble [ 18 ] , [ 19 ] , [ 56 ] , approach which be inaccurate for axial determination .",
        "the method propose here can be develop to be apply as an adjunct to these technique .",
        "the use of contrast microbubbles will allow translation to real imaging application where the limiting factor will be snr and image quality .",
        "new image post-processing may stem from combine the conventional lateral appearance of a point target and the sharpness derive axial one .",
        "this will have the advantage of improved psf shape deﬁnition in a noiseless meta-image , thus contribute to the optimization of current image base psf localization .",
        "furthermore , the sharpness method can be consider as an adjunct to other signal-based method for lateral resolution such as the minimum v ariance beamformer [ 30 ] , [ 53 ] , [ 54 ] .",
        "this may improve localization by provide a much small psf for further analysis by the same image base technique .",
        "the overall accuracy of the technique and its application to real-time mb image depends on a number of factor .",
        "first , the mbs be know for their poly-dispersed nature and their signal variation , and the normalization factor from ( 2 ) compensates for different mb echo signal .",
        "second , the snr in mb imaging be not the typical snr from ultrasound image , but rather the demodulated signal to clutter ratio , after the linear tissue signal have be reject , use pulse modulation ( such as phase or amplitude ) , to create the mb only image .",
        "in these image , mbs tend to be clearly identiﬁable compare to the dark background and the scatter can be identiﬁed in order to implement the sharp- ness method .",
        "the snr in the current study be well than that available in in-vivo imaging , but not signiﬁcantly .",
        "in any case , the impact of snr on localization accuracy need to be inves- tigated far in order to explore the potential of the technique for real imaging .",
        "another important aspect of ultrasound imag- ing be the psf , and thus snr variability , across the image .",
        "this be due to the signal processing as well as the beam change that occur due to attenuation and speed of sound variation impose by real tissue in the near ﬁeld for the transducer array .",
        "this may translate in vary localization accuracy across the image .",
        "further complexity be introduce by the sharpness relation to focus .",
        "it be the defocus that minimize localization error , which appear to counter balance the decrease in the ultrasound image snr in that range .",
        "third , the mb detection sensitivity may vary as , in addition to snr , the variable beam pressure across the im- age provide a variable number of mbs that scatter above noise [ 16 ] .",
        "note , that in-vivo there be a correlation between mb den- sity with blood volume , and as a result super-resolution contrast1850 ieee transactions on biomedical engineering , vol .",
        "65 , no .",
        "8 , august 2018 ultrasound image aim to generate quantitative blood volume map .",
        "the variation of the ultrasound beam pressure impact on the relationship between mb number and blood volume and the psf variation across the image .",
        "the psf may therefore be use as a marker of mb density variation .",
        "fourth , a single scatterer must be include in the select roi for each sharpness calculation as outline in section ii-a .",
        "in a real-time imaging environment an initial rough estimation of scatterers position base on standard das beamforming will be follow by the roi selection .",
        "the application of thresholding criterion such as intensity , shape or morphology will need to be implement to discard echo that violate the single scatterer requirement .",
        "this may be due to the overlap psfs or side- lobe contribution from neighbor scatterers .",
        "the localization technique will be apply to a single frame and then the whole processing will be repeat for the next frame .",
        "the concept be similar to optical microscopy [ 57 ] .",
        "in case of high mb den- sity , the roi rejection rate will be high , increase the number of frame that need to be process until an adequate number of isolated target be reach and localize throughout the en- tire image .",
        "as a consequence an efﬁcient roi size selection be closely relate to the single scatterer assumption and the acqui- sition time .",
        "in this work the roi selection be not signiﬁcant since there be only a single scatterer in all image .",
        "however , it be show that use the size of the psf main lobe as reference , be a valid approach in order to achieve a robust roi selection and potentially maximize the useful rois number in a frame .",
        "us- ing the ﬁgures present during the wire-target measurement , a1 5m m ×15 mm area divide into 2.3 mm ×2.3 mm box could include at most 42 rois include an isolated scatterer per frame .",
        "the localization of several thousand of mbs would be require for a density map generation .",
        "the number of frame will therefore depend on the number of mbs that can practi- cally be detect per frame give a low infusion concentration to achieve isolated mb scatter in the image , and the tissue vascular structure that impose a vary mb density across the image .",
        "moreover , the type of ultrasound transmission may have an impact on the method ’ s performance .",
        "the plane wave transmis- sion be choose in this paper , because it be the best approx- imation to the unfocused light transmission as in the optical measurement .",
        "in addition , it facilitate fast acquisition as only one emission be able to provide all the necessary data for the method and thus be not subject to artefact due to the parti- cle movement between several emission that be all use to form one image .",
        "however synthetic aperture ( sa ) ultrasound can offer similar beneﬁts .",
        "the image acquire from single sa emission will maintain the same high frame rate , without re- ducing image quality .",
        "the dependence of the sharpness-based localization method on the transmit focus need to be explore .",
        "focused ultrasound require a high number of emission to produce a single image , but the image quality around the focus area be signiﬁcantly improve .",
        "considering that apodization also play an important role in the ultrasound beam shaping , this be another parameter that need to be explore .",
        "however , all the above remain to be investigate .",
        "in addition , further research be require for target that be locate at great depth , or provide low snr .",
        "finally , in this paper it be demonstrate how 3receive focus at 2 mm separation be adequate for a localization precision of 10 .21μm over a displacement range of 15 mm .",
        "it be clear that by extend the number of receive focus this range can be increase , and that by optimize the foci space fur- ther localization accuracy can be tune .",
        "ultimately there will be trade-off between depth range , number of focus and focus spacing , which need to be balance in response to speciﬁc image prob- lem and system .",
        "in theory an unlimited number of s-curves can be form , as the receive focus location can be unlimited .",
        "this be a major advantage of the ultrasound implementation of the method compare to the optical equivalent , where hardware challenge limit the number of plane to typically less than 10 .",
        "in the end , the method need to be develop in tissue-like medium that provide complex aberration .",
        "indeed , the psf of ultrasound be know to be very variable across the image due to vary attenuation and reﬂections inside the human body .",
        "this be not unique to ultrasound .",
        "the ﬂickering of the star be cause by the change of refraction in the atmosphere due to its movement .",
        "while this problem be resolve systematically for astronomy use adaptive optic method [ 58 ] , it remain for ultrasound imaging , which be a highly operator dependent technique and the image be qualitatively compensate for the variation in the ultrasound ﬁeld .",
        "this may well prove a key advantage of the normalized sharpness method , which do not require an understanding of the exact aberration or any pre- deﬁned psf model .",
        "v. c onclusion the defocusing error of a point scatterer at different axial po- sitions be examine for ultrasound imaging .",
        "they be quan- tiﬁed by the metric of normalized sharpness , which become maximum for in-focused image and fall spatially roughly symmetrically away from focus .",
        "this depth dependence of the sharpness value when plot together , and the ability in ultra- sound image to obtain multi-focal image of the same object offer a simple method that provide high-precision axial local- ization .",
        "experimental result show that a set of 3 sharpness value be adequate to localize the axial position of a point tar- get with ≈10 micrometre accuracy , also reduce the conven- tional axial full-width-at-half-maximum ( fwhm ) by a factor of≈11 .",
        "this initial investigation show that the technique be well-suited for ultrasound point scatterers .",
        "the technique may complement image-based method currently use for microbub- ble detection , or other beamforming technique focus in the lateral resolution to fully describe point scatter position base exclusively on signal processing ."
    ],
    "processed_text": "1840 ieee transactions biomedical engineering vol 65 8 august 2018 superresolution axial localization ultrasound scatter using multifocal imaging konstantinos diamantis alan h greenaway tom anderson jrgen arendt jensen fellow ieee paul dalgarno vassilis sboros abstract objective paper aim develop method achieve micrometre axial scatterer local ization medical ultrasound surpass inherent pulse length dependence limit ultrasound imaging methods method directly translate cellular microscopy base multifocal imaging simple aberrationdependent image sharpness metric single point scatterer localization point scatterer relies generation multiple overlap sharpness curve create deploy three focus receive processing assess sharpness value acquisition function depth derive curve peak around receive focus unique position scatterer identified combine data curve use maximum likelihood algorithm calibration standard results simulated experimental ultrasound point scatter data show sharpness method provide scatterer axial localization average accuracy 1021 /21 114 time increased precision compare conventional localization improvement depend rate change sharpness use focus signal noise ratio image conclusion superresolution axial imaging optical microscopy suc cessfully translate ultrasound imaging use raw ultrasound data standard beamforming significance normalized sharpness method potential use scatterer localization application contribute current superresolution ultrasound image technique index terms axial localization beamforming multiple focusing normalized sharpness ultrasound image manuscript receive august 23 2017 accept october 17 2017 date publication december 6 2017 date current version july 17 2018 work support part science tech nology facilities council stfcst/m007804/1 part danish advanced technology foundation grant 8220124 part bk ultrasound aps corresponding author paul dalgarno vassilis sboros k diamantis institute biological chemistry biophysics bioengineering heriotwatt university h greenaway retire institute biological chemistry biophysics bioengineering heriotwatt university anderson school clinical sciences centre cardio vascular science university edinburgh j jensen department electrical engineering center fast ultrasound imaging technical university denmark p dalgarno v sboros institute biological chem istry biophysics bioengineering heriotwatt university edinburgh eh14 4as uk email p adalgarno @ hwacuk v sboros @ hwacuk digital object identifier 101109/tbme20172769164i introduction ultrasound imaging interference emit ted wavefront determine focusing capability aperture 1 image resolution lateral direction limit diffraction wavefront base image method may vary greatly depend beam width depth image hand axial resolution fixed depend duration transmitted pulse therefore small object dimension micrometre range appear size point spread function psf comparable wavelength apply sound wave 2 3 feasible reduce psf size us ing shorter pulse transducer high central frequency well large array practice however frequency relate attenuation inversely relate penetration depth 1 4 consequence tradeoff psf dimension penetration depth example axial dimension tissue image use transmission mhz achieve visualization several centimetre depth limit axial psf size around millimetre range 4 conversely use several hundred mhz provide psf size micrometre range penetration less 1 mm 5 6 superresolution imaging method base precise localization single scatterers meth od offer improved image quality great penetration depth also provide access exact scatterer positioning thus velocity enable scatter density dynamic mea surements directly relate blood volume blood flow quantification respectively lead directly additional ben efits across ultrasound imaging diagnostic application 7 superresolution imaging wellestablished fields sense 8 radar 9 11 astronomy 12 optical microscopy 13 15 however ultrasound image remain infancy general superresolution ultrasound connect contrast enhanced ultrasound ceus base use contrast microbubbles mbs establish despite small size mbs 110 diameter possible distinguish single scatter event due high scatter crosssection 16 ceus method therefore direct analogy single molecule microscopy modality single scattering event replace single point emission event modern imaging signal processing enable visualization mb signal flow vascular bed 17 however requirement 00189294 2017 ieee translations content mining permit academic research personal use also permit republication/ redistribution require ieee permission see http //wwwieeeorg/publications standards/publications/rights/indexhtml informationdiamantis et al superresolution axial localization ultrasound scatter using multifocal imaging 1841 use high concentration mbs produce image clinical application allow vary brightness provide qualitative assessment vascular kinetics ceus therefore diffraction limit generally qualitative limited potential advance robust quantitative measurement blood flow dynamic positron emission tomography pet magnetic resonance imaging mri contrast computed tomography ct provide improved quantitative assessment perfusion thus often technology choice clinic deem cost effective however ultrasound fast safe easy use generally highly cost effective ceus provide foundation super resolution ultrasound image large extent base utilization contrast mbs techniques focus resolution improvement achievable image single mbs rely ap r r knowledge mb point scatter method provide localization base superresolution comparable photoactivated localization microscopy palm stochastic optical reconstruction microscopy storm technique show detailed robust measurement blood flow dynamic may obtain use knowledge reilly hynynen able obtain high resolution transcranial image vascu lar structure 18 19 similar quality acquire microct invivo imaging mouse ear microvasculature 5fold resolution gain demonstrate christensenjeffries et al additional feature superresolution velocity map 20 couture et al demonstrate ultrasound equivalent optical localization microscopy microbubble ultrasound superlocalization imag ing musli achieve individual mb lateral localiza tion /38 accuracy 21 22 similarly desailly et al present analog fluorescence palm fpalm ultra sound imaging ultrafast ultrasound localization microscopy uulm 23 24 use uulm errico et al able achieve invivo imaging haemodynamic quantification of10mdiameter rodent cerebral microvessels 7 finally ackermann schmitz estimate single microbubble position apply foreground detection modified markov chain monte carlo data association mcmcda algorithm 25 allow reconstruction vessel beyond conventional resolution limit attempt demonstrate potential superresolution ultrasound imaging however image formation use ul trasound equipment design structural/anatomical imag ing ultrasound superresolution technique exception uulm 7 23 24 apply already beam formed image vulnerable image quality variation include highly variable psf noise number artefact encounter ultrasound image ro bust approach improve quality spatial resolution involve wavefront modification adaptive array beamforming example reemission received transducer element sponses compensate wavefront distortion cause change impedance mismatch transducer face target material 26 28 alternatively various adap tive beamforming approach show /12 lateral resolution localization isolated point scatterers beachieved 29 30 early demonstration use raw ultrasound data invivo measurement 31 result show particularly minimum v ariance mv beamforming could suit detection vessel stenosis 32 realtime cardiac ultrasound image 33 provide improve lateral resolution approach demonstrate significant research effort generate ultrasound image method improve lat eral resolution due dependence focusing sub ject improvement beyond conventional limit however little work improvement axial dimension localization single point reflector inherently challenging due strict dependence axial psf size spatial pulse length spl constant spl give ncy ncyis number cycle ultrasound pulse thus axial superresolution currently dealt image analysis approach describe 7 18 25 work new signalbased method precise axial ultrasound point scatter localization introduce method base simultaneous image use multiple focus originate optical microscopy also suffer complex nature psf beamforming use acquire mul tiple axially displace image single point source emitter image sharpness use convert image high precision axial localization coordinate image sharpness integrate square intensity emitter show viable method expand lateral superresolution 34 36 axial dimension 37 38 optical analogy simple metric represent deviation infocus image 39 41 combine multifocal imag ing system 42 maximum likelihood estimation mle use optical system extract axial localization precision 10 nm /50 43 44 paper technique translate ultrasound imaging feasibil ity method investigate use simple point reflector experimental setup ii ethods general overview propose method use axial localization isolated ultrasound point scatterers depict fig 1 ultrasound transmission see fig 1 provide point scatter data different depth data process multiple way receive show fig 1 b h e normalized sharpness calculate scatterer position receive focus create multiple equal number receive focus sharpness reference axial position sharp ness value translate axial position estimate micrometre deviation true scatterer position show fig 1 c image sharpness metric image sharpness see single descriptor total psf aberration high order aberration sharpness dominate defocus focus image present low sharpness value lower order aberration present small perturbation defocus change thus ignore sharpness thus provide single1842 ieee transactions biomedical engineering vol 65 8 august 2018 fig 1 description propose sharpnessbased axial localization method ultrasound reflection scatterer specific depth field acquire repeat several depth b data beamformed offline three receive focus c calculation sharpness us data small region interest roi calcu lation repeat scatterer image lead high precision axial localization quantifiable metric link particle defocus position unique mathematical definition image sharpness generally involve integration square modulation transfer function practice simplifies sum square pixel intensity exact formulation tailor optimize application 39 41 similar image sharpness concept early employ ultrasound image relate speckle brightness optimum focus 45 previous optical work 44 normalized version image sharpness sopt use defined sopt=k/summationdisplay k=1 n2 knk //parenleftbiggk/summationdisplay k=1nk/parenrightbigg2 1 image within window consisting kpixels nkis recorded intensity kth pixel window subtraction numerator eliminate photon bias lowflux regime intensity express photon count negligible effect modest highflux cal culation sharpness similar ultrasound image contain ing single point target subtraction neglect since data fluxdependent ultrasound image possible access raw radio frequency rf data final image create avoid distortion associate image formation stage ie interpolation logarithmic compres sion upon signal acquisition hilbert transform provide signal envelope subsequent rectification generate preimage signal free image processing bias resultthe pixel intensity proportional square signal amplitude may also substitute latter quan tity alternative ultrasound sharpness derivation give s=q/summationdisplay q=1eq4/ q/summationdisplay q=1eq2 2 2 sis normalized ultrasound sharpness eq2is squared amplitude value qth sample amplitude derive use envelope detect data however practical difference raw envelope detect data due use even power eqin 2 metric calculate qsamples total include single point scatterer region interest roi defined square box around psf centre size adequate encompass psf main lobe defocus condition larger rois enclose whole psf necessary sharpness calculation also likely include undesired overlap information presence multiple scatterers b beamforming indalgarno et al 43 dalgarno et al 44 image sharp ness use adjunct multiplane multifocal mi croscopy demonstrate axial superresolution potential live cell axial imaging sharpness peak focus fall approximately symmetrically either side focus single plane give ambiguous dissemination position one sharp ness value correspond two axial position 44 fur thermore zero dependence around focus sharpness peak poor correlation position multiplane microscopy distinct focal plane image simultane ously remove ambiguity provide multiple reference translate sharpness absolute axial position achieve optically distorted diffraction grate 42 pair relay lens use attachment standard optical microscope principle directly apply ultra sound imaging however multiple focusing achieve conventional beamforming without require additional hard ware therefore considerably simpler implement optical equivalent ultrasonic case receive focus provide high flexibility compare transmit focus element signal store transmission beamformed offline even real time multiple way conventional method process received transducer element signal delayandsum das beamformer 46 sig nals timedelayed weighted subsequently sum form maximized beamformer output b transducer array mactive element receive b extract b =m1/summationdisplay m=0wm xm tm = w hx 3 tis time index w = w0 w 1 w m1 h vector apodization weight x = x0 0 x1 t1 xm1 tm1 array trans ducer element signal mis time delay apply thediamantis et al superresolution axial localization ultrasound scatter using multifocal imaging 1843 mth receive element depend distance select focus point therefore b calculate different focus point simply change time delay way requirement simultaneous axially displaced image 43 44 easily meet work three different receive focus select three beamformer output produce different axially displace image object c maximum likelihood estimation mle established statistical method estimate parameter dataset know model employ optic approach 44 extract axial location single point scatterer use know calibration data applied multi focal imaging method estimate unique since position characterize three distinct sharpness value dependent number image plane employ calibration data obtain repetitive measurement point scatterers move depth equivalent experimental condition enable calculation standard deviation measured mean sharpness position mean sharpness plot point scatterer axial distance typically form lorentzianlike sharpness curve scurve peak around best focus position although standard deviation follow specific trend high value present around peak scurve low edge statistical measure interpolate factor provide sub resolution sampling reduce inaccuracy due quantization interpolated data use estimation probability density function pdf p sjz probability specific normalize sharpness value sj measure raw scatter data point scatterer locate depth z jdenotes focus receive since sharpness calculation receive focus depend calibration zknown probability set nsharpness measurement receive focus point scatterer locate z express l s1 s2 snz =n/productdisplay j=1p sjz 4 lis likelihood set sharpness measurement s1 s2 snand nis number receive focus max imum likelihood estimator point depth z st h ev l u eo f z lis maximize give actual dataset s1 s2 sn calibration pdfs p sjz pdf gamma dis tribution select fits best lorentzian shape scurves variance give p sjz =e s2 j s1 j z /gamma1 5 = s2 j z / 2 j = 2 j/ s2 j z sj z represent terpolated scurve 2 jthe interpolated variance /gamma1is gamma function mle solution substitute 5 4 point scatterer zdepth product n gamma distribution maximizedd data analysis set three sharpness value measure single data acquisition isolated point scatterer provide input algorithm output depth position estimate cor responding pdf maximum method result separate psf pdf use assess perfor mance first accuracy normalized sharpness method indicate depth deviation method zestimate actual scatterer position ddev true scatterer position know simulation establish high pre cision translation stage experimental measurement depth estimate acquire datasets calculate com par actual position vrepetitive measurement ddevresults root mean square error rmse allvcases average ddevis calculate total scatterer displacement several small depth range op tic equivalent 44 second fullwidthathalfmaximum fwhm pdf calculate depth position similar ddevanalysis average pdf fwhm value also extract compare corresponding axial fwhm measure psfs das beamformed sponses see fig 1 b provide comparable metric conventional localization limit third standard deviation dsd average ddev standard deviation fwhm sd average pdf fwhm calculate extra indicator measurement uncertainty fig 2 show example single pdf lead individual ddevand fwhm estima tions scatterer locate depth 40 mm das axial fwhm assessment signal envelope also include top right part figure e simulation point scatter ultrasound field simulation package field ii 47 48 use model multiple focusing requirement phan tom consisting single point scatterer depth 40 mm create use target replicate optical setup phantom scan single plane wave pw emis sion make 7 mhz 192 element linear array simulate transducer spacing central transducer element locate point target speed sound cwas set 1540 m/s parameter simulation experimental data discuss give table raw data single unfocused emission acquire 192 channel individually receive data store process repeat 151 axial dis placement step 100 position 325 mm 475 mm initial investigation noisefree sharpness data use introduce uncertainty necessary pdf calculation white gaussian noise later add raw simulate sig nals ten sharpness datasets create signaltonoise ratio snr equal 10 db acquisition data beamformed three different focus receive central receive focus select depth 40 mm target initial position two value 2m and+2 mm start depth sharpness value calculate area dimension 13 mm 13 mm1844 ieee transactions biomedical engineering vol 65 8 august 2018 fig 2 exemplary pdf normalized sharpness method plot depth simulated scatterer locate 40 mm depth ddevand pdf fwhm measure use performance evaluation show psf scatterer display 6 mm 6 mm image right 60 db dynamic range display use top right signal envelope psf centre plot depth das axial fwhm indicate pdf scale maximum envelope amplitude also include comparison table simulation experimental scan parameters parameter name simulation experiment transducer type linear array transducer element pitch 208 transducer element kerf 35 transducer element height 4 5m centre frequency f0 7m h z sampling frequency fs 100 mhz 70 mhz bandwidth 60 fractional speed sound c 1540 m/s 1484 m/s wavelength =c/f0 220m 212 excitation pulse twocycle sinusoid f0 transmit apodization hanning receive apodization hanning receive focal depth 38 mm/40 mm/42 mm number transmit element 192 number receive element 192 number emission 1 highest scatterer position x z = 0325 mm lowest scatterer position x z = 0475 mm total distance cover 15 mm axially zstep 2 emission 100 108 7m region interest roi 13 mm 13 mm 23 mm 23 mm around scatterer centre fully enclose defocused psf mainlobe minimize unnecessary background signal f wiretarget experiment experimental verification setup depict fig 3 use wire 0 07 mm diameter attach holder rod initially position x z = 0 40 mm inside water tank custom phantom position kept fixed two dimension xand yaxis emission wire move next zposition axial direction use aims iii position setup onda corporation sun nyvale ca control use matlab interface fig 3 illustration measurement setup wire target serted water tank onda aims iii position sys tem attach wire move initial position across zdimension image every displacement sarus scan ner use acquisition accuracy setup bad equal minimum movement step 1 /92 mm =1087m state equipment manual ratio 1 /92 attribute stepper motor system avoid potential mechanical inaccuracy minimal stepper mode increment zsteps 108 7mw e r e use consequently total distance 15 mm cover 139 step speed sound calculate c=1484 m/s base water temperature 49 measurement perform 1024 channel experimental ultrasound scan ner sarus synthetic aperture realtime ultrasound system diamantis et al superresolution axial localization ultrasound scatter using multifocal imaging 1845 fig 4 point target image different axial displacement generate use different receive focus columns represent different depth location 36 mm 44 mm respectively 1 mm gap image cover 10 mm 10 mm area noisefree simulated dataset beamformed three different receive rx focus position 38 mm 40 mm 42 mm show 1st2nd 3rd row respectively 60 db dynamic range display use normalized sharpness calculate envelope detect data sample image pixel include white box dimension 13 mm 13 mm show fi r tr w fig 5 normalized sharpness function axial displacement image derive sharpness display middle row noisefree field ii image show fig 4 use pixel value sharpness calculation corresponding signalderived sharpness display b use envelope detect data 2 c equivalent result optical microscopy show comparison 50 bk ultrasound herlev denmark linear array use scan custom singlewire phantom data ini tially sample 70 mhz sarus scanner require sampling frequency fswas decimate factor 2 35 mhz scan parameter find table simulation measurement conduct sim ilar manner use similar parameter indicate table transmission ultrasound perform single plane wave use transducer element transmit ting aperture rf data one unfocused emission ac quired 192 channel individually receive ten frame acquire per axial position acquisition data beamformed three different focus receive use inhouse programmed beamformation toolbox bft iii 51 receive focus select 38 mm 40 mm 42 mm data produce across 15 mm 325 mm 475 mm transducer face set 10 emission data store wire target move next location axial direction roi defined previous subsection small area enclose psf mainlobe 23 mm 23 mm around wire centre measurementiii r esults simulation first noisefree simulation result psfs single point scatterer move axial direction show fig 4 function point displacement similar 43 fig 4 demonstrate effect different receive focusing psf appearance exemplary scurves form ultrasound data correspond central receive focus 40 mm sharp ness calculate displacement use 1 without bias term nkinfig 5 use 2 fig 5 b interest curve fig 5 display alongside scurve derived optical confocal microscopy data fig 5 c generate setup include spatial pinhole diam eter 1 airy unit 52 position confocal plane lens use image red fluorosphere diameter 100 nm move axial defocus range equivalent zstage scanning optical wavelength equal 650 nm total displacement 8 fluorescent particle pinhole addition result elimination outoffocus light provide close approximation focus ultrasound upon receive use show fig 1 b 1846 ieee transactions biomedical engineering vol 65 8 august 2018 fig 6 set three normalized scurves lorentzian fits display generate use simulated ultrasound point target move depth direction unfocused pw ultrasound transmission beamformed use three different focus receive 38 mm 40 mm 42 mm respectively mean sharpness value single axial position 384 mm measure 3 psfs show left example see text sharpness value beamformed response corresponds receive focus specific depth position ddevand pdf fwhm achieve normalized sharpness method show b imagederived sharpness c signalderived sharpness depth position dark gray line b c indicate das axial fwhm general shape scurves show fig 5 simi lar maximize single peak around focus fall rapidly roughly symmetrically defocus provide confidence establish multifocal sharpness method translatable optical ultrasound imaging signal derived scurve see fig 5 b fall rapidly imagederived scurve see fig 5 high rate change notice fig 5 b increase sensitivity usingthe mle calculation ultrasound signal derive sharpness value 12 169 envelope detect data sam ples process correspond 13 mm 13 mm roi region represent 45 45 square pixel image data introduction noise rf signal allow gener ation calibration standard base calculation mean sharpness value standard deviation use thediamantis et al superresolution axial localization ultrasound scatter using multifocal imaging 1847 mle analysis fig 6 mean sharpness plot axial displacement three receive focus 38 mm 40 mm 42 mm best lorentzian fits 3 sharpness datasets also include fig 6 fits mean ac curate representation sharpness function however return correlation coefficient rvalues high 097 3 case fitted scurves allow example good approximation error bar represent sharpness standard deviation depth displayed data result ten field ii simulation zposition explain section iie curve peak locate around posi tion receive focus example set 3 psfs focal plane single axial position 384 mm also show image 6 mm 6 mm 60 db dynamic range display use mean sharpness value calcu lated displayed psfs 6 548103 6106 4197103 6106 2 972103 2106 f r 1st 2nd 3rd receive focus respectively fig 6 b c show theoretical accuracy scatterer axial localization base image signalderived sharp ness value respectively mle method metric de scribed section iid imagederived sharpness processing result average depth deviation actual scatterer position ddev equal 47 43m /5 whole depth range tween 325 mm 475 mm standard deviation ddev dsd equal 79 66m /3 several lowprecision depth estimate ddev= include calculation calculated pdf fwhm average equal 7867m /3 22 time low das axial fwhm 170 35m always constant regardless scatterer receive focus position corresponding stan dard deviation pdf fwhm fwhm sd 63 37m /35 metric improve significantly signal derived sharpness processing see fig 6 c range average ddevwas calculate 29 4m /75 dsdto 9147m /25 similar manner average pdf fwhm calculate 32 56m /7 68 time low das axial fwhm fwhm sdto 10342m /2 general high standard deviation val ues due increase ddevand pdf fwhm value region reduced rate sharpness change dis placement edge scurve peak see fig 6 feature common optical equivalent worth compare two small range ultrasound analogue instance 1 mm range 375 mm 385 mm far displacement end include peak first scurve around 38 mm receive focus low part two scurves slope range average ddevwas equal 3 48m dsdwas 272m average pdf fwhm 9 1m fwhm sdwas 691m 1 mm range 385 mm 395 mm include max imum rate sharpness change scurves correspond first two receive focus 38 mm 40 mm low part scurve slope correspond long receive focus 42 mm second small range average ddev w sa sl wa s1 25m dsdwas 067m average pdf fwhm 4 5m fwhm sdwas 126m fig 7 five psfs correspond maximum middle zero dis placement end wiretarget experiment ceive focus set 40 mm image include area 6 mm 6 mm 60 db dynamic range display use normalized sharpness calculate rf sample include white box dimension 23 mm 23 mm show result show avoid scurve edge focus slope performance method improve greatly inclusion peak slightly compromise accu racy localization consistent subranges across entire displacement investigate b wiretarget experiment five experimentally acquire psfs wiretarget moving axial direction single plane receive focus =40 mm show fig 7 different axial displacement figure equivalent fig 4 2nd row receive beamforming expand two far receive focus 38 mm 42 mm simulation fig 8 measure mean sharpness plot axial displacement best lorentzian scurve fits r > 098 also add error bar rep resent sharpness standard deviation depth displayed sharpness data result 10 experimentally ac quired frame zposition curve peak locate around position receive focus set 3 psfs z=3837 mm also show example image 6 mm 6 mm 60 db dynamic range display use mean sharpness value calculate 8 491103 14105 5938103 9106 4 053103 6106 1st 2nd 3rd receive focus respectively fig 8 b c show accuracy wire axial localization base sharpness processing image signalderived sharpness respectively simulation study use envelope detect data sharpness calculation outperform image sharpness processing latter result average ddevequal 63 67m r/3 dsdwas equal 10235 /2 due several ddev value higher wavelength 212 locate dis placement edge calculated pdf fwhm average equal 83 91m /25 34 time low das axial fwhm measure 287 31m signal envelope pass centre psf show fig 2 corresponding fwhm sdwas 83 86m /25 signalderived sharpness average ddev calculate 10 21m r/21 dsdfor entire depth range calculate 16 11m r/13 indicate small variation ddevvalues compare simulation study average pdf fwhm calculate to1848 ieee transactions biomedical engineering vol 65 8 august 2018 fig 8 set three normalized scurves lorentzian fits display generate use wiretarget move depth direction unfocused pw ultrasound transmission beamformed use three different focus receive 38 mm 40 mm 42 mm respectively mean sharpness value single axial position 3837 mm measure 3 psfs show left example see text sharpness value beamformed response corresponds receive focus specific depth position ddevand pdf fwhm achieve normalized sharpness method show b imagederived sharpness c signalderived sharpness depth position dark gray line b c indicate das axial fwhm 2515m /85 114 time low das axial fwhm fwhm sdwas 35 09m /6 two 1 mm range also investigate sim ulation study 1 mm depth range 375 mm 385 mm average ddevwas equal 3 22m dsd 207m average pdf fwhm 9 06m fwhm sdwas 293m 1 mm range 385 mm 395 mm result slightly low value metric confirming benefits examine area sharpness change rapidly average ddevequal 1 52m calculated dsdwas 090m average pdf fwhm 753m fwhm sdwas 266m iv iscussion principle multifocal axial ultrasound localization demonstrate use sharpness metric ap ply simulate experimental point scatter data large number beamforming method 30 53 54 show significant localization gain lateral ultrasound ardiamantis et al superresolution axial localization ultrasound scatter using multifocal imaging 1849 ray dimension first beamforming technique show significant gain axial direction propose method exploit effect defocus diffractionlimited lateral resolution achieve high precision localization axial di mension base previously present method superresolution optical microscopy 43 44 optic absence aberration sharpness purely dependent defocus influence defocus aberration psf shape similar optic ultrasonics enable trans lation technique difference wave length 500 nm optic compare 200m ultra sonics result nanometre 10 nm micrometre 10m depth localization precision respectively 25 low depth deviation ddev actual scatterer po sition acquire simulation 47 43m compare ex periment 63 67m imagederived sharpness analysis however processing utilize image data less reliable describe section iiia overall result limited localization improvement simulation experiment signalderived sharpness analysis show improved per formance factor 3 wiretarget measurement 1021m compare simulated scatterer 29 4m ddevvalues significantly low obtain image data difference simulation experimen tal study attribute nature amplitude noise add simulate data noise assume gaussian common practice noise process high experimental case provide increase ddevnear displacement edge subsequently high dsd similar conclusion draw introduction average pdf fwhm standard deviation performance metric also enable comparison dasderived axial localization das axial fwhm indirect com parison since propose method result psf however show fig 2 pdf generate sharpness processing use limit depth position range calculate axial psf size simula tion imagederived sharpness analysis provide 7 low average pdf fwhm 78 67m compare experiment 8193m however translate 22 34fold im provements compare das localization since das axial fwhm 287 31m wiretarget 170 35m simulated point scatterer signalderived sharpness analysis result similar average pdf fwhm value simulated scatterer 32 56m wiretarget measure ments 25 15m far increase axial localization gain 68 114fold respectively experimental case fwhm sdwas also calculate low factor 3 one obtain simulate data addition method perform uniformly whole displacement range data analysis small subregions show away displacement edge area dominate least two thescurve slop technique perform best achieve axial localization low 3 5m precision average pdf fwhm 38 time low das axial fwhm simulation measurement however result conclusive method need develop far order identify whether axial localization accuracy achieve consistently large range depth general ability propose method control sharpness value alter time delay could potentially allow usage optimum focusing definition aberration correction application ultrasound imaging 45 however obvious application ultrasound depth detection contrast microbubbles current microbubble visualization enable use localization algorithm image data typically accomplish identify psf centre mass spatially isolated bubble 20 55 fitting three dimensional gaussians approximate psf thus estimate position bubble 18 19 56 approach inaccurate axial determination method propose develop apply adjunct technique use contrast microbubbles allow translation real imaging application limiting factor snr image quality new image postprocessing may stem combine conventional lateral appearance point target sharpness derive axial one advantage improved psf shape definition noiseless metaimage thus contribute optimization current image base psf localization furthermore sharpness method consider adjunct signalbased method lateral resolution minimum v ariance beamformer 30 53 54 may improve localization provide much small psf analysis image base technique overall accuracy technique application realtime mb image depends number factor first mbs know polydispersed nature signal variation normalization factor 2 compensates different mb echo signal second snr mb imaging typical snr ultrasound image rather demodulated signal clutter ratio linear tissue signal reject use pulse modulation phase amplitude create mb image image mbs tend clearly identifiable compare dark background scatter identified order implement sharp ness method snr current study well available invivo imaging significantly case impact snr localization accuracy need inves tigated far order explore potential technique real imaging another important aspect ultrasound imag ing psf thus snr variability across image due signal processing well beam change occur due attenuation speed sound variation impose real tissue near field transducer array may translate vary localization accuracy across image complexity introduce sharpness relation focus defocus minimize localization error appear counter balance decrease ultrasound image snr range third mb detection sensitivity may vary addition snr variable beam pressure across im age provide variable number mbs scatter noise 16 note invivo correlation mb den sity blood volume result superresolution contrast1850 ieee transactions biomedical engineering vol 65 8 august 2018 ultrasound image aim generate quantitative blood volume map variation ultrasound beam pressure impact relationship mb number blood volume psf variation across image psf may therefore use marker mb density variation fourth single scatterer must include select roi sharpness calculation outline section iia realtime imaging environment initial rough estimation scatterers position base standard das beamforming follow roi selection application thresholding criterion intensity shape morphology need implement discard echo violate single scatterer requirement may due overlap psfs side lobe contribution neighbor scatterers localization technique apply single frame whole processing repeat next frame concept similar optical microscopy 57 case high mb den sity roi rejection rate high increase number frame need process adequate number isolated target reach localize throughout en tire image consequence efficient roi size selection closely relate single scatterer assumption acqui sition time work roi selection significant since single scatterer image however show use size psf main lobe reference valid approach order achieve robust roi selection potentially maximize useful rois number frame us ing figures present wiretarget measurement a1 5m 15 mm area divide 23 mm 23 mm box could include 42 rois include isolated scatterer per frame localization several thousand mbs would require density map generation number frame therefore depend number mbs practi cally detect per frame give low infusion concentration achieve isolated mb scatter image tissue vascular structure impose vary mb density across image moreover type ultrasound transmission may impact method performance plane wave transmis sion choose paper best approx imation unfocused light transmission optical measurement addition facilitate fast acquisition one emission able provide necessary data method thus subject artefact due parti cle movement several emission use form one image however synthetic aperture sa ultrasound offer similar benefits image acquire single sa emission maintain high frame rate without ducing image quality dependence sharpnessbased localization method transmit focus need explore focused ultrasound require high number emission produce single image image quality around focus area significantly improve considering apodization also play important role ultrasound beam shaping another parameter need explore however remain investigate addition research require target locate great depth provide low snr finally paper demonstrate 3receive focus 2 mm separation adequate localization precision 10 21m displacement range 15 mm clear extend number receive focus range increase optimize foci space fur ther localization accuracy tune ultimately tradeoff depth range number focus focus spacing need balance response specific image prob lem system theory unlimited number scurves form receive focus location unlimited major advantage ultrasound implementation method compare optical equivalent hardware challenge limit number plane typically less 10 end method need develop tissuelike medium provide complex aberration indeed psf ultrasound know variable across image due vary attenuation reflections inside human body unique ultrasound flickering star cause change refraction atmosphere due movement problem resolve systematically astronomy use adaptive optic method 58 remain ultrasound imaging highly operator dependent technique image qualitatively compensate variation ultrasound field may well prove key advantage normalized sharpness method require understanding exact aberration pre defined psf model v c onclusion defocusing error point scatterer different axial po sitions examine ultrasound imaging quan tified metric normalized sharpness become maximum infocused image fall spatially roughly symmetrically away focus depth dependence sharpness value plot together ability ultra sound image obtain multifocal image object offer simple method provide highprecision axial local ization experimental result show set 3 sharpness value adequate localize axial position point tar get 10 micrometre accuracy also reduce conven tional axial fullwidthathalfmaximum fwhm factor of11 initial investigation show technique wellsuited ultrasound point scatterers technique may complement imagebased method currently use microbub ble detection beamforming technique focus lateral resolution fully describe point scatter position base exclusively signal processing",
    "bag_of_words": {
        "ieee": 9,
        "transactions": 6,
        "biomedical": 6,
        "engineering": 7,
        "vol": 6,
        "august": 7,
        "superresolution": 20,
        "axial": 74,
        "localization": 49,
        "ultrasound": 75,
        "scatter": 20,
        "using": 6,
        "multifocal": 12,
        "imaging": 34,
        "konstantinos": 1,
        "diamantis": 3,
        "alan": 1,
        "greenaway": 2,
        "tom": 2,
        "anderson": 2,
        "jrgen": 1,
        "arendt": 1,
        "jensen": 2,
        "fellow": 1,
        "paul": 2,
        "dalgarno": 4,
        "vassilis": 2,
        "sboros": 4,
        "abstract": 1,
        "objective": 1,
        "paper": 4,
        "aim": 2,
        "develop": 4,
        "method": 47,
        "achieve": 13,
        "micrometre": 6,
        "scatterer": 42,
        "local": 2,
        "ization": 2,
        "medical": 1,
        "surpass": 1,
        "inherent": 1,
        "pulse": 7,
        "length": 3,
        "dependence": 6,
        "limit": 9,
        "methods": 1,
        "directly": 4,
        "translate": 7,
        "cellular": 1,
        "microscopy": 14,
        "base": 16,
        "simple": 4,
        "aberrationdependent": 1,
        "image": 92,
        "sharpness": 94,
        "metric": 12,
        "single": 34,
        "point": 39,
        "relies": 1,
        "generation": 2,
        "multiple": 10,
        "overlap": 3,
        "curve": 7,
        "create": 6,
        "deploy": 1,
        "three": 15,
        "focus": 59,
        "receive": 47,
        "processing": 12,
        "assess": 2,
        "value": 29,
        "acquisition": 7,
        "function": 8,
        "depth": 47,
        "derive": 5,
        "peak": 11,
        "around": 13,
        "unique": 4,
        "position": 46,
        "identified": 2,
        "combine": 3,
        "data": 46,
        "use": 69,
        "maximum": 7,
        "likelihood": 5,
        "algorithm": 4,
        "calibration": 6,
        "standard": 15,
        "results": 1,
        "simulated": 7,
        "experimental": 12,
        "show": 36,
        "provide": 26,
        "average": 25,
        "accuracy": 12,
        "/21": 1,
        "time": 12,
        "increased": 1,
        "precision": 8,
        "compare": 12,
        "conventional": 7,
        "improvement": 5,
        "depend": 6,
        "rate": 6,
        "change": 10,
        "signal": 24,
        "noise": 8,
        "ratio": 4,
        "conclusion": 2,
        "optical": 20,
        "suc": 1,
        "cessfully": 1,
        "raw": 7,
        "beamforming": 13,
        "significance": 1,
        "normalized": 16,
        "potential": 6,
        "application": 9,
        "contribute": 2,
        "current": 5,
        "technique": 16,
        "index": 2,
        "terms": 1,
        "focusing": 7,
        "manuscript": 1,
        "accept": 1,
        "october": 1,
        "date": 2,
        "publication": 1,
        "december": 1,
        "version": 2,
        "july": 1,
        "work": 6,
        "support": 1,
        "part": 6,
        "science": 2,
        "tech": 1,
        "nology": 1,
        "facilities": 1,
        "council": 1,
        "stfcst/m007804/1": 1,
        "danish": 1,
        "advanced": 1,
        "technology": 2,
        "foundation": 2,
        "grant": 1,
        "bk": 2,
        "aps": 1,
        "corresponding": 5,
        "author": 1,
        "institute": 3,
        "biological": 3,
        "chemistry": 2,
        "biophysics": 3,
        "bioengineering": 3,
        "heriotwatt": 3,
        "university": 5,
        "retire": 1,
        "school": 1,
        "clinical": 2,
        "sciences": 1,
        "centre": 8,
        "cardio": 1,
        "vascular": 4,
        "edinburgh": 2,
        "department": 1,
        "electrical": 1,
        "center": 1,
        "fast": 3,
        "technical": 1,
        "denmark": 2,
        "chem": 1,
        "istry": 1,
        "eh14": 1,
        "4as": 1,
        "uk": 1,
        "email": 1,
        "adalgarno": 1,
        "hwacuk": 2,
        "digital": 1,
        "object": 4,
        "identifier": 1,
        "101109/tbme20172769164i": 1,
        "introduction": 3,
        "interference": 1,
        "emit": 1,
        "ted": 1,
        "wavefront": 4,
        "determine": 1,
        "capability": 1,
        "aperture": 4,
        "resolution": 15,
        "lateral": 10,
        "direction": 8,
        "diffraction": 3,
        "may": 12,
        "vary": 6,
        "greatly": 2,
        "beam": 6,
        "width": 1,
        "hand": 1,
        "fixed": 2,
        "duration": 1,
        "transmitted": 1,
        "therefore": 7,
        "small": 11,
        "dimension": 10,
        "range": 28,
        "appear": 2,
        "size": 10,
        "spread": 1,
        "psf": 33,
        "comparable": 3,
        "wavelength": 4,
        "apply": 7,
        "sound": 8,
        "wave": 5,
        "feasible": 1,
        "reduce": 3,
        "us": 3,
        "ing": 7,
        "shorter": 1,
        "transducer": 14,
        "high": 20,
        "central": 4,
        "frequency": 6,
        "well": 4,
        "large": 4,
        "array": 8,
        "practice": 3,
        "however": 17,
        "relate": 5,
        "attenuation": 3,
        "inversely": 1,
        "penetration": 4,
        "consequence": 2,
        "tradeoff": 2,
        "example": 8,
        "tissue": 4,
        "transmission": 8,
        "mhz": 7,
        "visualization": 3,
        "several": 8,
        "centimetre": 1,
        "millimetre": 1,
        "conversely": 1,
        "hundred": 1,
        "less": 3,
        "mm": 93,
        "precise": 2,
        "scatterers": 8,
        "meth": 1,
        "od": 1,
        "offer": 3,
        "improved": 4,
        "quality": 7,
        "great": 2,
        "also": 17,
        "access": 2,
        "exact": 3,
        "positioning": 1,
        "thus": 9,
        "velocity": 2,
        "enable": 6,
        "density": 5,
        "dynamic": 8,
        "mea": 1,
        "surements": 1,
        "blood": 7,
        "volume": 4,
        "flow": 4,
        "quantification": 2,
        "respectively": 11,
        "lead": 3,
        "additional": 3,
        "ben": 1,
        "efits": 1,
        "across": 10,
        "diagnostic": 1,
        "wellestablished": 1,
        "fields": 1,
        "sense": 1,
        "radar": 1,
        "astronomy": 2,
        "remain": 3,
        "infancy": 1,
        "general": 5,
        "connect": 1,
        "contrast": 6,
        "enhanced": 1,
        "ceus": 4,
        "microbubbles": 3,
        "mbs": 10,
        "establish": 3,
        "despite": 1,
        "diameter": 3,
        "possible": 2,
        "distinguish": 1,
        "event": 3,
        "due": 13,
        "crosssection": 1,
        "direct": 1,
        "analogy": 2,
        "molecule": 1,
        "modality": 1,
        "scattering": 1,
        "replace": 1,
        "emission": 12,
        "modern": 1,
        "mb": 14,
        "bed": 1,
        "requirement": 4,
        "translations": 1,
        "content": 1,
        "mining": 1,
        "permit": 2,
        "academic": 1,
        "research": 3,
        "personal": 1,
        "republication/": 1,
        "redistribution": 1,
        "require": 7,
        "permission": 1,
        "see": 10,
        "http": 1,
        "//wwwieeeorg/publications": 1,
        "standards/publications/rights/indexhtml": 1,
        "informationdiamantis": 1,
        "et": 11,
        "al": 11,
        "concentration": 2,
        "produce": 4,
        "allow": 6,
        "brightness": 2,
        "qualitative": 2,
        "assessment": 3,
        "kinetics": 1,
        "generally": 3,
        "limited": 2,
        "advance": 1,
        "robust": 3,
        "quantitative": 3,
        "measurement": 16,
        "positron": 1,
        "tomography": 2,
        "pet": 1,
        "magnetic": 1,
        "resonance": 1,
        "mri": 1,
        "computed": 1,
        "ct": 1,
        "perfusion": 1,
        "often": 1,
        "choice": 1,
        "clinic": 1,
        "deem": 1,
        "cost": 2,
        "effective": 2,
        "safe": 1,
        "easy": 1,
        "highly": 3,
        "super": 1,
        "extent": 1,
        "utilization": 1,
        "techniques": 1,
        "achievable": 1,
        "rely": 1,
        "ap": 2,
        "knowledge": 2,
        "photoactivated": 1,
        "palm": 2,
        "stochastic": 1,
        "reconstruction": 2,
        "storm": 1,
        "detailed": 1,
        "obtain": 6,
        "reilly": 1,
        "hynynen": 1,
        "able": 3,
        "transcranial": 1,
        "vascu": 1,
        "lar": 2,
        "structure": 2,
        "similar": 12,
        "acquire": 9,
        "microct": 1,
        "invivo": 5,
        "mouse": 1,
        "ear": 1,
        "microvasculature": 1,
        "5fold": 1,
        "gain": 4,
        "demonstrate": 8,
        "christensenjeffries": 1,
        "feature": 2,
        "map": 3,
        "couture": 1,
        "equivalent": 9,
        "microbubble": 3,
        "superlocalization": 1,
        "imag": 4,
        "musli": 1,
        "individual": 2,
        "localiza": 1,
        "tion": 3,
        "/38": 1,
        "similarly": 1,
        "desailly": 1,
        "present": 6,
        "analog": 1,
        "fluorescence": 1,
        "fpalm": 1,
        "ultra": 4,
        "ultrafast": 1,
        "uulm": 3,
        "errico": 1,
        "haemodynamic": 1,
        "of10mdiameter": 1,
        "rodent": 1,
        "cerebral": 1,
        "microvessels": 1,
        "finally": 2,
        "ackermann": 1,
        "schmitz": 1,
        "estimate": 8,
        "foreground": 1,
        "detection": 5,
        "modified": 1,
        "markov": 1,
        "chain": 1,
        "monte": 1,
        "carlo": 1,
        "association": 1,
        "mcmcda": 1,
        "vessel": 2,
        "beyond": 2,
        "attempt": 1,
        "formation": 2,
        "ul": 1,
        "trasound": 1,
        "equipment": 2,
        "design": 1,
        "structural/anatomical": 1,
        "exception": 1,
        "already": 1,
        "formed": 1,
        "vulnerable": 1,
        "variation": 8,
        "include": 16,
        "variable": 4,
        "number": 22,
        "artefact": 2,
        "encounter": 1,
        "ro": 1,
        "bust": 1,
        "approach": 7,
        "improve": 7,
        "spatial": 3,
        "involve": 2,
        "modification": 1,
        "adaptive": 2,
        "reemission": 1,
        "received": 2,
        "element": 14,
        "sponses": 2,
        "compensate": 2,
        "distortion": 2,
        "cause": 2,
        "impedance": 1,
        "mismatch": 1,
        "face": 2,
        "target": 12,
        "material": 1,
        "alternatively": 1,
        "various": 1,
        "adap": 1,
        "tive": 1,
        "/12": 1,
        "isolated": 7,
        "beachieved": 1,
        "early": 2,
        "demonstration": 1,
        "result": 18,
        "particularly": 1,
        "minimum": 3,
        "ariance": 2,
        "mv": 1,
        "could": 3,
        "suit": 1,
        "stenosis": 1,
        "realtime": 4,
        "cardiac": 1,
        "significant": 4,
        "effort": 1,
        "generate": 8,
        "lat": 1,
        "eral": 1,
        "sub": 2,
        "ject": 1,
        "little": 1,
        "reflector": 2,
        "inherently": 1,
        "challenging": 1,
        "strict": 1,
        "spl": 2,
        "constant": 2,
        "give": 7,
        "ncy": 1,
        "ncyis": 1,
        "cycle": 1,
        "currently": 2,
        "dealt": 1,
        "analysis": 9,
        "describe": 3,
        "new": 2,
        "signalbased": 2,
        "introduce": 3,
        "simultaneous": 2,
        "originate": 1,
        "suffer": 1,
        "complex": 2,
        "nature": 3,
        "mul": 1,
        "tiple": 1,
        "axially": 4,
        "displace": 2,
        "source": 1,
        "emitter": 2,
        "convert": 1,
        "coordinate": 1,
        "integrate": 1,
        "square": 7,
        "intensity": 6,
        "viable": 1,
        "expand": 2,
        "represent": 5,
        "deviation": 16,
        "infocus": 1,
        "system": 5,
        "estimation": 4,
        "mle": 6,
        "extract": 4,
        "nm": 5,
        "/50": 1,
        "feasibil": 1,
        "ity": 1,
        "investigate": 4,
        "setup": 7,
        "ii": 4,
        "ethods": 1,
        "overview": 1,
        "propose": 6,
        "depict": 2,
        "fig": 37,
        "different": 16,
        "process": 6,
        "way": 3,
        "calculate": 20,
        "equal": 11,
        "reference": 3,
        "sharp": 6,
        "ness": 6,
        "true": 2,
        "descriptor": 1,
        "total": 6,
        "aberration": 8,
        "order": 6,
        "dominate": 2,
        "defocus": 10,
        "low": 17,
        "lower": 1,
        "perturbation": 1,
        "ignore": 1,
        "single1842": 1,
        "description": 1,
        "sharpnessbased": 2,
        "reflection": 1,
        "specific": 6,
        "field": 7,
        "repeat": 4,
        "beamformed": 10,
        "offline": 2,
        "calculation": 11,
        "region": 5,
        "interest": 4,
        "roi": 11,
        "calcu": 2,
        "lation": 2,
        "quantifiable": 1,
        "link": 1,
        "particle": 2,
        "mathematical": 1,
        "definition": 3,
        "integration": 1,
        "modulation": 2,
        "transfer": 1,
        "simplifies": 1,
        "sum": 2,
        "pixel": 6,
        "formulation": 1,
        "tailor": 1,
        "optimize": 2,
        "concept": 2,
        "employ": 3,
        "speckle": 1,
        "optimum": 2,
        "previous": 2,
        "sopt": 1,
        "defined": 4,
        "sopt=k/summationdisplay": 1,
        "k=1": 1,
        "n2": 1,
        "knk": 1,
        "//parenleftbiggk/summationdisplay": 1,
        "k=1nk/parenrightbigg2": 1,
        "within": 1,
        "window": 2,
        "consisting": 2,
        "kpixels": 1,
        "nkis": 1,
        "recorded": 1,
        "kth": 1,
        "subtraction": 2,
        "numerator": 1,
        "eliminate": 1,
        "photon": 2,
        "bias": 3,
        "lowflux": 1,
        "regime": 1,
        "express": 2,
        "count": 1,
        "negligible": 1,
        "effect": 3,
        "modest": 1,
        "highflux": 1,
        "cal": 1,
        "culation": 1,
        "contain": 1,
        "neglect": 1,
        "since": 6,
        "fluxdependent": 1,
        "radio": 1,
        "rf": 4,
        "final": 1,
        "avoid": 3,
        "associate": 1,
        "stage": 2,
        "ie": 1,
        "interpolation": 1,
        "logarithmic": 1,
        "compres": 1,
        "sion": 3,
        "upon": 2,
        "hilbert": 1,
        "transform": 1,
        "envelope": 11,
        "subsequent": 1,
        "rectification": 1,
        "preimage": 1,
        "free": 1,
        "resultthe": 1,
        "proportional": 1,
        "amplitude": 6,
        "substitute": 2,
        "latter": 2,
        "quan": 2,
        "tity": 1,
        "alternative": 1,
        "derivation": 1,
        "s=q/summationdisplay": 1,
        "q=1eq4/": 1,
        "q/summationdisplay": 1,
        "q=1eq2": 1,
        "sis": 1,
        "eq2is": 1,
        "squared": 1,
        "qth": 1,
        "sample": 4,
        "detect": 7,
        "practical": 1,
        "difference": 3,
        "even": 2,
        "power": 1,
        "eqin": 1,
        "qsamples": 1,
        "box": 4,
        "adequate": 4,
        "encompass": 1,
        "main": 2,
        "lobe": 3,
        "condition": 2,
        "larger": 1,
        "rois": 3,
        "enclose": 3,
        "whole": 4,
        "necessary": 3,
        "likely": 1,
        "undesired": 1,
        "information": 1,
        "presence": 1,
        "indalgarno": 1,
        "adjunct": 3,
        "multiplane": 2,
        "mi": 1,
        "croscopy": 1,
        "live": 1,
        "cell": 1,
        "fall": 4,
        "approximately": 1,
        "symmetrically": 3,
        "either": 1,
        "side": 2,
        "plane": 10,
        "ambiguous": 1,
        "dissemination": 1,
        "one": 6,
        "correspond": 6,
        "two": 9,
        "fur": 2,
        "thermore": 1,
        "zero": 2,
        "poor": 1,
        "correlation": 3,
        "distinct": 2,
        "focal": 4,
        "simultane": 1,
        "ously": 1,
        "remove": 1,
        "ambiguity": 1,
        "absolute": 1,
        "optically": 1,
        "distorted": 1,
        "grate": 1,
        "pair": 1,
        "relay": 1,
        "lens": 2,
        "attachment": 1,
        "microscope": 1,
        "principle": 2,
        "without": 3,
        "hard": 1,
        "ware": 1,
        "considerably": 1,
        "simpler": 1,
        "implement": 3,
        "ultrasonic": 1,
        "case": 6,
        "flexibility": 1,
        "transmit": 5,
        "store": 3,
        "real": 4,
        "delayandsum": 1,
        "das": 15,
        "beamformer": 4,
        "sig": 2,
        "nals": 2,
        "timedelayed": 1,
        "weighted": 1,
        "subsequently": 2,
        "form": 5,
        "maximized": 1,
        "output": 3,
        "mactive": 1,
        "=m1/summationdisplay": 1,
        "m=0wm": 1,
        "xm": 1,
        "tm": 1,
        "hx": 1,
        "tis": 1,
        "w0": 1,
        "m1": 1,
        "vector": 1,
        "apodization": 4,
        "weight": 1,
        "x0": 1,
        "x1": 1,
        "t1": 1,
        "xm1": 1,
        "tm1": 1,
        "trans": 2,
        "ducer": 1,
        "mis": 1,
        "delay": 3,
        "thediamantis": 2,
        "mth": 1,
        "distance": 4,
        "select": 6,
        "simply": 1,
        "displaced": 1,
        "easily": 1,
        "meet": 1,
        "established": 1,
        "statistical": 2,
        "parameter": 6,
        "dataset": 3,
        "know": 5,
        "model": 3,
        "optic": 5,
        "location": 4,
        "applied": 1,
        "multi": 1,
        "characterize": 1,
        "dependent": 3,
        "repetitive": 1,
        "move": 8,
        "measured": 1,
        "mean": 11,
        "plot": 6,
        "typically": 3,
        "lorentzianlike": 1,
        "scurve": 11,
        "best": 6,
        "although": 1,
        "follow": 2,
        "trend": 1,
        "edge": 6,
        "measure": 10,
        "interpolate": 1,
        "factor": 8,
        "sampling": 3,
        "inaccuracy": 2,
        "quantization": 1,
        "interpolated": 2,
        "probability": 3,
        "pdf": 29,
        "sjz": 4,
        "normalize": 1,
        "sj": 2,
        "locate": 9,
        "jdenotes": 1,
        "zknown": 1,
        "set": 11,
        "nsharpness": 1,
        "s1": 5,
        "s2": 6,
        "snz": 1,
        "=n/productdisplay": 1,
        "j=1p": 1,
        "lis": 2,
        "snand": 1,
        "nis": 1,
        "max": 2,
        "imum": 2,
        "estimator": 1,
        "st": 1,
        "ev": 1,
        "eo": 1,
        "maximize": 3,
        "actual": 5,
        "sn": 1,
        "pdfs": 1,
        "gamma": 3,
        "dis": 5,
        "tribution": 1,
        "fits": 6,
        "lorentzian": 5,
        "shape": 5,
        "scurves": 9,
        "variance": 2,
        "=e": 1,
        "/gamma1": 1,
        "j/": 1,
        "terpolated": 1,
        "jthe": 1,
        "/gamma1is": 1,
        "solution": 1,
        "zdepth": 1,
        "product": 1,
        "distribution": 1,
        "maximizedd": 1,
        "input": 1,
        "cor": 1,
        "responding": 1,
        "separate": 1,
        "perfor": 1,
        "mance": 1,
        "first": 6,
        "indicate": 6,
        "zestimate": 1,
        "ddev": 8,
        "simulation": 17,
        "pre": 2,
        "cision": 1,
        "translation": 2,
        "datasets": 3,
        "com": 2,
        "par": 1,
        "vrepetitive": 1,
        "ddevresults": 1,
        "root": 1,
        "error": 5,
        "rmse": 1,
        "allvcases": 1,
        "ddevis": 1,
        "displacement": 16,
        "op": 1,
        "tic": 1,
        "second": 3,
        "fullwidthathalfmaximum": 2,
        "fwhm": 44,
        "ddevanalysis": 1,
        "psfs": 10,
        "third": 2,
        "dsd": 4,
        "sd": 2,
        "extra": 1,
        "indicator": 1,
        "uncertainty": 2,
        "ddevand": 5,
        "estima": 1,
        "tions": 1,
        "top": 2,
        "right": 3,
        "figure": 2,
        "package": 1,
        "phan": 1,
        "replicate": 1,
        "phantom": 3,
        "scan": 6,
        "pw": 3,
        "emis": 1,
        "make": 1,
        "linear": 4,
        "simulate": 5,
        "spacing": 2,
        "speed": 4,
        "cwas": 1,
        "m/s": 4,
        "discuss": 1,
        "table": 4,
        "unfocused": 5,
        "channel": 3,
        "individually": 2,
        "placement": 4,
        "step": 3,
        "initial": 5,
        "investigation": 2,
        "noisefree": 4,
        "white": 3,
        "gaussian": 2,
        "later": 1,
        "add": 3,
        "ten": 3,
        "signaltonoise": 1,
        "snr": 10,
        "db": 6,
        "2m": 1,
        "and+2": 1,
        "start": 1,
        "area": 8,
        "mm1844": 1,
        "exemplary": 2,
        "performance": 4,
        "evaluation": 1,
        "display": 11,
        "scale": 1,
        "comparison": 3,
        "parameters": 1,
        "name": 1,
        "experiment": 6,
        "type": 2,
        "pitch": 1,
        "kerf": 1,
        "height": 1,
        "5m": 4,
        "f0": 2,
        "7m": 2,
        "fs": 1,
        "bandwidth": 1,
        "fractional": 1,
        "=c/f0": 1,
        "220m": 1,
        "excitation": 1,
        "twocycle": 1,
        "sinusoid": 1,
        "hanning": 2,
        "mm/40": 1,
        "mm/42": 1,
        "highest": 1,
        "lowest": 1,
        "cover": 3,
        "zstep": 1,
        "fully": 2,
        "defocused": 1,
        "mainlobe": 2,
        "minimize": 2,
        "unnecessary": 1,
        "background": 2,
        "wiretarget": 9,
        "verification": 1,
        "wire": 7,
        "attach": 2,
        "holder": 1,
        "rod": 1,
        "initially": 1,
        "inside": 2,
        "water": 3,
        "tank": 2,
        "custom": 2,
        "kept": 1,
        "xand": 1,
        "yaxis": 1,
        "next": 3,
        "zposition": 3,
        "aims": 2,
        "iii": 3,
        "onda": 2,
        "corporation": 1,
        "sun": 1,
        "nyvale": 1,
        "ca": 1,
        "control": 2,
        "matlab": 1,
        "interface": 1,
        "illustration": 1,
        "serted": 1,
        "sys": 1,
        "tem": 1,
        "zdimension": 1,
        "every": 1,
        "sarus": 3,
        "ner": 2,
        "bad": 1,
        "movement": 3,
        "/92": 2,
        "=1087m": 1,
        "state": 1,
        "manual": 1,
        "attribute": 2,
        "stepper": 2,
        "motor": 1,
        "mechanical": 1,
        "minimal": 1,
        "mode": 1,
        "increment": 1,
        "zsteps": 1,
        "7mw": 1,
        "consequently": 1,
        "c=1484": 1,
        "temperature": 1,
        "perform": 4,
        "synthetic": 2,
        "columns": 1,
        "gap": 1,
        "rx": 1,
        "1st2nd": 1,
        "3rd": 3,
        "row": 3,
        "fi": 1,
        "tr": 1,
        "middle": 2,
        "signalderived": 8,
        "herlev": 1,
        "singlewire": 1,
        "ini": 1,
        "tially": 1,
        "scanner": 1,
        "fswas": 1,
        "decimate": 1,
        "find": 1,
        "conduct": 1,
        "sim": 2,
        "ilar": 1,
        "manner": 2,
        "ting": 1,
        "ac": 3,
        "quired": 2,
        "frame": 10,
        "per": 4,
        "inhouse": 1,
        "programmed": 1,
        "beamformation": 1,
        "toolbox": 1,
        "bft": 1,
        "subsection": 1,
        "measurementiii": 1,
        "esults": 1,
        "appearance": 2,
        "term": 1,
        "nkinfig": 1,
        "alongside": 1,
        "derived": 3,
        "confocal": 2,
        "pinhole": 2,
        "diam": 1,
        "eter": 1,
        "airy": 1,
        "unit": 1,
        "red": 1,
        "fluorosphere": 1,
        "zstage": 1,
        "scanning": 1,
        "fluorescent": 1,
        "addition": 5,
        "elimination": 1,
        "outoffocus": 1,
        "light": 2,
        "close": 1,
        "approximation": 2,
        "left": 2,
        "text": 2,
        "response": 3,
        "corresponds": 2,
        "imagederived": 6,
        "dark": 3,
        "gray": 2,
        "line": 2,
        "simi": 1,
        "rapidly": 3,
        "roughly": 2,
        "confidence": 1,
        "translatable": 1,
        "notice": 1,
        "increase": 6,
        "sensitivity": 2,
        "usingthe": 1,
        "sam": 1,
        "ples": 1,
        "gener": 1,
        "ation": 1,
        "curate": 1,
        "representation": 1,
        "return": 1,
        "coefficient": 1,
        "rvalues": 1,
        "fitted": 1,
        "good": 1,
        "bar": 2,
        "displayed": 3,
        "explain": 1,
        "section": 4,
        "iie": 1,
        "posi": 1,
        "lated": 1,
        "1st": 2,
        "2nd": 3,
        "theoretical": 1,
        "de": 1,
        "scribed": 1,
        "iid": 1,
        "43m": 2,
        "/5": 1,
        "tween": 1,
        "66m": 1,
        "/3": 2,
        "lowprecision": 1,
        "ddev=": 1,
        "calculated": 3,
        "7867m": 1,
        "35m": 2,
        "always": 1,
        "regardless": 1,
        "stan": 1,
        "dard": 1,
        "37m": 1,
        "/35": 1,
        "significantly": 4,
        "ddevwas": 3,
        "4m": 2,
        "/75": 1,
        "dsdto": 1,
        "9147m": 1,
        "/25": 3,
        "56m": 2,
        "/7": 1,
        "sdto": 1,
        "10342m": 1,
        "/2": 2,
        "val": 1,
        "ues": 1,
        "reduced": 1,
        "common": 2,
        "worth": 1,
        "analogue": 1,
        "instance": 1,
        "far": 5,
        "end": 3,
        "slope": 3,
        "48m": 1,
        "dsdwas": 4,
        "272m": 1,
        "1m": 1,
        "sdwas": 7,
        "691m": 1,
        "long": 1,
        "sa": 3,
        "sl": 1,
        "wa": 1,
        "25m": 1,
        "067m": 1,
        "126m": 1,
        "five": 2,
        "ceive": 1,
        "inclusion": 1,
        "slightly": 2,
        "compromise": 1,
        "accu": 1,
        "racy": 1,
        "consistent": 1,
        "subranges": 1,
        "entire": 2,
        "experimentally": 2,
        "moving": 1,
        "=40": 1,
        "rep": 1,
        "resent": 1,
        "z=3837": 1,
        "study": 5,
        "outperform": 1,
        "ddevequal": 2,
        "67m": 3,
        "r/3": 1,
        "higher": 1,
        "91m": 1,
        "31m": 2,
        "pass": 1,
        "86m": 1,
        "21m": 2,
        "r/21": 1,
        "dsdfor": 1,
        "11m": 1,
        "r/13": 1,
        "ddevvalues": 2,
        "to1848": 1,
        "2515m": 1,
        "/85": 1,
        "09m": 1,
        "/6": 1,
        "ulation": 1,
        "22m": 1,
        "207m": 1,
        "06m": 1,
        "293m": 1,
        "confirming": 1,
        "benefits": 2,
        "examine": 2,
        "52m": 1,
        "090m": 1,
        "753m": 1,
        "266m": 1,
        "iv": 1,
        "iscussion": 1,
        "ply": 1,
        "ardiamantis": 1,
        "ray": 1,
        "exploit": 1,
        "diffractionlimited": 1,
        "di": 1,
        "mension": 1,
        "previously": 1,
        "absence": 1,
        "purely": 1,
        "influence": 1,
        "ultrasonics": 1,
        "200m": 1,
        "sonics": 1,
        "nanometre": 1,
        "10m": 1,
        "po": 2,
        "sition": 2,
        "ex": 1,
        "periment": 1,
        "utilize": 1,
        "reliable": 1,
        "iiia": 1,
        "overall": 2,
        "formance": 1,
        "1021m": 1,
        "experimen": 1,
        "tal": 1,
        "assume": 1,
        "ddevnear": 1,
        "draw": 1,
        "dasderived": 1,
        "indirect": 1,
        "parison": 1,
        "simula": 1,
        "8193m": 1,
        "34fold": 1,
        "im": 2,
        "provements": 1,
        "ments": 1,
        "15m": 1,
        "114fold": 1,
        "uniformly": 1,
        "subregions": 1,
        "away": 2,
        "least": 1,
        "thescurve": 1,
        "slop": 1,
        "conclusive": 1,
        "need": 8,
        "identify": 2,
        "whether": 1,
        "consistently": 1,
        "ability": 2,
        "alter": 1,
        "potentially": 2,
        "usage": 1,
        "correction": 1,
        "obvious": 1,
        "accomplish": 1,
        "mass": 1,
        "spatially": 2,
        "bubble": 2,
        "fitting": 1,
        "dimensional": 1,
        "gaussians": 1,
        "approximate": 1,
        "inaccurate": 1,
        "determination": 1,
        "limiting": 1,
        "postprocessing": 1,
        "stem": 1,
        "advantage": 3,
        "noiseless": 1,
        "metaimage": 1,
        "optimization": 1,
        "furthermore": 1,
        "consider": 1,
        "much": 1,
        "depends": 1,
        "polydispersed": 1,
        "normalization": 1,
        "compensates": 1,
        "echo": 2,
        "typical": 1,
        "rather": 1,
        "demodulated": 1,
        "clutter": 1,
        "reject": 1,
        "phase": 1,
        "tend": 1,
        "clearly": 1,
        "identifiable": 1,
        "available": 1,
        "impact": 3,
        "inves": 1,
        "tigated": 1,
        "explore": 3,
        "another": 2,
        "important": 2,
        "aspect": 1,
        "variability": 1,
        "occur": 1,
        "impose": 2,
        "near": 1,
        "complexity": 1,
        "relation": 1,
        "counter": 1,
        "balance": 2,
        "decrease": 1,
        "pressure": 2,
        "age": 1,
        "note": 1,
        "den": 2,
        "sity": 2,
        "contrast1850": 1,
        "relationship": 1,
        "marker": 1,
        "fourth": 1,
        "must": 1,
        "outline": 1,
        "iia": 1,
        "environment": 1,
        "rough": 1,
        "selection": 4,
        "thresholding": 1,
        "criterion": 1,
        "morphology": 1,
        "discard": 1,
        "violate": 1,
        "contribution": 1,
        "neighbor": 1,
        "rejection": 1,
        "reach": 1,
        "localize": 2,
        "throughout": 1,
        "en": 1,
        "tire": 1,
        "efficient": 1,
        "closely": 1,
        "assumption": 1,
        "acqui": 1,
        "valid": 1,
        "useful": 1,
        "figures": 1,
        "a1": 1,
        "divide": 1,
        "thousand": 1,
        "would": 1,
        "practi": 1,
        "cally": 1,
        "infusion": 1,
        "moreover": 1,
        "transmis": 1,
        "choose": 1,
        "approx": 1,
        "imation": 1,
        "facilitate": 1,
        "subject": 1,
        "parti": 1,
        "cle": 1,
        "maintain": 1,
        "ducing": 1,
        "focused": 1,
        "considering": 1,
        "play": 1,
        "role": 1,
        "shaping": 1,
        "3receive": 1,
        "separation": 1,
        "clear": 1,
        "extend": 1,
        "foci": 1,
        "space": 1,
        "ther": 1,
        "tune": 1,
        "ultimately": 1,
        "prob": 1,
        "lem": 1,
        "theory": 1,
        "unlimited": 2,
        "major": 1,
        "implementation": 1,
        "hardware": 1,
        "challenge": 1,
        "tissuelike": 1,
        "medium": 1,
        "indeed": 1,
        "reflections": 1,
        "human": 1,
        "body": 1,
        "flickering": 1,
        "star": 1,
        "refraction": 1,
        "atmosphere": 1,
        "problem": 1,
        "resolve": 1,
        "systematically": 1,
        "operator": 1,
        "qualitatively": 1,
        "prove": 1,
        "key": 1,
        "understanding": 1,
        "onclusion": 1,
        "defocusing": 1,
        "sitions": 1,
        "tified": 1,
        "become": 1,
        "infocused": 1,
        "together": 1,
        "highprecision": 1,
        "tar": 1,
        "get": 1,
        "conven": 1,
        "tional": 1,
        "of11": 1,
        "wellsuited": 1,
        "complement": 1,
        "imagebased": 1,
        "microbub": 1,
        "ble": 1,
        "exclusively": 1
    },
    "objective": [
        "8 , august 2018 super-resolution axial localization of ultrasound scatter using multi-focal imaging konstantinos diamantis , alan h. greenaway , tom anderson , jørgen arendt jensen , fellow , ieee , paul a. dalgarno , and vassilis sboros abstract —objective : this paper aim to develop a method for achieve micrometre axial scatterer local- ization for medical ultrasound , surpass the inherent , pulse length dependence limit ultrasound imaging .",
        "m ethods a general overview of the propose method which be use for axial localization of isolated ultrasound point scatterers be depict in fig .",
        "description of the propose sharpness-based axial localization method .",
        "the propose method exploit the effect of defocus on the diffraction-limited lateral resolution to achieve high precision localization in the axial di- mension , and be base on a previously present method for super-resolution optical microscopy [ 43 ] , [ 44 ] .",
        "this be an indirect com- parison since the propose method do not result in a psf .",
        "in general , the ability of the propose method to control the sharpness value by alter the time delay could potentially allow its usage for optimum focusing deﬁnition or aberration correction application in ultrasound imaging [ 45 ] ."
    ],
    "references": [
        "",
        "REFERENCES [1] P . Hoskins et al. ,Diagnostic Ultrasound: Physics and Equipment , 2nd ed. Cambridge, U.K.: Cambridge Univ. Press, 2010. [2] M. L. Oelze and W. D. O. Jr, “Deﬁning optimal axial and lateral reso- lution for estimating scatterer properties from volumes using ultrasound backscatter,” J. Acoust. Soc. Amer . , vol. 115, no. 6, pp. 3226–3234, 2004. [3] J. A. Jensen, “Deconvolution of ultrasound images,” Ultrason. Imag. , vol. 14, no. 1, pp. 1–15, 1992. [4] T. Szabo, Diagnostic Ultrasound Imaging: Inside Out , 2nd ed. New Y ork, NY , USA: Elsevier, 2013.DIAMANTIS et al. : SUPER-RESOLUTION AXIAL LOCALIZATION OF ULTRASOUND SCATTER USING MULTI-FOCAL IMAGING 1851 [ 5 ] D .A .K n a p i k et al. , “A 100–200 MHz ultrasound biomicroscope,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 47, no. 6, pp. 1540–1549, Nov. 2000. [6] F. S. Foster et al. , “Advances in ultrasound biomicroscopy,” Ultrasound Med. Biol. , vol. 26, no. 1, pp. 1–27, Jan. 2000. [7] C. Errico et al. , “Ultrafast ultrasound localization microscopy for deep super-resolution vascular imaging,” Nature Lett. , vol. 527, no. 7579, pp. 499–502, 2015. [8] S. Haykin et al. ,Array Signal Processing . Englewood Cliffs, NJ, USA: Prentice-Hall, 1985. [9] A. Quinquis et al. , “Some radar imagery results using superresolution techniques,” IEEE Trans. Antennas Propag. , vol. 52, no. 5, pp. 1–15, May 2004. [10] I. J. Clarke et al. , “Resolution limits of a two dimensional antenna array,” Proc. SPIE Real-Time Signal Process. VIII , vol. 0564, pp. 0564-0564-8, Jan. 1986, doi: 10.1117/12.949698. [11] I. J. Clarke and G. Spence, “A space-time estimator for the detection and estimation of multiple sinusoidal signals,” in Proc. IEE Colloq. High Resolution Radar Sonar , 1999, pp. 9/1–9/6. [12] K. G. Puschmann and F. Kneer, “On super-resolution in astronomical imaging,” Astron. Astrophys. , vol. 436, no. 1, pp. 373–378, 2005. [13] S. T. Hess et al. , “Ultra-high resolution imaging by ﬂuorescence photoac- tivation localization microscopy,” Biophys. J. , vol. 91, no. 11, pp. 4258– 4272, 2006. [14] S. Djidel et al. , “High-speed, 3-dimensional, telecentric imaging,” Opt. Express , vol. 14, no. 18, pp. 8269–8277, 2006. [15] M. Bates et al. , “Multicolor super-resolution imaging with photo- switchable ﬂuorescent probes,” Science , vol. 317, no. 5845, pp. 1749– 1753, 2007. [16] V . Sboros et al. , “The behaviour of individual contrast agent microbub- bles,” Ultrasound Med. Biol. , vol. 29, no. 5, pp. 687–694, 2003. [17] R. J. Eckersley et al. , “Microbubble contrast agent detection using binary coded pulses,” Ultrasound Med. Biol. , vol. 33, no. 11, pp. 1787–1795, 2007. [18] M. A. O’Reilly and K. Hynynen, “A super-resolution ultrasound method for brain vascular mapping,” Med. Phys. , vol. 40, no. 11, 2013, Art. no. 110701. [19] M. A. O’Reilly et al. , “Three-dimensional transcranial ultrasound imaging of microbubble clouds using a sparse hemispherical array,” IEEE Trans. Biomed. Eng. , vol. 61, no. 4, pp. 1285–1294, Apr. 2014. [20] K. Christensen-Jeffries et al. ,“In vivo acoustic super-resolution and super- resolved velocity mapping using microbubbles,” IEEE Trans. Med. Imag. , vol. 34, no. 2, pp. 433–440, Feb. 2015. [21] O. Couture et al. , “Microbubble ultrasound super-localization imaging (MUSLI),” in Proc. IEEE Ultrason. Symp. , 2011, pp. 1285–1287. [22] M. Tanter and M. Fink, “Ultrafast imaging in biomedical ultrasound,” IEEE Trans. Ultrason., Ferroelect., Freq. Control. , vol. 61, no. 1, pp. 102– 119, Jan. 2014. [23] Y . Desailly et al. , “Sono-activated ultrasound localization microscopy,” Appl. Phys. Lett. , vol. 103, no. 17, 2013, Art. no. 174107. [24] Y . Desailly et al. , “Resolution limits of ultrafast ultrasound localization microscopy,” Phys. Med. Biol. , vol. 60, no. 22, pp. 8723–8740, 2015. [25] D. Ackermann and G. Schmitz, “Detection and tracking of multiple mi- crobubbles in ultrasound b-mode images,” IEEE Trans. Ultrason., Ferro- elect., Freq. Control , vol. 63, no. 1, pp. 72–82, Jan. 2016. [26] M. Fink, “Time reversal of ultrasonic ﬁelds-part I: Basic principles,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 39, no. 5, pp. 555–566, Sep. 1992. [27] O. Couture et al. , “Time-reversal focusing of therapeutic ultrasound on targeted microbubbles,” Appl. Phys. Lett. , vol. 94, 2009, Art. no. 173901. [28] M. Pernot et al. , “Ultrasonic stars for time-reversal focusing using induced cavitation bubbles,” Appl. Phys. Lett. , vol. 88, 2006, Art. no. 034102. [29] K. Diamantis et al. , “A comparison between temporal and subband mini- mum variance adaptive beamforming,” Proc. SPIE Med. Imag. , vol. 9040, Mar. 2014, Art. no. 90400L, doi: 10.1117/12.2043602. [30] K. Diamantis et al. , “Experimental performance assessment of the sub- band minimum variance beamformer for ultrasound imaging,” Ultrason- ics, vol. 79, pp. 87–95, 2017. [31] S. Cho et al. , “Phantom and in vivo evaluation of sound speed estimation methods: Preliminary results,” in Proc. IEEE Ultrason. Symp. , Sep. 2014, pp. 1678–1681. [32] H. Taki et al. , “High range resolution ultrasonographic vascular imaging using frequency domain interferometry with the Capon method,” IEEE Trans. Med. Imag. , vol. 31, no. 2, pp. 417–429, Feb. 2012.[33] J. P . Asen et al. , “Implementing Capon beamforming on a GPU for real- time cardiac ultrasound imaging,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 61, no. 1, pp. 76–85, Jan. 2014. [34] X. Qu et al. , “Nanometer-localized multiple single-molecule ﬂuorescence microscopy,” Proc. Nat. Acad. Sci. USA , vol. 101, no. 31, pp. 11298– 11303, 2004. [35] A. L. McEvoy et al. , “Q&A: Single-molecule localization microscopy for biological imaging,” BMC Biol. , vol. 8, no. 106, pp. 1–9, 2010. [36] Y . Sun et al. , “Parallax: High accuracy three-dimensional single molecule tracking using split images,” Nano Lett. , vol. 9, no. 7, pp. 2676–2682, 2009. [37] M. Speidel et al. , “Three-dimensional tracking of ﬂuorescent nanoparticles with subnanometer precision by use of off-focus imaging,” Opt. Lett. , vol. 28, no. 2, pp. 69–71, 2003. [38] G. A. Lessard et al. , “Three-dimensional tracking of individual quantum dots,” Appl. Phys. Lett. , vol. 91, no. 22, 2007, Art. no. 224106. [39] R. A. Muller and A. Bufﬁngton, “Real-time correction of atmospheri- cally degraded telescope images through image sharpnening,” J. Opt. Soc. Amer . , vol. 64, no. 9, pp. 1200–1210, Sep. 1974. [40] M. Subbarao and J.-K. Tyan, “Selecting the optimal focus measure for autofocusing and depth-from-focus,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 20, no. 8, pp. 864–870, Aug. 1998. [41] N. K. Chern et al. , “Practical issues in pixel-based auto focusing for machine vision,” in Proc. IEEE Robot. Autom. , May 2001, pp. 2791– 2796. [42] P . M. Blanchard and A. H. Greenaway, “Simultaneous multiplane imaging with a distorted diffraction grating,” Appl. Opt. , vol. 38, no. 32, pp. 6692– 6699, 1999. [43] P . A. Dalgarno et al. , “Multiplane imaging and three dimensional nanoscale particle tracking in biological microscopy,” Opt. Express , vol. 18, no. 2, pp. 877–884, 2010. [44] H. I. C. Dalgarno et al. , “Nanometric depth resolution from multi-focal images in microscopy,” J. Roy. Soc. Interface , vol. 8, no. 60, pp. 942–951, Jul. 2011. [45] L. Nock et al. , “Phase aberration correction in medical ultrasound using speckle brightness as a quality factor,” J. Acoust. Soc. Amer . , vol. 85, no. 5, pp. 1819–1833, 1989. [46] K. E. Thomenius, “Evolution of ultrasound beamformers,” in Proc. IEEE Ultrason. Symp. , Nov. 1996, vol. 2, pp. 1615–1622. [47] J. A. Jensen and N. B. Svendsen, “Calculation of pressure ﬁelds from arbitrarily shaped, apodized, and excited ultrasound transducers,” IEEE Trans. Ultrason., Ferroelectr ., Freq. Control , vol. 39, no. 2, pp. 262–267, Mar. 1992. [48] J. A. Jensen, “Field: A program for simulating ultrasound systems,” Med. Biol. Eng. Comput. , vol. 34, Suppl. 1, Pt. 1, pp. 351–353, 1996. [49] W. Marczak, “Water as a standard in the measurements of speed of sound in liquids,” J. Acoust. Soc. Amer . , vol. 102, no. 5, pp. 2776–2779, 1997. [50] J. A. Jensen et al. , “Sarus: A synthetic aperture real-time ultrasound sys- tem,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 60, no. 9, pp. 1838–1852, Sep. 2013. [51] J. M. Hansen et al. , “An object-oriented multi-threaded software beam formation toolbox,” Proc. SPIE Med. Imag. , vol. 7968, Mar. 2011, Art. no. 79680Y , doi: 10.1117/12.878178. [52] J. B. Pawley, Handbook of Biological Confocal Microscopy , 3rd ed. Berlin, Germany: Springer, 2006. [53] J. F. Synnev ˚aget al. , “Adaptive beamforming applied to medical ultra- sound imaging,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 54, no. 8, pp. 1606–1613, Aug. 2007. [54] I. K. Holfort et al. , “Broadband minimum variance beamforming for ultra- sound imaging,” IEEE Trans. Ultrason., Ferroelect., Freq. Control , vol. 56, no. 2, pp. 314–325, Feb. 2009. [55] O. M. Viessmann et al. , “Acoustic super-resolution with ultrasound and microbubbles,” Phys. Med. Biol. , vol. 58, no. 18, pp. 6447–6458, 2013. [56] M. A. O’Reilly et al. , “Investigating a method for non-invasive ultrasound aberration correction through the skull bone,” Proc. SPIE Med. Imag. , vol. 9040, Mar. 2014, Art. no. 904013, doi: 10.1117/12.2043832. [57] P . K ˇr´ıˇzek et al. , “Minimizing detection errors in single molecule lo- calization microscopy,” Opt. Express , vol. 19, no. 4, pp. 3226–3235, 2011. [58] C. A. Primmerman et al. , “Atmospheric-compensation experiments in strong-scintillation conditions,” Appl. Opt. , vol. 34, no. 12, pp. 2081– 2088, 1995."
    ]
}